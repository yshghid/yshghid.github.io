<!doctype html><html lang=en-us dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="
  #2 Explainable AI
  #

#2025-06-26


  1. Explainable AI란?
  #

Explainable AI는 인공지능(AI) 또는 머신러닝(ML) 모델이 어떤 방식으로 특정 결과를 도출했는지 사람이 이해할 수 있도록 설명하는 기술과 방법론.

  2. XAI 기법 분류
  #

모델 구조

Intrinsic:	모델 자체가 설명 가능한 구조 (예: 의사결정나무, 선형회귀 등)
Post-hoc:	모델 학습 후 별도로 설명 생성 (예: SHAP, LIME)
대상
Global:	전체 모델의 작동 원리를 설명
Local:	특정 샘플의 예측 결과를 설명


  3. 주요 Post-hoc 설명 기법
  #

LIME (Local Interpretable Model-Agnostic Explanations): 주변 입력을 랜덤하게 생성하고, 단순 모델(선형 회귀 등)을 학습해 근사"><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="https://yshghid.github.io/docs/study/etc/etc2/"><meta property="og:site_name" content=" "><meta property="og:title" content="#2 Explainable AI"><meta property="og:description" content="#2 Explainable AI # #2025-06-26
1. Explainable AI란? # Explainable AI는 인공지능(AI) 또는 머신러닝(ML) 모델이 어떤 방식으로 특정 결과를 도출했는지 사람이 이해할 수 있도록 설명하는 기술과 방법론.
2. XAI 기법 분류 # 모델 구조
Intrinsic:	모델 자체가 설명 가능한 구조 (예: 의사결정나무, 선형회귀 등) Post-hoc:	모델 학습 후 별도로 설명 생성 (예: SHAP, LIME) 대상 Global:	전체 모델의 작동 원리를 설명 Local:	특정 샘플의 예측 결과를 설명 3. 주요 Post-hoc 설명 기법 # LIME (Local Interpretable Model-Agnostic Explanations): 주변 입력을 랜덤하게 생성하고, 단순 모델(선형 회귀 등)을 학습해 근사"><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="docs"><meta property="article:published_time" content="2025-06-26T00:00:00+00:00"><meta property="article:modified_time" content="2025-06-26T00:00:00+00:00"><meta property="article:tag" content="2025-06"><title>#2 Explainable AI |</title><link rel=icon href=/favicon.png><link rel=manifest href=/manifest.json><link rel=canonical href=https://yshghid.github.io/docs/study/etc/etc2/><link rel=stylesheet href=/book.min.6217d077edb4189fd0578345e84bca1a884dfdee121ff8dc9a0f55cfe0852bc9.css integrity="sha256-YhfQd+20GJ/QV4NF6EvKGohN/e4SH/jcmg9Vz+CFK8k=" crossorigin=anonymous><script defer src=/fuse.min.js></script><script defer src=/en.search.min.2a7aa936a18295cf56d89ec2f18a4dc8c6228b483b5c22b584c1588aded86d07.js integrity="sha256-KnqpNqGClc9W2J7C8YpNyMYii0g7XCK1hMFYit7YbQc=" crossorigin=anonymous></script></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><img src=/logo.png alt=Logo class=book-icon><span></span></a></h2><div class="book-search hidden"><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><script>document.querySelector(".book-search").classList.remove("hidden")</script><ul><li class=book-section-flat><span>기록</span><ul><li><a href=/docs/hobby/book/>글</a><ul></ul></li><li><a href=/docs/hobby/daily/>일상</a><ul></ul></li><li><a href=/docs/hobby/baking/>베이킹</a><ul></ul></li><li><a href=/docs/hobby/favorite/>🌸</a><ul></ul></li></ul></li><li class=book-section-flat><span>공부</span><ul><li><a href=/docs/study/bioinformatics/>생물정보학</a><ul></ul></li><li><a href=/docs/study/algorithm/>코테</a><ul></ul></li><li><a href=/docs/study/career/>취업</a><ul></ul></li><li><a href=/docs/study/etc/>기타</a><ul></ul></li></ul></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu></label><h3>#2 Explainable AI</h3><label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><ul><li><a href=#1-explainable-ai란>1. Explainable AI란?</a></li><li><a href=#2-xai-기법-분류>2. XAI 기법 분류</a></li><li><a href=#3-주요-post-hoc-설명-기법>3. 주요 Post-hoc 설명 기법</a></li><li><a href=#4-shap이란>4. SHAP이란?</a></li><li><a href=#5-rf의-feature-importance와의-차이>5. RF의 feature importance와의 차이?</a></li><li><a href=#6-결론>6. 결론</a></li><li><a href=#7-예시-코드>7. 예시 코드</a></li></ul></li></ul></nav></aside></header><article class="markdown book-article"><h1 id=2-explainable-ai>#2 Explainable AI
<a class=anchor href=#2-explainable-ai>#</a></h1><p>#2025-06-26</p><hr><h3 id=1-explainable-ai란>1. Explainable AI란?
<a class=anchor href=#1-explainable-ai%eb%9e%80>#</a></h3><p>Explainable AI는 인공지능(AI) 또는 머신러닝(ML) 모델이 어떤 방식으로 특정 결과를 도출했는지 사람이 이해할 수 있도록 설명하는 기술과 방법론.</p><h3 id=2-xai-기법-분류>2. XAI 기법 분류
<a class=anchor href=#2-xai-%ea%b8%b0%eb%b2%95-%eb%b6%84%eb%a5%98>#</a></h3><p>모델 구조</p><ul><li>Intrinsic: 모델 자체가 설명 가능한 구조 (예: 의사결정나무, 선형회귀 등)</li><li>Post-hoc: 모델 학습 후 별도로 설명 생성 (예: SHAP, LIME)
대상</li><li>Global: 전체 모델의 작동 원리를 설명</li><li>Local: 특정 샘플의 예측 결과를 설명</li></ul><h3 id=3-주요-post-hoc-설명-기법>3. 주요 Post-hoc 설명 기법
<a class=anchor href=#3-%ec%a3%bc%ec%9a%94-post-hoc-%ec%84%a4%eb%aa%85-%ea%b8%b0%eb%b2%95>#</a></h3><p>LIME (Local Interpretable Model-Agnostic Explanations): 주변 입력을 랜덤하게 생성하고, 단순 모델(선형 회귀 등)을 학습해 근사</p><p>SHAP (SHapley Additive exPlanations): 게임 이론의 샤플리 값 기반</p><ul><li>각 피처가 기여한 정도를 공정하게 분배하여 설명<ul><li>장점: 수학적으로 정당성 확보, 일관된 설명 제공</li><li>단점: 계산 비용 큼</li></ul></li></ul><p>Permutation Importance: 입력 피처를 무작위로 섞은 후 예측 성능 감소 정도 측정</p><ul><li>예측 성능이 크게 감소하면, 중요한 피처로 판단</li></ul><p>Saliency Maps (이미지 분야)</p><h3 id=4-shap이란>4. SHAP이란?
<a class=anchor href=#4-shap%ec%9d%b4%eb%9e%80>#</a></h3><p>각 feature(입력 변수)가 모델의 예측값에 얼마나 기여했는지 정량적으로 계산.</p><p>원래는 협력 게임 이론에서</p><ul><li>여러 플레이어가 팀을 이뤄 보상을 받았을 때, 각 플레이어가 전체 보상에 얼마나 기여했는지를 계산하는 방법인데</li><li>예시로<ul><li>축구 게임을 하여 팀 전체가 100점을 획득했다고 가정</li><li>팀에는 선수 A, B, C가 있다<ul><li>누가 더 중요한 선수인지, 각 선수가 점수에 얼마나 기여했는지를 구하려면?</li><li>샤플리 값은 다음 순서로 기여도를 평가:<ol><li>가능한 모든 순열을 고려</li><li>각 순열에서 A, B, C가 언제 팀에 합류했는지</li><li>그 선수가 팀에 들어오면서 얼마나 점수가 늘었는지 확인 -> 각 선수의 이 평균 기여도를 “샤플리 값”이라고 함.</li></ol></li></ul></li></ul></li></ul><p>머신러닝 모델에서:</p><ul><li>각 feature가 플레이어 역할을 함<ul><li>모델의 예측값이 팀이 얻은 점수이고<ul><li>SHAP은 &ldquo;이 예측값이 나오는 데, 각 feature가 얼마나 기여했는가?&ldquo;를 계산.</li><li>예를 들어 모델이 어떤 환자의 사망 확률을 80%라고 예측했을 때<ul><li>나이: +15%</li><li>흡연 여부: +10%</li><li>혈압: +5%</li><li>기본값: 50%<ul><li>총합: 50% + 15 + 10 + 5 = 80%</li></ul></li></ul></li></ul></li></ul></li><li>즉 SHAP은 예측값을 base value + 각 feature의 기여도로 분해해준다.</li></ul><p>수학적 계산 과정:</p><ul><li>3개의 feature (A, B, C)에서 가능한 feature 조합:<ul><li>{}, {A}, {B}, {C}, {A,B}, {A,C}, {B,C}, {A,B,C}</li><li>SHAP은 모든 조합에 대해,<ul><li>해당 feature가 들어갔을 때와 안 들어갔을 때 예측값 차이를 계산<ul><li>이를 평균하여 기여도(샤플리 값)로 설정한다.<ul><li>단점: 조합 수가 2^M이라서 feature 수가 많으면 계산량 폭발</li></ul></li></ul></li></ul></li></ul></li></ul><h3 id=5-rf의-feature-importance와의-차이>5. RF의 feature importance와의 차이?
<a class=anchor href=#5-rf%ec%9d%98-feature-importance%ec%99%80%ec%9d%98-%ec%b0%a8%ec%9d%b4>#</a></h3><table><thead><tr><th>항목</th><th>Random Forest Feature Importance</th><th>SHAP</th></tr></thead><tbody><tr><td>기반 개념</td><td>모델 구조 기반 (gini 감소 등)</td><td>게임 이론 기반 (샤플리 값)</td></tr><tr><td>설명 방식</td><td>전체 모델 수준 (global)</td><td>전체 + 개별 샘플 수준 (global + local)</td></tr><tr><td>음/양 구분</td><td>없음 (0 이상, 크기만 제공)</td><td>있음 (양수: 예측 ↑, 음수: 예측 ↓)</td></tr><tr><td>상호작용 고려</td><td>부분적으로만 고려</td><td>일부 고려 가능 (특정 SHAP variant)</td></tr><tr><td>정확성</td><td>대략적인 영향도</td><td>수학적으로 보장된 기여도</td></tr><tr><td>단점</td><td>bias 있음 (범주 수 많은 변수 선호 등)</td><td>느릴 수 있음, 계산 비용 높음</td></tr></tbody></table><p>Random Forest의 Feature Importance</p><ul><li>작동 방식</li><li>RF는 다수의 결정트리를 만들고<ul><li>각 트리에서 어떤 feature를 쪼갤 때 예측 성능이 얼마나 좋아졌는지(ex: Gini impurity 감소량)를 기록.</li><li>여러 트리에서 해당 feature가 얼마나 자주, 얼마나 크게 성능 향상에 기여했는지를 평균하여 importance로 계산</li></ul></li><li>단점<ul><li>범주 수가 많은 feature가 유리 (더 잘 쪼갤 확률 높음)</li><li>상호작용 고려 부족</li><li>왜 중요했는지 설명 불가</li><li>개별 샘플 설명 불가</li></ul></li></ul><p>SHAP의 Feature Importance</p><ul><li>SHAP은 다음을 제공:<ul><li>각 feature가 개별 예측값에 얼마나 영향을 줬는지. 양/음 포함.</li><li>모든 샘플에 대해 계산한 후 평균을 내면, global feature importance가 됨.</li><li>왜 중요했는지 샘플별로 추적 가능</li></ul></li></ul><p>먼소린지 이해 안돼서.. 직관적 예시.</p><ul><li>Random Forest의 Feature Importance는 누가 결정 과정에 자주 참여했는지 본다, 마치 회의에서 많이 말한 사람을 중요한 사람이라고 보는 것과 같음.</li><li>SHAP의 Feature Importance는 누가 실제로 의사결정 결과에 영향을 줬는지 본다, 마치 회의에서 실제로 투표를 바꿔놓은 사람을 중요한 사람으로 보는 것과 같음.
즉 RF는 참여 횟수, SHAP은 결과에 기여한 정도를 보는 거예요.</li></ul><p>모델 예시</p><ul><li>모델이 환자의 사망 확률을 예측할때<ul><li>환자 입력: 나이 80세 / 체온 39도 / 혈압 100 / 흡연 여부 Yes</li></ul></li><li>Random Forest는?<ul><li>100개의 트리에서 나이로 70번 쪼갬 / 체온으로 10번 쪼갬 / 혈압으로 15번 쪼갬 / 흡연 여부로 5번 쪼갬<ul><li>그래서 나이가 제일 중요하다고 판단 (근데 ‘나이’가 예측값에 얼마나 영향을 줬는지는 모름)</li></ul></li></ul></li><li>SHAP은?<ul><li>이 환자의 예측값은 0.80 (기본값은 0.50)</li><li>기여도: 나이 +0.20 / 체온: +0.10 / 흡연: +0.08 / 혈압: -0.08<ul><li>합치면: 0.50 + 0.20 + 0.10 + 0.08 - 0.08 = 0.80</li><li>즉 SHAP은 예측값이 왜 0.80이 되었는지 명확하게 설명.</li></ul></li></ul></li></ul><p>하나의 feature라도 값이 높을 때 어떤 경우엔 예측을 ↑ 어떤 경우엔 예측을 ↓ 시킬 수 있다 그리고 이 복잡한 관계를 시각적으로 한 번에 보여주는 것이 바로 SHAP의 summary plot.</p><p>&lsquo;체온&rsquo; feature로 예시.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-plain data-lang=plain><span style=display:flex><span>      체온  ───🔵🔵🔵🔴🔴🔴🔴🔴🔵🔵──▶
</span></span><span style=display:flex><span>          (SHAP 값: 음수~양수)
</span></span></code></pre></div><p>🔴: 체온이 높은 샘플들</p><ul><li>오른쪽(+)에 위치한 🔴: 체온이 높아서 예측값(사망 확률)이 증가</li><li>왼쪽(-)에 위치한 🔴: 체온이 높지만 예측값은 오히려 감소
🔵: 체온이 낮은 샘플들</li><li>오른쪽(+)에 위치한 🔵: 체온이 낮지만 예측값은 증가</li><li>왼쪽(-)에 위치한 🔵: 체온이 낮고 예측값도 낮음</li></ul><p>샘플마다 기여도와 방향이 다른 이유</p><ul><li>SHAP은 모든 feature를 &ldquo;다른 feature와 함께 썼을 때"의 영향력을 따진다.<ul><li>그래서 &ldquo;조건부 기여도"라고도 함.<ul><li>즉 체온이 높아도 젊은 환자라면 사망 확률이 낮을 수 있고 체온이 낮아도 기저질환이 심한 환자라면 사망 확률이 높을 수 있다</li><li>이런 복잡한 상호작용을 반영하다보니 같은 feature라도 샘플마다 기여 방향이 다를 수 있다.</li></ul></li></ul></li></ul><h3 id=6-결론>6. 결론
<a class=anchor href=#6-%ea%b2%b0%eb%a1%a0>#</a></h3><p>같은 feature라도, 샘플마다 다른 상황(context)이기 때문에, 그 feature의 예측에 대한 기여 방향(↑ 또는 ↓)이 달라질 수 있다.</p><p>예를 들어</p><ul><li>나이 = 70인 사람이라도<ul><li>다른 feature(혈압, 체온, 기저질환 등)에 따라<ul><li>어떤 샘플에선 사망 확률 ↑에 기여 (양의 SHAP 값)</li><li>어떤 샘플에선 사망 확률 ↓에 기여 (음의 SHAP 값)<ul><li>그래서 SHAP summary plot에서 같은 feature의 🔴와 🔵 점들이 좌우로 흩어져 있다.</li></ul></li></ul></li></ul></li></ul><p>정리하면?</p><ul><li>SHAP은 &ldquo;같은 feature"가 &ldquo;다양한 맥락에서 어떻게 작용하는가"를 보여주는 도구이다.</li></ul><h3 id=7-예시-코드>7. 예시 코드
<a class=anchor href=#7-%ec%98%88%ec%8b%9c-%ec%bd%94%eb%93%9c>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> pandas <span style=color:#66d9ef>as</span> pd
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> pickle
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> joblib
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> shap
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> matplotlib.pyplot <span style=color:#66d9ef>as</span> plt
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> seaborn <span style=color:#66d9ef>as</span> sns
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e>#Load rf model</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>with</span> open(<span style=color:#e6db74>&#39;/model/rf_model.pkl&#39;</span>,<span style=color:#e6db74>&#39;rb&#39;</span>) <span style=color:#66d9ef>as</span> f:
</span></span><span style=display:flex><span>    rf_model <span style=color:#f92672>=</span> joblib<span style=color:#f92672>.</span>load(f)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>#Load dataset</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>with</span> open(<span style=color:#e6db74>&#39;/preprocessing/processed_data.pickle&#39;</span>,<span style=color:#e6db74>&#39;rb&#39;</span>) <span style=color:#66d9ef>as</span> f:
</span></span><span style=display:flex><span>    preproc_data <span style=color:#f92672>=</span> pickle<span style=color:#f92672>.</span>load(f)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>cytokine_df <span style=color:#f92672>=</span> preproc_data[<span style=color:#e6db74>&#39;cytokine_data&#39;</span>]
</span></span><span style=display:flex><span>patient_meta <span style=color:#f92672>=</span> preproc_data[<span style=color:#e6db74>&#39;metadata&#39;</span>] 
</span></span><span style=display:flex><span>patient_info <span style=color:#f92672>=</span> preproc_data[<span style=color:#e6db74>&#39;clinical&#39;</span>] 
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># Get feature importances</span>
</span></span><span style=display:flex><span>importances <span style=color:#f92672>=</span> rf_model<span style=color:#f92672>.</span>feature_importances_
</span></span><span style=display:flex><span>feature_names <span style=color:#f92672>=</span> cytokine_df<span style=color:#f92672>.</span>columns
</span></span><span style=display:flex><span>feature_importances <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>DataFrame({<span style=color:#e6db74>&#39;feature&#39;</span>: feature_names, <span style=color:#e6db74>&#39;importance&#39;</span>: importances})
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Sort the feature importances in descending order and select the top 20</span>
</span></span><span style=display:flex><span>top_20_features <span style=color:#f92672>=</span> feature_importances<span style=color:#f92672>.</span>sort_values(by<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;importance&#39;</span>, ascending<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)<span style=color:#f92672>.</span>head(<span style=color:#ae81ff>20</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Plot the top 20 feature importances</span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>figure(figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>6</span>, <span style=color:#ae81ff>10</span>))
</span></span><span style=display:flex><span>sns<span style=color:#f92672>.</span>barplot(x<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;importance&#39;</span>, y<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;feature&#39;</span>, data<span style=color:#f92672>=</span>top_20_features)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>show()
</span></span></code></pre></div><p>RF 내부의 feature importance를 시각화</p><ul><li>어떤 사이토카인이 모델에서 자주 쓰였는지(중요한지)를 보여줌</li><li>이 값은 SHAP처럼 &ldquo;예측에 얼마나 기여했는가"를 나타내지 않고, 단순히 &ldquo;쪼개는 데 많이 쓰였는가&rdquo; 기준.</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>tree_explainer <span style=color:#f92672>=</span> shap<span style=color:#f92672>.</span>TreeExplainer(rf_model) <span style=color:#75715e>## TreeExplainer</span>
</span></span><span style=display:flex><span>shap_values <span style=color:#f92672>=</span> tree_explainer<span style=color:#f92672>.</span>shap_values(cytokine_df) <span style=color:#75715e>## SHAP Value</span>
</span></span></code></pre></div><p>이진 분류 모델(Random Forest, XGBoost 등)에 shap.TreeExplainer를 적용하면</p><ul><li>이 shap_values는 리스트 2개로 구성:<ul><li>shap_values[0]: 클래스 0 (음성 클래스)에 대한 SHAP 값</li><li>shap_values[1]: 클래스 1 (양성 클래스)에 대한 SHAP 값</li></ul></li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>fig <span style=color:#f92672>=</span> plt<span style=color:#f92672>.</span>figure(figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>8</span>,<span style=color:#ae81ff>8</span>))
</span></span><span style=display:flex><span>fig<span style=color:#f92672>.</span>set_facecolor(<span style=color:#e6db74>&#39;white&#39;</span>)
</span></span><span style=display:flex><span>ax <span style=color:#f92672>=</span> fig<span style=color:#f92672>.</span>add_subplot()
</span></span><span style=display:flex><span><span style=color:#75715e>#Plot SHAP as sever probability</span>
</span></span><span style=display:flex><span>shap<span style=color:#f92672>.</span>summary_plot(shap_values[<span style=color:#ae81ff>1</span>], cytokine_df, 
</span></span><span style=display:flex><span>                  cmap<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;bwr&#39;</span>, 
</span></span><span style=display:flex><span>                  show<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>, 
</span></span><span style=display:flex><span>                 plot_type<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;dot&#39;</span>)
</span></span><span style=display:flex><span>ax<span style=color:#f92672>.</span>set_xlabel(<span style=color:#e6db74>&#39;SHAP Value&#39;</span>)
</span></span><span style=display:flex><span>ax<span style=color:#f92672>.</span>set_title(<span style=color:#e6db74>&#39;SHAP Dot Plot&#39;</span>, fontsize<span style=color:#f92672>=</span><span style=color:#ae81ff>20</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>show()
</span></span></code></pre></div><p>shap_values[1]: 이진 분류에서 양성 클래스에 대한 SHAP 값</p><p>summary plot: 각 feature가 예측에 미친 영향(양/음, 세기)을 샘플별로 시각화 (빨강=값 큼, 파랑=값 작음)</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>shap_df <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>DataFrame(shap_values[<span style=color:#ae81ff>1</span>],columns <span style=color:#f92672>=</span> cytokine_df<span style=color:#f92672>.</span>columns)
</span></span><span style=display:flex><span>shap_df<span style=color:#f92672>.</span>index <span style=color:#f92672>=</span> cytokine_df<span style=color:#f92672>.</span>index
</span></span><span style=display:flex><span>shap_df
</span></span></code></pre></div><p><img src=https://github.com/user-attachments/assets/32d7410b-f67c-4f88-9587-e6b41e8c8276 alt=image></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> umap.umap_ <span style=color:#66d9ef>as</span> umap
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> pandas <span style=color:#66d9ef>as</span> pd
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> matplotlib.pyplot <span style=color:#66d9ef>as</span> plt
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> seaborn <span style=color:#66d9ef>as</span> sns
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>reducer <span style=color:#f92672>=</span> umap<span style=color:#f92672>.</span>UMAP()
</span></span><span style=display:flex><span>embedding <span style=color:#f92672>=</span> reducer<span style=color:#f92672>.</span>fit_transform(shap_df)
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> matplotlib.pyplot <span style=color:#66d9ef>as</span> plt
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Extract UMAP coordinates and labels</span>
</span></span><span style=display:flex><span>umap_x <span style=color:#f92672>=</span> embedding[:, <span style=color:#ae81ff>0</span>]
</span></span><span style=display:flex><span>umap_y <span style=color:#f92672>=</span> embedding[:, <span style=color:#ae81ff>1</span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Create scatter plot</span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>figure(figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>10</span>, <span style=color:#ae81ff>8</span>))
</span></span><span style=display:flex><span>scatter <span style=color:#f92672>=</span> plt<span style=color:#f92672>.</span>scatter(umap_x, umap_y, cmap<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;bwr&#34;</span>, s<span style=color:#f92672>=</span><span style=color:#ae81ff>50</span>, alpha<span style=color:#f92672>=</span><span style=color:#ae81ff>0.7</span>, edgecolors<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;w&#34;</span>, linewidth<span style=color:#f92672>=</span><span style=color:#ae81ff>0.5</span>)
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.cluster <span style=color:#f92672>import</span> DBSCAN
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Initialize DBSCAN</span>
</span></span><span style=display:flex><span>dbscan <span style=color:#f92672>=</span> DBSCAN(eps<span style=color:#f92672>=</span><span style=color:#ae81ff>0.8</span>, min_samples<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>) <span style=color:#75715e># partial data is too small to set min_sample=20.</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Fit to UMAP data and get cluster labels</span>
</span></span><span style=display:flex><span>clusters <span style=color:#f92672>=</span> dbscan<span style=color:#f92672>.</span>fit_predict(embedding)
</span></span><span style=display:flex><span>embedding, clusters
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>(array([[<span style=color:#ae81ff>16.714314</span> , <span style=color:#f92672>-</span><span style=color:#ae81ff>2.0475426</span>],
</span></span><span style=display:flex><span>        [<span style=color:#ae81ff>17.279623</span> , <span style=color:#f92672>-</span><span style=color:#ae81ff>2.4140635</span>],
</span></span><span style=display:flex><span>        [<span style=color:#ae81ff>16.705837</span> , <span style=color:#f92672>-</span><span style=color:#ae81ff>3.002305</span> ],
</span></span><span style=display:flex><span>        [<span style=color:#ae81ff>17.19955</span>  , <span style=color:#f92672>-</span><span style=color:#ae81ff>1.342096</span> ],
</span></span><span style=display:flex><span>        [<span style=color:#ae81ff>17.838465</span> , <span style=color:#f92672>-</span><span style=color:#ae81ff>2.021136</span> ],
</span></span><span style=display:flex><span>        [<span style=color:#ae81ff>18.537838</span> , <span style=color:#f92672>-</span><span style=color:#ae81ff>1.5079662</span>],
</span></span><span style=display:flex><span>        [<span style=color:#ae81ff>21.44188</span>  , <span style=color:#f92672>-</span><span style=color:#ae81ff>2.1259143</span>],
</span></span><span style=display:flex><span>        [<span style=color:#ae81ff>21.123413</span> , <span style=color:#f92672>-</span><span style=color:#ae81ff>3.075382</span> ],
</span></span><span style=display:flex><span>        [<span style=color:#ae81ff>20.373632</span> , <span style=color:#f92672>-</span><span style=color:#ae81ff>3.0233152</span>],
</span></span><span style=display:flex><span>        [<span style=color:#ae81ff>21.83852</span>  , <span style=color:#f92672>-</span><span style=color:#ae81ff>2.899527</span> ],
</span></span><span style=display:flex><span>        [<span style=color:#ae81ff>20.435349</span> , <span style=color:#f92672>-</span><span style=color:#ae81ff>2.2629123</span>]], dtype<span style=color:#f92672>=</span>float32),
</span></span><span style=display:flex><span> array([ <span style=color:#ae81ff>0</span>,  <span style=color:#ae81ff>0</span>, <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>, <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>,  <span style=color:#ae81ff>0</span>, <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>, <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>,  <span style=color:#ae81ff>1</span>,  <span style=color:#ae81ff>1</span>,  <span style=color:#ae81ff>1</span>,  <span style=color:#ae81ff>1</span>]))
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>plt<span style=color:#f92672>.</span>figure(figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>10</span>, <span style=color:#ae81ff>6</span>))
</span></span><span style=display:flex><span>unique_clusters <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>unique(clusters)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> cluster <span style=color:#f92672>in</span> unique_clusters:
</span></span><span style=display:flex><span>    idx <span style=color:#f92672>=</span> clusters <span style=color:#f92672>==</span> cluster
</span></span><span style=display:flex><span>    plt<span style=color:#f92672>.</span>scatter(embedding[idx, <span style=color:#ae81ff>0</span>], embedding[idx, <span style=color:#ae81ff>1</span>], label<span style=color:#f92672>=</span><span style=color:#e6db74>f</span><span style=color:#e6db74>&#39;Cluster </span><span style=color:#e6db74>{</span>cluster<span style=color:#e6db74>}</span><span style=color:#e6db74>&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>title(<span style=color:#e6db74>&#39;Scatter Plot of UMAP Colored by Cluster&#39;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>xlabel(<span style=color:#e6db74>&#39;UMAP_1&#39;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>ylabel(<span style=color:#e6db74>&#39;UMAP_2&#39;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>legend()
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>grid(<span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>show()
</span></span></code></pre></div></article><footer class=book-footer><div class="flex flex-wrap justify-between"></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments><script src=https://giscus.app/client.js data-repo=yshghid/yshghid.github.io data-repo-id=R_kgDONkMkNg data-category-id=DIC_kwDONkMkNs4CloJh data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=ko crossorigin=anonymous async></script></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><ul><li><a href=#1-explainable-ai란>1. Explainable AI란?</a></li><li><a href=#2-xai-기법-분류>2. XAI 기법 분류</a></li><li><a href=#3-주요-post-hoc-설명-기법>3. 주요 Post-hoc 설명 기법</a></li><li><a href=#4-shap이란>4. SHAP이란?</a></li><li><a href=#5-rf의-feature-importance와의-차이>5. RF의 feature importance와의 차이?</a></li><li><a href=#6-결론>6. 결론</a></li><li><a href=#7-예시-코드>7. 예시 코드</a></li></ul></li></ul></nav></div></aside></main></body></html>