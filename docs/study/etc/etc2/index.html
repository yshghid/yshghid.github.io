<!doctype html><html lang=en-us dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="
  #2 Explainable AI
  #

#2025-06-26


  1. Explainable AI란?
  #

Explainable AI는 인공지능(AI) 또는 머신러닝(ML) 모델이 어떤 방식으로 특정 결과를 도출했는지 사람이 이해할 수 있도록 설명하는 기술과 방법론.

  2. XAI 기법 분류
  #

모델 구조

Intrinsic:	모델 자체가 설명 가능한 구조 (예: 의사결정나무, 선형회귀 등)
Post-hoc:	모델 학습 후 별도로 설명 생성 (예: SHAP, LIME)
대상
Global:	전체 모델의 작동 원리를 설명
Local:	특정 샘플의 예측 결과를 설명


  3. 주요 Post-hoc 설명 기법
  #

LIME (Local Interpretable Model-Agnostic Explanations): 주변 입력을 랜덤하게 생성하고, 단순 모델(선형 회귀 등)을 학습해 근사"><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="https://yshghid.github.io/docs/study/etc/etc2/"><meta property="og:site_name" content="Lifelog 2025"><meta property="og:title" content="#2 Explainable AI"><meta property="og:description" content="#2 Explainable AI # #2025-06-26
1. Explainable AI란? # Explainable AI는 인공지능(AI) 또는 머신러닝(ML) 모델이 어떤 방식으로 특정 결과를 도출했는지 사람이 이해할 수 있도록 설명하는 기술과 방법론.
2. XAI 기법 분류 # 모델 구조
Intrinsic:	모델 자체가 설명 가능한 구조 (예: 의사결정나무, 선형회귀 등) Post-hoc:	모델 학습 후 별도로 설명 생성 (예: SHAP, LIME) 대상 Global:	전체 모델의 작동 원리를 설명 Local:	특정 샘플의 예측 결과를 설명 3. 주요 Post-hoc 설명 기법 # LIME (Local Interpretable Model-Agnostic Explanations): 주변 입력을 랜덤하게 생성하고, 단순 모델(선형 회귀 등)을 학습해 근사"><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="docs"><meta property="article:published_time" content="2025-06-26T00:00:00+00:00"><meta property="article:modified_time" content="2025-06-26T00:00:00+00:00"><meta property="article:tag" content="2025-06"><title>#2 Explainable AI | Lifelog 2025</title><link rel=icon href=/favicon.png><link rel=manifest href=/manifest.json><link rel=canonical href=https://yshghid.github.io/docs/study/etc/etc2/><link rel=stylesheet href=/book.min.6217d077edb4189fd0578345e84bca1a884dfdee121ff8dc9a0f55cfe0852bc9.css integrity="sha256-YhfQd+20GJ/QV4NF6EvKGohN/e4SH/jcmg9Vz+CFK8k=" crossorigin=anonymous><script defer src=/fuse.min.js></script><script defer src=/en.search.min.775045b04826deba13acfb469542a5f640728ed8a102f82c6518408024717ec2.js integrity="sha256-d1BFsEgm3roTrPtGlUKl9kByjtihAvgsZRhAgCRxfsI=" crossorigin=anonymous></script></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><img src=/logo.png alt=Logo class=book-icon><span>Lifelog 2025</span></a></h2><div class="book-search hidden"><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><script>document.querySelector(".book-search").classList.remove("hidden")</script><ul><li class=book-section-flat><span>기록</span><ul><li><a href=/docs/hobby/book/>글</a><ul></ul></li><li><a href=/docs/hobby/daily/>일상</a><ul></ul></li><li><a href=/docs/hobby/etc/>기타</a><ul></ul></li><li><a href=/docs/hobby/favorite/>🤍</a><ul></ul></li></ul></li><li class=book-section-flat><span>공부</span><ul><li><a href=/docs/study/tech/>연구실</a><ul></ul></li><li><a href=/docs/study/career/>취업</a><ul></ul></li><li><a href=/docs/study/etc/>기타</a><ul></ul></li></ul></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu></label><h3>#2 Explainable AI</h3><label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><ul><li><a href=#1-explainable-ai란>1. Explainable AI란?</a></li><li><a href=#2-xai-기법-분류>2. XAI 기법 분류</a></li><li><a href=#3-주요-post-hoc-설명-기법>3. 주요 Post-hoc 설명 기법</a></li><li><a href=#4-shap이란>4. SHAP이란?</a></li><li><a href=#5-예시-코드>5. 예시 코드</a></li></ul></li></ul></nav></aside></header><article class="markdown book-article"><h1 id=2-explainable-ai>#2 Explainable AI
<a class=anchor href=#2-explainable-ai>#</a></h1><p>#2025-06-26</p><hr><h3 id=1-explainable-ai란>1. Explainable AI란?
<a class=anchor href=#1-explainable-ai%eb%9e%80>#</a></h3><p>Explainable AI는 인공지능(AI) 또는 머신러닝(ML) 모델이 어떤 방식으로 특정 결과를 도출했는지 사람이 이해할 수 있도록 설명하는 기술과 방법론.</p><h3 id=2-xai-기법-분류>2. XAI 기법 분류
<a class=anchor href=#2-xai-%ea%b8%b0%eb%b2%95-%eb%b6%84%eb%a5%98>#</a></h3><p>모델 구조</p><ul><li>Intrinsic: 모델 자체가 설명 가능한 구조 (예: 의사결정나무, 선형회귀 등)</li><li>Post-hoc: 모델 학습 후 별도로 설명 생성 (예: SHAP, LIME)
대상</li><li>Global: 전체 모델의 작동 원리를 설명</li><li>Local: 특정 샘플의 예측 결과를 설명</li></ul><h3 id=3-주요-post-hoc-설명-기법>3. 주요 Post-hoc 설명 기법
<a class=anchor href=#3-%ec%a3%bc%ec%9a%94-post-hoc-%ec%84%a4%eb%aa%85-%ea%b8%b0%eb%b2%95>#</a></h3><p>LIME (Local Interpretable Model-Agnostic Explanations): 주변 입력을 랜덤하게 생성하고, 단순 모델(선형 회귀 등)을 학습해 근사</p><p>SHAP (SHapley Additive exPlanations): 게임 이론의 샤플리 값 기반</p><ul><li>각 피처가 기여한 정도를 공정하게 분배하여 설명<ul><li>장점: 수학적으로 정당성 확보, 일관된 설명 제공</li><li>단점: 계산 비용 큼</li></ul></li></ul><p>Permutation Importance: 입력 피처를 무작위로 섞은 후 예측 성능 감소 정도 측정</p><ul><li>예측 성능이 크게 감소하면, 중요한 피처로 판단</li></ul><p>Saliency Maps (이미지 분야)</p><h3 id=4-shap이란>4. SHAP이란?
<a class=anchor href=#4-shap%ec%9d%b4%eb%9e%80>#</a></h3><p>각 feature(입력 변수)가 모델의 예측값에 얼마나 기여했는지 정량적으로 계산.</p><p>원래는 협력 게임 이론에서</p><ul><li>여러 플레이어가 팀을 이뤄 보상을 받았을 때, 각 플레이어가 전체 보상에 얼마나 기여했는지를 계산하는 방법인데</li><li>예시로<ul><li>축구 게임을 하여 팀 전체가 100점을 획득했다고 가정</li><li>팀에는 선수 A, B, C가 있다<ul><li>누가 더 중요한 선수인지, 각 선수가 점수에 얼마나 기여했는지를 구하려면?</li><li>샤플리 값은 다음 순서로 기여도를 평가:<ol><li>가능한 모든 순열을 고려</li><li>각 순열에서 A, B, C가 언제 팀에 합류했는지</li><li>그 선수가 팀에 들어오면서 얼마나 점수가 늘었는지 확인 -> 각 선수의 이 평균 기여도를 “샤플리 값”이라고 함.</li></ol></li></ul></li></ul></li></ul><p>머신러닝 모델에서:</p><ul><li>각 feature가 플레이어 역할을 함<ul><li>모델의 예측값이 팀이 얻은 점수이고<ul><li>SHAP은 &ldquo;이 예측값이 나오는 데, 각 feature가 얼마나 기여했는가?&ldquo;를 계산.</li><li>예를 들어 모델이 어떤 환자의 사망 확률을 80%라고 예측했을 때<ul><li>나이: +15%</li><li>흡연 여부: +10%</li><li>혈압: +5%</li><li>기본값: 50%<ul><li>총합: 50% + 15 + 10 + 5 = 80%</li></ul></li></ul></li></ul></li></ul></li><li>즉 SHAP은 예측값을 base value + 각 feature의 기여도로 분해해준다.</li></ul><p>수학적 계산 과정:</p><ul><li>3개의 feature (A, B, C)에서 가능한 feature 조합:<ul><li>{}, {A}, {B}, {C}, {A,B}, {A,C}, {B,C}, {A,B,C}</li><li>SHAP은 모든 조합에 대해,<ul><li>해당 feature가 들어갔을 때와 안 들어갔을 때 예측값 차이를 계산<ul><li>이를 평균하여 기여도(샤플리 값)로 설정한다.<ul><li>단점: 조합 수가 2^M이라서 feature 수가 많으면 계산량 폭발</li></ul></li></ul></li></ul></li></ul></li></ul><h3 id=5-예시-코드>5. 예시 코드
<a class=anchor href=#5-%ec%98%88%ec%8b%9c-%ec%bd%94%eb%93%9c>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> pandas <span style=color:#66d9ef>as</span> pd
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> pickle
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> joblib
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> shap
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> matplotlib.pyplot <span style=color:#66d9ef>as</span> plt
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> seaborn <span style=color:#66d9ef>as</span> sns
</span></span></code></pre></div></article><footer class=book-footer><div class="flex flex-wrap justify-between"></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments><script src=https://giscus.app/client.js data-repo=yshghid/yshghid.github.io data-repo-id=R_kgDONkMkNg data-category-id=DIC_kwDONkMkNs4CloJh data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=ko crossorigin=anonymous async></script></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><ul><li><a href=#1-explainable-ai란>1. Explainable AI란?</a></li><li><a href=#2-xai-기법-분류>2. XAI 기법 분류</a></li><li><a href=#3-주요-post-hoc-설명-기법>3. 주요 Post-hoc 설명 기법</a></li><li><a href=#4-shap이란>4. SHAP이란?</a></li><li><a href=#5-예시-코드>5. 예시 코드</a></li></ul></li></ul></nav></div></aside></main></body></html>