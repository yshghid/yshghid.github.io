<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>기타 on Lifelog 2025</title><link>https://yshghid.github.io/docs/study/etc/</link><description>Recent content in 기타 on Lifelog 2025</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Fri, 27 Jun 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://yshghid.github.io/docs/study/etc/index.xml" rel="self" type="application/rss+xml"/><item><title>#4 Random Forest pseudocode로 이해하기</title><link>https://yshghid.github.io/docs/study/etc/etc4/</link><pubDate>Fri, 27 Jun 2025 00:00:00 +0000</pubDate><guid>https://yshghid.github.io/docs/study/etc/etc4/</guid><description>&lt;h1 id="4-random-forest-pseudocode로-이해하기">
 #4 Random Forest pseudocode로 이해하기
 &lt;a class="anchor" href="#4-random-forest-pseudocode%eb%a1%9c-%ec%9d%b4%ed%95%b4%ed%95%98%ea%b8%b0">#&lt;/a>
&lt;/h1>
&lt;p>#2025-06-27&lt;/p>
&lt;hr>
&lt;h3 id="1-random-forest-분류-슈도코드">
 1. Random Forest 분류 슈도코드
 &lt;a class="anchor" href="#1-random-forest-%eb%b6%84%eb%a5%98-%ec%8a%88%eb%8f%84%ec%bd%94%eb%93%9c">#&lt;/a>
&lt;/h3>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">RandomForestClassifier&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">__init__&lt;/span>(self, n_trees, max_features, max_depth):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>n_trees &lt;span style="color:#f92672">=&lt;/span> n_trees &lt;span style="color:#75715e"># 트리 개수&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>max_features &lt;span style="color:#f92672">=&lt;/span> max_features &lt;span style="color:#75715e"># 각 노드에서 무작위로 선택할 feature 수&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>max_depth &lt;span style="color:#f92672">=&lt;/span> max_depth &lt;span style="color:#75715e"># 트리 최대 깊이&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>trees &lt;span style="color:#f92672">=&lt;/span> [] &lt;span style="color:#75715e"># 의사결정트리 저장 리스트&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">fit&lt;/span>(self, X, y):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">for&lt;/span> _ &lt;span style="color:#f92672">in&lt;/span> range(self&lt;span style="color:#f92672">.&lt;/span>n_trees):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># 1. 부트스트랩 샘플링 (데이터 중복 허용 샘플링)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> X_sample, y_sample &lt;span style="color:#f92672">=&lt;/span> bootstrap_sample(X, y)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># 2. 의사결정트리 학습 (노드마다 무작위 feature 선택)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> tree &lt;span style="color:#f92672">=&lt;/span> DecisionTree(max_features&lt;span style="color:#f92672">=&lt;/span>self&lt;span style="color:#f92672">.&lt;/span>max_features, max_depth&lt;span style="color:#f92672">=&lt;/span>self&lt;span style="color:#f92672">.&lt;/span>max_depth)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> tree&lt;span style="color:#f92672">.&lt;/span>fit(X_sample, y_sample)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> 
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>trees&lt;span style="color:#f92672">.&lt;/span>append(tree)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">predict&lt;/span>(self, X):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># 각 트리로부터 예측 결과 수집&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> tree_preds &lt;span style="color:#f92672">=&lt;/span> [tree&lt;span style="color:#f92672">.&lt;/span>predict(X) &lt;span style="color:#66d9ef">for&lt;/span> tree &lt;span style="color:#f92672">in&lt;/span> self&lt;span style="color:#f92672">.&lt;/span>trees]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># 각 샘플에 대해 다수결(Majority Vote)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> final_preds &lt;span style="color:#f92672">=&lt;/span> []
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">for&lt;/span> i &lt;span style="color:#f92672">in&lt;/span> range(len(X)):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> votes &lt;span style="color:#f92672">=&lt;/span> [pred[i] &lt;span style="color:#66d9ef">for&lt;/span> pred &lt;span style="color:#f92672">in&lt;/span> tree_preds]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> final_preds&lt;span style="color:#f92672">.&lt;/span>append(majority_vote(votes))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> final_preds
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 보조 함수 (부트스트랩 샘플링)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">bootstrap_sample&lt;/span>(X, y):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> n_samples &lt;span style="color:#f92672">=&lt;/span> len(X)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> indices &lt;span style="color:#f92672">=&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>random&lt;span style="color:#f92672">.&lt;/span>choice(n_samples, size&lt;span style="color:#f92672">=&lt;/span>n_samples, replace&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">True&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> X[indices], y[indices]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 보조 함수 (다수결)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">majority_vote&lt;/span>(votes):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> most_common_label(votes)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>데이터 샘플링 -&amp;gt; 트리 학습 -&amp;gt; 트리들의 예측 결과 수집, 다수결.&lt;/p></description></item><item><title>#5 Confusion matrix</title><link>https://yshghid.github.io/docs/study/etc/etc5/</link><pubDate>Fri, 27 Jun 2025 00:00:00 +0000</pubDate><guid>https://yshghid.github.io/docs/study/etc/etc5/</guid><description>&lt;h1 id="5-confusion-matrix">
 #5 Confusion matrix
 &lt;a class="anchor" href="#5-confusion-matrix">#&lt;/a>
&lt;/h1>
&lt;p>#2025-06-27&lt;/p>
&lt;hr>
&lt;h3 id="1-정의">
 1. 정의
 &lt;a class="anchor" href="#1-%ec%a0%95%ec%9d%98">#&lt;/a>
&lt;/h3>
&lt;p>confusion matrix는&lt;/p>
&lt;ul>
&lt;li>분류 모델의 예측 성능을 상세하게 평가하는 도구
&lt;ul>
&lt;li>특히 이진 분류에서 매우 유용함&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;table>
 &lt;thead>
 &lt;tr>
 &lt;th>&lt;/th>
 &lt;th>&lt;strong>실제: 정상 (0)&lt;/strong>&lt;/th>
 &lt;th>&lt;strong>실제: 중증 (1)&lt;/strong>&lt;/th>
 &lt;/tr>
 &lt;/thead>
 &lt;tbody>
 &lt;tr>
 &lt;td>&lt;strong>예측: 정상 (0)&lt;/strong>&lt;/td>
 &lt;td>&lt;strong>TN&lt;/strong> (True Negative)&lt;/td>
 &lt;td>&lt;strong>FN&lt;/strong> (False Negative)&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>&lt;strong>예측: 중증 (1)&lt;/strong>&lt;/td>
 &lt;td>&lt;strong>FP&lt;/strong> (False Positive)&lt;/td>
 &lt;td>&lt;strong>TP&lt;/strong> (True Positive)&lt;/td>
 &lt;/tr>
 &lt;/tbody>
&lt;/table>
&lt;h3 id="2-예시">
 2. 예시
 &lt;a class="anchor" href="#2-%ec%98%88%ec%8b%9c">#&lt;/a>
&lt;/h3>
&lt;table>
 &lt;thead>
 &lt;tr>
 &lt;th>&lt;/th>
 &lt;th>실제: 정상&lt;/th>
 &lt;th>실제: 중증&lt;/th>
 &lt;/tr>
 &lt;/thead>
 &lt;tbody>
 &lt;tr>
 &lt;td>예측: 정상&lt;/td>
 &lt;td>50&lt;/td>
 &lt;td>10&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>예측: 중증&lt;/td>
 &lt;td>5&lt;/td>
 &lt;td>35&lt;/td>
 &lt;/tr>
 &lt;/tbody>
&lt;/table>
&lt;p>confusion matrix는&lt;/p>
&lt;ul>
&lt;li>단순한 정확도만으로는 보이지 않는 문제점(FP, FN)을 보여줌&lt;/li>
&lt;li>특히 의료나 보안 분야처럼 FN이 위험한 경우 매우 중요하다 (FN: 중증을 정상으로 잘못 예측)&lt;/li>
&lt;/ul>
&lt;h3 id="3-정확도-정밀도-재현율">
 3. 정확도 정밀도 재현율
 &lt;a class="anchor" href="#3-%ec%a0%95%ed%99%95%eb%8f%84-%ec%a0%95%eb%b0%80%eb%8f%84-%ec%9e%ac%ed%98%84%ec%9c%a8">#&lt;/a>
&lt;/h3>
&lt;p>정확도는 높고 정밀도는 높지만 재현율은 낮은 경우&lt;/p></description></item><item><title>#2 Explainable AI</title><link>https://yshghid.github.io/docs/study/etc/etc2/</link><pubDate>Thu, 26 Jun 2025 00:00:00 +0000</pubDate><guid>https://yshghid.github.io/docs/study/etc/etc2/</guid><description>&lt;h1 id="2-explainable-ai">
 #2 Explainable AI
 &lt;a class="anchor" href="#2-explainable-ai">#&lt;/a>
&lt;/h1>
&lt;p>#2025-06-26&lt;/p>
&lt;hr>
&lt;h3 id="1-explainable-ai란">
 1. Explainable AI란?
 &lt;a class="anchor" href="#1-explainable-ai%eb%9e%80">#&lt;/a>
&lt;/h3>
&lt;p>Explainable AI는 인공지능(AI) 또는 머신러닝(ML) 모델이 어떤 방식으로 특정 결과를 도출했는지 사람이 이해할 수 있도록 설명하는 기술과 방법론.&lt;/p>
&lt;h3 id="2-xai-기법-분류">
 2. XAI 기법 분류
 &lt;a class="anchor" href="#2-xai-%ea%b8%b0%eb%b2%95-%eb%b6%84%eb%a5%98">#&lt;/a>
&lt;/h3>
&lt;p>모델 구조&lt;/p>
&lt;ul>
&lt;li>Intrinsic:	모델 자체가 설명 가능한 구조 (예: 의사결정나무, 선형회귀 등)&lt;/li>
&lt;li>Post-hoc:	모델 학습 후 별도로 설명 생성 (예: SHAP, LIME)
대상&lt;/li>
&lt;li>Global:	전체 모델의 작동 원리를 설명&lt;/li>
&lt;li>Local:	특정 샘플의 예측 결과를 설명&lt;/li>
&lt;/ul>
&lt;h3 id="3-주요-post-hoc-설명-기법">
 3. 주요 Post-hoc 설명 기법
 &lt;a class="anchor" href="#3-%ec%a3%bc%ec%9a%94-post-hoc-%ec%84%a4%eb%aa%85-%ea%b8%b0%eb%b2%95">#&lt;/a>
&lt;/h3>
&lt;p>LIME (Local Interpretable Model-Agnostic Explanations): 주변 입력을 랜덤하게 생성하고, 단순 모델(선형 회귀 등)을 학습해 근사&lt;/p></description></item><item><title>#3 Random Forest</title><link>https://yshghid.github.io/docs/study/etc/etc3/</link><pubDate>Thu, 26 Jun 2025 00:00:00 +0000</pubDate><guid>https://yshghid.github.io/docs/study/etc/etc3/</guid><description>&lt;h1 id="3-random-forest">
 #3 Random Forest
 &lt;a class="anchor" href="#3-random-forest">#&lt;/a>
&lt;/h1>
&lt;p>#2025-06-26&lt;/p>
&lt;hr>
&lt;h3 id="1-random-forest의-분류와-회귀">
 1. Random Forest의 분류와 회귀
 &lt;a class="anchor" href="#1-random-forest%ec%9d%98-%eb%b6%84%eb%a5%98%ec%99%80-%ed%9a%8c%ea%b7%80">#&lt;/a>
&lt;/h3>
&lt;p>랜덤 포레스트(Random Forest)는&lt;/p>
&lt;ul>
&lt;li>RandomForestClassifier: 분류용&lt;/li>
&lt;li>RandomForestRegressor: 회귀용 이다.&lt;/li>
&lt;/ul>
&lt;p>분류와 회귀의 핵심 차이는&lt;/p>
&lt;ul>
&lt;li>분류는 각 leaf node에 속한 클래스의 비율을 기반으로 확률 예측&lt;/li>
&lt;li>회귀는 leaf node에 있는 target 값들의 평균을 예측값으로 사용&lt;/li>
&lt;/ul>
&lt;p>랜덤 포레스트의 트리 구조(= 리프 분기 방식)는 분류나 회귀나 똑같고&lt;/p>
&lt;ul>
&lt;li>단지 리프 노드에 어떤 데이터 형식이 들어가느냐에 따라
&lt;ul>
&lt;li>분류이면 라벨 비율(확률 분포)&lt;/li>
&lt;li>회귀이면 값의 평균으로 예측을 내놓는다&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="2-트리-기반-모델과-클러스터링의-차이">
 2. 트리 기반 모델과 클러스터링의 차이
 &lt;a class="anchor" href="#2-%ed%8a%b8%eb%a6%ac-%ea%b8%b0%eb%b0%98-%eb%aa%a8%eb%8d%b8%ea%b3%bc-%ed%81%b4%eb%9f%ac%ec%8a%a4%ed%84%b0%eb%a7%81%ec%9d%98-%ec%b0%a8%ec%9d%b4">#&lt;/a>
&lt;/h3>
&lt;p>랜덤 포레스트(혹은 결정 트리)의 리프 분기 방식은 &amp;lsquo;거리 기반&amp;rsquo;이 아님&lt;/p></description></item><item><title>#1 DBSCAN</title><link>https://yshghid.github.io/docs/study/etc/etc1/</link><pubDate>Wed, 25 Jun 2025 00:00:00 +0000</pubDate><guid>https://yshghid.github.io/docs/study/etc/etc1/</guid><description>&lt;h1 id="1-dbscan">
 #1 DBSCAN
 &lt;a class="anchor" href="#1-dbscan">#&lt;/a>
&lt;/h1>
&lt;p>#2025-06-25&lt;/p>
&lt;hr>
&lt;h2 id="개념">
 개념
 &lt;a class="anchor" href="#%ea%b0%9c%eb%85%90">#&lt;/a>
&lt;/h2>
&lt;p>DBSCAN은 밀도 기반 클러스터링 알고리즘으로&lt;/p>
&lt;ul>
&lt;li>데이터가 밀집된 영역을 클러스터로 인식하고&lt;/li>
&lt;li>밀도가 낮은 영역은 노이즈(이상치)로 간주하는 방법.&lt;/li>
&lt;/ul>
&lt;p>KMeans와 달리, 군집 수를 미리 정하지 않아도 되며,&lt;/p>
&lt;ul>
&lt;li>비선형 구조나 잡음이 있는 데이터에서 잘 작동한다.&lt;/li>
&lt;/ul>
&lt;h2 id="파라미터와-핵심-용어">
 파라미터와 핵심 용어
 &lt;a class="anchor" href="#%ed%8c%8c%eb%9d%bc%eb%af%b8%ed%84%b0%ec%99%80-%ed%95%b5%ec%8b%ac-%ec%9a%a9%ec%96%b4">#&lt;/a>
&lt;/h2>
&lt;p>주요 파라미터는 2개&lt;/p>
&lt;ul>
&lt;li>eps: 반지름 거리. 한 점에서 eps 거리 내에 있는 점들을 &amp;ldquo;이웃&amp;quot;이라고 판단.&lt;/li>
&lt;li>min_samples: core point로 인정되기 위해 필요한 최소 이웃 수&lt;/li>
&lt;/ul>
&lt;p>핵심 용어는 3개&lt;/p></description></item></channel></rss>