<!doctype html><html lang=en-us dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="
  #3 Random Forest
  #

#2025-06-26


  1. Random Forest의 분류와 회귀
  #

랜덤 포레스트(Random Forest)는

RandomForestClassifier: 분류용
RandomForestRegressor: 회귀용 이다.

분류와 회귀의 핵심 차이는

분류는 각 leaf node에 속한 클래스의 비율을 기반으로 확률 예측
회귀는 leaf node에 있는 target 값들의 평균을 예측값으로 사용

랜덤 포레스트의 트리 구조(= 리프 분기 방식)는 분류나 회귀나 똑같고

단지 리프 노드에 어떤 데이터 형식이 들어가느냐에 따라

분류이면 라벨 비율(확률 분포)
회귀이면 값의 평균으로 예측을 내놓는다




  2. 트리 기반 모델과 클러스터링의 차이
  #

랜덤 포레스트(혹은 결정 트리)의 리프 분기 방식은 &lsquo;거리 기반&rsquo;이 아님"><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="https://yshghid.github.io/docs/study/etc/etc3/"><meta property="og:site_name" content=" "><meta property="og:title" content="#3 Random Forest"><meta property="og:description" content="#3 Random Forest # #2025-06-26
1. Random Forest의 분류와 회귀 # 랜덤 포레스트(Random Forest)는
RandomForestClassifier: 분류용 RandomForestRegressor: 회귀용 이다. 분류와 회귀의 핵심 차이는
분류는 각 leaf node에 속한 클래스의 비율을 기반으로 확률 예측 회귀는 leaf node에 있는 target 값들의 평균을 예측값으로 사용 랜덤 포레스트의 트리 구조(= 리프 분기 방식)는 분류나 회귀나 똑같고
단지 리프 노드에 어떤 데이터 형식이 들어가느냐에 따라 분류이면 라벨 비율(확률 분포) 회귀이면 값의 평균으로 예측을 내놓는다 2. 트리 기반 모델과 클러스터링의 차이 # 랜덤 포레스트(혹은 결정 트리)의 리프 분기 방식은 ‘거리 기반’이 아님"><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="docs"><meta property="article:published_time" content="2025-06-26T00:00:00+00:00"><meta property="article:modified_time" content="2025-06-26T00:00:00+00:00"><meta property="article:tag" content="2025-06"><title>#3 Random Forest |</title><link rel=icon href=/favicon.png><link rel=manifest href=/manifest.json><link rel=canonical href=https://yshghid.github.io/docs/study/etc/etc3/><link rel=stylesheet href=/book.min.6217d077edb4189fd0578345e84bca1a884dfdee121ff8dc9a0f55cfe0852bc9.css integrity="sha256-YhfQd+20GJ/QV4NF6EvKGohN/e4SH/jcmg9Vz+CFK8k=" crossorigin=anonymous><script defer src=/fuse.min.js></script><script defer src=/en.search.min.ef4259f6fcec8ae16bfcfcdc2c34664bf814c09edbc4564e33626ce5c8781a7b.js integrity="sha256-70JZ9vzsiuFr/PzcLDRmS/gUwJ7bxFZOM2Js5ch4Gns=" crossorigin=anonymous></script></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><img src=/logo.png alt=Logo class=book-icon><span></span></a></h2><div class="book-search hidden"><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><script>document.querySelector(".book-search").classList.remove("hidden")</script><ul><li class=book-section-flat><span>기록</span><ul><li><a href=/docs/hobby/book/>글</a><ul></ul></li><li><a href=/docs/hobby/daily/>일상</a><ul></ul></li><li><a href=/docs/hobby/shopping/>쇼핑</a><ul></ul></li><li><a href=/docs/hobby/youtube/>유튜브</a><ul></ul></li><li><a href=/docs/hobby/music/>음악</a><ul></ul></li><li><a href=/docs/hobby/baking/>베이킹</a><ul></ul></li><li><a href=/docs/hobby/movie/>영화</a><ul></ul></li></ul></li><li class=book-section-flat><span>공부</span><ul><li><a href=/docs/study/ai/>AI</a><ul></ul></li><li><a href=/docs/study/sw/>SW</a><ul></ul></li><li><a href=/docs/study/bioinformatics/>Bioinformatics</a><ul></ul></li><li><a href=/docs/study/algorithm/>코테</a><ul></ul></li><li><a href=/docs/study/career/>취업</a><ul></ul></li><li><a href=/docs/study/github/>깃허브</a><ul></ul></li></ul></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu></label><h3>#3 Random Forest</h3><label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><ul><li><a href=#1-random-forest의-분류와-회귀>1. Random Forest의 분류와 회귀</a></li><li><a href=#2-트리-기반-모델과-클러스터링의-차이>2. 트리 기반 모델과 클러스터링의 차이</a></li><li><a href=#3-트리-기반-모델과-클러스터링의-차이-2>3. 트리 기반 모델과 클러스터링의 차이 (2)</a></li></ul></li></ul></nav></aside></header><article class="markdown book-article"><h1 id=3-random-forest>#3 Random Forest
<a class=anchor href=#3-random-forest>#</a></h1><p>#2025-06-26</p><hr><h3 id=1-random-forest의-분류와-회귀>1. Random Forest의 분류와 회귀
<a class=anchor href=#1-random-forest%ec%9d%98-%eb%b6%84%eb%a5%98%ec%99%80-%ed%9a%8c%ea%b7%80>#</a></h3><p>랜덤 포레스트(Random Forest)는</p><ul><li>RandomForestClassifier: 분류용</li><li>RandomForestRegressor: 회귀용 이다.</li></ul><p>분류와 회귀의 핵심 차이는</p><ul><li>분류는 각 leaf node에 속한 클래스의 비율을 기반으로 확률 예측</li><li>회귀는 leaf node에 있는 target 값들의 평균을 예측값으로 사용</li></ul><p>랜덤 포레스트의 트리 구조(= 리프 분기 방식)는 분류나 회귀나 똑같고</p><ul><li>단지 리프 노드에 어떤 데이터 형식이 들어가느냐에 따라<ul><li>분류이면 라벨 비율(확률 분포)</li><li>회귀이면 값의 평균으로 예측을 내놓는다</li></ul></li></ul><h3 id=2-트리-기반-모델과-클러스터링의-차이>2. 트리 기반 모델과 클러스터링의 차이
<a class=anchor href=#2-%ed%8a%b8%eb%a6%ac-%ea%b8%b0%eb%b0%98-%eb%aa%a8%eb%8d%b8%ea%b3%bc-%ed%81%b4%eb%9f%ac%ec%8a%a4%ed%84%b0%eb%a7%81%ec%9d%98-%ec%b0%a8%ec%9d%b4>#</a></h3><p>랜덤 포레스트(혹은 결정 트리)의 리프 분기 방식은 &lsquo;거리 기반&rsquo;이 아님</p><ul><li>대신, 목표 변수(y)를 가장 잘 구분할 수 있도록<ul><li>feature를 기준으로 데이터 공간을 분할한다.</li></ul></li></ul><p>분기 기준</p><ul><li><p>분류 문제</p><ul><li>Gini 불순도, Entropy(정보이득) 등을 기준으로<ul><li>분기를 통해 클래스가 더 순수하게 나뉘도록 자름</li></ul></li></ul></li><li><p>회귀 문제</p><ul><li>MSE (Mean Squared Error) 또는 MAE (평균 절댓값 오차) 감소가 큰 방향으로 분기</li></ul></li><li><p>분기의 본질은 분기를 할 때 두 점 사이의 거리를 따지지 않음. 대신 &ldquo;어떤 feature에서 자르면, y가 더 잘 나눠지냐"만을 고려함.</p></li></ul><p>궁극적으로 차이점</p><table><thead><tr><th>항목</th><th>결정 트리 / 랜덤 포레스트</th><th>계층적 클러스터링</th></tr></thead><tbody><tr><td>학습 방식</td><td>지도 학습 (y 필요)</td><td>비지도 학습 (y 없음)</td></tr><tr><td>분기 기준</td><td>y를 잘 나누는 feature 기준</td><td>입력 간 거리 기준</td></tr><tr><td>분할 구조</td><td>트리 구조 (특정 feature 기준 분할)</td><td>덴드로그램 구조 (거리 기반 병합/분할)</td></tr><tr><td>목적</td><td>예측 성능 향상</td><td>그룹 내 유사성 확보</td></tr><tr><td>거리 개념</td><td>사용 안 함</td><td>핵심 기준</td></tr></tbody></table><p>학습 방식이</p><ul><li>RF는 지도 학습으로 y필요, 클러스터링은 비지도 학습으로 y 불필요
분기 기준이</li><li>RF는 y를 잘 나누는 feature 기준, 클러스터링은 입력 간 거리 기준
목적이</li><li>RF는 얘측 성능 향상, 클러스터링은 그룹 내 유사성 확보.</li></ul><h3 id=3-트리-기반-모델과-클러스터링의-차이-2>3. 트리 기반 모델과 클러스터링의 차이 (2)
<a class=anchor href=#3-%ed%8a%b8%eb%a6%ac-%ea%b8%b0%eb%b0%98-%eb%aa%a8%eb%8d%b8%ea%b3%bc-%ed%81%b4%eb%9f%ac%ec%8a%a4%ed%84%b0%eb%a7%81%ec%9d%98-%ec%b0%a8%ec%9d%b4-2>#</a></h3><p>랜덤 포레스트(RF)의 분기 조건이 리프 내 순도(클래스의 동질성)를 높이는 거라면, 클러스터링의 목적(그룹 내 유사성 확보)과 본질적으로 같은 거 아닌가?</p><p>핵심 차이 1: 무엇을 기준으로 유사하다고 보는지.</p><ul><li>결정트리 (RF)는 &ldquo;예측값 y가 비슷하면 유사하다"고 생각함. 즉, 입력 X가 다르더라도 y가 비슷하면 같은 노드로 분기</li><li>클러스터링은 &ldquo;입력 값 X가 비슷하면 유사하다"고 생각함 즉 y는 고려하지 않음<ul><li>예를 들어 두 환자의 면역 프로파일이 완전히 달라도 둘 다 사망(y=1)이라면, RF는 둘을 같은 리프에 보낼 수 있다.<ul><li>반대로 클러스터링은 면역 프로파일이 다르면 y와 무관하게 다른 그룹으로 나눈다.</li></ul></li></ul></li></ul><p>핵심 차이 2: 지도 vs 비지도</p><ul><li>RF는 정답(y)이 있는 지도학습이고</li><li>클러스터링은 y 없이 입력 X의 분포만으로 구조를 파악<ul><li>즉 클러스터링은 &ldquo;데이터 간 관계"에 집중, RF는 &ldquo;데이터와 정답 간 관계"에 집중</li></ul></li></ul><p>예시</p><ul><li>Feature X1, X2로 된 점 100개</li><li>Class 0/1 이 섞여 있음<ul><li>Random Forest: 어떤 feature (예: X1 &lt; 5)로 나눴더니 클래스 0/1이 잘 나뉜다 -> 분기 수행. 이 과정에서 X 간의 거리나 모양은 고려 안 한다.</li><li>클러스터링: X1, X2 기준으로 거리상 가까운 점들끼리 묶음. 클래스(y) 정보는 전혀 고려하지 않는다.</li></ul></li></ul><p>비슷해보이는 이유</p><ul><li>결정트리는 리프 내 클래스가 비슷해지도록 데이터를 쪼개다 보니 결국 리프 안의 X 값들도 어느 정도 비슷해지는 경향이 발생.</li><li>이 때문에 시각적으로 보면 &ldquo;트리가 일종의 분할 기반 클러스터링"처럼 보이기도 함 특히, y 자체가 X의 분포에 강하게 의존할 경우에는 트리 분기 ≈ 거리 기반 분할처럼 보인다.</li></ul><p>하지만 유사성이 목표인지 수단인지가 다름:</p><ul><li>클러스터링은 목표 자체</li><li>결정 트리 / RF는 예측을 위한 수단.<ul><li>둘 다 &ldquo;비슷한 것들끼리 묶는다"는 점에서 결과적으로 유사한 구조를 만들 수 있지만 클러스터링은 유사성 자체가 목적 결정 트리는 예측을 위한 수단으로 유사한 샘플을 묶을 뿐.</li></ul></li></ul></article><footer class=book-footer><div class="flex flex-wrap justify-between"></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments><script src=https://giscus.app/client.js data-repo=yshghid/yshghid.github.io data-repo-id=R_kgDONkMkNg data-category-id=DIC_kwDONkMkNs4CloJh data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=ko crossorigin=anonymous async></script></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><ul><li><a href=#1-random-forest의-분류와-회귀>1. Random Forest의 분류와 회귀</a></li><li><a href=#2-트리-기반-모델과-클러스터링의-차이>2. 트리 기반 모델과 클러스터링의 차이</a></li><li><a href=#3-트리-기반-모델과-클러스터링의-차이-2>3. 트리 기반 모델과 클러스터링의 차이 (2)</a></li></ul></li></ul></nav></div></aside></main></body></html>