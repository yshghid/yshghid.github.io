<!doctype html><html lang=en-us dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="
  Selenium: Influenza fasta 파일 크롤링
  #

#2025-07-28


  1. Load package
  #

import pandas as pd
import numpy as np
import os

  
  #


  2. Set path
  #

os.chdir('/Users/yshmbid/Desktop/workspace/gisaid')
os.getcwd()
'/Users/yshmbid/Desktop/workspace/gisaid'

  
  #


  3. Run crawling
  #

# ChromeDriver 경로를 설치하고 Service 객체로 전달
chrome_service = Service(ChromeDriverManager().install())

try:
    # ChromeDriver 실행
    crawler = webdriver.Chrome(service=chrome_service)
except:
    # 크롬드라이버가 없을 때 autoinstaller로 설치
    chromedriver_autoinstaller.install(True)
    crawler = webdriver.Chrome(service=chrome_service)

crawler.implicitly_wait(6)  # 크롤러 대기 시간 설정
crawler.get('https://gisaid.org/')  # 웹사이트 열기

# login 선택
engine = WebDriverWait(crawler, 10).until(EC.element_to_be_clickable((By.XPATH, '//*[@id=&#34;menuequer&#34;]/li[7]/a')))
engine.click()

# id 입력
WebDriverWait(crawler, 10).until(EC.element_to_be_clickable((By.XPATH, '//*[@id=&#34;elogin&#34;]')))
engine = crawler.find_element(By.XPATH, '//*[@id=&#34;elogin&#34;]')
crawler.execute_script(&#34;arguments[0].click();&#34;, engine)
engine.send_keys('*') # *: id 블라인드 처리

# pw 입력
#WebDriverWait(crawler, 10).until(EC.element_to_be_clickable((By.XPATH, '//*[@id=&#34;login&#34;]/div[2]/br[3]')))
engine = crawler.find_element(By.XPATH, '//*[@id=&#34;epassword&#34;]')
crawler.execute_script(&#34;arguments[0].click();&#34;, engine)
engine.send_keys('*')  # *: pw 블라인드 처리

#engine = crawler.find_element(By.XPATH, '//*[@id=&#34;login&#34;]/div[2]/input[3]')
engine = WebDriverWait(crawler, 10).until(EC.element_to_be_clickable((By.XPATH, '//*[@id=&#34;login&#34;]/div[2]/input[3]')))
engine.click()
# epiflu 선택
engine = crawler.find_element(By.XPATH, '//*[@id=&#34;main_nav&#34;]/ul/li[2]/a')
engine.click()

# search&amp;browse 선택
#engine = crawler.find_element(By.XPATH, '//*[@id=&#34;c_sjk17x_ey-c_sjk17x_ey&#34;]/div/div/div[7]/div')
engine = crawler.find_element(By.XPATH, '//*[@id=&#34;c_sjlgnx_11g-c_sjlgnx_11g&#34;]/div/div/div[7]/div')
#engine = WebDriverWait(crawler, 10).until(EC.element_to_be_clickable((By.XPATH, '//*[@id=&#34;c_sjk17x_ey-c_sjk17x_ey&#34;]/div/div/div[7]/div')))
engine.click()

# collection-date 선택
#engine = crawler.find_element(By.XPATH, '//*[@id=&#34;ce_sjk17x_q_input&#34;]') 
engine = crawler.find_element(By.XPATH, '//*[@id=&#34;ce_sjlgnx_hv_input&#34;]')
engine.click()
engine.send_keys('2024-01-01')

#engine = crawler.find_element(By.XPATH, '//*[@id=&#34;ce_sjk17x_r_input&#34;]') 
engine = crawler.find_element(By.XPATH, '//*[@id=&#34;ce_sjlgnx_hw_input&#34;]')
engine.click()
engine.send_keys('2024-02-01')

# search 선택
#engine = WebDriverWait(crawler, 10).until(EC.element_to_be_clickable((By.XPATH, '//*[@id=&#34;ce_sjk17x_1p&#34;]/div/button')))
#engine.click()
#engine = crawler.find_element(By.XPATH, '//*[@id=&#34;ce_sjlgnx_iu&#34;]/div/button') 
engine = WebDriverWait(crawler, 10).until(EC.element_to_be_clickable((By.XPATH, '//*[@id=&#34;ce_sjlgnx_iu&#34;]/div/button')))
engine.click()
# check all
engine = crawler.find_element(By.XPATH, '//*[@id=&#34;yui-dt0-th-c-liner&#34;]/span/input')
engine.click()

  
  #


분명 알고리즘 개발에는 22만개 sequence를 사용했는데 validation set으로 190만개 sequence를 쓰는게 맞았을까 생각했던작업
그와중에 GISAID의 xpath가 매일 업데이트돼서 매일아침 코드 수정해가면서 돌렸던기억이 있다
그리구 이상한게 핫스팟연결하면 오류나가지고 이기간엔 라운지도 못가고 연구실에만 있었어야했다..


  
  #
"><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="https://yshghid.github.io/docs/study/bioinformatics/bi28/"><meta property="og:site_name" content=" "><meta property="og:title" content="Selenium: Influenza fasta 파일 크롤링"><meta property="og:description" content="Selenium: Influenza fasta 파일 크롤링 # #2025-07-28
1. Load package # import pandas as pd import numpy as np import os # 2. Set path # os.chdir('/Users/yshmbid/Desktop/workspace/gisaid') os.getcwd() '/Users/yshmbid/Desktop/workspace/gisaid' # 3. Run crawling # # ChromeDriver 경로를 설치하고 Service 객체로 전달 chrome_service = Service(ChromeDriverManager().install()) try: # ChromeDriver 실행 crawler = webdriver.Chrome(service=chrome_service) except: # 크롬드라이버가 없을 때 autoinstaller로 설치 chromedriver_autoinstaller.install(True) crawler = webdriver.Chrome(service=chrome_service) crawler.implicitly_wait(6) # 크롤러 대기 시간 설정 crawler.get('https://gisaid.org/') # 웹사이트 열기 # login 선택 engine = WebDriverWait(crawler, 10).until(EC.element_to_be_clickable((By.XPATH, '//*[@id=&#34;menuequer&#34;]/li[7]/a'))) engine.click() # id 입력 WebDriverWait(crawler, 10).until(EC.element_to_be_clickable((By.XPATH, '//*[@id=&#34;elogin&#34;]'))) engine = crawler.find_element(By.XPATH, '//*[@id=&#34;elogin&#34;]') crawler.execute_script(&#34;arguments[0].click();&#34;, engine) engine.send_keys('*') # *: id 블라인드 처리 # pw 입력 #WebDriverWait(crawler, 10).until(EC.element_to_be_clickable((By.XPATH, '//*[@id=&#34;login&#34;]/div[2]/br[3]'))) engine = crawler.find_element(By.XPATH, '//*[@id=&#34;epassword&#34;]') crawler.execute_script(&#34;arguments[0].click();&#34;, engine) engine.send_keys('*') # *: pw 블라인드 처리 #engine = crawler.find_element(By.XPATH, '//*[@id=&#34;login&#34;]/div[2]/input[3]') engine = WebDriverWait(crawler, 10).until(EC.element_to_be_clickable((By.XPATH, '//*[@id=&#34;login&#34;]/div[2]/input[3]'))) engine.click() # epiflu 선택 engine = crawler.find_element(By.XPATH, '//*[@id=&#34;main_nav&#34;]/ul/li[2]/a') engine.click() # search&amp;browse 선택 #engine = crawler.find_element(By.XPATH, '//*[@id=&#34;c_sjk17x_ey-c_sjk17x_ey&#34;]/div/div/div[7]/div') engine = crawler.find_element(By.XPATH, '//*[@id=&#34;c_sjlgnx_11g-c_sjlgnx_11g&#34;]/div/div/div[7]/div') #engine = WebDriverWait(crawler, 10).until(EC.element_to_be_clickable((By.XPATH, '//*[@id=&#34;c_sjk17x_ey-c_sjk17x_ey&#34;]/div/div/div[7]/div'))) engine.click() # collection-date 선택 #engine = crawler.find_element(By.XPATH, '//*[@id=&#34;ce_sjk17x_q_input&#34;]') engine = crawler.find_element(By.XPATH, '//*[@id=&#34;ce_sjlgnx_hv_input&#34;]') engine.click() engine.send_keys('2024-01-01') #engine = crawler.find_element(By.XPATH, '//*[@id=&#34;ce_sjk17x_r_input&#34;]') engine = crawler.find_element(By.XPATH, '//*[@id=&#34;ce_sjlgnx_hw_input&#34;]') engine.click() engine.send_keys('2024-02-01') # search 선택 #engine = WebDriverWait(crawler, 10).until(EC.element_to_be_clickable((By.XPATH, '//*[@id=&#34;ce_sjk17x_1p&#34;]/div/button'))) #engine.click() #engine = crawler.find_element(By.XPATH, '//*[@id=&#34;ce_sjlgnx_iu&#34;]/div/button') engine = WebDriverWait(crawler, 10).until(EC.element_to_be_clickable((By.XPATH, '//*[@id=&#34;ce_sjlgnx_iu&#34;]/div/button'))) engine.click() # check all engine = crawler.find_element(By.XPATH, '//*[@id=&#34;yui-dt0-th-c-liner&#34;]/span/input') engine.click() # 분명 알고리즘 개발에는 22만개 sequence를 사용했는데 validation set으로 190만개 sequence를 쓰는게 맞았을까 생각했던작업 그와중에 GISAID의 xpath가 매일 업데이트돼서 매일아침 코드 수정해가면서 돌렸던기억이 있다 그리구 이상한게 핫스팟연결하면 오류나가지고 이기간엔 라운지도 못가고 연구실에만 있었어야했다.. #"><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="docs"><meta property="article:published_time" content="2025-07-28T00:00:00+00:00"><meta property="article:modified_time" content="2025-07-28T00:00:00+00:00"><meta property="article:tag" content="2025-07"><title>Selenium: Influenza fasta 파일 크롤링 |</title><link rel=icon href=/favicon.png><link rel=manifest href=/manifest.json><link rel=canonical href=https://yshghid.github.io/docs/study/bioinformatics/bi28/><link rel=stylesheet href=/book.min.c1243161bf0533845410166eed8d51c01c88b7495cb920164aa7f624f5f1e66a.css integrity="sha256-wSQxYb8FM4RUEBZu7Y1RwByIt0lcuSAWSqf2JPXx5mo=" crossorigin=anonymous><script defer src=/fuse.min.js></script><script defer src=/en.search.min.ab8b18a6aa16d81716433fafa0c3faa5403ab0b7e747140bcc6d5180711d2070.js integrity="sha256-q4sYpqoW2BcWQz+voMP6pUA6sLfnRxQLzG1RgHEdIHA=" crossorigin=anonymous></script></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><img src=/logo.png alt=Logo class=book-icon><span></span></a></h2><div class="book-search hidden"><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><script>document.querySelector(".book-search").classList.remove("hidden")</script><ul><li class=book-section-flat><span>기록</span><ul><li><a href=/docs/hobby/book/>글</a><ul></ul></li><li><a href=/docs/hobby/daily/>일상</a><ul></ul></li></ul></li><li class=book-section-flat><span>공부</span><ul><li><a href=/docs/study/bioinformatics/>Bioinformatics</a><ul></ul></li><li><a href=/docs/study/ai/>AI</a><ul></ul></li><li><a href=/docs/study/sw/>SW</a><ul></ul></li><li><a href=/docs/study/algorithm/>알고리즘</a><ul></ul></li><li><a href=/docs/study/career/>취업</a><ul></ul></li></ul></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu></label><h3>Selenium: Influenza fasta 파일 크롤링</h3><label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><ul><li><a href=#1-load-package>1. Load package</a></li><li></li><li><a href=#2-set-path>2. Set path</a></li><li></li><li><a href=#3-run-crawling>3. Run crawling</a></li></ul></li></ul></nav></aside></header><article class="markdown book-article"><h1 id=selenium-influenza-fasta-파일-크롤링>Selenium: Influenza fasta 파일 크롤링
<a class=anchor href=#selenium-influenza-fasta-%ed%8c%8c%ec%9d%bc-%ed%81%ac%eb%a1%a4%eb%a7%81>#</a></h1><p>#2025-07-28</p><hr><h3 id=1-load-package>1. Load package
<a class=anchor href=#1-load-package>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> pandas <span style=color:#66d9ef>as</span> pd
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> os
</span></span></code></pre></div><h3><a class=anchor href=#>#</a></h3><h3 id=2-set-path>2. Set path
<a class=anchor href=#2-set-path>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>os<span style=color:#f92672>.</span>chdir(<span style=color:#e6db74>&#39;/Users/yshmbid/Desktop/workspace/gisaid&#39;</span>)
</span></span><span style=display:flex><span>os<span style=color:#f92672>.</span>getcwd()
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-plain data-lang=plain><span style=display:flex><span>&#39;/Users/yshmbid/Desktop/workspace/gisaid&#39;
</span></span></code></pre></div><h3><a class=anchor href=#>#</a></h3><h3 id=3-run-crawling>3. Run crawling
<a class=anchor href=#3-run-crawling>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># ChromeDriver 경로를 설치하고 Service 객체로 전달</span>
</span></span><span style=display:flex><span>chrome_service <span style=color:#f92672>=</span> Service(ChromeDriverManager()<span style=color:#f92672>.</span>install())
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>try</span>:
</span></span><span style=display:flex><span>    <span style=color:#75715e># ChromeDriver 실행</span>
</span></span><span style=display:flex><span>    crawler <span style=color:#f92672>=</span> webdriver<span style=color:#f92672>.</span>Chrome(service<span style=color:#f92672>=</span>chrome_service)
</span></span><span style=display:flex><span><span style=color:#66d9ef>except</span>:
</span></span><span style=display:flex><span>    <span style=color:#75715e># 크롬드라이버가 없을 때 autoinstaller로 설치</span>
</span></span><span style=display:flex><span>    chromedriver_autoinstaller<span style=color:#f92672>.</span>install(<span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>    crawler <span style=color:#f92672>=</span> webdriver<span style=color:#f92672>.</span>Chrome(service<span style=color:#f92672>=</span>chrome_service)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>crawler<span style=color:#f92672>.</span>implicitly_wait(<span style=color:#ae81ff>6</span>)  <span style=color:#75715e># 크롤러 대기 시간 설정</span>
</span></span><span style=display:flex><span>crawler<span style=color:#f92672>.</span>get(<span style=color:#e6db74>&#39;https://gisaid.org/&#39;</span>)  <span style=color:#75715e># 웹사이트 열기</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># login 선택</span>
</span></span><span style=display:flex><span>engine <span style=color:#f92672>=</span> WebDriverWait(crawler, <span style=color:#ae81ff>10</span>)<span style=color:#f92672>.</span>until(EC<span style=color:#f92672>.</span>element_to_be_clickable((By<span style=color:#f92672>.</span>XPATH, <span style=color:#e6db74>&#39;//*[@id=&#34;menuequer&#34;]/li[7]/a&#39;</span>)))
</span></span><span style=display:flex><span>engine<span style=color:#f92672>.</span>click()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># id 입력</span>
</span></span><span style=display:flex><span>WebDriverWait(crawler, <span style=color:#ae81ff>10</span>)<span style=color:#f92672>.</span>until(EC<span style=color:#f92672>.</span>element_to_be_clickable((By<span style=color:#f92672>.</span>XPATH, <span style=color:#e6db74>&#39;//*[@id=&#34;elogin&#34;]&#39;</span>)))
</span></span><span style=display:flex><span>engine <span style=color:#f92672>=</span> crawler<span style=color:#f92672>.</span>find_element(By<span style=color:#f92672>.</span>XPATH, <span style=color:#e6db74>&#39;//*[@id=&#34;elogin&#34;]&#39;</span>)
</span></span><span style=display:flex><span>crawler<span style=color:#f92672>.</span>execute_script(<span style=color:#e6db74>&#34;arguments[0].click();&#34;</span>, engine)
</span></span><span style=display:flex><span>engine<span style=color:#f92672>.</span>send_keys(<span style=color:#e6db74>&#39;*&#39;</span>) <span style=color:#75715e># *: id 블라인드 처리</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># pw 입력</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#WebDriverWait(crawler, 10).until(EC.element_to_be_clickable((By.XPATH, &#39;//*[@id=&#34;login&#34;]/div[2]/br[3]&#39;)))</span>
</span></span><span style=display:flex><span>engine <span style=color:#f92672>=</span> crawler<span style=color:#f92672>.</span>find_element(By<span style=color:#f92672>.</span>XPATH, <span style=color:#e6db74>&#39;//*[@id=&#34;epassword&#34;]&#39;</span>)
</span></span><span style=display:flex><span>crawler<span style=color:#f92672>.</span>execute_script(<span style=color:#e6db74>&#34;arguments[0].click();&#34;</span>, engine)
</span></span><span style=display:flex><span>engine<span style=color:#f92672>.</span>send_keys(<span style=color:#e6db74>&#39;*&#39;</span>)  <span style=color:#75715e># *: pw 블라인드 처리</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>#engine = crawler.find_element(By.XPATH, &#39;//*[@id=&#34;login&#34;]/div[2]/input[3]&#39;)</span>
</span></span><span style=display:flex><span>engine <span style=color:#f92672>=</span> WebDriverWait(crawler, <span style=color:#ae81ff>10</span>)<span style=color:#f92672>.</span>until(EC<span style=color:#f92672>.</span>element_to_be_clickable((By<span style=color:#f92672>.</span>XPATH, <span style=color:#e6db74>&#39;//*[@id=&#34;login&#34;]/div[2]/input[3]&#39;</span>)))
</span></span><span style=display:flex><span>engine<span style=color:#f92672>.</span>click()
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># epiflu 선택</span>
</span></span><span style=display:flex><span>engine <span style=color:#f92672>=</span> crawler<span style=color:#f92672>.</span>find_element(By<span style=color:#f92672>.</span>XPATH, <span style=color:#e6db74>&#39;//*[@id=&#34;main_nav&#34;]/ul/li[2]/a&#39;</span>)
</span></span><span style=display:flex><span>engine<span style=color:#f92672>.</span>click()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># search&amp;browse 선택</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#engine = crawler.find_element(By.XPATH, &#39;//*[@id=&#34;c_sjk17x_ey-c_sjk17x_ey&#34;]/div/div/div[7]/div&#39;)</span>
</span></span><span style=display:flex><span>engine <span style=color:#f92672>=</span> crawler<span style=color:#f92672>.</span>find_element(By<span style=color:#f92672>.</span>XPATH, <span style=color:#e6db74>&#39;//*[@id=&#34;c_sjlgnx_11g-c_sjlgnx_11g&#34;]/div/div/div[7]/div&#39;</span>)
</span></span><span style=display:flex><span><span style=color:#75715e>#engine = WebDriverWait(crawler, 10).until(EC.element_to_be_clickable((By.XPATH, &#39;//*[@id=&#34;c_sjk17x_ey-c_sjk17x_ey&#34;]/div/div/div[7]/div&#39;)))</span>
</span></span><span style=display:flex><span>engine<span style=color:#f92672>.</span>click()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># collection-date 선택</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#engine = crawler.find_element(By.XPATH, &#39;//*[@id=&#34;ce_sjk17x_q_input&#34;]&#39;) </span>
</span></span><span style=display:flex><span>engine <span style=color:#f92672>=</span> crawler<span style=color:#f92672>.</span>find_element(By<span style=color:#f92672>.</span>XPATH, <span style=color:#e6db74>&#39;//*[@id=&#34;ce_sjlgnx_hv_input&#34;]&#39;</span>)
</span></span><span style=display:flex><span>engine<span style=color:#f92672>.</span>click()
</span></span><span style=display:flex><span>engine<span style=color:#f92672>.</span>send_keys(<span style=color:#e6db74>&#39;2024-01-01&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>#engine = crawler.find_element(By.XPATH, &#39;//*[@id=&#34;ce_sjk17x_r_input&#34;]&#39;) </span>
</span></span><span style=display:flex><span>engine <span style=color:#f92672>=</span> crawler<span style=color:#f92672>.</span>find_element(By<span style=color:#f92672>.</span>XPATH, <span style=color:#e6db74>&#39;//*[@id=&#34;ce_sjlgnx_hw_input&#34;]&#39;</span>)
</span></span><span style=display:flex><span>engine<span style=color:#f92672>.</span>click()
</span></span><span style=display:flex><span>engine<span style=color:#f92672>.</span>send_keys(<span style=color:#e6db74>&#39;2024-02-01&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># search 선택</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#engine = WebDriverWait(crawler, 10).until(EC.element_to_be_clickable((By.XPATH, &#39;//*[@id=&#34;ce_sjk17x_1p&#34;]/div/button&#39;)))</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#engine.click()</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#engine = crawler.find_element(By.XPATH, &#39;//*[@id=&#34;ce_sjlgnx_iu&#34;]/div/button&#39;) </span>
</span></span><span style=display:flex><span>engine <span style=color:#f92672>=</span> WebDriverWait(crawler, <span style=color:#ae81ff>10</span>)<span style=color:#f92672>.</span>until(EC<span style=color:#f92672>.</span>element_to_be_clickable((By<span style=color:#f92672>.</span>XPATH, <span style=color:#e6db74>&#39;//*[@id=&#34;ce_sjlgnx_iu&#34;]/div/button&#39;</span>)))
</span></span><span style=display:flex><span>engine<span style=color:#f92672>.</span>click()
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># check all</span>
</span></span><span style=display:flex><span>engine <span style=color:#f92672>=</span> crawler<span style=color:#f92672>.</span>find_element(By<span style=color:#f92672>.</span>XPATH, <span style=color:#e6db74>&#39;//*[@id=&#34;yui-dt0-th-c-liner&#34;]/span/input&#39;</span>)
</span></span><span style=display:flex><span>engine<span style=color:#f92672>.</span>click()
</span></span></code></pre></div><h1><a class=anchor href=#>#</a></h1><ul><li>분명 알고리즘 개발에는 22만개 sequence를 사용했는데 validation set으로 190만개 sequence를 쓰는게 맞았을까 생각했던작업</li><li>그와중에 GISAID의 xpath가 매일 업데이트돼서 매일아침 코드 수정해가면서 돌렸던기억이 있다</li><li>그리구 이상한게 핫스팟연결하면 오류나가지고 이기간엔 라운지도 못가고 연구실에만 있었어야했다..</li></ul><h1><a class=anchor href=#>#</a></h1></article><footer class=book-footer><div class="flex flex-wrap justify-between"></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments><script src=https://giscus.app/client.js data-repo=yshghid/yshghid.github.io data-repo-id=R_kgDONkMkNg data-category-id=DIC_kwDONkMkNs4CloJh data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=ko crossorigin=anonymous async></script></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><ul><li><a href=#1-load-package>1. Load package</a></li><li></li><li><a href=#2-set-path>2. Set path</a></li><li></li><li><a href=#3-run-crawling>3. Run crawling</a></li></ul></li></ul></nav></div></aside></main></body></html>