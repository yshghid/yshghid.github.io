<!doctype html><html lang=en-us dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="
  TFT PyTorch Forecasting - Stallion 튜토리얼
  #

#2025-05-28

#introduction

데이터셋: Kaggle - Stallion 데이터셋
목적: Temporal Fusion Transformer(TFT)를 활용하여 음료 판매량을 예측

#install
$ nvidia-smi
Wed May 28 14:00:07 2025       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA RTX A6000               Off | 00000000:3B:00.0 Off |                  Off |
| 30%   59C    P2             204W / 300W |   8339MiB / 49140MiB |     95%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
|   1  NVIDIA RTX A6000               Off | 00000000:5E:00.0 Off |                  Off |
| 30%   60C    P2             213W / 300W |   6897MiB / 49140MiB |     94%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
|   2  NVIDIA RTX A6000               Off | 00000000:B1:00.0 Off |                  Off |
| 30%   60C    P2             203W / 300W |   6799MiB / 49140MiB |     94%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
|   3  NVIDIA RTX A6000               Off | 00000000:D9:00.0 Off |                  Off |
| 32%   63C    P2             212W / 300W |   6885MiB / 49140MiB |     96%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A     20199      C   ...dg/miniconda3/envs/woodg/bin/python      664MiB |
|    0   N/A  N/A    860801      C   ...jyj/miniconda3/envs/TiCC/bin/python      338MiB |
|    0   N/A  N/A   1201205      C   ...u1098/anaconda3/envs/dna/bin/python     6198MiB |
|    0   N/A  N/A   1216286      C   ...jyj/miniconda3/envs/TiCC/bin/python      338MiB |
|    0   N/A  N/A   1225349      C   python                                      782MiB |
|    1   N/A  N/A   1201206      C   ...u1098/anaconda3/envs/dna/bin/python     6104MiB |
|    1   N/A  N/A   1224607      C   python                                      782MiB |
|    2   N/A  N/A   1201207      C   ...u1098/anaconda3/envs/dna/bin/python     6006MiB |
|    2   N/A  N/A   1224848      C   python                                      782MiB |
|    3   N/A  N/A   1201208      C   ...u1098/anaconda3/envs/dna/bin/python     6092MiB |
|    3   N/A  N/A   1225121      C   python                                      782MiB |
+---------------------------------------------------------------------------------------+


NVIDIA 드라이버 버전: 545.23.08"><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="https://yshghid.github.io/docs/study/tech/tech12/"><meta property="og:site_name" content=" "><meta property="og:title" content="TFT PyTorch Forecasting - Stallion 튜토리얼"><meta property="og:description" content="TFT PyTorch Forecasting - Stallion 튜토리얼 # #2025-05-28
#introduction
데이터셋: Kaggle - Stallion 데이터셋 목적: Temporal Fusion Transformer(TFT)를 활용하여 음료 판매량을 예측 #install
$ nvidia-smi Wed May 28 14:00:07 2025 +---------------------------------------------------------------------------------------+ | NVIDIA-SMI 545.23.08 Driver Version: 545.23.08 CUDA Version: 12.3 | |-----------------------------------------+----------------------+----------------------+ | GPU Name Persistence-M | Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap | Memory-Usage | GPU-Util Compute M. | | | | MIG M. | |=========================================+======================+======================| | 0 NVIDIA RTX A6000 Off | 00000000:3B:00.0 Off | Off | | 30% 59C P2 204W / 300W | 8339MiB / 49140MiB | 95% Default | | | | N/A | +-----------------------------------------+----------------------+----------------------+ | 1 NVIDIA RTX A6000 Off | 00000000:5E:00.0 Off | Off | | 30% 60C P2 213W / 300W | 6897MiB / 49140MiB | 94% Default | | | | N/A | +-----------------------------------------+----------------------+----------------------+ | 2 NVIDIA RTX A6000 Off | 00000000:B1:00.0 Off | Off | | 30% 60C P2 203W / 300W | 6799MiB / 49140MiB | 94% Default | | | | N/A | +-----------------------------------------+----------------------+----------------------+ | 3 NVIDIA RTX A6000 Off | 00000000:D9:00.0 Off | Off | | 32% 63C P2 212W / 300W | 6885MiB / 49140MiB | 96% Default | | | | N/A | +-----------------------------------------+----------------------+----------------------+ +---------------------------------------------------------------------------------------+ | Processes: | | GPU GI CI PID Type Process name GPU Memory | | ID ID Usage | |=======================================================================================| | 0 N/A N/A 20199 C ...dg/miniconda3/envs/woodg/bin/python 664MiB | | 0 N/A N/A 860801 C ...jyj/miniconda3/envs/TiCC/bin/python 338MiB | | 0 N/A N/A 1201205 C ...u1098/anaconda3/envs/dna/bin/python 6198MiB | | 0 N/A N/A 1216286 C ...jyj/miniconda3/envs/TiCC/bin/python 338MiB | | 0 N/A N/A 1225349 C python 782MiB | | 1 N/A N/A 1201206 C ...u1098/anaconda3/envs/dna/bin/python 6104MiB | | 1 N/A N/A 1224607 C python 782MiB | | 2 N/A N/A 1201207 C ...u1098/anaconda3/envs/dna/bin/python 6006MiB | | 2 N/A N/A 1224848 C python 782MiB | | 3 N/A N/A 1201208 C ...u1098/anaconda3/envs/dna/bin/python 6092MiB | | 3 N/A N/A 1225121 C python 782MiB | +---------------------------------------------------------------------------------------+ NVIDIA 드라이버 버전: 545.23.08"><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="docs"><meta property="article:published_time" content="2025-05-28T00:00:00+00:00"><meta property="article:modified_time" content="2025-05-28T00:00:00+00:00"><meta property="article:tag" content="2025-05"><title>TFT PyTorch Forecasting - Stallion 튜토리얼 |</title><link rel=icon href=/favicon.png><link rel=manifest href=/manifest.json><link rel=canonical href=https://yshghid.github.io/docs/study/tech/tech12/><link rel=stylesheet href=/book.min.6217d077edb4189fd0578345e84bca1a884dfdee121ff8dc9a0f55cfe0852bc9.css integrity="sha256-YhfQd+20GJ/QV4NF6EvKGohN/e4SH/jcmg9Vz+CFK8k=" crossorigin=anonymous><script defer src=/fuse.min.js></script><script defer src=/en.search.min.578a2d8e6e30e0a0ae3682797882d89ca0cbbf1734d206705396ea76cf57bbb6.js integrity="sha256-V4otjm4w4KCuNoJ5eILYnKDLvxc00gZwU5bqds9Xu7Y=" crossorigin=anonymous></script></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><img src=/logo.png alt=Logo class=book-icon><span></span></a></h2><div class="book-search hidden"><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><script>document.querySelector(".book-search").classList.remove("hidden")</script><ul><li class=book-section-flat><span>기록</span><ul><li><a href=/docs/hobby/book/>글</a><ul></ul></li><li><a href=/docs/hobby/daily/>일상</a><ul></ul></li></ul></li><li class=book-section-flat><span>공부</span><ul><li><a href=/docs/study/bioinformatics/>Bioinformatics</a><ul></ul></li><li><a href=/docs/study/ai/>AI</a><ul></ul></li><li><a href=/docs/study/sw/>SW</a><ul></ul></li><li><a href=/docs/study/algorithm/>알고리즘</a><ul></ul></li><li><a href=/docs/study/career/>취업</a><ul></ul></li></ul></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu></label><h3>TFT PyTorch Forecasting - Stallion 튜토리얼</h3><label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents></nav></aside></header><article class="markdown book-article"><h1 id=tft-pytorch-forecasting---stallion-튜토리얼>TFT PyTorch Forecasting - Stallion 튜토리얼
<a class=anchor href=#tft-pytorch-forecasting---stallion-%ed%8a%9c%ed%86%a0%eb%a6%ac%ec%96%bc>#</a></h1><p>#2025-05-28</p><hr><p>#introduction</p><ul><li>데이터셋: <a href=https://www.kaggle.com/datasets/utathya/future-volume-prediction>Kaggle - Stallion 데이터셋</a></li><li>목적: Temporal Fusion Transformer(TFT)를 활용하여 음료 판매량을 예측</li></ul><p>#install</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>$ nvidia-smi
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-plain data-lang=plain><span class=line><span class=cl>Wed May 28 14:00:07 2025       
</span></span><span class=line><span class=cl>+---------------------------------------------------------------------------------------+
</span></span><span class=line><span class=cl>| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |
</span></span><span class=line><span class=cl>|-----------------------------------------+----------------------+----------------------+
</span></span><span class=line><span class=cl>| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
</span></span><span class=line><span class=cl>| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
</span></span><span class=line><span class=cl>|                                         |                      |               MIG M. |
</span></span><span class=line><span class=cl>|=========================================+======================+======================|
</span></span><span class=line><span class=cl>|   0  NVIDIA RTX A6000               Off | 00000000:3B:00.0 Off |                  Off |
</span></span><span class=line><span class=cl>| 30%   59C    P2             204W / 300W |   8339MiB / 49140MiB |     95%      Default |
</span></span><span class=line><span class=cl>|                                         |                      |                  N/A |
</span></span><span class=line><span class=cl>+-----------------------------------------+----------------------+----------------------+
</span></span><span class=line><span class=cl>|   1  NVIDIA RTX A6000               Off | 00000000:5E:00.0 Off |                  Off |
</span></span><span class=line><span class=cl>| 30%   60C    P2             213W / 300W |   6897MiB / 49140MiB |     94%      Default |
</span></span><span class=line><span class=cl>|                                         |                      |                  N/A |
</span></span><span class=line><span class=cl>+-----------------------------------------+----------------------+----------------------+
</span></span><span class=line><span class=cl>|   2  NVIDIA RTX A6000               Off | 00000000:B1:00.0 Off |                  Off |
</span></span><span class=line><span class=cl>| 30%   60C    P2             203W / 300W |   6799MiB / 49140MiB |     94%      Default |
</span></span><span class=line><span class=cl>|                                         |                      |                  N/A |
</span></span><span class=line><span class=cl>+-----------------------------------------+----------------------+----------------------+
</span></span><span class=line><span class=cl>|   3  NVIDIA RTX A6000               Off | 00000000:D9:00.0 Off |                  Off |
</span></span><span class=line><span class=cl>| 32%   63C    P2             212W / 300W |   6885MiB / 49140MiB |     96%      Default |
</span></span><span class=line><span class=cl>|                                         |                      |                  N/A |
</span></span><span class=line><span class=cl>+-----------------------------------------+----------------------+----------------------+
</span></span><span class=line><span class=cl>                                                                                         
</span></span><span class=line><span class=cl>+---------------------------------------------------------------------------------------+
</span></span><span class=line><span class=cl>| Processes:                                                                            |
</span></span><span class=line><span class=cl>|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
</span></span><span class=line><span class=cl>|        ID   ID                                                             Usage      |
</span></span><span class=line><span class=cl>|=======================================================================================|
</span></span><span class=line><span class=cl>|    0   N/A  N/A     20199      C   ...dg/miniconda3/envs/woodg/bin/python      664MiB |
</span></span><span class=line><span class=cl>|    0   N/A  N/A    860801      C   ...jyj/miniconda3/envs/TiCC/bin/python      338MiB |
</span></span><span class=line><span class=cl>|    0   N/A  N/A   1201205      C   ...u1098/anaconda3/envs/dna/bin/python     6198MiB |
</span></span><span class=line><span class=cl>|    0   N/A  N/A   1216286      C   ...jyj/miniconda3/envs/TiCC/bin/python      338MiB |
</span></span><span class=line><span class=cl>|    0   N/A  N/A   1225349      C   python                                      782MiB |
</span></span><span class=line><span class=cl>|    1   N/A  N/A   1201206      C   ...u1098/anaconda3/envs/dna/bin/python     6104MiB |
</span></span><span class=line><span class=cl>|    1   N/A  N/A   1224607      C   python                                      782MiB |
</span></span><span class=line><span class=cl>|    2   N/A  N/A   1201207      C   ...u1098/anaconda3/envs/dna/bin/python     6006MiB |
</span></span><span class=line><span class=cl>|    2   N/A  N/A   1224848      C   python                                      782MiB |
</span></span><span class=line><span class=cl>|    3   N/A  N/A   1201208      C   ...u1098/anaconda3/envs/dna/bin/python     6092MiB |
</span></span><span class=line><span class=cl>|    3   N/A  N/A   1225121      C   python                                      782MiB |
</span></span><span class=line><span class=cl>+---------------------------------------------------------------------------------------+
</span></span></code></pre></div><ul><li><p>NVIDIA 드라이버 버전: 545.23.08</p></li><li><p>CUDA 버전: 12.3</p></li><li><p>PyTorch 및 관련 패키지를 설치할 때 CUDA 12.3을 지원하는 버전으로 맞춰야 GPU 사용이 가능.</p><ul><li>CUDA 12.3을 그대로 쓰는 경우 PyTorch GPU 버전과의 호환성이 낮거나 불안정할 수 있어 CUDA 11.7로 설치해준다</li></ul></li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>$ pip install <span class=nv>torch</span><span class=o>==</span>1.13.1+cu117 <span class=nv>torchvision</span><span class=o>==</span>0.14.1+cu117 <span class=nv>torchaudio</span><span class=o>==</span>0.13.1 -f https://download.pytorch.org/whl/torch_stable.html
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>Looking in links: https://download.pytorch.org/whl/torch_stable.html
</span></span><span class=line><span class=cl>Collecting <span class=nv>torch</span><span class=o>==</span>1.13.1+cu117
</span></span><span class=line><span class=cl>  Downloading https://download.pytorch.org/whl/cu117/torch-1.13.1%2Bcu117-cp37-cp37m-linux_x86_64.whl <span class=o>(</span>1801.9 MB<span class=o>)</span>
</span></span><span class=line><span class=cl>     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.8/1.8 GB 1.5 MB/s eta 0:00:00
</span></span><span class=line><span class=cl>Collecting <span class=nv>torchvision</span><span class=o>==</span>0.14.1+cu117
</span></span><span class=line><span class=cl>  Downloading https://download.pytorch.org/whl/cu117/torchvision-0.14.1%2Bcu117-cp37-cp37m-linux_x86_64.whl <span class=o>(</span>24.3 MB<span class=o>)</span>
</span></span><span class=line><span class=cl>     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 24.3/24.3 MB 42.5 MB/s eta 0:00:00
</span></span><span class=line><span class=cl>Collecting <span class=nv>torchaudio</span><span class=o>==</span>0.13.1
</span></span><span class=line><span class=cl>  Downloading https://download.pytorch.org/whl/rocm5.2/torchaudio-0.13.1%2Brocm5.2-cp37-cp37m-linux_x86_64.whl <span class=o>(</span>3.9 MB<span class=o>)</span>
</span></span><span class=line><span class=cl>     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.9/3.9 MB 60.0 MB/s eta 0:00:00
</span></span><span class=line><span class=cl>Requirement already satisfied: typing-extensions in /home/ysh980101/miniconda3/envs/workspace/lib/python3.7/site-packages <span class=o>(</span>from <span class=nv>torch</span><span class=o>==</span>1.13.1+cu117<span class=o>)</span> <span class=o>(</span>4.7.1<span class=o>)</span>
</span></span><span class=line><span class=cl>Requirement already satisfied: numpy in /home/ysh980101/miniconda3/envs/workspace/lib/python3.7/site-packages <span class=o>(</span>from <span class=nv>torchvision</span><span class=o>==</span>0.14.1+cu117<span class=o>)</span> <span class=o>(</span>1.21.6<span class=o>)</span>
</span></span><span class=line><span class=cl>Requirement already satisfied: requests in /home/ysh980101/miniconda3/envs/workspace/lib/python3.7/site-packages <span class=o>(</span>from <span class=nv>torchvision</span><span class=o>==</span>0.14.1+cu117<span class=o>)</span> <span class=o>(</span>2.31.0<span class=o>)</span>
</span></span><span class=line><span class=cl>Requirement already satisfied: pillow!<span class=o>=</span>8.3.*,&gt;<span class=o>=</span>5.3.0 in /home/ysh980101/miniconda3/envs/workspace/lib/python3.7/site-packages <span class=o>(</span>from <span class=nv>torchvision</span><span class=o>==</span>0.14.1+cu117<span class=o>)</span> <span class=o>(</span>9.5.0<span class=o>)</span>
</span></span><span class=line><span class=cl>Requirement already satisfied: charset-normalizer&lt;4,&gt;<span class=o>=</span><span class=m>2</span> in /home/ysh980101/miniconda3/envs/workspace/lib/python3.7/site-packages <span class=o>(</span>from requests-&gt;torchvision<span class=o>==</span>0.14.1+cu117<span class=o>)</span> <span class=o>(</span>3.3.2<span class=o>)</span>
</span></span><span class=line><span class=cl>Requirement already satisfied: certifi&gt;<span class=o>=</span>2017.4.17 in /home/ysh980101/miniconda3/envs/workspace/lib/python3.7/site-packages <span class=o>(</span>from requests-&gt;torchvision<span class=o>==</span>0.14.1+cu117<span class=o>)</span> <span class=o>(</span>2022.12.7<span class=o>)</span>
</span></span><span class=line><span class=cl>Requirement already satisfied: urllib3&lt;3,&gt;<span class=o>=</span>1.21.1 in /home/ysh980101/miniconda3/envs/workspace/lib/python3.7/site-packages <span class=o>(</span>from requests-&gt;torchvision<span class=o>==</span>0.14.1+cu117<span class=o>)</span> <span class=o>(</span>1.26.20<span class=o>)</span>
</span></span><span class=line><span class=cl>Requirement already satisfied: idna&lt;4,&gt;<span class=o>=</span>2.5 in /home/ysh980101/miniconda3/envs/workspace/lib/python3.7/site-packages <span class=o>(</span>from requests-&gt;torchvision<span class=o>==</span>0.14.1+cu117<span class=o>)</span> <span class=o>(</span>3.7<span class=o>)</span>
</span></span><span class=line><span class=cl>Installing collected packages: torch, torchvision, torchaudio
</span></span><span class=line><span class=cl>  Attempting uninstall: torch
</span></span><span class=line><span class=cl>    Found existing installation: torch 1.13.1
</span></span><span class=line><span class=cl>    Uninstalling torch-1.13.1:
</span></span><span class=line><span class=cl>      Successfully uninstalled torch-1.13.1
</span></span><span class=line><span class=cl>Successfully installed torch-1.13.1+cu117 torchaudio-0.13.1+rocm5.2 torchvision-0.14.1+cu117
</span></span></code></pre></div><p>정상 설치 여부 확인</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>python -c <span class=s2>&#34;import torch; print(torch.__version__); print(torch.cuda.is_available()); print(torch.cuda.get_device_name(0) if torch.cuda.is_available() else &#39;No GPU&#39;)&#34;</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>1.13.1+cu117
</span></span><span class=line><span class=cl>True
</span></span><span class=line><span class=cl>NVIDIA RTX A6000
</span></span></code></pre></div><p>문제없이 설치되었다!</p><p>#load package</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>$ pip install lightning
</span></span><span class=line><span class=cl>$ pip install pytorch-forecasting
</span></span><span class=line><span class=cl>$ pip install pyarrow
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>warnings</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>warnings</span><span class=o>.</span><span class=n>filterwarnings</span><span class=p>(</span><span class=s2>&#34;ignore&#34;</span><span class=p>)</span>  <span class=c1># avoid printing out absolute paths</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>copy</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pathlib</span> <span class=kn>import</span> <span class=n>Path</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>warnings</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>lightning.pytorch</span> <span class=k>as</span> <span class=nn>pl</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>lightning.pytorch.callbacks</span> <span class=kn>import</span> <span class=n>EarlyStopping</span><span class=p>,</span> <span class=n>LearningRateMonitor</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>lightning.pytorch.loggers</span> <span class=kn>import</span> <span class=n>TensorBoardLogger</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pytorch_forecasting</span> <span class=kn>import</span> <span class=n>Baseline</span><span class=p>,</span> <span class=n>TemporalFusionTransformer</span><span class=p>,</span> <span class=n>TimeSeriesDataSet</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pytorch_forecasting.data</span> <span class=kn>import</span> <span class=n>GroupNormalizer</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pytorch_forecasting.metrics</span> <span class=kn>import</span> <span class=n>MAE</span><span class=p>,</span> <span class=n>SMAPE</span><span class=p>,</span> <span class=n>PoissonLoss</span><span class=p>,</span> <span class=n>QuantileLoss</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pytorch_forecasting.models.temporal_fusion_transformer.tuning</span> <span class=kn>import</span> <span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>optimize_hyperparameters</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span></code></pre></div><p>#load data</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pytorch_forecasting.data.examples</span> <span class=kn>import</span> <span class=n>get_stallion_data</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>data</span> <span class=o>=</span> <span class=n>get_stallion_data</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># add time index</span>
</span></span><span class=line><span class=cl><span class=n>data</span><span class=p>[</span><span class=s2>&#34;time_idx&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>data</span><span class=p>[</span><span class=s2>&#34;date&#34;</span><span class=p>]</span><span class=o>.</span><span class=n>dt</span><span class=o>.</span><span class=n>year</span> <span class=o>*</span> <span class=mi>12</span> <span class=o>+</span> <span class=n>data</span><span class=p>[</span><span class=s2>&#34;date&#34;</span><span class=p>]</span><span class=o>.</span><span class=n>dt</span><span class=o>.</span><span class=n>month</span>
</span></span><span class=line><span class=cl><span class=n>data</span><span class=p>[</span><span class=s2>&#34;time_idx&#34;</span><span class=p>]</span> <span class=o>-=</span> <span class=n>data</span><span class=p>[</span><span class=s2>&#34;time_idx&#34;</span><span class=p>]</span><span class=o>.</span><span class=n>min</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># add additional features</span>
</span></span><span class=line><span class=cl><span class=n>data</span><span class=p>[</span><span class=s2>&#34;month&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>data</span><span class=o>.</span><span class=n>date</span><span class=o>.</span><span class=n>dt</span><span class=o>.</span><span class=n>month</span><span class=o>.</span><span class=n>astype</span><span class=p>(</span><span class=nb>str</span><span class=p>)</span><span class=o>.</span><span class=n>astype</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;category&#34;</span>
</span></span><span class=line><span class=cl><span class=p>)</span>  <span class=c1># categories have be strings</span>
</span></span><span class=line><span class=cl><span class=n>data</span><span class=p>[</span><span class=s2>&#34;log_volume&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>log</span><span class=p>(</span><span class=n>data</span><span class=o>.</span><span class=n>volume</span> <span class=o>+</span> <span class=mf>1e-8</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>data</span><span class=p>[</span><span class=s2>&#34;avg_volume_by_sku&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>data</span><span class=o>.</span><span class=n>groupby</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=s2>&#34;time_idx&#34;</span><span class=p>,</span> <span class=s2>&#34;sku&#34;</span><span class=p>],</span> <span class=n>observed</span><span class=o>=</span><span class=kc>True</span>
</span></span><span class=line><span class=cl><span class=p>)</span><span class=o>.</span><span class=n>volume</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=s2>&#34;mean&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>data</span><span class=p>[</span><span class=s2>&#34;avg_volume_by_agency&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>data</span><span class=o>.</span><span class=n>groupby</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=s2>&#34;time_idx&#34;</span><span class=p>,</span> <span class=s2>&#34;agency&#34;</span><span class=p>],</span> <span class=n>observed</span><span class=o>=</span><span class=kc>True</span>
</span></span><span class=line><span class=cl><span class=p>)</span><span class=o>.</span><span class=n>volume</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=s2>&#34;mean&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># we want to encode special days as one variable and thus need to first reverse one-hot encoding</span>
</span></span><span class=line><span class=cl><span class=n>special_days</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;easter_day&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;good_friday&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;new_year&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;christmas&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;labor_day&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;independence_day&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;revolution_day_memorial&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;regional_games&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;fifa_u_17_world_cup&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;football_gold_cup&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;beer_capital&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;music_fest&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>data</span><span class=p>[</span><span class=n>special_days</span><span class=p>]</span> <span class=o>=</span> <span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>data</span><span class=p>[</span><span class=n>special_days</span><span class=p>]</span><span class=o>.</span><span class=n>apply</span><span class=p>(</span><span class=k>lambda</span> <span class=n>x</span><span class=p>:</span> <span class=n>x</span><span class=o>.</span><span class=n>map</span><span class=p>({</span><span class=mi>0</span><span class=p>:</span> <span class=s2>&#34;-&#34;</span><span class=p>,</span> <span class=mi>1</span><span class=p>:</span> <span class=n>x</span><span class=o>.</span><span class=n>name</span><span class=p>}))</span><span class=o>.</span><span class=n>astype</span><span class=p>(</span><span class=s2>&#34;category&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>data</span><span class=o>.</span><span class=n>sample</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>521</span><span class=p>)</span>
</span></span></code></pre></div><p><img src=https://github.com/user-attachments/assets/e27cc10a-d51a-4182-9324-04f009ffb41b alt=image></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>data</span><span class=o>.</span><span class=n>describe</span><span class=p>()</span>
</span></span></code></pre></div><p><img src=https://github.com/user-attachments/assets/fbffee77-5b44-4004-8f9b-0d3d3698a439 alt=image></p><p>#Create dataset and dataloaders</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>max_prediction_length</span> <span class=o>=</span> <span class=mi>6</span>
</span></span><span class=line><span class=cl><span class=n>max_encoder_length</span> <span class=o>=</span> <span class=mi>24</span>
</span></span><span class=line><span class=cl><span class=n>training_cutoff</span> <span class=o>=</span> <span class=n>data</span><span class=p>[</span><span class=s2>&#34;time_idx&#34;</span><span class=p>]</span><span class=o>.</span><span class=n>max</span><span class=p>()</span> <span class=o>-</span> <span class=n>max_prediction_length</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>training</span> <span class=o>=</span> <span class=n>TimeSeriesDataSet</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>data</span><span class=p>[</span><span class=k>lambda</span> <span class=n>x</span><span class=p>:</span> <span class=n>x</span><span class=o>.</span><span class=n>time_idx</span> <span class=o>&lt;=</span> <span class=n>training_cutoff</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=n>time_idx</span><span class=o>=</span><span class=s2>&#34;time_idx&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>target</span><span class=o>=</span><span class=s2>&#34;volume&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>group_ids</span><span class=o>=</span><span class=p>[</span><span class=s2>&#34;agency&#34;</span><span class=p>,</span> <span class=s2>&#34;sku&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=n>min_encoder_length</span><span class=o>=</span><span class=n>max_encoder_length</span>
</span></span><span class=line><span class=cl>    <span class=o>//</span> <span class=mi>2</span><span class=p>,</span>  <span class=c1># keep encoder length long (as it is in the validation set)</span>
</span></span><span class=line><span class=cl>    <span class=n>max_encoder_length</span><span class=o>=</span><span class=n>max_encoder_length</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>min_prediction_length</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>max_prediction_length</span><span class=o>=</span><span class=n>max_prediction_length</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>static_categoricals</span><span class=o>=</span><span class=p>[</span><span class=s2>&#34;agency&#34;</span><span class=p>,</span> <span class=s2>&#34;sku&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=n>static_reals</span><span class=o>=</span><span class=p>[</span><span class=s2>&#34;avg_population_2017&#34;</span><span class=p>,</span> <span class=s2>&#34;avg_yearly_household_income_2017&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=n>time_varying_known_categoricals</span><span class=o>=</span><span class=p>[</span><span class=s2>&#34;special_days&#34;</span><span class=p>,</span> <span class=s2>&#34;month&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=n>variable_groups</span><span class=o>=</span><span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;special_days&#34;</span><span class=p>:</span> <span class=n>special_days</span>
</span></span><span class=line><span class=cl>    <span class=p>},</span>  <span class=c1># group of categorical variables can be treated as one variable</span>
</span></span><span class=line><span class=cl>    <span class=n>time_varying_known_reals</span><span class=o>=</span><span class=p>[</span><span class=s2>&#34;time_idx&#34;</span><span class=p>,</span> <span class=s2>&#34;price_regular&#34;</span><span class=p>,</span> <span class=s2>&#34;discount_in_percent&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=n>time_varying_unknown_categoricals</span><span class=o>=</span><span class=p>[],</span>
</span></span><span class=line><span class=cl>    <span class=n>time_varying_unknown_reals</span><span class=o>=</span><span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;volume&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;log_volume&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;industry_volume&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;soda_volume&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;avg_max_temp&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;avg_volume_by_agency&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;avg_volume_by_sku&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=n>target_normalizer</span><span class=o>=</span><span class=n>GroupNormalizer</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>groups</span><span class=o>=</span><span class=p>[</span><span class=s2>&#34;agency&#34;</span><span class=p>,</span> <span class=s2>&#34;sku&#34;</span><span class=p>],</span> <span class=n>transformation</span><span class=o>=</span><span class=s2>&#34;softplus&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>),</span>  <span class=c1># use softplus and normalize by group</span>
</span></span><span class=line><span class=cl>    <span class=n>add_relative_time_idx</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>add_target_scales</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>add_encoder_length</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># create validation set (predict=True) which means to predict the last max_prediction_length points in time</span>
</span></span><span class=line><span class=cl><span class=c1># for each series</span>
</span></span><span class=line><span class=cl><span class=n>validation</span> <span class=o>=</span> <span class=n>TimeSeriesDataSet</span><span class=o>.</span><span class=n>from_dataset</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>training</span><span class=p>,</span> <span class=n>data</span><span class=p>,</span> <span class=n>predict</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>stop_randomization</span><span class=o>=</span><span class=kc>True</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># create dataloaders for model</span>
</span></span><span class=line><span class=cl><span class=n>batch_size</span> <span class=o>=</span> <span class=mi>128</span>  <span class=c1># set this between 32 to 128</span>
</span></span><span class=line><span class=cl><span class=n>train_dataloader</span> <span class=o>=</span> <span class=n>training</span><span class=o>.</span><span class=n>to_dataloader</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>train</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>batch_size</span><span class=o>=</span><span class=n>batch_size</span><span class=p>,</span> <span class=n>num_workers</span><span class=o>=</span><span class=mi>0</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>val_dataloader</span> <span class=o>=</span> <span class=n>validation</span><span class=o>.</span><span class=n>to_dataloader</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>train</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> <span class=n>batch_size</span><span class=o>=</span><span class=n>batch_size</span> <span class=o>*</span> <span class=mi>10</span><span class=p>,</span> <span class=n>num_workers</span><span class=o>=</span><span class=mi>0</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span></code></pre></div><p>#Create baseline model</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># calculate baseline mean absolute error, i.e. predict next value as the last available value from the history</span>
</span></span><span class=line><span class=cl><span class=n>baseline_predictions</span> <span class=o>=</span> <span class=n>Baseline</span><span class=p>()</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>val_dataloader</span><span class=p>,</span> <span class=n>return_y</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>MAE</span><span class=p>()(</span><span class=n>baseline_predictions</span><span class=o>.</span><span class=n>output</span><span class=p>,</span> <span class=n>baseline_predictions</span><span class=o>.</span><span class=n>y</span><span class=p>)</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-plain data-lang=plain><span class=line><span class=cl>---------------------------------------------------------------------------
</span></span><span class=line><span class=cl>TypeError                                 Traceback (most recent call last)
</span></span><span class=line><span class=cl>/tmp/ipykernel_1239848/2174382858.py in &lt;module&gt;
</span></span><span class=line><span class=cl>      1 # calculate baseline mean absolute error, i.e. predict next value as the last available value from the history
</span></span><span class=line><span class=cl>----&gt; 2 baseline_predictions = Baseline().predict(val_dataloader, return_y=True)
</span></span><span class=line><span class=cl>      3 MAE()(baseline_predictions.output, baseline_predictions.y)
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>~/miniconda3/envs/workspace/lib/python3.7/site-packages/pytorch_forecasting/models/base_model.py in predict(self, data, mode, return_index, return_decoder_lengths, batch_size, num_workers, fast_dev_run, show_progress_bar, return_x, mode_kwargs, **kwargs)
</span></span><span class=line><span class=cl>   1157 
</span></span><span class=line><span class=cl>   1158                 # make prediction
</span></span><span class=line><span class=cl>-&gt; 1159                 out = self(x, **kwargs)  # raw output is dictionary
</span></span><span class=line><span class=cl>   1160 
</span></span><span class=line><span class=cl>   1161                 lengths = x[&#34;decoder_lengths&#34;]
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>~/miniconda3/envs/workspace/lib/python3.7/site-packages/torch/nn/modules/module.py in _call_impl(self, *input, **kwargs)
</span></span><span class=line><span class=cl>   1192         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
</span></span><span class=line><span class=cl>   1193                 or _global_forward_hooks or _global_forward_pre_hooks):
</span></span><span class=line><span class=cl>-&gt; 1194             return forward_call(*input, **kwargs)
</span></span><span class=line><span class=cl>   1195         # Do not call functions when jit is used
</span></span><span class=line><span class=cl>   1196         full_backward_hooks, non_full_backward_hooks = [], []
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>TypeError: forward() got an unexpected keyword argument &#39;return_y&#39;
</span></span></code></pre></div><ul><li>왜인지 모르겠지만 <code>baseline_predictions = Baseline().predict(val_dataloader, return_y=True)</code>에서 return_y라는 인자는 안받는다고함.<ul><li>return_y=True를 빼고 <code>Baseline().predict(val_dataloader)</code>만 사용하면 예측값(prediction)만 반환되고 실제값(y)은 반환되지 않음</li><li>return_y=True 결과를 얻으려면 즉 MAE를 계산하려면 직접 val_dataloader에서 y 값을 꺼내도록 코드 수정</li></ul></li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pytorch_forecasting.metrics</span> <span class=kn>import</span> <span class=n>MAE</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pytorch_forecasting.models.baseline</span> <span class=kn>import</span> <span class=n>Baseline</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>baseline_model</span> <span class=o>=</span> <span class=n>Baseline</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>y_pred</span> <span class=o>=</span> <span class=n>baseline_model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>val_dataloader</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>y_true</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>([</span><span class=n>batch</span><span class=p>[</span><span class=mi>0</span><span class=p>][</span><span class=s2>&#34;decoder_target&#34;</span><span class=p>]</span> <span class=k>for</span> <span class=n>batch</span> <span class=ow>in</span> <span class=n>val_dataloader</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>mae</span> <span class=o>=</span> <span class=n>MAE</span><span class=p>()(</span><span class=n>y_pred</span><span class=p>,</span> <span class=n>y_true</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>mae</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-plain data-lang=plain><span class=line><span class=cl>tensor(293.0088)
</span></span></code></pre></div><p>#Train the Temporal Fusion Transformer</p><p>##Find optimal learning rate</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># configure network and trainer</span>
</span></span><span class=line><span class=cl><span class=n>pl</span><span class=o>.</span><span class=n>seed_everything</span><span class=p>(</span><span class=mi>42</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>trainer</span> <span class=o>=</span> <span class=n>pl</span><span class=o>.</span><span class=n>Trainer</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>accelerator</span><span class=o>=</span><span class=s2>&#34;cpu&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=c1># clipping gradients is a hyperparameter and important to prevent divergance</span>
</span></span><span class=line><span class=cl>    <span class=c1># of the gradient for recurrent neural networks</span>
</span></span><span class=line><span class=cl>    <span class=n>gradient_clip_val</span><span class=o>=</span><span class=mf>0.1</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>tft</span> <span class=o>=</span> <span class=n>TemporalFusionTransformer</span><span class=o>.</span><span class=n>from_dataset</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>training</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=c1># not meaningful for finding the learning rate but otherwise very important</span>
</span></span><span class=line><span class=cl>    <span class=n>learning_rate</span><span class=o>=</span><span class=mf>0.03</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>hidden_size</span><span class=o>=</span><span class=mi>8</span><span class=p>,</span>  <span class=c1># most important hyperparameter apart from learning rate</span>
</span></span><span class=line><span class=cl>    <span class=c1># number of attention heads. Set to up to 4 for large datasets</span>
</span></span><span class=line><span class=cl>    <span class=n>attention_head_size</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>dropout</span><span class=o>=</span><span class=mf>0.1</span><span class=p>,</span>  <span class=c1># between 0.1 and 0.3 are good values</span>
</span></span><span class=line><span class=cl>    <span class=n>hidden_continuous_size</span><span class=o>=</span><span class=mi>8</span><span class=p>,</span>  <span class=c1># set to &lt;= hidden_size</span>
</span></span><span class=line><span class=cl>    <span class=n>loss</span><span class=o>=</span><span class=n>QuantileLoss</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>    <span class=n>optimizer</span><span class=o>=</span><span class=s2>&#34;ranger&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=c1># reduce learning rate if no improvement in validation loss after x epochs</span>
</span></span><span class=line><span class=cl>    <span class=c1># reduce_on_plateau_patience=1000,</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Number of parameters in network: </span><span class=si>{</span><span class=n>tft</span><span class=o>.</span><span class=n>size</span><span class=p>()</span> <span class=o>/</span> <span class=mf>1e3</span><span class=si>:</span><span class=s2>.1f</span><span class=si>}</span><span class=s2>k&#34;</span><span class=p>)</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-plain data-lang=plain><span class=line><span class=cl>Global seed set to 42
</span></span><span class=line><span class=cl>GPU available: True (cuda), used: False
</span></span><span class=line><span class=cl>TPU available: False, using: 0 TPU cores
</span></span><span class=line><span class=cl>IPU available: False, using: 0 IPUs
</span></span><span class=line><span class=cl>HPU available: False, using: 0 HPUs
</span></span><span class=line><span class=cl>Number of parameters in network: 13.5k
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># find optimal learning rate</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>lightning.pytorch.tuner</span> <span class=kn>import</span> <span class=n>Tuner</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>res</span> <span class=o>=</span> <span class=n>Tuner</span><span class=p>(</span><span class=n>trainer</span><span class=p>)</span><span class=o>.</span><span class=n>lr_find</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>tft</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>train_dataloaders</span><span class=o>=</span><span class=n>train_dataloader</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>val_dataloaders</span><span class=o>=</span><span class=n>val_dataloader</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>max_lr</span><span class=o>=</span><span class=mf>10.0</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>min_lr</span><span class=o>=</span><span class=mf>1e-6</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;suggested learning rate: </span><span class=si>{</span><span class=n>res</span><span class=o>.</span><span class=n>suggestion</span><span class=p>()</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>fig</span> <span class=o>=</span> <span class=n>res</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>show</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>suggest</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>fig</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-plain data-lang=plain><span class=line><span class=cl>---------------------------------------------------------------------------
</span></span><span class=line><span class=cl>ImportError                               Traceback (most recent call last)
</span></span><span class=line><span class=cl>/tmp/ipykernel_1239848/4268711780.py in &lt;module&gt;
</span></span><span class=line><span class=cl>      1 # find optimal learning rate
</span></span><span class=line><span class=cl>----&gt; 2 from lightning.pytorch.tuner import Tuner
</span></span><span class=line><span class=cl>      3 
</span></span><span class=line><span class=cl>      4 res = Tuner(trainer).lr_find(
</span></span><span class=line><span class=cl>      5     tft,
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>ImportError: cannot import name &#39;Tuner&#39; from &#39;lightning.pytorch.tuner&#39; (/home/ysh980101/miniconda3/envs/workspace/lib/python3.7/site-packages/lightning/pytorch/tuner/__init__.py)
</span></span></code></pre></div><ul><li><code>pip show lightning</code>으로 확인 결과 lightning 버전이 1.9.5이고 lightning.pytorch 패키지 구조가 도입되기 전 버전이어서 오류가 났다</li><li>import를 수정해주고 import한거에 맞춰서 코드도 수정<ul><li>lr_finder 종료 후 자동 복원, 학습률 자동 업데이트 &#171;를 충족하도록 수정했다.</li></ul></li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># find optimal learning rate</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pytorch_lightning</span> <span class=kn>import</span> <span class=n>Trainer</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pytorch_lightning.tuner.tuning</span> <span class=kn>import</span> <span class=n>Tuner</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>tuner</span> <span class=o>=</span> <span class=n>Tuner</span><span class=p>(</span><span class=n>trainer</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>lr_finder</span> <span class=o>=</span> <span class=n>tuner</span><span class=o>.</span><span class=n>lr_find</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>tft</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>train_dataloaders</span><span class=o>=</span><span class=n>train_dataloader</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>val_dataloaders</span><span class=o>=</span><span class=n>val_dataloader</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>min_lr</span><span class=o>=</span><span class=mf>1e-6</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>max_lr</span><span class=o>=</span><span class=mf>10.0</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>update_attr</span><span class=o>=</span><span class=kc>False</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span></code></pre></div><ul><li>왜인지 모르겟는데 수정한 코드에서는 &lsquo;ranger&rsquo;가 안먹어서, 학습률 선택은 다른 optimizer로 하고 선택한 학습률을 ranger optimizer 쓰는 원래 모델에 적용시키는 아래 코드를 챗지피티가 추천해줬다</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pytorch_forecasting.models.temporal_fusion_transformer.tuning</span> <span class=kn>import</span> <span class=n>optimize_hyperparameters</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pytorch_forecasting</span> <span class=kn>import</span> <span class=n>TemporalFusionTransformer</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Ranger 대신 Adam 사용 (lr 찾기 전용)</span>
</span></span><span class=line><span class=cl><span class=n>tft_tmp</span> <span class=o>=</span> <span class=n>TemporalFusionTransformer</span><span class=o>.</span><span class=n>from_dataset</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>training</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>learning_rate</span><span class=o>=</span><span class=mf>0.03</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>hidden_size</span><span class=o>=</span><span class=mi>8</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>attention_head_size</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>dropout</span><span class=o>=</span><span class=mf>0.1</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>hidden_continuous_size</span><span class=o>=</span><span class=mi>8</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>loss</span><span class=o>=</span><span class=n>QuantileLoss</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>    <span class=n>optimizer</span><span class=o>=</span><span class=s2>&#34;adam&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># lr_find()</span>
</span></span><span class=line><span class=cl><span class=n>tuner</span> <span class=o>=</span> <span class=n>Tuner</span><span class=p>(</span><span class=n>trainer</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>lr_finder</span> <span class=o>=</span> <span class=n>tuner</span><span class=o>.</span><span class=n>lr_find</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>tft_tmp</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>train_dataloaders</span><span class=o>=</span><span class=n>train_dataloader</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>val_dataloaders</span><span class=o>=</span><span class=n>val_dataloader</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>min_lr</span><span class=o>=</span><span class=mf>1e-6</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>max_lr</span><span class=o>=</span><span class=mf>10.0</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>suggested_lr</span> <span class=o>=</span> <span class=n>lr_finder</span><span class=o>.</span><span class=n>suggestion</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Suggested LR: </span><span class=si>{</span><span class=n>suggested_lr</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>fig</span> <span class=o>=</span> <span class=n>lr_finder</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>suggest</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>fig</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-plain data-lang=plain><span class=line><span class=cl>Suggested LR: 0.0019498445997580445
</span></span></code></pre></div><p><img src=https://github.com/user-attachments/assets/7a9f568a-21a1-4b23-9617-169c02f79c66 alt=image></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>tft</span><span class=o>.</span><span class=n>hparams</span><span class=o>.</span><span class=n>learning_rate</span> <span class=o>=</span> <span class=n>suggested_lr</span> <span class=c1>#ranger 옵티마이저를 사용하는 원래 tft 모델에 이 학습률을 적용</span>
</span></span></code></pre></div><p>근데 이게 맞나.. 싶어서 버전 맞춰서 다시해볼예정.</p><blockquote><p>코드: <a href=https://pytorch-forecasting.readthedocs.io/en/latest/tutorials/stallion.html>https://pytorch-forecasting.readthedocs.io/en/latest/tutorials/stallion.html</a></p></blockquote></article><footer class=book-footer><div class="flex flex-wrap justify-between"></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments><script src=https://giscus.app/client.js data-repo=yshghid/yshghid.github.io data-repo-id=R_kgDONkMkNg data-category-id=DIC_kwDONkMkNs4CloJh data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=ko crossorigin=anonymous async></script></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents></nav></div></aside></main></body></html>