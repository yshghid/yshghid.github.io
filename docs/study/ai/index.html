<!doctype html><html lang=en-us dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="
  AI
  #


2025-09-22 ⋯ AI #2 HPO, XAI 실습
1. 실습 개요 목적 UCI Breast Cancer 데이터를 로드하고 전처리 후 XGBoost 모델을 구축 및 평가 교차검증(StratifiedKFold, KFold)과 하이퍼파라미터 탐색 기법(RandomizedSearchCV, Optuna)을 비교하여 최적 성능을 도출 SHAP을 활용하여 전역적·집단적·개별적 수준에서 해석력을 확보하고 도메인 지식과 연결  ⋯

2025-09-19 ⋯ AI #1 ML 방법론 기초
#1 ML 방법론 통계기반 방법론은? linear regression이나 logistic regression 같은걸 말함 가설과 근거가 명확히 세워져 있고 데이터가 알고리즘에 맞게 정제돼있고 통계적 유의성으로 결과가 나오는 깔끔한 방식 ML 방법론은? 작은 경연을 열듯 시행착오를 거치며 가장 적합한 모델을 찾는다는 컨셉이다. #2 지도 비지도 준지도 모두 입력 데이터 ⋯"><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="https://yshghid.github.io/docs/study/ai/"><meta property="og:site_name" content=" "><meta property="og:title" content="AI"><meta property="og:description" content="AI # 2025-09-22 ⋯ AI #2 HPO, XAI 실습
1. 실습 개요 목적 UCI Breast Cancer 데이터를 로드하고 전처리 후 XGBoost 모델을 구축 및 평가 교차검증(StratifiedKFold, KFold)과 하이퍼파라미터 탐색 기법(RandomizedSearchCV, Optuna)을 비교하여 최적 성능을 도출 SHAP을 활용하여 전역적·집단적·개별적 수준에서 해석력을 확보하고 도메인 지식과 연결 ⋯
2025-09-19 ⋯ AI #1 ML 방법론 기초
#1 ML 방법론 통계기반 방법론은? linear regression이나 logistic regression 같은걸 말함 가설과 근거가 명확히 세워져 있고 데이터가 알고리즘에 맞게 정제돼있고 통계적 유의성으로 결과가 나오는 깔끔한 방식 ML 방법론은? 작은 경연을 열듯 시행착오를 거치며 가장 적합한 모델을 찾는다는 컨셉이다. #2 지도 비지도 준지도 모두 입력 데이터 ⋯"><meta property="og:locale" content="en_us"><meta property="og:type" content="website"><title>AI |</title><link rel=icon href=/favicon.png><link rel=manifest href=/manifest.json><link rel=canonical href=https://yshghid.github.io/docs/study/ai/><link rel=stylesheet href=/book.min.30a7836b6a89342da3b88e7afd1036166aeced16c8de12df060ded2031837886.css integrity="sha256-MKeDa2qJNC2juI56/RA2Fmrs7RbI3hLfBg3tIDGDeIY=" crossorigin=anonymous><script defer src=/fuse.min.js></script><script defer src=/en.search.min.a4faf8c7eb09d384a77580339df21dfbb4b8776b59ee39bd0b96794f82b7078b.js integrity="sha256-pPr4x+sJ04SndYAznfId+7S4d2tZ7jm9C5Z5T4K3B4s=" crossorigin=anonymous></script><link rel=alternate type=application/rss+xml href=https://yshghid.github.io/docs/study/ai/index.xml title=" "></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><img src=/logo.png alt=Logo class=book-icon><span></span></a></h2><div class="book-search hidden"><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><script>document.querySelector(".book-search").classList.remove("hidden")</script><ul><li class=book-section-flat><span>기록</span><ul><li><a href=/docs/hobby/daily/>일상</a><ul></ul></li><li><a href=/docs/hobby/book/>글</a><ul></ul></li></ul></li><li class=book-section-flat><span>공부</span><ul><li><a href=/docs/study/bioinformatics/>Bioinformatics</a><ul></ul></li><li><a href=/docs/study/ai/ class=active>AI</a><ul></ul></li><li><a href=/docs/study/sw/>SW</a><ul></ul></li><li><a href=/docs/study/algorithm/>알고리즘</a><ul></ul></li><li><a href=/docs/study/career/>취업</a><ul></ul></li></ul></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu></label><h3>AI</h3><label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents></nav></aside></header><article class="markdown book-article"><h1 id=ai>AI
<a class=anchor href=#ai>#</a></h1><hr><p><em>2025-09-22</em> ⋯ AI #2 HPO, XAI 실습</p><p><a href=https://yshghid.github.io/docs/study/ai/ai38/>1. 실습 개요 목적 UCI Breast Cancer 데이터를 로드하고 전처리 후 XGBoost 모델을 구축 및 평가 교차검증(StratifiedKFold, KFold)과 하이퍼파라미터 탐색 기법(RandomizedSearchCV, Optuna)을 비교하여 최적 성능을 도출 SHAP을 활용하여 전역적·집단적·개별적 수준에서 해석력을 확보하고 도메인 지식과 연결 ⋯</a></p><hr><p><em>2025-09-19</em> ⋯ AI #1 ML 방법론 기초</p><p><a href=https://yshghid.github.io/docs/study/ai/ai36/>#1 ML 방법론 통계기반 방법론은? linear regression이나 logistic regression 같은걸 말함 가설과 근거가 명확히 세워져 있고 데이터가 알고리즘에 맞게 정제돼있고 통계적 유의성으로 결과가 나오는 깔끔한 방식 ML 방법론은? 작은 경연을 열듯 시행착오를 거치며 가장 적합한 모델을 찾는다는 컨셉이다. #2 지도 비지도 준지도 모두 입력 데이터 ⋯</a></p><hr><p><em>2025-09-15</em> ⋯ Ray #1 (스터디) Batch Prediction with Ray Core</p><p><a href=https://yshghid.github.io/docs/study/ai/ai34/>스터디때 준비해갔던 Ray Core를 사용해서 batch prediction 수행하는 예제!! batch prediction이 batch를 예측하는건줄알았는데(..) batch로 prediction하는것이었다. 순서는 Task 기반, actor 기반 batch prediction, 그리고 GPU 기반 수행 코드이다. 출처는 Ray Document의 Batch Prediction with Ray Core이다. ⋯</a></p><hr><p><em>2025-09-10</em> ⋯ Langchain #1 (스터디) 노션 데이터로 나만의 RAG 시스템 구축하기</p><p><a href=https://yshghid.github.io/docs/study/ai/ai30/>노션 데이터를 임베딩 생성하여 FAISS 벡터 스토어에 저장하고 이를 기반으로 유사 문서 검색을 수행하며, 청킹 기법을 통해 데이터 구조를 이해하고 LLM 프롬프트 제약을 적용한 뒤, RAG 구조를 접목해 자동 답변 구현 실습 설계 임베딩 생성: SentenceTransformer(&ldquo;BAAI/bge-m3&rdquo;) 유사 문서 검색: 코사인 유사도 + FAISS ⋯</a></p><hr><p><em>2025-08-22</em> ⋯ MLflow #2 mlflow 파이프라인</p><p><a href=https://yshghid.github.io/docs/study/ai/ai25/>1. 코드 #1 트래킹 서버 설정 import os import mlflow 1. 로그를 저장할 서버/위치 지정 mlflow.set_tracking_uri(uri=os.getenv(&ldquo;MLFLOW_TRACKING_URI&rdquo;, &ldquo;&rdquo;)) # MLFLOW_TRACKING_URI로 MLflow 서버를 연결 current_uri = mlflow.get_tracking_uri() print(f"Current Tracking URI ⋯</a></p><hr><p><em>2025-08-21</em> ⋯ MLflow #1 설치 & 실습</p><p><a href=https://yshghid.github.io/docs/study/ai/ai24/>1. mlflow 설치 및 docker 띄우기 $ export CR_PAT=* # *: github token 블라인드 처리 $ echo $CR_PAT | docker login ghcr.io -u yshghid &ndash;password-stdin Login Succeeded 로그인햇으면 도커를 켠다음에 다음을 수행. $ docker pull ghcr.io/mlflow/mlflow:v2.0.1 v2.0.1: Pulling from mlflow ⋯</a></p><hr><p><em>2025-08-19</em> ⋯ LLM #2 LLM과 AI 기술요소를 활용하여 비즈니스 서비스 기획안 작성</p><p><a href=https://yshghid.github.io/docs/study/ai/ai23/>1. 목적 등기부등본/건축물대장 업로드 시 AI가 자동으로 문서를 분석하여 전세사기 위험 요소를 탐지하고 수치화한다. 2. 모델 구성도 #1 데이터 수집및 정규화 기술요소: PaddleOCR 선택 이유: 한국어 인식 정확도와 속도가 좋고, 오픈소스+온프레미스 운영 가능(비용·보안 유리), 표 레이아웃/좌표 추출 지원. 입력 파일: PDF/스캔 이미지(JPG/ ⋯</a></p><hr><p><em>2025-08-19</em> ⋯ 데이터분석 #4 리뷰 데이터 분석</p><p><a href=https://yshghid.github.io/docs/study/ai/ai22/>이제야복습하는 저번주실습 1. 목적 리뷰 데이터를 보고 감성 점수와 평점의 관계 리뷰 길이와 감성 점수의 관계 카테고리별 감성 차이 Review_length가 AI 임베딩 유사도에 영향을 줄 수 있는지 인사이트 생성하기. 2. 코드 import os import pandas as pd import numpy as np import seaborn as sns import matplotlib.pyplot ⋯</a></p><hr><p><em>2025-08-11</em> ⋯ LLM #1 LLM 이해와 Transformer</p><p><a href=https://yshghid.github.io/docs/study/ai/ai21/>1. LLM 기본이해 #1 Word Embedding (p.27-28) Word Embedding 핵심 아이디어는 단어가 어떤 맥락에서 자주 함께 등장하는지를 학습. “you say goodbye and I say hello”에서 ‘goodbye’주변에는 ‘you’, ‘say’, ‘and’, ‘I’ 같은 단어가 함께 등장하고 그 관계를 학습하도록 신경망을 훈련시킨다. 학습이 반복되면 각 단어는 ⋯</a></p><hr><p><em>2025-08-09</em> ⋯ 생성형 AI #2 Prompt Engineering 실습 미리돌려보기</p><p><a href=https://yshghid.github.io/docs/study/ai/ai19/>1. VOC 분석 setting https://openrouter.ai/ Model: GPT-5 Temperature: 0.2 (낮게: 일관성 있는 분류 결과) Top-k / Top-p: default Max tokens: 1024 system prompt 너는 IT 시스템의 평가전문가야. 이번에 개발한 AI를 적용한 회계세무 시스템을 테스트한 고객의 평가내용인 VOC를 분석하는 것이 너의 역할이야 ⋯</a></p><hr><p><em>2025-08-09</em> ⋯ 생성형 AI #1 생성형 AI 기초 및 Prompt Engineering</p><p><a href=https://yshghid.github.io/docs/study/ai/ai18/>#1 RAG (p.27) RAG의 역할? 질문을 LLM에 던지기 전에 knowledge corpus에 질문을 미리 검색한다(회사 데이터에 대한 지식 벡터 db). 질문과 연관된 문서를 찾고 적절하게 만들어서 retrieval 던지면 의도대로 답변이 잘 나온다. #2 LLM 출력 구성 (p.42-45) Output Length (Max Tockens) - 500자로 제한을 걸면 ⋯</a></p><hr><p><em>2025-08-07</em> ⋯ 데이터 분석 #3 회귀분석</p><p><a href=https://yshghid.github.io/docs/study/ai/ai17/>#1 Oversampling Techinique (p.69-71) SMOTE 소수 클래스 포인트 중 하나를 랜덤하게 고르고 이웃 포인트 k개를 찾고 이 이웃들과의 연결선을 따라 중간 어딘가에 새로운 샘플을 만든다. 즉 원본과 이웃 사이에 위치한 점들을 생성한다. SMOTE는 소수 클래스 포인트들 사이의 직선 위에서만 새로운 데이터를 만들기 때문에 실제로는 decision ⋯</a></p><hr><p><em>2025-08-06</em> ⋯ 데이터 분석 #2 Preprocessing</p><p><a href=https://yshghid.github.io/docs/study/ai/ai16/>#1 머신러닝 프로세스 (p.25) test data가 필요한 이유? hyperparameter tuning을 하면서 validation data는 모델이 이미 참고했다 즉 간접적으로 학습에 영향을 줬기 때문에 모델 학습 과정에서 한번도 보지않은 데이터가 필요함. #2 Box plot (p.38) 그림이 7개 차종에서 연비 플롯이라고 가정 투입됏을때 예측에 긍정적영향을 줄수잇는건? ⋯</a></p><hr><p><em>2025-08-05</em> ⋯ 데이터 분석 #1 기초통계</p><p><a href=https://yshghid.github.io/docs/study/ai/ai14/>1. 기술 통계 #1 IQR? 가운데 50%의 거리. #2 IQR 그림 설명 (p.34) 그림의 2,3: 각각 IQR의 1.5배 선, median 값 선. 그림의 B: ⚬ 가 많으면 특이값이 많은 것. 그림의 1,2,3: 1,2는 각각 IQR의 1.5배 선이라고 했는데 3과의 거리가 서로 다른 이유는? 1.5배 안쪽에 데이터들이 다 분포해서. 즉max가 1.5배보다 작아서. #3 변이 계수(Coefficient of ⋯</a></p><hr><p><em>2025-07-23</em> ⋯ TFT #2 입력 feature 생성</p><p><a href=https://yshghid.github.io/docs/study/ai/ai6/>1. Load package %load_ext autoreload %autoreload 2 import sys import pandas as pd import numpy as np import os import pickle import ast sys.path.append(&rsquo;/data3/projects/2025_Antibiotics/YSH/bin&rsquo;) from sc import * os.chdir(&rsquo;/data3/projects/2025_Antibiotics/YSH/workspace&rsquo;) 2. Make feature1 ⋯</a></p><hr><p><em>2025-07-23</em> ⋯ TFT #1 입력 시퀀스 생성</p><p><a href=https://yshghid.github.io/docs/study/ai/ai5/>1. Load package %load_ext autoreload %autoreload 2 import sys import pandas as pd import numpy as np import os import pickle import ast sys.path.append(&rsquo;/data3/projects/2025_Antibiotics/YSH/bin&rsquo;) from sc import * os.chdir(&rsquo;/data3/projects/2025_Antibiotics/YSH/workspace&rsquo;) ⋯</a></p><hr><p><em>2025-07-23</em> ⋯ TFT #0 연구 방향</p><p><a href=https://yshghid.github.io/docs/study/ai/ai4/>0. 연구 개요 목적: 항생제 종류에 따라 NEWS score를 예측 모델: Temporal Fusion Transformer(TFT) 1. 데이터 구성 및 TFT 입력 형식 1. 데이터 종류 Clinical feature (17개, float): Creatinine, Hemoglobin, LDH, Lymphocytes, Neutrophils, Platelet count, WBC count, hs-CRP, D-Dimer, BDTEMP, BREATH, ⋯</a></p><hr><p><em>2025-05-29</em> ⋯ TFT PyTorch Forecasting - Stallion 튜토리얼 #2</p><p><a href=https://yshghid.github.io/docs/study/tech/tech13/>#version check 예제 코드에 맞는 패키지 버전 CUDA: 11.7 PyTorch: 1.13.1+cu117 PyTorch Lightning: 1.9.0 PyTorch Forecasting: 0.10.3 PyTorch Forecasting 0.10.3 선택 이유: 최신 버전은 아래 코드랑 호환 안됨 1. Tuner().lr_find() -> 학습률 탐색, lightning>=2.x에서는 내부 콜백 구조 변경됨 2. trainer ⋯</a></p><hr><p><em>2025-05-28</em> ⋯ TFT PyTorch Forecasting - Stallion 튜토리얼</p><p><a href=https://yshghid.github.io/docs/study/tech/tech12/>#introduction 데이터셋: Kaggle - Stallion 데이터셋 목적: Temporal Fusion Transformer(TFT)를 활용하여 음료 판매량을 예측 #install $ nvidia-smi Wed May 28 14:00:07 2025 +&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;+ | NVIDIA-SMI 545.23.08 Driver Version ⋯</a></p><h1><a class=anchor href=#>#</a></h1></article><footer class=book-footer><div class="flex flex-wrap justify-between"></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents></nav></div></aside></main></body></html>