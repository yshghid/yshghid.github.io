<!doctype html><html lang=en-us dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="
  AI
  #

"><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="https://yshghid.github.io/docs/study/ai/"><meta property="og:site_name" content=" "><meta property="og:title" content="AI"><meta property="og:description" content="AI #"><meta property="og:locale" content="en_us"><meta property="og:type" content="website"><title>AI |</title><link rel=icon href=/favicon.png><link rel=manifest href=/manifest.json><link rel=canonical href=https://yshghid.github.io/docs/study/ai/><link rel=stylesheet href=/book.min.30a7836b6a89342da3b88e7afd1036166aeced16c8de12df060ded2031837886.css integrity="sha256-MKeDa2qJNC2juI56/RA2Fmrs7RbI3hLfBg3tIDGDeIY=" crossorigin=anonymous><script defer src=/fuse.min.js></script><script defer src=/en.search.min.8575bdc0ca02b9d35ac83cf3086aa234089a0f48cdce980be8704064bf26f8c3.js integrity="sha256-hXW9wMoCudNayDzzCGqiNAiaD0jNzpgL6HBAZL8m+MM=" crossorigin=anonymous></script><link rel=alternate type=application/rss+xml href=https://yshghid.github.io/docs/study/ai/index.xml title=" "></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><img src=/logo.png alt=Logo class=book-icon><span></span></a></h2><div class="book-search hidden"><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><script>document.querySelector(".book-search").classList.remove("hidden")</script><ul><li class=book-section-flat><span>기록</span><ul><li><a href=/docs/hobby/daily/>일상</a><ul></ul></li><li><a href=/docs/hobby/book/>글</a><ul></ul></li></ul></li><li class=book-section-flat><span>공부</span><ul><li><a href=/docs/study/ai/ class=active>AI</a><ul></ul></li><li><a href=/docs/study/bioinformatics/>Bioinformatics</a><ul></ul></li><li><a href=/docs/study/be/>BE</a><ul></ul></li><li><a href=/docs/study/fe/>FE</a><ul></ul></li><li><a href=/docs/study/career/>취업</a><ul></ul></li></ul></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu></label><h3>AI</h3><label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents></nav></aside></header><article class="markdown book-article"><h1 id=ai>AI
<a class=anchor href=#ai>#</a></h1><hr><p><em>2025-07-28</em> ⋯ DBSCAN: #1 1D 클러스터링의 성능 평가</p><p style=height:4.5em;overflow:hidden><a href=/docs/study/ai/ai8/>1. Problem 클러스터 응집도는 보통 클러스터 내 데이터 간의 평균 거리나 분산, 혹은 실루엣 계수처럼 군집 내 응집도와 군집 간 분리도를 동시에 평가한다. 하지만 1차원 데이터에서는 클러스터 응집도(Cluster Cohesion) 또는 실루엣 계수(Silhouette coefficient) 같은 지표가 잘 작동하지 않는다. 2. 클러스터 응집도 클러스터링 성능을 평가하는 지표 중 하나인 응집도(Cohesion)는 클러스터 내부의 데이터들이 얼마나 서로 가까운지를 측정하는 지표다. 대표적으로는 클러스터 내 모든 점 간의 평균 거리, 클러스터 중심과 각 점 사이의 평균 거리, 혹은 분산을 사용하는 방식 등이 있다. 이와 함께 자주 사용되는 분리도(Separation)는 클러스터 간의 거리가 얼마나 떨어져 있는지를 평가하며, 이 두 지표를 동시에 고려하는 실루엣 계수(Silhouette coefficient) 같은 복합 지표도 존재한다. 이러한 거리 기반의 평가 지표들은 특히 고차원 공간에서 데이터의 분포가 복잡할 때 군집화의 품질을 효과적으로 판단하는 데 유용하지만, 1차원 데이터에서는 근본적인 한계가 있다. 1차원에서는 데이터가 선형적으로 배열되어 있고, 데이터 간의 절대적인 거리 외에 고려할 수 있는 구조적 정보가 거의 없다. 다시 말해, 1차원 데이터에서는 클러스터 간의 공간적 분리나 복잡한 분포 형태, 경계의 불확실성 같은 요소가 존재하지 않는다.
예를 들어, [1, 2, 3]이라는 클러스터와 [10, 11, 12]라는 또 다른 클러스터가 있을 때, 두 클러스터는 각자 내부에서 점들이 밀집되어 있으며, 동시에 클러스터 간의 거리도 매우 크다.
이 경우, 응집도 지표로 보면 내부 응집도는 낮은 거리로 인해 높게 평가되고, 분리도 역시 충분히 큰 거리 차이로 인해 좋게 평가된다. 결국 이 두 클러스터는 매우 이상적인 군집으로 간주되며, 실루엣 계수도 1에 가까운 매우 높은 값을 얻게 된다. 하지만 이는 거리 기반 평가 지표가 본래 측정하고자 했던 군집화의 “품질”을 왜곡할 수 있다. 실루엣 계수가 높다는 것은, 클러스터 내부는 서로 가까우면서 다른 클러스터와는 충분히 떨어져 있다는 뜻인데, 1차원에서는 어느 정도 떨어져 있기만 하면 항상 이런 조건을 쉽게 만족할 수 있다.
즉, 고차원 데이터에서는 이 조건을 만족시키기 위해 정교한 군집 경계 설정이나 복잡한 군집 구조의 이해가 필요하지만, 1차원에서는 단순한 거리 기준만으로도 응집도와 분리도를 동시에 높이는 것이 너무 쉽다.
이러한 특성 때문에 실루엣 계수 같은 지표는 거의 항상 과대 평가되는 경향이 있으며, 이로 인해 군집화가 “잘 되었다”고 착각할 수 있다. 또한, 1차원에서는 데이터가 클러스터의 중심을 기준으로 대칭적으로 분포해 있을 가능성이 높기 때문에, 중심 기반 평가 지표들이 지나치게 이상적인 값을 반환하게 된다.
예를 들어, k-means 알고리즘으로 클러스터링을 수행하고 각 클러스터의 중심을 기준으로 점들을 평가할 때, 각 클러스터가 비슷한 크기와 간격을 가지고 있으면 군집 품질이 매우 좋게 평가된다.
하지만 실제 분석 목적이 예를 들어 데이터의 숨겨진 구조나 경계의 복잡성, 비정상적인 데이터 분포 등을 파악하는 것이라면, 이러한 단순한 평가 기준은 적절하지 않다. 이러한 이유 때문에, 1차원에서는 실루엣 계수나 거리 기반 응집도 지표가 클러스터링 품질을 객관적으로 반영하지 못한다.
다시 말해, 1차원에서는 거의 모든 클러스터링 결과가 높은 응집도와 분리도로 인해 좋은 평가를 받을 수 있기 때문에, 지표 간 차별성이 떨어지고, 모델 간의 성능 비교가 무의미해질 수 있다.
예를 들어, 클러스터 수를 다르게 설정하거나, 군집 경계를 조금씩 조정해도, 응집도 지표는 큰 차이를 보이지 않기 때문에, 최적의 군집 수를 찾기 어렵고, 과적합된 군집 결과도 높은 점수를 받을 수 있다. 한편, 거리 기반 지표가 고차원에서는 데이터 분포의 구조, 군집의 모양, 방향성, 밀도 차이 등을 반영할 수 있지만, 1차원에서는 이런 복잡성이 존재하지 않는다.
따라서 클러스터 간 거리만 멀면 분리도는 항상 높고, 클러스터 내 거리가 작으면 응집도는 항상 높게 측정된다.
이런 구조적 단순성 때문에 거리 기반 지표는 본래 설계된 목적, 즉 클러스터 품질의 차이를 드러내는 데에 실패할 수밖에 없다. 결국 1차원 데이터에서 클러스터링 성능을 평가하기 위해서는 거리 기반 응집도 지표에만 의존하는 것은 위험하며, 대안적인 평가 방식을 고려해야 한다.
예를 들어, 클러스터 내 분산과 클러스터 간 거리의 비율을 이용해 평가하거나, 클러스터 경계에서의 밀도 차이를 분석하거나, 시각화 및 도메인 지식을 활용하여 군집의 타당성을 해석하는 방식이 더 적절할 수 있다.
특히 노이즈가 포함된 1차원 데이터에서 DBSCAN 같은 밀도 기반 알고리즘을 사용할 경우, 군집이 얼마나 의미 있는 구간으로 나뉘었는지를 인간이 직접 시각적으로 검토하는 것이 지표보다 더 신뢰성 있는 평가 방식이 될 수 있다. 요약하자면, 1차원 데이터에서는 거리 기반 응집도 지표가 매우 단순한 거리 정보만을 반영하게 되며, 그 결과 지나치게 높은 품질 점수를 반환하게 되어 클러스터링 성능을 왜곡하는 경향이 있다.
따라서 이러한 지표는 1차원에서는 신뢰도가 낮으며, 클러스터링 결과의 실제 타당성이나 분석 목적을 반영하지 못할 수 있다. 이런 상황에서는 시각화 기반 평가, 분산-거리 비율 계산, 또는 실제 문제의 목적에 맞는 해석 중심의 평가가 필요하다. 3. 실루엣 스코어 실루엣 계수(Silhouette Coefficient)는 클러스터링의 품질을 평가하기 위한 대표적인 내부 지표 중 하나로, 각 데이터 포인트가 자신이 속한 클러스터 내부에서는 얼마나 밀접하게 모여 있는지(응집도), 그리고 다른 클러스터와는 얼마나 잘 분리되어 있는지(분리도)를 동시에 반영한다.
구체적으로, 어떤 점 i에 대해 실루엣 계수를 계산하려면 두 가지 거리 평균을 계산해야 한다. 첫 번째는 a(i), 즉 점 i와 같은 클러스터에 속한 다른 모든 점들과의 평균 거리이며, 이는 클러스터 내부 응집도를 의미한다.
두 번째는 b(i), 점 i와 가장 가까운 다른 클러스터에 있는 모든 점들과의 평균 거리로, 이는 클러스터 간 분리도를 나타낸다.
최종 실루엣 점수는 s(i)= b(i)−a(i) / max(a(i),b(i)) 로 정의되며, -1부터 1 사이의 값을 가진다. 점수가 1에 가까울수록 클러스터링 품질이 좋다는 뜻이다. 이러한 실루엣 계수는 고차원 공간에서 다양한 모양의 클러스터가 형성될 때 매우 유용한 지표가 된다.
예를 들어, 서로 다른 밀도를 가지거나 비대칭적인 분포, 비선형 경계를 가지는 클러스터들이 존재할 경우, 실루엣 계수는 클러스터 내부 밀집도와 외부 분리도를 동시에 반영함으로써 유의미한 평가를 제공한다. 그러나 이 지표는 1차원 데이터에서는 정보 손실이 크고 왜곡된 평가 결과를 내놓는다는 점에서 큰 한계를 가진다.
그 이유는 실루엣 계수가 기반으로 삼고 있는 거리 정보가 1차원에서는 지나치게 단순하기 때문이다.
1차원 데이터는 본질적으로 수직선 위에 점들이 배열된 구조이므로, 두 점 사이의 거리는 단순히 절댓값 차이 하나로 결정된다.
이 절댓값 거리에는 방향성도 없고, 구조적인 특이성도 반영되지 않기 때문에, 다양한 분포 형태나 클러스터의 복잡성, 클러스터 간 경계 모호성 등 실루엣 계수가 원래 평가하고자 하는 핵심적인 특성들이 반영되지 않는다.
즉, 다양한 군집 구조나 모양이 나타나는 고차원 공간에서는 실루엣 계수가 그 구조의 복잡성을 반영할 수 있지만, 1차원에서는 단순히 가까운가 먼가만 판단하기 때문에 정보량이 극단적으로 줄어들게 된다. 이러한 정보 손실은 실루엣 계수가 의미 있는 분포의 차이를 구분하지 못하게 만들고, 결과적으로 항상 높은 값이 나오도록 만든다.
예를 들어, 1차원 상에서 [1.0, 1.1, 1.2], [5.0, 5.1, 5.2], [10.0, 10.1, 10.2]라는 세 개의 클러스터가 있다고 가정하자.
이 데이터는 각 클러스터 내부 응집도가 높고, 클러스터 간 거리는 멀기 때문에 실루엣 계수는 거의 1에 가까운 값을 줄 것이다.
그런데 클러스터의 개수를 3개에서 5개로 늘려 조금 더 세분화하거나, 혹은 노이즈가 섞인 데이터를 추가하더라도 실루엣 점수는 여전히 높을 수 있다. 왜냐하면 각 점이 속한 클러스터 내부 거리와 다른 클러스터와의 평균 거리는 여전히 큰 차이를 유지하기 때문이다. 더 나아가, 1차원에서는 클러스터 간 경계가 명확하게 정의되는 경우가 많아, 대부분의 점이 실루엣 계수 계산 시 자신의 클러스터 내부에서는 매우 가까운 거리 평균을, 외부 클러스터와는 비교적 먼 거리 평균을 가지게 된다. 이로 인해 실루엣 점수가 인위적으로 높게 유지된다.
하지만 이 점수는 반드시 클러스터링이 실제로 의미 있는 구분을 잘 수행했음을 의미하지는 않는다. 예를 들어, 데이터가 실제로는 하나의 연속적인 분포를 가지지만 임의로 여러 개의 클러스터로 나눈 경우에도 실루엣 점수는 인위적으로 높게 나올 수 있다.
이런 경우, 실루엣 계수는 클러스터링이 오히려 과도하게 나누어진(over-segmentation) 상태를 정당화하는 수치로 오용될 수 있다. 실루엣 계수의 또 다른 한계는 노이즈에 대한 민감도다. DBSCAN처럼 노이즈를 탐지하는 알고리즘은 클러스터 외부에 속하는 점들을 -1로 라벨링하고 클러스터링에서 제외한다.
하지만 실루엣 계수는 클러스터에 속하지 않는 노이즈 점들에 대해 정의되지 않거나 무시되는 경우가 많다.
이런 구조에서는 노이즈가 많을수록 오히려 실루엣 점수가 인위적으로 상승하는 경향이 나타난다. 즉, 전체 데이터에서 모호하거나 경계선에 위치한 점들을 제거하면, 남은 데이터는 더 응집되어 보이고 클러스터 간 거리도 상대적으로 더 커지기 때문에 실루엣 점수는 더 높아진다.
그러나 이 역시 클러스터링의 품질을 제대로 반영한 것이라고 보기 어렵다. 실제로는 데이터 전체의 분포를 보존하면서 클러스터링하는 것이 더 중요할 수 있으며, 단지 점수를 높이기 위해 노이즈를 제거하는 것은 정당한 방법이 아니다. 또한 실루엣 계수는 모든 점에 대해 평균을 내어 전체 점수로 활용되는데, 이 평균 역시 1차원에서는 쉽게 왜곡된다.
예를 들어, 중심에 있는 점들은 클러스터 내부 거리도 작고 외부 거리도 크기 때문에 실루엣 값이 1에 가까워지지만, 경계에 있는 점들은 이 값이 작거나 음수가 될 수도 있다.
하지만 전체적으로 중심에 있는 점들이 더 많으면 평균 실루엣 점수는 여전히 높게 나올 수 있다. 이로 인해 일부 클러스터가 실제로는 나쁜 품질을 가지고 있음에도 평균 점수는 좋게 나타나는 문제가 발생한다.
고차원에서는 다양한 방향성과 경계를 고려하여 이런 문제가 부분적으로 완화되지만, 1차원에서는 클러스터 경계가 단순히 "왼쪽/오른쪽"으로 나뉘기 때문에 경계점의 정보가 매우 단조롭게 반영된다. 결국, 실루엣 계수는 고차원에서는 거리 정보와 군집 구조를 반영하여 유용하게 사용될 수 있지만, 1차원에서는 거리 정보 외의 구조적 특성이 존재하지 않기 때문에 그 유용성이 현저히 떨어진다.
다양한 클러스터 모양이나 방향성을 구분할 수 없고, 군집 경계의 모호함이나 데이터의 특수한 분포도 반영하지 못한다.
특히, 실루엣 계수는 클러스터링 알고리즘이 자동으로 학습한 구조에 대한 정량적 평가를 수행하고자 할 때 사용되지만, 1차원에서는 구조 자체가 단순하기 때문에 이러한 목적에 부합하지 않는다. 따라서 1차원 데이터에서 실루엣 계수를 그대로 사용하는 것은 실제 군집 품질에 대한 잘못된 인상을 줄 수 있으며, 이를 보완하기 위해서는 실루엣 계수를 단독으로 사용하기보다는 시각화, 클러스터 간 거리 대비 분산 비율, 도메인 지식 기반 해석 등 보조적 평가 방법과 병행하여 해석하는 것이 필요하다. 1차원에서는 클러스터링 평가를 위한 정량 지표가 제공하는 정보가 제한적이므로, 단순히 점수에 의존하기보다는 클러스터 경계의 타당성과 데이터 분포의 맥락을 함께 고려한 해석 중심 접근이 보다 적합하다. 4. 1차원 데이터에서 클러스터링 성능 평가 방법? 1차원 데이터에서 클러스터링 성능을 평가하려면, 분석 목적과 데이터의 구조에 맞는 평가 지표를 선택하는 것이 중요하다. 특히 정답 레이블(ground truth)이 존재하는 경우와 존재하지 않는 경우에 따라 평가 방식이 크게 달라진다. 우선 정답 레이블이 있는 경우라면, 일반적인 지도학습의 분류 문제처럼 외부 평가 지표를 활용할 수 있다. 이 경우 가장 많이 사용되는 지표는 ARI, NMI, F1-score 등이며, 클러스터링의 정확도와 유사성을 정량적으로 비교할 수 있다는 점에서 매우 유용하다. ARI(Adjusted Rand Index)는 예측된 클러스터링 결과와 실제 정답 라벨 간의 유사도를 측정하는 대표적인 지표다. 단순히 일치 비율만 따지는 것이 아니라, 무작위로 클러스터를 나눴을 때 기대되는 일치 비율을 보정한 값이기 때문에 더 객관적인 평가가 가능하다. 예를 들어, 두 개의 클러스터가 존재하고 정답도 두 개의 그룹으로 되어 있을 때, 클러스터 수가 서로 달라도 ARI는 군집 간 일관성만 맞다면 높은 점수를 줄 수 있다. 따라서 다양한 클러스터 수를 실험할 때 성능 비교 지표로 매우 적합하다. NMI(Normalized Mutual Information)는 정보 이론에 기반한 지표로, 정답 레이블과 예측된 클러스터 간의 상호 정보를 측정한다. 이 지표는 클러스터의 라벨 이름이 달라도, 구조적으로 동일한 군집을 형성했다면 높은 점수를 부여한다는 장점이 있다. 특히 클러스터 수가 많거나 라벨이 복잡할 때도 비교적 안정적인 평가가 가능하다. 예를 들어, 동일한 데이터를 가지고 두 개의 알고리즘이 다른 라벨을 부여했지만 군집 구조가 비슷하다면 NMI는 이를 긍정적으로 평가한다. F1-score는 클러스터링 결과를 분류 문제처럼 간주하여 계산할 수 있다. 각 클러스터를 하나의 클래스처럼 보고, 정답 라벨과의 일치 여부를 precision, recall을 통해 계산한 후 F1 점수로 요약한다. 이 방법은 특히 정답 라벨이 명확하게 주어져 있을 때 각 클러스터의 품질을 파악하는 데 유용하다. 다만, 이 방식은 클러스터의 수가 실제 클래스 수와 유사할 때 잘 작동하며, 군집 간 매칭 문제를 적절히 해결하지 않으면 왜곡된 결과를 낼 수 있다는 점을 주의해야 한다. 이처럼 외부 지표들은 1차원인지 고차원인지에 관계없이 정답 라벨만 있다면 적용 가능하며, 클러스터링의 정량적 평가에 매우 효과적이다. 하지만 현실적으로는 클러스터링 대상 데이터에 정답이 없는 경우가 더 많다. 이럴 때는 내재적 평가 지표 또는 해석 기반의 평가 방식이 필요하다. 그러나 1차원에서는 내재적 지표들이 예상보다 신뢰성이 떨어지거나 의미 없는 수치를 제공할 수 있기 때문에, 보다 조심스럽게 접근해야 한다. 정답 라벨이 없는 경우 사용할 수 있는 한 가지 방법은 클러스터 간 구간 분리도를 측정하는 것이다. 이는 각 클러스터 중심 간의 평균 거리와 클러스터 내부의 평균 분산을 비교하는 방식이다. 예를 들어, 각 클러스터의 중심이 10, 20, 30이고 클러스터 내 표준편차가 2라면, 중심 간 거리는 크고 내부 분산은 작으므로 구분이 잘 된 클러스터라고 볼 수 있다. 이때 사용되는 수식은 보통 separation = 평균 중심 거리 / 평균 클러스터 내 표준편차이며, 이 값이 1보다 크면 기본적으로 “구간이 잘 나뉘었다”고 해석할 수 있다. 이 방식은 실루엣 계수처럼 평균 거리 기반이지만, 보다 단순하고 1차원에 특화된 해석이 가능하다. 또한 클러스터 내 분산을 개별적으로 분석하는 방식도 고려해볼 수 있다. 각 클러스터가 얼마나 응집되어 있는지를 개별적으로 확인하고, 동시에 전체 클러스터 수와 비교함으로써 과적합 여부를 점검하는 것이다. 예를 들어, 클러스터 수가 지나치게 많고 각 클러스터의 분산이 매우 작다면 이는 과도하게 군집이 나뉜 것일 수 있다. 반대로, 클러스터 수가 적지만 분산이 너무 크다면 서로 다른 군집을 하나로 합쳐버린 잘못된 분할일 수 있다. 이처럼 분산 기반 평가는 군집 수 조정과 해석의 균형을 맞추는 데 도움이 된다. 무엇보다도 1차원에서는 데이터의 시각화가 매우 쉬우므로, 직접적인 시각 검토가 가장 효과적일 수 있다. 각 클러스터의 경계를 눈으로 확인하고, 클러스터 간 간격이 얼마나 명확한지, 데이터가 밀집되어 있는 구간과 노이즈가 포함된 영역이 어떻게 나뉘는지를 직접 확인할 수 있다. 예를 들어, 시계열 데이터에서 특정 시점마다 분포가 급격히 달라진다면 이를 시각적으로 포착하여 클러스터 구간을 재조정할 수 있다. 또한, 노이즈가 많은 경우에는 클러스터 외부의 데이터가 어떻게 분포되어 있는지도 판단할 수 있으며, 이러한 시각적 정보는 단순한 수치보다 더 신뢰성 높은 해석을 제공할 수 있다. 요약하자면, 1차원 데이터에서 클러스터링 성능을 평가할 때 정답 레이블이 있다면 외부 지표를 적극 활용하는 것이 가장 바람직하며, ARI, NMI, F1-score 등은 군집 수, 라벨 이름의 차이에 상관없이 비교적 객관적인 판단을 제공한다. 그러나 정답 레이블이 없는 경우에는 클러스터 간 거리 대비 분산 비율, 클러스터 내 분산 분석, 시각적 경계 확인 등 보다 해석 중심의 방법을 병행하여 평가하는 것이 필요하다. 특히 1차원에서는 구조가 단순하고, 거리 기반 지표가 과대평가되는 경향이 있으므로, 수치적 평가보다는 데이터의 실제 분포와 의미를 고려한 통합적 판단이 중요하다.</a></p><hr><p><em>2025-07-28</em> ⋯ DBSCAN #2 슈도코드</p><p style=height:4.5em;overflow:hidden><a href=/docs/study/ai/ai9/>데이터 집합 D, 파라미터 eps와 minPts가 들어간다. 주석 처리 안된 부분만 보기. 먼저 현재위치 x의 eps 내에 데이터 포인트가 몇개인지부터 확인한다. minPts보다 작으면, 노이즈로 처리한다. 아니면? 클러스터 확장을 수행한다. 현재위치 x의 eps 내에 데이터포인트들을 봣을때, 노이즈가 아닌 이웃포인트 y는 regionQuery를 수행해서 반경 내 데이터포인트수가 minPts 보다 크면 반경 내 모든 데이터포인트들을 x의 neighbor로 통합한다. 노이즈였지만 현재는 x의 이웃포인트가 된 y는 border point로 재분류해준다.</a></p><hr><p><em>2025-07-23</em> ⋯ TFT #3 모델 학습</p><p style=height:4.5em;overflow:hidden><a href=/docs/study/ai/ai7/>1. Load package data 2. Load data 3.</a></p><hr><p><em>2025-07-23</em> ⋯ TFT #2 입력 feature 생성</p><p style=height:4.5em;overflow:hidden><a href=/docs/study/ai/ai6/>1. Load package 2. Make feature1 data result functions `sc.py` provided in github</a></p><hr><p><em>2025-07-23</em> ⋯ TFT #1 입력 시퀀스 생성</p><p style=height:4.5em;overflow:hidden><a href=/docs/study/ai/ai5/>1. Load package 2. Load raw data data 3. Raw data processing result 4. Make input sequence data result functions `sc.py` provided in github</a></p><hr><p><em>2025-07-23</em> ⋯ TFT #0 연구 방향</p><p style=height:4.5em;overflow:hidden><a href=/docs/study/ai/ai4/>( 작성) 사용하고자 하는 데이터는? - feature - Clinical feature (17, float): Creatinine, Hemoglobin, LDH, Lymphocytes, Neutrophils, Platelet count, WBC count, hs-CRP, D-Dimer, BDTEMP, BREATH, DBP, SBP, PULSE, SPO2, O2_APPLY - Antibiotics feature (2, str) - Treatment (list, str): 투여한 항생제, 결측값일수도있고 2개 이상일수도 있음 - Strain (str): 환자가 감염된 균주, 1개 - NEWS (int): 중증도 - Code (int/str): 환자 등록번호 - time-series - 10개 시점 (항생제 투여 기준 D-3 ~ D+6) TFT input 형식은? - Observed (18): Creatinine, Hemoglobin, LDH, Lymphocytes, Neutrophils, Platelet count, WBC count, hs-CRP, D-Dimer, BDTEMP, BREATH, DBP, SBP, PULSE, SPO2, O2_APPLY / Strain - Known (1): Treatment - Static (1): Code - Target: NEWS 목적? - 항생제 투여에 따른 NEWS 예측 문제점1 - ‘Treatment’ 즉 리스트를 feature로 넣으려면 one hot encoding 해야함 - one hot encoding 하면? ‘Treatment’ feature의 차원이 너무 많아짐 항생제가 100종류 이상이라서 문제점1의 solution - ‘Treatment’ feature를 항생제 리스트 대신 존재 유무 (0,1)로 변경 - ‘Strain’ feature도 항생제랑 관련된 feature이므로 우선 제거 수정된 input - Observed (17): Creatinine, Hemoglobin, LDH, Lymphocytes, Neutrophils, Platelet count, WBC count, hs-CRP, D-Dimer, BDTEMP, BREATH, DBP, SBP, PULSE, SPO2, O2_APPLY - Known (1): Treatment - Static (1): Code - Target: NEWS 문제점2 데이터 단순화 과정에서 무시된 내용 - 항생제의 균주 특이성 - 항생제는 투여 1일만에 NEWS를 낮출 수도 있고 2일 이상 소요될 수도 있음 - 중복 투여된 항생제가 서로 영향을 줬을 가능성 문제점2의 solution - 항생제별 균주 특이성 feature 추가 - 원래 데이터에서 항생제 별로 Sequence를 찾고 투여 후 NEWS가 감소하는 Sequence를 식별 (K means등 clustering 기법을 써도되고 단순히 감소폭을 봐도 되고) - Sequence의 투여 첫날 기준 항생제-균주 pair를 찾기 - Paired_antibiotics feature 추가 - 항생제별 NEWS를 낮추는데 소요시간 feature 추가 - 항생제 투여 후 NEWS가 일정 수준까지 낮아지는데 소요되는 일수에 따라 유형 A, B, C로 구분 - Response_time feature로 추가 문제점1,2의 solution 의 효과 - ‘항생제 종류’와 ‘균주’를 제거한 대신에 ‘항생제 종류’와 ‘균주’가 갖는 아래 특성만 (중요하다고 가정하고) 반영시킴 - 특정 균주 감염된 경우에 NEWS를 일정 수준 감소시킨 이력이 있는지 (0,1) - 모든 투여 경우에서 NEWS를 일정 수준 감소시키는데 걸리는 시간이 느린편인지 빠른편인지 (A, B, C) --- 문제점1,2의 solution에서 생각할수있는 이슈 사항 - 추후 항생제 시뮬레이션을 할때도 자체적으로 annotation한 Paired_antibiotics 및 Response_time feature를 넣어줘야 할것인데 우리 데이터상에 적은 antibiotics나 strain인 경우 과대적합일 수도 있고 우리 데이터셋이 없는 antibiotics나 strain에 대해서는 적용하기 어렵다는 문제가 있음 - known feature인 Treatment가 모든 sequence에서 투여 이전에 0인데 이게 TFT 알고리즘에서 불리하게 작용하는 점은 없을까? - Encoder와 Decoder에 다른 feature가 들어가도 괜찮던데 이걸 최대로 이용할 방법은 없을까? 문제점1,2의 solution를 사용한 결과 모델의 의의 - 17개 임상 feature와 항생제 투여유무 feature에 추가적으로 항생제-균주가 NEWS를 낮추는지 여부, 항생제 효과 소요시간을 반영했을때 NEWS 예측 성능이 올라갔다. - 이는 항생제 항목 자체를 넣어주는 원-핫 인코딩을 썻을때보다는 dimension 축소 효과로 인해 예측 성능이 높아진거고 - 항생제-균주가 NEWS를 낮추는지 여부, 항생제 효과 소요시간을 반영하지 않았을때보다는 항생제의 2가지 특성을 반영했다는 이유로 인해 예측 성능이 높아진 것이며 - 이런 모델을 통해 6종 항생제 투여로 시뮬레이션 해본 결과 최적의 항생제 탐색에 사용 가능할거같다. - 항생제 자체가 갖는 다차원 특성을 medical insight를 토대로 2개로 줄인것에 의의가 있다. 생각 이대로 진행해도 괜찮지만 뭔가 일찍부터 카테고리를 나눠서 수행하는것보다 항생제별로 다 결과를 뽑은 담에 결과를 토대로 역으로 그 카테고리가 나오게 하는게 이쁠거같음 --- 이슈사항정리 Q1) 항생제 feature가 D+0 이전에는 결측인 경우가 문제되지 않을까? A1) TFT의 known feature는 미래 예측을 위한 입력이며, 과거 구간에서는 비어있어도 문제가 되지 않는다고함. Encoder는 과거 임상 수치와 항생제 미투여 상태(0)만 보고 학습하고, Decoder는 항생제 시나리오가 주어졌을 때 그 조건하에 예측을 수행하는것은 TFT 구조 설계상 허용되는 일반적인 상황. Q2) 항생제 종류가 너무 많은 경우(100종 이상) 직접 one-hot or embedding 사용하면? A2) 100개 one-hot 인코딩 시 차원이 너무 크고 sparse하여 과적합 유발. Embedding도 너무 많아지면 학습 어렵고 특히 데이터 적으면 성능 저하될수있음. Q3) multi-hot 임베딩 하면? A3) 100종 항생제라고 치면 100개 binary feature로 넣어주는건데 구조가 단순하고 해석이 쉽지만 feature 수 많고 sparse하고 상호작용 표현 어려움 Q4) 항생제 군 분류 후 군 정보 feature 쓰면? A4) beta-lactam계, macrolide계 등으로 10~15종으로 분류한 feature를 넣어주는건데 feature 수 줄고 효과 해석도 나쁘지않음 다른 항생제 종류 쓴 데이터에 시뮬레이션 하기도 괜찮을듯 근데 일반적으로 나누는 분류법이라서 일반적인 결과가 나와버릴수도 Q5) 항생제 임베딩해서 균주, 반응시간과의 상호작용 반영된 latent vector 학습 A5) feature를 가내수공업으로 넣어주는게 아니라 항생제 효과 요약 벡터를 생성하는건데 균주와의 관계, 반응소요시간 등에서 내가 놓칠수있는 부분을 캐치해서 넣어줄수있음. 예를들어 나는 샘플을 보고 NEWS를 3.0 이하로 떨어뜨린 경우가 많으면 “효과적” 아니면 “알수없음"으로 생각하는 알고리즘인데 딥러닝 돌리면 샘플을 보고 “~~~” 하니까 임베딩공간상 이 위치, 이 샘플은 “~~~” 하니까 임베딩공간상 다른 위치 이렇게 할당하는거고 ““에 NEWS를 3.0 이하로 떨어뜨린 경우가 많은지에 대한 비중이 큰지 작은지 없는지는 모르지만 어떤 weight가 줘진상태든 간에 데이터 상 내가생각한 저 기준보다 더 중요한 특성이 있으니가 weight를 덜 줬겠지 라고 생각하는것임. 이 방법은 설명력이 낮을 수 있다. Q6) Q5 연구는 TFT를 적용한 항생제 연구로서 항생제 투여에 따른 NEWS 예측에 중요한 feature와 그렇지 않은 feature를 자동으로 weight 조절해서 학습하는게 포인트임. 근데 항생제 종류에 따라 중요한 feature가 다를 수도 있지 않나? 이걸 반영하지 않고 도출한 ‘중요한 feature 목록’은 그냥 “항생제"라는 x로 “NEWS"라는 y를 예측할때 일반적으로 이런 feature가 중요하다 선에서 그침. 모조리 넣고 항생제마다 결과를 봣을때 이런이런 feature가 비슷하다고 나온 애들은 확인해보니 이런 공통 특성을 갖더라 이런식으로, 카테고리화는 마무리 단계에 들어가야하지 않나 싶음. A6) 조건 분기 Decoder를 적용하는 방법이 있는데 더 찾아봐야함 Q7) 중복 투여에 따른 영향을 고려 안해도되나.. A7) 아래 gpt 넣엇을때 추천받은 방법을 일단 수행해보고 결정하기. > 목적: 본 연구는 “항생제 종류에 따라 NEWS score를 예측"하는 문제를 해결하고자 한다. 이를 위해 기존 Temporal Fusion Transformer(TFT) 구조에 다음 네 가지 기능을 통합한 모델을 제안한다: > > - Multi-path 구조 > - 항생제-균주 상호작용 임베딩 > - 조건부 시나리오 입력 > - 항생제 효과 지연 시간 반영 > > 기존 TFT 구조 요약 > > - Encoder: 과거 시계열(임상 수치 등) 정보를 인코딩 > - Decoder: 미래 시점 예측 (known feature 사용) > - GRN + Attention: 중요 변수 선택 및 장기 의존성 반영 > > 기존 TFT의 한계 (본 연구 기준) > > 1. 항생제 효과 구분 불가: 항생제 정보를 모델에 제대로 반영하지 못함 > 2. 균주와 항생제 상호작용 무시 특정 항생제가 어떤 균주에 효과적인지 파악 불가 > 3. 약물 반응 지연 미반영 투여 즉시 효과가 나타난다고 가정함 > 4. 조건부 시나리오 예측 불가 같은 환자라도 항생제를 바꾸었을 때의 결과 비교 불가 > 5. 데이터 부족 문제 항생제별로 모델을 나누면 데이터가 부족하고 과적합 발생 가능 > > 제안하는 개선 TFT: Multi-path TFT with Antibiotic × Strain Interaction > > [1] Multi-path 구조: 항생제 종류에 따라 Decoder 경로 또는 Attention 흐름을 다르게 설정/Decoder 입력에 항생제 조건을 명시하여 조건부 예측 가능/같은 환자에 대해 항생제 시나리오를 바꿔 결과 비교 가능 [2] 항생제 × 균주 상호작용 임베딩: 항생제 임베딩과 균주 임베딩 간의 상호작용을 모델링 (concat, bilinear 등)/항균력 차이를 자동 학습할 수 있어 특정 조합의 효과를 반영 가능 [3] 조건부 Gated Layer: 항생제와 균주 정보에 따라 경로 가중치를 다르게 부여/특정 조합에 따라 예측 흐름을 다르게 조정 가능 [4] 효과 지연 반영: 항생제마다 효과가 나타나는 시간 차이를 가중치 또는 마스크 형태로 반영/예: Vancomycin은 1일 후, Piperacillin은 2일 후 효과가 나타나는 지연 구조를 학습 > > 최종 구조 개요 > > - Static Encoder: 항생제 종류, 감염 균주 등 고정 정보 인코딩 > - Encoder (Observed features): 시계열 임상 수치 및 항생제 투여 여부 등 > - Decoder (Known future inputs): 미래 시점의 항생제 종류 및 투여 계획 > - Conditional Gating Layer: 항생제와 균주 정보를 입력으로 받아 예측 경로 가중치 조절 > - Output: 조건에 따른 NEWS score 예측 > > 기대 효과 > > - 항생제 반응 차이 반영: 항생제-균주 조합에 따른 실제 임상 반응 예측 가능 > - 시나리오 기반 예측: 항생제 변경 시 예후 변화를 시뮬레이션 가능 > - 데이터 손실 방지: 항생제별로 데이터를 분할하지 않아 데이터 효율성 유지 > - 상호작용 내재화: 항생제-균주 관계를 잠재 공간에서 학습 가능 > - 반응 지연 반영: 실제 약물 효과 발생 시점을 반영해 예측 정확도 향상 → 항생제나 균주에 따라 중요한 feature가 다를 수도 있고 delay 효과가 다를 수도 있음을 반영 가능 (맞나?)</a></p><hr><p><em>2025-07-19</em> ⋯ RAG #3 자동 대화 이력 관리</p><p style=height:4.5em;overflow:hidden><a href=/docs/study/ai/ai3/>1. 자동 대화 이력 관리 `ChatPromptTemplate`을 통해 시스템 메시지를 포함하는 프롬프트를 만든다. 시스템 메시지는 모델에게 “너는 금융 상담사야”라고 역할을 부여하는 것이다. 이어지는 `("placeholder", "{messages}")`는 실제 사용자의 질문과 AI의 답변이 이 자리에 채워질 것이라는 의미다. 이 프롬프트는 `chat = ChatOpenAI(model="gpt-4o-mini")`와 연결되는데, 이는 OpenAI의 gpt-4o-mini 모델을 사용하는 챗 인터페이스이다. 이 프롬프트와 모델을 `prompt | chat`이라는 LCEL 표현으로 묶으면, 하나의 체인이 만들어진다. 이 체인은 주어진 메시지 목록을 받아, GPT 모델에 전달하고 응답을 생성하는 구조다. 이제 이 체인을 사용해 실제 대화를 진행한다. 첫 번째 방법은 단순히 리스트로 과거 대화 내용을 전달하는 것이다. 사람이 “저축을 늘리려면 어떻게 해야 하나요?”라고 묻고, AI가 답하고, 사용자가 다시 “방금 뭐라고 했나요?”라고 재확인 질문을 던진다. 이 때 invoke() 메서드로 전체 메시지 리스트를 넘기면, 모델은 이 대화를 바탕으로 응답을 생성한다. 하지만 이 방식은 매번 메시지를 수동으로 넘겨야 하므로 실전에서는 불편하다. 그래서 등장하는 것이 ChatMessageHistory다. 이 클래스는 이전 대화 내용을 메모리에 저장하고 관리하는 도구이다. add_user_message()와 add_ai_message()를 통해 메시지를 하나씩 저장할 수 있고, 이후에는 .messages를 통해 전체 대화 내용을 꺼낼 수 있다. 이 메시지를 체인에 넘기면, 마치 인간과 대화하듯 연속적인 문맥이 반영된 응답이 나온다. 이 방식은 훨씬 유연하며, 체인과 연결해서 반복적으로 사용할 수 있다. 하지만 여전히 문제는 있다. 대화가 길어지면 모델의 입력 토큰 수가 초과될 수 있고, 세션 별로 기억을 구분해야 하는 요구도 발생한다. 이를 해결하기 위해 RunnableWithMessageHistory가 사용된다. 이 클래스는 체인을 감싸고, 특정 세션 ID에 따라 메시지 기록을 저장하거나 불러올 수 있도록 해준다. 즉, 사용자 A와 B가 서로 다른 대화를 동시에 해도, 각각의 대화가 독립적으로 기억되는 것이다. RunnableWithMessageHistory는 어떤 키를 기준으로 입력 메시지와 대화 이력을 구분할 것인지도 명시할 수 있다. 예를 들어 사용자의 질문은 "input"이라는 키에, 이전 대화는 "chat_history"라는 키에 저장된다. 이제 세션 기반 체인을 실행해보면, 처음 사용자가 "저축을 늘리려면 어떻게 해야 하나요?"라고 질문하고, 이후 "내가 방금 뭐라고 했나요?"라고 하면, 모델은 그 이전에 했던 말을 기억하고 그대로 요약해서 말해준다. 이건 LLM이 마치 실제 사람처럼, “방금 내가 뭐라고 했지?”라는 질문에 자연스럽게 답한다. 하지만 대화가 길어지면 또 다른 문제가 생긴다. 너무 많은 대화가 누적되면 입력 제한 때문에 모델이 다 받아들이지 못할 수 있다. 이를 해결하기 위해 trim_messages가 등장한다. 이 함수는 과거 메시지 중 일부만 남기고 나머지는 제거하는데, 예제에서는 "last" 전략을 사용하고 최대 2개의 메시지만 유지하도록 설정했다. 메시지를 트리밍한 후에는 그 줄어든 메시지를 기반으로 다시 체인을 실행할 수 있다. 이 방식은 마치 인간이 “최근 이야기만 기억하고 과거는 까먹는” 것과 같은 전략이다. 이걸 통해 시스템은 메모리 부담을 줄일 수 있고, 짧고 효율적인 대화를 유지할 수 있다. 더 고급 기능으로는 대화 내용을 ‘요약’해서 기억하는 방식이 있다. summarize_messages() 함수는 현재까지의 대화 내용을 GPT에게 전달해 요약을 요청하고, 요약된 내용을 새로운 시스템 메시지로 저장한다. 이 방식은 메시지를 전부 저장하는 대신 핵심 요약만 기억하게 만드는 전략이다. 마치 비서에게 “지금까지의 대화 요약 좀 해줘”라고 말한 뒤, 그 요약 내용을 기반으로 다음 대화를 이어가는 방식이다. 예를 들어 “저에게 어떤 재정적 조언을 해주셨나요?”라는 질문을 받았을 때, 모델은 이전 대화 전체를 기억하는 대신 그 요약된 내용을 참조하여 응답하게 된다. 이 접근법은 특히 긴 세션을 유지하면서도 중요한 맥락을 잃지 않도록 하기 위해 유용하다. 2. 정리 출처 책 RAG 마스터: 랭체인으로 완성하는 LLM 서비스: 멀티모달, 그래프 RAG, 에이전트, 파인튜닝까지</a></p><hr><p><em>2025-07-19</em> ⋯ RAG #2 출력 파서의 개념, Pydantic/Json 출력 파서</p><p style=height:4.5em;overflow:hidden><a href=/docs/study/ai/ai2/>1. 출력 파서의 개념과 종류 그리고 세가지 주요 메서드 출력 파서(output parser)는 LLM에서 생성된 응답을 받아서 우리가 원하는 형식으로 변환해주는 역할을 한다. 쉽게 말해, LLM은 텍스트만 생성하지만 우리는 그 텍스트를 리스트, 딕셔너리, JSON, 숫자 등 구조화된 데이터로 바꾸어서 프로그램에 넘기거나, 다음 단계 체인으로 활용하길 원할 때가 많다. 출력 파서는 이 연결고리 역할을 한다. 출력 파서는 LLM이라는 기계가 말한 인간 언어를 다시 기계가 이해할 수 있는 언어로 '번역'하는 통역사 같은 존재이다. 예를 들어 LLM이 “답은 아시아입니다”라고 말하면, 이걸 다시 `{"answer": "아시아"}` 같은 JSON 객체로 바꿔주는 게 파서의 역할이다. 반대로 말하면, 출력 파서 없이는 LLM이 말한 결과를 그대로 사람이 읽고 판단하거나 후처리 코드를 추가해야만 한다. 출력 파서에는 다양한 종류가 있다. 가장 기본적인 것이 `StrOutputParser`이다. 이 파서는 LLM이 생성한 응답을 그대로 문자열로 반환한다. 아무런 후처리를 하지 않기 때문에 단순하지만, 그만큼 유연성은 떨어진다. 다음은 `JsonOutputParser`인데, 이 파서는 LLM이 생성한 텍스트가 JSON 형태일 것으로 기대하고, 그것을 Python의 딕셔너리 형태로 파싱해준다. 예를 들어 LLM이 `{"answer": "아시아"}`라는 응답을 내놓았다면, JsonOutputParser는 이걸 `dict(answer="아시아")` 형태로 바꿔주는 것이다. 이때 중요한 것은 LLM이 정말로 JSON 형태로 출력했는지 여부이다. 만약 사람이 말하듯 그냥 “아시아입니다.”라고 하면 파싱에 실패하게 된다. 이때 등장하는 것이 `RetryWithErrorOutputParser`다. 이 파서는 기본 파서(예: JsonOutputParser)에 덧붙여 사용하는 구조로, LLM의 응답이 잘못된 형식일 때 자동으로 LLM에게 “출력을 다시 해주세요. 이 형식에 맞춰서요.”라고 재요청을 보내는 기능을 포함한다. 예를 들어 사용자가 “가장 큰 대륙은?”이라고 물었고, LLM이 “아시아입니다.”라고 대답했는데 우리는 JSON이 필요하다면, RetryWithErrorOutputParser는 이 응답을 보고 “JSON 형식이 아니네요, 다시 해주세요”라고 LLM에게 새로운 요청을 자동으로 보낸다. 즉, 이 파서는 파싱 실패를 감지하고 그것을 LLM에게 피드백으로 주어 재시도하게 만든다는 점에서 매우 실용적이다. 이제 주요 메서드를 살펴보자. 출력 파서의 핵심 기능은 크게 세 가지로 요약할 수 있다. 첫 번째는 `parse()` 메서드다. 이 메서드는 가장 기본적이면서도 핵심적인 함수인데, LLM이 생성한 문자열을 받아서 우리가 원하는 구조로 변환하는 역할을 한다. 예를 들어 JsonOutputParser의 `parse()`는 문자열을 JSON으로 바꾸는 역할을 하고, StrOutputParser의 `parse()`는 그냥 텍스트 그대로 반환한다. 사용자는 이 메서드만 호출하면 LLM의 응답을 쉽게 활용 가능한 형식으로 바꿀 수 있다. 두 번째는 `get_format_instructions()` 메서드다. 이 메서드는 LLM이 어떤 형식으로 출력을 생성해야 하는지 알려주는 설명 텍스트를 반환한다. 예를 들어 JsonOutputParser의 경우 이 메서드는 “출력은 반드시 다음과 같은 JSON 형식이어야 합니다”라는 문장을 반환한다. 이 설명은 보통 프롬프트에 포함되어, LLM이 출력 포맷을 정확하게 지키도록 유도하는 데 쓰인다. 다시 말해, 이 메서드는 LLM과 사용자 사이의 형식적 계약을 정의해주는 문장이다. 프롬프트를 구성할 때 "당신의 응답은 반드시 이 형식에 맞춰야 합니다"라고 할 수 있도록 도와주는 것이다. 세 번째는 `parse_with_prompt()` 메서드다. 이 메서드는 응답을 단순히 파싱하는 것을 넘어서, 어떤 프롬프트에 대해 생성된 응답인지를 함께 받아들이고, 그 문맥을 고려해서 파싱을 수행한다. 특히 RetryWithErrorOutputParser에서 이 메서드는 중요한 역할을 한다. 왜냐하면 LLM에게 재요청을 보낼 때 원래 프롬프트가 무엇이었는지를 같이 알아야 하기 때문이다. 예를 들어, LLM이 “아시아입니다.”라고 잘못된 응답을 내놓았다면, RetryWithErrorOutputParser는 원래의 질문("가장 큰 대륙은?")과 함께 LLM에게 "다시 JSON 형식으로 출력해주세요"라고 재요청할 수 있어야 하는데, 그때 이 `parse_with_prompt()`가 그 문맥을 함께 넘겨주는 역할을 한다. 이 메서드는 LLM이 실수했을 때 '정정 질문'을 만드는 데 필요한 모든 정보를 갖고 있다고 보면 된다. 결국 출력 파서는 단순한 문자열을 넘어서, 구조화된 데이터로의 다리 역할을 해주는 필수 도구이고, LLM을 단순한 텍스트 생성기가 아니라 모듈화된 시스템으로 쓸 수 있게 해주는 핵심 장치이다. 특히 JSON, 리스트, 숫자, 불리언 같은 구체적인 타입이 필요한 downstream task나 체인 구성에서는 출력 파서 없이는 체계적인 처리가 거의 불가능하다. `parse()`, `get_format_instructions()`, `parse_with_prompt()`는 각각 결과 변환, 포맷 명세, 실패 시 재처리의 핵심 기능을 제공하며, LangChain 전체 체인의 견고함과 재사용 가능성을 높이는 데 매우 중요한 역할을 한다. LLM의 응답은 본질적으로 예측이며, 그 예측이 우리가 원하는 구조에 맞지 않을 수 있기 때문에, 출력 파서는 이 예측을 수용 가능한 형식으로 '정제하는 마지막 관문'이라고 할 수 있다. 2. Pydantic 출력 파서 아래 코드는 LangChain에서 LLM의 출력 결과를 구조화된 데이터로 변환하고, 그 데이터가 특정 조건을 만족하는지 검증하는 전체 흐름을 보여주는 예제이다. 핵심적으로는 Pydantic이라는 데이터 모델링 및 검증 도구를 활용하여, LLM이 생성한 텍스트를 일종의 '폼'에 맞게 채우고, 그 값이 유효한지 검사하는 작업이다. 쉽게 말하면, LLM에게 빈칸이 있는 서식을 주고 “이 틀에 맞춰서 정확히 채워줘”라고 요구하고, 심지어 “네가 채운 값이 올바른지 내가 마지막에 확인도 할 거야”라고 하는 방식이다. 이건 마치 LLM을 한 명의 비서라고 가정하고, 우리가 미리 준비해둔 체크리스트에 따라 문서를 작성하게 시키되, 마지막에는 또 다른 직원인 Pydantic에게 이 문서가 규칙에 맞게 작성되었는지 확인하게 만드는 것이다. 먼저 `ChatOpenAI(model_name="gpt-4o", temperature=0.0)`은 OpenAI의 GPT-4o 모델을 초기화하는 부분이다. 여기서 temperature가 0.0이라는 것은 모델의 출력을 가장 결정론적(deterministic)으로 만들겠다는 뜻이다. 즉, 같은 입력에 항상 같은 출력을 내놓도록 하는 설정이다. 금융 조언처럼 신뢰성이 중요한 분야에서는 이런 설정이 흔히 사용된다. 이제 핵심은 `FinancialAdvice`라는 Pydantic 기반의 데이터 클래스다. 이 클래스는 우리가 기대하는 출력 형태를 정의한다. 필드는 두 개다. `setup`은 사용자가 던지는 질문이고, `advice`는 그 질문에 대한 금융 조언이다. 단순히 구조만 정의한 것이 아니라, 그 안에 유효성 검사 로직도 포함되어 있다. `@model_validator`를 사용한 `question_ends_with_question_mark` 함수는 setup이 반드시 물음표(`?`)로 끝나는 문장인지 확인한다. 만약 그렇지 않다면, 즉 “부동산 투자 어떻게 생각해”처럼 평서문이라면, 에러를 발생시키고 실행을 중단한다. 이런 식의 검증은 데이터의 형식적 정확성을 보장하는 데 매우 유용하다. LLM은 아무리 잘 훈련되어 있어도 항상 원하는 형식대로 출력을 내지 않기 때문에, 사후에 이런 검사 절차가 들어가는 것이 매우 중요하다. 이제 `PydanticOutputParser`를 설정한다. 이 파서는 LLM의 응답을 받아 `FinancialAdvice`라는 데이터 모델에 맞춰 자동으로 파싱해주는 역할을 한다. 즉, GPT가 `{ "setup": "어떤 상황이죠?", "advice": "이렇게 하면 좋겠습니다." }`처럼 텍스트를 생성하면, 이 파서가 이를 Python 객체로 바꿔준다. 특히 이 과정에서 위에서 정의한 유효성 검사 함수도 함께 작동한다. 그다음은 프롬프트 템플릿 구성이다. 여기서 중요한 점은 `format_instructions`라는 변수이다. 이것은 PydanticOutputParser의 `get_format_instructions()` 메서드에서 가져온 것으로, “이런 형식으로 출력해 주세요”라는 안내 문장을 LLM에게 보여주기 위한 것이다. 이 지침에는 예를 들어 출력이 JSON이어야 하고, 필드는 어떤 것들이 있어야 하며, 문자열은 따옴표로 감싸야 한다는 등의 구체적인 조건이 담겨 있다. 이런 지침이 없으면 LLM은 “음, 내 마음대로 써야지”라고 생각하고 엉뚱하게 문단을 쓰거나 서술체로 응답할 수도 있다. 따라서 명확한 출력 형식을 미리 보여주는 것은 매우 중요하다. 프롬프트 자체는 `"다음 금융 관련 질문에 답변해 주세요.\n{format_instructions}\n질문: {query}\n"`와 같은 형식이다. LLM은 이 프롬프트를 받으면, 주어진 질문에 대해 `setup`과 `advice`라는 두 개의 항목이 포함된 JSON 형식으로 응답하게 된다. 이 구조는 이후 체인으로 연결된다. 체인은 `prompt | model | parser`의 형태로, 순서대로 프롬프트를 생성하고, 이를 모델에 입력하고, 모델의 출력을 파서에 넘겨 구조화된 객체로 변환하는 연산을 의미한다. 이것은 LangChain Expression Language(LCEL)의 핵심 개념으로, 각 단계를 파이프라인처럼 연결하는 방식이다. 이제 실제로 체인을 실행한다. `chain.invoke({"query": "부동산에 관련하여 금융 조언을 받을 수 있는 질문하여라."})`를 호출하면, 먼저 프롬프트가 구성되고, GPT-4o 모델이 응답을 생성하고, 그 결과가 `FinancialAdvice` 형식에 맞게 파싱된다. 만약 모델이 "부동산에 대해 생각해보는 것이 좋습니다."와 같은 setup을 제공하고, 그것이 `?`로 끝나지 않는다면, 앞서 정의한 유효성 검사에서 실패하게 되고 `ValueError`가 발생한다. 이 오류는 try-except 문에서 잡히고, "오류 발생" 메시지를 출력하게 된다. 이 전체 코드는 단순히 GPT에게 질문을 던지고 응답을 받는 것을 넘어서, 응답의 형식을 규정하고, 그 형식이 제대로 지켜졌는지 검증하며, 결과를 안전하게 사용할 수 있도록 구조화하는 전체 흐름을 보여준다. LLM은 자유롭게 말할 수 있지만, 실제 애플리케이션에서는 그런 자유로운 응답이 문제가 될 수 있다. 예를 들어 API로 전달되는 값은 항상 딕셔너리여야 하거나, 숫자여야 하거나, 특정 포맷을 따라야 할 수도 있다. 이런 상황에서 PydanticOutputParser와 같은 파서는 LLM을 안전하게 시스템 내부로 끌어들이는 '입력 정화 필터'로 작동한다. 사용자는 LLM의 강력한 언어 생성 능력을 활용하면서도, 그 결과가 시스템 전체 흐름을 망가뜨리지 않도록 제어할 수 있는 수단을 갖게 되는 것이다. 3. Json 출력 파서 아래 코드는 LangChain에서 LLM의 응답을 JSON 형식으로 받아올 때 사용할 수 있는 두 가지 출력 파서, 즉 `SimpleJsonOutputParser`와 `JsonOutputParser`의 차이와 사용 예시를 보여준다. 모두 공통적으로 하는 일은 LLM이 생성한 문자열을 Python 프로그램에서 다룰 수 있는 구조화된 JSON 형태로 변환하는 것이다. 하지만 각 파서는 기능과 사용 목적이 조금 다르다. 이 파서들은 마치 사람이 말한 문장을 보고 “이걸 JSON 문서처럼 해석해서 내가 쓸 수 있게 바꿔줄게”라고 말하는 해석기와 같다. 그런데 어떤 해석기는 단순히 `{}`로 된 구조만 확인하고 해석하는 반면, 다른 해석기는 “이건 정확히 어떤 항목이 있어야 하고, 어떤 설명이 붙어야 해”라는 조건까지 점검하고 이해하려고 든다. 바로 이 점이 두 파서의 핵심적인 차이다. 먼저 `SimpleJsonOutputParser`는 말 그대로 단순한 JSON 파서다. LLM이 만들어낸 응답이 단순히 JSON 포맷으로 되어 있다면, 그걸 그대로 `dict`로 변환해주는 기능을 한다. 특별한 데이터 모델을 요구하지 않기 때문에 사용이 간편하다. 이 파서는 사람이 손으로 JSON을 썼을 때처럼 `{ "key": "value" }`와 같이만 구성되어 있으면 문제없이 동작한다. 예를 들어 `"비트코인에 대한 짧은 한문장 설명"`이라는 질문에 대해 모델이 `{"description": "비트코인은 분산형 디지털 통화입니다."}`라고 응답하면, SimpleJsonOutputParser는 이걸 바로 Python의 딕셔너리로 바꿔준다. 중요한 점은 이 파서는 ‘무슨 내용이 있는지’에는 관심이 없고, 오직 JSON 문법을 따르느냐만 본다는 것이다. 특히 `stream()` 메서드는 이 파서를 사용할 때 유용한 기능이다. 이는 LLM의 응답을 스트리밍 방식으로 받아오면서, JSON 조각이 도착할 때마다 실시간으로 구문 분석할 수 있게 해준다. 마치 누군가 JSON 문서를 타이핑하고 있을 때, 한 줄씩 도착하자마자 그걸 실시간으로 읽고 처리하는 것과 비슷하다. 따라서 대용량 출력이나 실시간 피드백이 필요한 시스템에서는 이 스트리밍 방식이 유용하다. 사용자는 `list(json_chain.stream({...}))`과 같이 호출하면, 모델이 출력한 JSON 조각들이 순차적으로 처리되는 과정을 직접 볼 수 있다. 반면 `JsonOutputParser`는 훨씬 더 정교하고 강력한 구조를 갖는다. 이 파서는 Pydantic 모델과 연동되어, LLM의 출력이 특정 데이터 모델에 꼭 맞도록 강제할 수 있다. 예제에서는 `FinancialAdvice`라는 Pydantic 모델을 만들었고, 이 모델은 `setup`이라는 질문 항목과 `advice`라는 답변 항목을 포함한다. 이처럼 JsonOutputParser는 단순히 JSON 문법을 지키는지를 넘어서, “setup이라는 항목이 있어야 하며 그건 문자열이어야 하고, advice도 마찬가지”라는 구조적인 조건까지 검사한다. LLM이 아무리 JSON처럼 보이는 출력을 만들어도, 이 필드가 빠졌거나 형식이 잘못되면 에러가 난다. 따라서 이 파서는 구조적인 안정성이 중요할 때 더 적합하다. 또한 `get_format_instructions()` 메서드는 매우 중요한 역할을 한다. 이 메서드는 “너는 이런 형식으로 응답을 작성해야 해”라고 LLM에게 알려주는 포맷 지침을 자동으로 생성해준다. 즉, 프롬프트 안에 이 지침을 포함시켜, LLM이 정확히 어떤 형식의 JSON을 생성해야 하는지 이해하도록 돕는다. 예제에서 사용한 프롬프트는 `template="다음 금융 관련 질문에 답변해 주세요.\n{format_instructions}\n{query}\n"`와 같이 구성되어 있는데, 이 중 `{format_instructions}` 자리에 이 지침이 삽입된다. 이걸 LLM이 읽고 “아, 나는 setup과 advice라는 필드를 가진 JSON 객체를 만들어야 하는구나”라고 이해하는 것이다. 이제 체인 구성 부분을 보자. `prompt | model | parser`라는 구문은 LangChain의 LCEL 방식으로, 프롬프트 생성 → 모델 응답 → 응답 파싱의 전체 파이프라인을 한 줄로 구성하는 방법이다. 프롬프트는 사용자의 질문을 받아 LLM에 전달할 형태로 바꾸고, 모델은 해당 질문에 답변을 생성하며, 마지막으로 파서는 그 답변이 JSON 형식에 맞게 잘 만들어졌는지를 확인하고 파싱해서 구조화된 데이터로 변환한다. 이 과정을 체인 하나로 묶으면, 개발자는 한 번의 호출로 텍스트 → 구조화 응답이라는 전체 과정을 자동화할 수 있다. `chain.invoke(...)`는 이 전체 체인을 실행하는 명령이다. 여기서는 `"부동산에 관련하여 금융 조언을 받을 수 있는 질문하여라."`라는 문장이 입력되고, LLM은 이에 대해 `{ "setup": "부동산 투자에 있어 어떤 점을 고려해야 할까요?", "advice": "지역 개발 계획과 대출 이자율을 꼼꼼히 따져보세요." }`와 같은 응답을 생성할 것으로 기대된다. 이 응답은 JsonOutputParser를 거쳐 Python 객체로 변환되며, 구조가 올바르지 않으면 예외가 발생하게 된다. 결론적으로 SimpleJsonOutputParser와 JsonOutputParser는 모두 LLM의 출력 결과를 JSON으로 다루기 위한 도구지만, 전자는 단순히 문법만 확인하는 해석기이고, 후자는 구조까지 엄격히 검사하는 검열관 같은 역할을 한다. SimpleJsonOutputParser는 유연하고 빠르지만 구조 안정성이 낮고, JsonOutputParser는 안정적이고 신뢰할 수 있지만, 구조에 어긋난 응답에 대해서는 더 엄격하다. 사용자는 시스템의 목적에 따라 이 두 파서 중 적절한 것을 선택하면 된다. 예를 들어 유저와의 대화에서 간단한 정보만 뽑아낼 때는 SimpleJsonOutputParser가 적합하고, LLM의 출력을 그대로 다음 프로세스로 넘겨야 하는 정형화된 응용에서는 JsonOutputParser가 더 적합하다. 이 두 파서는 LLM을 마치 JSON API처럼 다룰 수 있게 만들어주는 핵심 도구라고 할 수 있다. 출처 책 RAG 마스터: 랭체인으로 완성하는 LLM 서비스: 멀티모달, 그래프 RAG, 에이전트, 파인튜닝까지</a></p><hr><div class=pagination style=margin-top:2rem;display:flex;justify-content:center;align-items:center;gap:1rem><a href=/docs/study/ai/page/2/ style="padding:.5rem 1rem;text-decoration:none">←</a>
<span style=color:#666>3 / 4
</span><a href=/docs/study/ai/page/4/ style="padding:.5rem 1rem;text-decoration:none">→</a></div></article><footer class=book-footer><div class="flex flex-wrap justify-between"></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents></nav></div></aside></main></body></html>