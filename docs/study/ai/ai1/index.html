<!doctype html><html lang=en-us dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="
  RAG #1 랭체인, LCEL, 프롬프트
  #

#2025-07-17


  1. 랭체인 생태계의 주요 패키지
  #

랭체인(LangChain)은 LLM(Large Language Model)을 활용한 애플리케이션을 쉽게 만들 수 있도록 돕는 프레임워크이다. 이 생태계는 단일 라이브러리로 구성된 것이 아니라 여러 개의 하위 패키지로 나뉘어 있고, 각각의 역할이 명확하게 분리되어 있다. 랭체인의 주요 목적은 LLM을 단순한 텍스트 생성 도구가 아니라, 여러 시스템과 결합하여 유의미한 작업을 수행하는 &ldquo;생각하고 행동하는&rdquo; 에이전트로 만드는 것이다. 이 생태계의 핵심 구성 요소들을 쉽게 설명하자면, 마치 LLM이라는 뇌에 주변 감각기관과 기억장치, 도구들, 그리고 의사결정 능력을 붙여주는 것이라고 보면 된다."><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="https://yshghid.github.io/docs/study/ai/ai1/"><meta property="og:site_name" content=" "><meta property="og:title" content="RAG #1 랭체인, LCEL, 프롬프트"><meta property="og:description" content="RAG #1 랭체인, LCEL, 프롬프트 # #2025-07-17
1. 랭체인 생태계의 주요 패키지 # 랭체인(LangChain)은 LLM(Large Language Model)을 활용한 애플리케이션을 쉽게 만들 수 있도록 돕는 프레임워크이다. 이 생태계는 단일 라이브러리로 구성된 것이 아니라 여러 개의 하위 패키지로 나뉘어 있고, 각각의 역할이 명확하게 분리되어 있다. 랭체인의 주요 목적은 LLM을 단순한 텍스트 생성 도구가 아니라, 여러 시스템과 결합하여 유의미한 작업을 수행하는 “생각하고 행동하는” 에이전트로 만드는 것이다. 이 생태계의 핵심 구성 요소들을 쉽게 설명하자면, 마치 LLM이라는 뇌에 주변 감각기관과 기억장치, 도구들, 그리고 의사결정 능력을 붙여주는 것이라고 보면 된다."><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="docs"><meta property="article:published_time" content="2025-07-17T00:00:00+00:00"><meta property="article:modified_time" content="2025-07-17T00:00:00+00:00"><meta property="article:tag" content="2025-07"><title>RAG #1 랭체인, LCEL, 프롬프트 |</title><link rel=icon href=/favicon.png><link rel=manifest href=/manifest.json><link rel=canonical href=https://yshghid.github.io/docs/study/ai/ai1/><link rel=stylesheet href=/book.min.6217d077edb4189fd0578345e84bca1a884dfdee121ff8dc9a0f55cfe0852bc9.css integrity="sha256-YhfQd+20GJ/QV4NF6EvKGohN/e4SH/jcmg9Vz+CFK8k=" crossorigin=anonymous><script defer src=/fuse.min.js></script><script defer src=/en.search.min.142473304c3c79ae8504ea13318c884b53bd4274e51108f4694404626a40b344.js integrity="sha256-FCRzMEw8ea6FBOoTMYyIS1O9QnTlEQj0aUQEYmpAs0Q=" crossorigin=anonymous></script></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><img src=/logo.png alt=Logo class=book-icon><span></span></a></h2><div class="book-search hidden"><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><script>document.querySelector(".book-search").classList.remove("hidden")</script><ul><li class=book-section-flat><span>기록</span><ul><li><a href=/docs/hobby/book/>글</a><ul></ul></li><li><a href=/docs/hobby/daily/>일상</a><ul></ul></li></ul></li><li class=book-section-flat><span>공부</span><ul><li><a href=/docs/study/algorithm/>Algorithm</a><ul></ul></li><li><a href=/docs/study/bioinformatics/>Bioinformatics</a><ul></ul></li><li><a href=/docs/study/ai/>AI</a><ul></ul></li><li><a href=/docs/study/sw/>SW</a><ul></ul></li><li><a href=/docs/study/career/>취업</a><ul></ul></li><li><a href=/docs/study/etc/>etc</a><ul></ul></li></ul></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu></label><h3>RAG #1 랭체인, LCEL, 프롬프트</h3><label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><ul><li><a href=#1-랭체인-생태계의-주요-패키지>1. 랭체인 생태계의 주요 패키지</a></li><li><a href=#2-랭체인-표현언어>2. 랭체인 표현언어</a></li><li><a href=#3-랭체인-프롬프트-탬플릿>3. 랭체인 프롬프트 탬플릿</a></li></ul></li></ul></nav></aside></header><article class="markdown book-article"><h1 id=rag-1-랭체인-lcel-프롬프트>RAG #1 랭체인, LCEL, 프롬프트
<a class=anchor href=#rag-1-%eb%9e%ad%ec%b2%b4%ec%9d%b8-lcel-%ed%94%84%eb%a1%ac%ed%94%84%ed%8a%b8>#</a></h1><p>#2025-07-17</p><hr><h3 id=1-랭체인-생태계의-주요-패키지>1. 랭체인 생태계의 주요 패키지
<a class=anchor href=#1-%eb%9e%ad%ec%b2%b4%ec%9d%b8-%ec%83%9d%ed%83%9c%ea%b3%84%ec%9d%98-%ec%a3%bc%ec%9a%94-%ed%8c%a8%ed%82%a4%ec%a7%80>#</a></h3><p>랭체인(LangChain)은 LLM(Large Language Model)을 활용한 애플리케이션을 쉽게 만들 수 있도록 돕는 프레임워크이다. 이 생태계는 단일 라이브러리로 구성된 것이 아니라 여러 개의 하위 패키지로 나뉘어 있고, 각각의 역할이 명확하게 분리되어 있다. 랭체인의 주요 목적은 LLM을 단순한 텍스트 생성 도구가 아니라, 여러 시스템과 결합하여 유의미한 작업을 수행하는 &ldquo;생각하고 행동하는&rdquo; 에이전트로 만드는 것이다. 이 생태계의 핵심 구성 요소들을 쉽게 설명하자면, 마치 LLM이라는 뇌에 주변 감각기관과 기억장치, 도구들, 그리고 의사결정 능력을 붙여주는 것이라고 보면 된다.</p><p>가장 중심이 되는 패키지는 <code>langchain-core</code>이다. 이 패키지는 랭체인의 모든 기반 구조를 제공한다. 쉽게 말해, LLM이 다양한 입력을 받아들이고, 체계적으로 이를 가공한 후 출력을 생성할 수 있도록 돕는 클래스들과 프로토콜이 담겨 있다. 예를 들어, 프롬프트 템플릿을 정의하는 기능, 체인(chain)이라고 불리는 논리적 연산 흐름을 정의하는 구조, 그리고 다양한 입출력 변환 도구가 이곳에 속한다. 이 핵심 패키지는 독립적으로 작동할 수는 없지만, 다른 모든 모듈들의 기반이 되는 뼈대라고 할 수 있다. 자동차로 치면 차체 프레임과 같다.</p><p>다음으로 중요한 것은 <code>langchain-openai</code>이다. 이는 OpenAI의 GPT 모델, 예를 들어 ChatGPT나 GPT-4 같은 모델과 랭체인을 연결해주는 역할을 한다. 이 패키지를 통해 사용자는 OpenAI API 키를 입력하고, 랭체인의 LLM 인터페이스를 이용해 손쉽게 질문을 던지고 응답을 받을 수 있다. 단순한 API 호출 이상의 기능을 제공하는데, 예를 들어 텍스트를 기반으로 함수 호출을 유도하거나, Chat 모델을 Memory나 Agent와 결합하는 식의 고급 기능도 여기에서 가능해진다.</p><p>LLM을 제대로 쓰기 위해서는 외부 지식과 연동하는 것이 중요하다. 여기서 등장하는 것이 <code>langchain-community</code>이다. 이 패키지는 다양한 데이터 소스, 벡터 데이터베이스, 웹 검색 API, 문서 리더 등 수많은 외부 리소스와 연결할 수 있는 커넥터들을 제공한다. PDF를 읽거나, Notion의 내용을 가져오거나, Pinecone, FAISS, Weaviate 같은 벡터 DB에 질의할 수 있는 기능도 모두 여기에 포함된다. 쉽게 말하면 LLM이 세상의 다양한 지식에 손을 뻗을 수 있게 해주는 다리 역할을 한다.</p><p>문서 기반 질의 응답 시스템을 만들고 싶다면 <code>langchain-text-splitters</code>가 중요하다. 대형 문서를 LLM이 이해할 수 있도록 적절히 쪼개는 기능을 수행한다. 사람이 책을 읽을 때 한 문단씩 끊어서 요약하듯, LLM도 긴 글을 나눠서 이해해야 한다. 이 패키지는 문장을 의미 단위로 자르거나, 특정 길이로 잘라서 겹치게 만드는 등 다양한 전략을 제공한다. 이는 나중에 벡터 DB에 문서를 넣고, 검색을 통해 적절한 조각을 찾아 LLM의 입력으로 넣을 때 필수적인 전처리 단계이다.</p><p>벡터 검색은 현대 LLM 응용의 핵심이다. <code>langchain-embeddings</code> 패키지는 텍스트를 벡터로 변환하는 다양한 임베딩 모델을 래핑한다. 예를 들어 OpenAI의 text-embedding-3 모델이나 HuggingFace에서 제공하는 임베딩 모델들을 이 모듈을 통해 쉽게 쓸 수 있다. 이렇게 얻은 벡터는 이후 벡터 데이터베이스에 저장되어 유사도 검색에 사용된다. 유저가 입력한 질문과 가장 유사한 문서 조각을 찾아 LLM에게 제공하는 것이 RAG(Retrieval Augmented Generation)의 핵심인데, 그 시작점이 바로 이 임베딩 패키지이다.</p><p>이제 검색된 결과를 기반으로 LLM이 응답을 생성하게 하려면 <code>langchain-chains</code> 패키지가 필요하다. 이 모듈은 프롬프트 체이닝, 질의 응답 체인, 요약 체인 등 다양한 고수준 작업 흐름을 정의하는 데 쓰인다. 즉, 질문을 프롬프트로 바꾸고, 임베딩을 찾고, 결과를 조합해 응답하는 일련의 흐름을 순차적으로 정의하는데 적합하다. 마치 레고 블록을 조립하듯 체인을 구성하면 복잡한 작업도 쉽게 재사용할 수 있다.</p><p>한편, 반복적이고 기억이 필요한 대화를 만들기 위해서는 <code>langchain-memory</code> 패키지가 쓰인다. 이 모듈은 사용자의 이전 발화를 기억하여 대화의 문맥을 유지하거나, 요약된 기억을 저장하는 데 사용된다. 장기기억과 단기기억을 구성할 수 있고, 이를 바탕으로 에이전트 기반 응용에도 확장 가능하다.</p><p>마지막으로 중요한 것이 <code>langchain-agents</code>이다. 이 패키지는 LLM이 단순히 응답하는 수준을 넘어, &ldquo;도구(tool)&ldquo;를 호출하고, 스스로 다음 행동을 결정하며, 일련의 작업을 해결하도록 만드는 핵심 모듈이다. 예를 들어 유저가 &ldquo;내일 서울 날씨 알려줘"라고 하면, 에이전트는 스스로 웹 검색 도구를 호출해 결과를 받아오고, 이를 종합해 LLM이 답변을 생성하게 한다. 이 때 도구(tool)는 <code>langchain-tools</code> 패키지에서 정의되며, 검색, 계산, API 호출 등의 기능을 구성할 수 있다.</p><p>요약하자면, LangChain 생태계는 단일 LLM을 중심으로 프롬프트, 체인, 메모리, 에이전트, 임베딩, 벡터 검색, 외부 도구 연결을 모듈화한 프레임워크이다. 각 패키지는 뉴런을 감싸는 신경망처럼 유기적으로 결합되어, 단순한 챗봇을 넘어 실제 사용 가능한 AI 서비스로의 확장을 가능하게 한다. LangChain을 이해한다는 것은 결국 LLM이 텍스트 생성뿐 아니라 사고하고, 검색하고, 행동하는 존재로 발전하는 과정을 구성요소 단위로 이해하고 활용하는 것이라고 할 수 있다.</p><h3 id=2-랭체인-표현언어>2. 랭체인 표현언어
<a class=anchor href=#2-%eb%9e%ad%ec%b2%b4%ec%9d%b8-%ed%91%9c%ed%98%84%ec%96%b8%ec%96%b4>#</a></h3><p>랭체인 표현언어(LangChain Expression Language, LCEL)는 LLM 기반 애플리케이션을 만들 때 복잡한 구성 요소를 쉽게 조립하고, 재사용 가능하며, 추론 가능한 방식으로 연결할 수 있도록 만든 일종의 &ldquo;언어"이다. 하지만 여기서 말하는 &lsquo;언어&rsquo;는 우리가 흔히 생각하는 프로그래밍 언어나 자연어처럼 텍스트로 명령을 쓰는 형식은 아니다. 대신, 여러 LLM 관련 구성 요소들—예를 들어 프롬프트, LLM 호출, 도구 사용, 조건 분기, 반복 등—을 조합하는 방식을 일관되고 체계적으로 정의한 표현 프레임워크를 의미한다. LCEL은 마치 레고 블록을 조립하듯이 LLM 애플리케이션을 짜기 위한 설계도 같은 것이다. 이 설계도를 이용하면 개별 부품(프롬프트, 툴, 체인)을 이해하지 못해도 전체 시스템을 어떻게 연결하고 동작시키는지는 명확하게 이해할 수 있게 된다.</p><p>기본적으로 LCEL은 &ldquo;Runnable"이라는 추상 개념을 중심으로 작동한다. Runnable은 실행 가능한 어떤 것이라는 뜻인데, 쉽게 말해 입력을 받아 출력을 내놓는 모든 구성 요소를 의미한다. 예를 들어 단순한 텍스트 프롬프트도 하나의 Runnable이고, OpenAI 모델을 호출하는 객체도 Runnable이며, 여러 단계를 거쳐 문서를 요약하고 질문에 답하는 전체 체인도 하나의 Runnable이 된다. 이렇게 정의하면, 어떤 구성 요소든 입력-출력 형태로 다루기만 하면 연결할 수 있기 때문에 시스템 전체를 일관되게 조립할 수 있게 된다.</p><p>LCEL에서 가장 중요한 특징 중 하나는 <code>|</code> 연산자, 즉 파이프라인 연결이다. 이 연산자는 Unix 명령어에서 여러 명령을 연쇄적으로 연결하듯, LCEL에서도 여러 Runnable들을 연결하는 데 쓰인다. 예를 들어, 사용자가 입력한 질문을 프롬프트 템플릿에 넣고, 그것을 LLM에 넣어 응답을 받는 구조는 <code>PromptTemplate | LLM</code> 같은 식으로 표현할 수 있다. 더 나아가 이 결과를 요약하거나 다른 도구에 전달하는 것도 <code>|</code>로 계속 연결할 수 있다. 즉, LCEL은 LLM 기반 파이프라인을 함수형 스타일로 구성할 수 있게 해주는 방식이다.</p><p>흥미로운 점은 LCEL이 단순히 기능을 연결하는 것에 그치지 않고, 각 단계의 타입(입력과 출력 형식)을 자동으로 추론하고 검증할 수 있다는 점이다. 예를 들어 어떤 프롬프트 템플릿이 dictionary 형태의 입력을 받아 string 형태의 프롬프트를 만든다면, 이 Runnable의 타입은 <code>Runnable[Dict[str, Any], str]</code> 같은 식으로 정의된다. 이는 다음에 연결될 LLM이 string을 입력으로 받는다는 것을 기대하기 때문에, 두 블록이 잘 맞는지 타입 수준에서 확인할 수 있게 된다. 다시 말해 LCEL은 동작 가능할 뿐 아니라 안전하게 구성된 시스템을 만드는 데 도움을 준다.</p><p>또한 LCEL은 분기와 반복 같은 고급 제어 흐름도 지원한다. 예를 들어 특정 조건에 따라 서로 다른 체인을 실행할 수 있게 하는 <code>Router</code>, 여러 문서에 대해 반복해서 같은 처리(예: 요약)를 적용하는 <code>map_runnables</code> 같은 유틸리티도 LCEL의 표현 언어 구조 안에 포함되어 있다. 이는 LLM 기반 시스템이 단순한 일직선의 흐름을 넘어서, 조건에 따라 다른 행동을 하고, 복수의 입력을 처리하고, 기억을 활용하는 등 복잡한 애플리케이션으로 확장되는 것을 가능하게 한다.</p><p>LCEL은 구조적으로 정의되기 때문에 디버깅도 쉽고, 시각적으로 표현하기에도 유리하다. 각 Runnable이 무엇을 하고 어떤 입력을 받고 어떤 출력을 내는지를 명확히 추적할 수 있고, 전체 파이프라인을 시각화할 수 있는 도구와도 잘 어울린다. 이런 특성은 LLM 시스템을 팀 단위로 개발할 때 특히 유용한데, 각 구성 요소를 모듈로 나누어 개발하고, 이를 LCEL 표현으로 연결함으로써 협업이 용이해지고 유지보수가 쉬워진다.</p><p>또한 LCEL은 back-end에 구애받지 않는다. 예를 들어 프롬프트를 ChatGPT에 넣을 수도 있고, HuggingFace 모델에 넣을 수도 있으며, 심지어 임베딩 벡터 생성기, 툴, API 호출 등의 기능과도 동일한 인터페이스로 연결할 수 있다. LCEL 표현 하나로 다양한 구성 요소가 섞인 복합 시스템을 일관된 방식으로 표현할 수 있는 것이다. 이는 LLM 중심 서비스가 실제 업무 환경에서 쓰일 때 다양한 외부 API, 사용자 입력, 문서, 데이터베이스와 연결되어야 하는 현실적인 요구에 매우 잘 맞는 설계이다.</p><p>결국 LCEL은 LangChain 생태계에서 LLM 애플리케이션을 구성하는 기본 문법이자 철학이다. 기존에는 각 기능을 코드로 조합하면서 많은 예외 처리를 해야 했던 작업들을, LCEL은 타입 안전성과 모듈성, 재사용성을 기반으로 구조화된 방식으로 구현할 수 있게 해준다. 이를 통해 개발자는 로우레벨 구현에 빠져들지 않고도 복잡한 LLM 시스템을 설계하고 조립할 수 있다. 마치 블록 쌓기처럼 눈에 보이는 단계를 통해 추론 가능한 시스템을 만들 수 있다는 점에서, LCEL은 LLM을 활용한 AI 개발의 추상화 수준을 한 단계 끌어올린 중요한 도구라고 할 수 있다.</p><h3 id=3-랭체인-프롬프트-탬플릿>3. 랭체인 프롬프트 탬플릿
<a class=anchor href=#3-%eb%9e%ad%ec%b2%b4%ec%9d%b8-%ed%94%84%eb%a1%ac%ed%94%84%ed%8a%b8-%ed%83%ac%ed%94%8c%eb%a6%bf>#</a></h3><p>아래 코드는 LangChain의 프롬프트 템플릿 시스템을 사용하는 예제이다. LangChain에서는 LLM에 보낼 입력을 단순한 문자열이 아니라 체계적으로 조립하고 재사용 가능한 구조로 만들 수 있도록 <code>PromptTemplate</code>이나 <code>ChatPromptTemplate</code> 같은 템플릿 클래스를 제공한다. 이 구조는 우리가 매번 LLM에게 보낼 프롬프트를 수작업으로 쓰는 대신, 일정한 형식에 따라 변수만 바꿔서 쓸 수 있도록 도와주는 일종의 &lsquo;서식 문서&rsquo; 같은 역할을 한다. 파인만 식으로 설명하자면, 이건 마치 이메일을 쓸 때 &ldquo;안녕하세요, {이름}님. 오늘은 {주제}에 대해 이야기해볼까요?&rdquo; 같은 틀을 미리 만들어 놓고, 이름과 주제만 매번 바꿔 쓰는 것과 비슷하다.</p><p><code>PromptTemplate.from_template("주제 {topic}에 대해 금융 관련 짧은 조언을 해주세요")</code>는 하나의 일반적인 프롬프트 템플릿을 만든다. 여기서 <code>from_template()</code>은 문자열 안에 중괄호로 감싼 <code>{topic}</code> 같은 변수를 지정할 수 있는 텍스트 포맷팅 기반 템플릿이다. 이 템플릿은 마치 &ldquo;틀"처럼 작동한다. 나중에 누군가가 &ldquo;topic"이라는 키를 가진 값을 전달하면, 해당 부분이 채워진 하나의 프롬프트 문자열이 만들어진다. 즉, <code>invoke({"topic": "투자"})</code>를 호출하면 실제 모델에 전달되는 프롬프트는 “주제 투자에 대해 금융 관련 짧은 조언을 해주세요”라는 문장이 된다. 여기서 핵심은 이 템플릿을 한 번 정의해두면, 다양한 주제에 대해 반복해서 재사용할 수 있다는 점이다.</p><p>그 다음에는 <code>ChatPromptTemplate</code>이 등장한다. 이 클래스는 조금 더 복잡한 대화를 모델링할 수 있는 구조를 제공한다. 우리가 단순히 텍스트 한 줄을 주는 것이 아니라, 시스템 메시지와 사용자 메시지를 구분해서 LLM에게 전달하는 방식이다. 예를 들어 <code>ChatPromptTemplate.from_messages()</code>를 사용할 경우, <code>("system", "당신은 유능한 금융 조언가입니다.")</code>는 시스템 역할의 메시지를 의미하고, 이는 LLM이 자기 자신을 어떻게 행동해야 하는지 정의해주는 &lsquo;성격 부여&rsquo; 문장이다. 반면에 <code>("user", "주제 {topic}에 대해 금융 관련 조언을 해주세요")</code>는 실제 사용자가 질문한 내용에 해당한다. 이렇게 역할(role)을 명시적으로 구분함으로써, LLM은 자신이 어떤 역할인지 이해하고 그에 맞춰 응답하게 된다. 이후 <code>invoke({"topic": "주식"})</code>을 통해 <code>{topic}</code> 자리에 &ldquo;주식"이라는 단어가 들어가게 되고, 전체 메시지는 시스템과 사용자 간의 구성된 대화 구조로 모델에 전달된다.</p><p>이제 세 번째 방식은 자리 표시자(placeholder)를 더 유연하게 사용하는 경우이다. <code>ChatPromptTemplate.from_messages()</code>를 사용하면서 메시지 중 하나로 <code>MessagesPlaceholder("msgs")</code>를 정의한다. 이는 템플릿 안에 단일 메시지가 아닌, 여러 개의 메시지를 묶어서 한 번에 넣을 수 있는 구조를 만든 것이다. 예를 들어 사용자가 이전에 했던 대화 내용 여러 줄을 다시 LLM에 전달하고 싶을 때 유용하다. <code>invoke({"msgs": [HumanMessage(content="안녕하세요!")]})</code>처럼 메시지 리스트를 전달하면, 시스템은 자동으로 이 메시지를 하나하나 LLM의 입력으로 포함시킨다. 이건 마치 친구와의 대화 내역을 LLM에게 모두 보여주고 &ldquo;이제 이 맥락을 바탕으로 대답해줘"라고 말하는 것과 같다.</p><p>마지막으로 나오는 방식은 위와 같은 자리 표시자를 <code>MessagesPlaceholder</code> 클래스로 정의하지 않고 문자열로 직접 <code>"placeholder", "{msgs}"</code>라고 명시하는 것이다. 여기서도 마찬가지로 <code>"msgs"</code> 자리에 여러 메시지를 리스트 형태로 전달하면, LangChain은 이를 자동으로 각각의 메시지 형식에 맞춰 변환해 LLM에게 넘겨준다. 이는 내부적으로 <code>HumanMessage</code>나 <code>SystemMessage</code> 등으로 변환되기 때문에, 입력 데이터가 일관된 메시지 객체라면 둘 다 동일한 방식으로 처리된다. 이 방법은 간단한 경우에 더 직관적으로 사용할 수 있다.</p><p>전체적으로 보면 이 코드는 LangChain에서 프롬프트를 어떻게 구조화하고, 다양한 형태의 사용자 입력과 시스템 지시를 조합하여 LLM에게 전달하는지를 보여준다. 중요한 건 단순히 텍스트를 이어 붙이는 것이 아니라, 시스템적인 구조로 대화를 표현함으로써 재사용성, 확장성, 유지보수성을 높이는 것이다. 특히 LCEL이나 체인과 결합할 때 이러한 템플릿들은 모듈화된 요소로써 기능하게 되며, 마치 전자회로에서 부품들을 연결하듯 텍스트 흐름과 LLM 행동을 설계할 수 있게 된다. 즉, 이 프롬프트 시스템은 단순한 문자열 입력을 넘어, LLM을 하나의 에이전트처럼 설계하고 조정하는 핵심적인 도구가 되는 것이다.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> langchain_core.prompts <span style=color:#f92672>import</span> PromptTemplate
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 주어진 주제에 대한 조언을 요청하는 프롬프트 템플릿 정의</span>
</span></span><span style=display:flex><span>prompt_template <span style=color:#f92672>=</span> PromptTemplate<span style=color:#f92672>.</span>from_template(<span style=color:#e6db74>&#34;주제 </span><span style=color:#e6db74>{topic}</span><span style=color:#e6db74>에 대해 금융 관련 짧은 조언을 해주세요&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># &#39;투자&#39; 주제로 프롬프트 템플릿 호출</span>
</span></span><span style=display:flex><span>prompt_template<span style=color:#f92672>.</span>invoke({<span style=color:#e6db74>&#34;topic&#34;</span>:<span style=color:#e6db74>&#34;투자&#34;</span>})
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 챗 프롬프트 템플릿 정의: 사용자와 시스템 간의 메시지 포함</span>
</span></span><span style=display:flex><span>prompt_template <span style=color:#f92672>=</span> ChatPromptTemplate<span style=color:#f92672>.</span>from_messages([
</span></span><span style=display:flex><span>    (<span style=color:#e6db74>&#34;system&#34;</span>, <span style=color:#e6db74>&#34;당신은 유능한 금융 조언가입니다.&#34;</span>),
</span></span><span style=display:flex><span>    (<span style=color:#e6db74>&#34;user&#34;</span>, <span style=color:#e6db74>&#34;주제 </span><span style=color:#e6db74>{topic}</span><span style=color:#e6db74>에 대해 금융 관련 조언을 해주세요&#34;</span>)
</span></span><span style=display:flex><span>])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># &#39;주식&#39; 주제로 챗 프롬프트 템플릿 호출</span>
</span></span><span style=display:flex><span>prompt_template<span style=color:#f92672>.</span>invoke({<span style=color:#e6db74>&#34;topic&#34;</span>: <span style=color:#e6db74>&#34;주식&#34;</span>})
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> langchain_core.prompts <span style=color:#f92672>import</span> ChatPromptTemplate, MessagesPlaceholder
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> langchain_core.messages <span style=color:#f92672>import</span> HumanMessage
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># (방법1) 메시지 자리 표시자를 포함한 챗 프롬프트 템플릿 정의</span>
</span></span><span style=display:flex><span>prompt_template <span style=color:#f92672>=</span> ChatPromptTemplate<span style=color:#f92672>.</span>from_messages([
</span></span><span style=display:flex><span>    (<span style=color:#e6db74>&#34;system&#34;</span>, <span style=color:#e6db74>&#34;당신은 유능한 금융 조언가입니다.&#34;</span>),
</span></span><span style=display:flex><span>    MessagesPlaceholder(<span style=color:#e6db74>&#34;msgs&#34;</span>)
</span></span><span style=display:flex><span>])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 메시지 리스트를 &#39;msgs&#39; 자리 표시자에 전달하여 호출</span>
</span></span><span style=display:flex><span>prompt_template<span style=color:#f92672>.</span>invoke({<span style=color:#e6db74>&#34;msgs&#34;</span>: [HumanMessage(content<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;안녕하세요!&#34;</span>)]})
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># (방법2) MessagesPlaceHolder 클래스를 사용하지 않고 비슷한 작업 수행</span>
</span></span><span style=display:flex><span>prompt_template <span style=color:#f92672>=</span> ChatPromptTemplate<span style=color:#f92672>.</span>from_messages([
</span></span><span style=display:flex><span>    (<span style=color:#e6db74>&#34;system&#34;</span>, <span style=color:#e6db74>&#34;당신은 유능한 금융 조언가입니다.&#34;</span>),
</span></span><span style=display:flex><span>    (<span style=color:#e6db74>&#34;placeholder&#34;</span>, <span style=color:#e6db74>&#34;</span><span style=color:#e6db74>{msgs}</span><span style=color:#e6db74>&#34;</span>) <span style=color:#75715e># &lt;- 여기서 &#39;msgs&#39;가 자리 표시자로 사용됩니다.</span>
</span></span><span style=display:flex><span>])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 메시지 리스트를 &#39;msgs&#39; 자리 표시자에 전달하여 호출</span>
</span></span><span style=display:flex><span>prompt_template<span style=color:#f92672>.</span>invoke({<span style=color:#e6db74>&#34;msgs&#34;</span>: [HumanMessage(content<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;안녕하세요!&#34;</span>)]})
</span></span></code></pre></div><h1><a class=anchor href=#>#</a></h1><p>#출처</p><p>책 RAG 마스터: 랭체인으로 완성하는 LLM 서비스: 멀티모달, 그래프 RAG, 에이전트, 파인튜닝까지</p></article><footer class=book-footer><div class="flex flex-wrap justify-between"></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments><script src=https://giscus.app/client.js data-repo=yshghid/yshghid.github.io data-repo-id=R_kgDONkMkNg data-category-id=DIC_kwDONkMkNs4CloJh data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=ko crossorigin=anonymous async></script></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><ul><li><a href=#1-랭체인-생태계의-주요-패키지>1. 랭체인 생태계의 주요 패키지</a></li><li><a href=#2-랭체인-표현언어>2. 랭체인 표현언어</a></li><li><a href=#3-랭체인-프롬프트-탬플릿>3. 랭체인 프롬프트 탬플릿</a></li></ul></li></ul></nav></div></aside></main></body></html>