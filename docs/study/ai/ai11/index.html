<!doctype html><html lang=en-us dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="
  skala 강의자료공부 #1 DL-CNN, RNN
  #

#2025-08-03

#1 p.90-92
Convolution, 즉 합성곱은 CNN의 가장 핵심적인 연산이다. 말 그대로 &lsquo;겹쳐서 곱하고 더하는&rsquo; 방식이다. 이는 우리가 이미지를 처리할 때, 그 이미지의 일부분만을 보며 특징을 추출하는 원리와 매우 유사하다. CNN에서는 이 연산을 통해 이미지 속에서 선, 모서리, 윤곽선 같은 패턴을 뽑아낸다.
p.90에서는 합성곱을 아주 직관적으로 보여준다. 왼쪽에 있는 초록색 격자는 이미지이고, 그 위에 씌워진 주황색 네모는 필터(또는 커널)다. 이 필터는 보통 3x3 크기를 가지며, 그 내부에 있는 값들은 학습을 통해 결정된다. 필터가 한 위치에 씌워지면, 그 영역의 이미지 픽셀들과 필터 값을 각각 곱한 뒤 전부 더한다. 이 값이 새로운 출력 이미지의 한 칸이 된다. 즉, 이미지의 한 조각에 필터를 덧씌워 곱하고 더한 값을 새로운 이미지의 특징으로 만들어내는 것이다. 필터가 한 칸씩 옆으로 이동하면서(이것이 stride), 전체 이미지를 스캔하듯 반복하게 되면, 하나의 convolved feature map이 생성된다. 그림에서는 결과값이 4로 계산되었고, 이 값이 오른쪽의 새로운 이미지에 기록되었다."><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="https://yshghid.github.io/docs/study/ai/ai11/"><meta property="og:site_name" content=" "><meta property="og:title" content="skala 강의자료공부 #1 DL-CNN, RNN"><meta property="og:description" content="skala 강의자료공부 #1 DL-CNN, RNN # #2025-08-03
#1 p.90-92
Convolution, 즉 합성곱은 CNN의 가장 핵심적인 연산이다. 말 그대로 ‘겹쳐서 곱하고 더하는’ 방식이다. 이는 우리가 이미지를 처리할 때, 그 이미지의 일부분만을 보며 특징을 추출하는 원리와 매우 유사하다. CNN에서는 이 연산을 통해 이미지 속에서 선, 모서리, 윤곽선 같은 패턴을 뽑아낸다.
p.90에서는 합성곱을 아주 직관적으로 보여준다. 왼쪽에 있는 초록색 격자는 이미지이고, 그 위에 씌워진 주황색 네모는 필터(또는 커널)다. 이 필터는 보통 3x3 크기를 가지며, 그 내부에 있는 값들은 학습을 통해 결정된다. 필터가 한 위치에 씌워지면, 그 영역의 이미지 픽셀들과 필터 값을 각각 곱한 뒤 전부 더한다. 이 값이 새로운 출력 이미지의 한 칸이 된다. 즉, 이미지의 한 조각에 필터를 덧씌워 곱하고 더한 값을 새로운 이미지의 특징으로 만들어내는 것이다. 필터가 한 칸씩 옆으로 이동하면서(이것이 stride), 전체 이미지를 스캔하듯 반복하게 되면, 하나의 convolved feature map이 생성된다. 그림에서는 결과값이 4로 계산되었고, 이 값이 오른쪽의 새로운 이미지에 기록되었다."><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="docs"><meta property="article:published_time" content="2025-08-03T00:00:00+00:00"><meta property="article:modified_time" content="2025-08-03T00:00:00+00:00"><meta property="article:tag" content="2025-08"><title>skala 강의자료공부 #1 DL-CNN, RNN |</title><link rel=icon href=/favicon.png><link rel=manifest href=/manifest.json><link rel=canonical href=https://yshghid.github.io/docs/study/ai/ai11/><link rel=stylesheet href=/book.min.6217d077edb4189fd0578345e84bca1a884dfdee121ff8dc9a0f55cfe0852bc9.css integrity="sha256-YhfQd+20GJ/QV4NF6EvKGohN/e4SH/jcmg9Vz+CFK8k=" crossorigin=anonymous><script defer src=/fuse.min.js></script><script defer src=/en.search.min.4f8a0cab9134c7768682471c3512fdf092ccf735d13e4306b110e9a6fcdb7044.js integrity="sha256-T4oMq5E0x3aGgkccNRL98JLM9zXRPkMGsRDppvzbcEQ=" crossorigin=anonymous></script></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><img src=/logo.png alt=Logo class=book-icon><span></span></a></h2><div class="book-search hidden"><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><script>document.querySelector(".book-search").classList.remove("hidden")</script><ul><li class=book-section-flat><span>기록</span><ul><li><a href=/docs/hobby/book/>글</a><ul></ul></li><li><a href=/docs/hobby/daily/>일상</a><ul></ul></li></ul></li><li class=book-section-flat><span>공부</span><ul><li><a href=/docs/study/bioinformatics/>Bioinformatics</a><ul></ul></li><li><a href=/docs/study/ai/>AI</a><ul></ul></li><li><a href=/docs/study/sw/>SW</a><ul></ul></li><li><a href=/docs/study/algorithm/>알고리즘</a><ul></ul></li><li><a href=/docs/study/career/>취업</a><ul></ul></li></ul></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu></label><h3>skala 강의자료공부 #1 DL-CNN, RNN</h3><label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents></nav></aside></header><article class="markdown book-article"><h1 id=skala-강의자료공부-1-dl-cnn-rnn>skala 강의자료공부 #1 DL-CNN, RNN
<a class=anchor href=#skala-%ea%b0%95%ec%9d%98%ec%9e%90%eb%a3%8c%ea%b3%b5%eb%b6%80-1-dl-cnn-rnn>#</a></h1><p>#2025-08-03</p><hr><p>#1 p.90-92</p><p>Convolution, 즉 합성곱은 CNN의 가장 핵심적인 연산이다. 말 그대로 &lsquo;겹쳐서 곱하고 더하는&rsquo; 방식이다. 이는 우리가 이미지를 처리할 때, 그 이미지의 일부분만을 보며 특징을 추출하는 원리와 매우 유사하다. CNN에서는 이 연산을 통해 이미지 속에서 선, 모서리, 윤곽선 같은 패턴을 뽑아낸다.</p><p>p.90에서는 합성곱을 아주 직관적으로 보여준다. 왼쪽에 있는 초록색 격자는 이미지이고, 그 위에 씌워진 주황색 네모는 필터(또는 커널)다. 이 필터는 보통 3x3 크기를 가지며, 그 내부에 있는 값들은 학습을 통해 결정된다. 필터가 한 위치에 씌워지면, 그 영역의 이미지 픽셀들과 필터 값을 각각 곱한 뒤 전부 더한다. 이 값이 새로운 출력 이미지의 한 칸이 된다. 즉, 이미지의 한 조각에 필터를 덧씌워 곱하고 더한 값을 새로운 이미지의 특징으로 만들어내는 것이다. 필터가 한 칸씩 옆으로 이동하면서(이것이 stride), 전체 이미지를 스캔하듯 반복하게 되면, 하나의 convolved feature map이 생성된다. 그림에서는 결과값이 4로 계산되었고, 이 값이 오른쪽의 새로운 이미지에 기록되었다.</p><p>이 과정을 통해 CNN은 이미지 속에서 눈에 보이는 선, 곡선, 방향성 같은 ‘특징’을 효과적으로 감지할 수 있다. 이 특징맵은 이미지 그 자체라기보다는 &lsquo;이미지에 존재하는 패턴의 강도&rsquo;를 담고 있다고 보면 된다.</p><p>p.91에서는 이 연산을 3차원 이미지에 확장해 보여준다. 실제 이미지, 예를 들어 컬러 이미지의 경우 RGB 세 가지 색상 채널로 구성된다. 따라서 필터도 이 세 채널을 모두 처리할 수 있어야 한다. 이를 표현하기 위해 그림에서는 레고 블록처럼 구성된 구조를 보여준다. 아래쪽에는 입력 이미지의 세 채널이 있고, 그 위에는 필터(커널)가 각 채널별로 따로 구성되어 있다. 각 필터는 해당 채널에만 곱해지며, 마지막에는 이들을 전부 더한 뒤 결과값을 얻는다. 예를 들어 빨강 채널에 -1, 초록 채널에 +1, 파랑 채널에 0.5 같은 필터가 존재한다면, 각 채널에 맞춰 계산된 값들을 전부 더해 최종 출력값을 만드는 것이다. 이처럼 CNN은 단순히 2D 연산이 아니라, 다채널 입력을 처리하기 위한 다층 합성곱 구조를 사용한다.</p><p>p.92는 합성곱의 조금 더 수학적인 동작을 시각적으로 설명한다. 이 페이지에서는 stride와 padding의 개념도 함께 등장한다. stride는 필터가 이미지 위를 이동할 때 한 번에 몇 칸씩 건너뛰느냐를 의미한다. stride가 1이면 한 칸씩 이동하며 연산하지만, stride가 2 이상이면 더 큰 폭으로 건너뛰기 때문에 출력의 크기가 줄어들게 된다. 그림에서는 stride가 1인 경우를 보여주고 있으며, 5x5 입력 이미지에 3x3 커널을 적용하고 있다.</p><p>padding은 입력 이미지 주변에 0을 덧붙여주는 과정이다. 왜 필요하냐면, 필터를 씌우는 과정에서 이미지의 가장자리는 연산 대상이 되는 영역이 부족해진다. 이때 패딩을 이용하면 가장자리에 인위적으로 0을 추가해 크기를 유지할 수 있다. 그림에서는 padding을 적용해 필터가 이미지 전체를 고르게 커버할 수 있도록 조정한 예시를 보여준다. 이렇게 하면 출력 이미지의 크기를 입력과 동일하게 유지할 수 있다. 이를 &lsquo;same padding&rsquo;이라고 한다.</p><p>정리하면, CNN의 합성곱 연산은 작은 필터가 이미지의 일부분과 연산을 수행하면서 새로운 정보를 만들어내는 과정이다. 이 과정을 통해 CNN은 이미지의 형태적 특징을 추출하게 되고, 이 특징은 다음 계층에서 더 고차원적인 정보로 발전된다. 3차원 이미지 처리, stride와 padding은 이 연산이 보다 유연하고 강력하게 작동할 수 있게 도와주는 핵심적인 요소들이다.</p><p>#2 p.93-95</p><p>CNN에서 가장 중요한 개념 중 하나는 바로 &ldquo;커널(Kernel)&rdquo; 또는 &ldquo;필터(Filter)&ldquo;이다. 이 커널은 이미지 위를 움직이며 일정한 규칙으로 연산을 수행하는 작은 창(window)이다. 93페이지 이미지를 보면, RGB 세 개의 채널로 구성된 이미지가 등장한다. 각각의 채널에 대해 다른 커널이 적용되는데, 예를 들어 빨간 채널에는 [-1, -1, -1], [0, 1, -1], [0, 1, 1] 같은 커널이 쓰이고, 녹색과 파란 채널에는 각각 다른 형태의 커널이 적용된다.</p><p>이 커널이 하는 일은 간단하다. 이미지의 한 부분을 잘라서 커널과 곱하고, 그 결과를 모두 더한 하나의 숫자를 만들어내는 것이다. 이를 “합성곱 연산(Convolution)”이라고 한다. 그리고 이 연산 결과는 새로운 이미지(출력 특징맵)의 한 픽셀이 된다. CNN은 이런 연산을 이미지 전체에 반복적으로 적용하며, 입력 이미지의 패턴을 감지하고 새로운 특징을 생성한다. 예를 들어, 경계선이나 모서리를 탐지하거나, 특정 방향의 선에 민감한 커널을 학습할 수 있다.</p><p>중요한 것은, 이런 커널 값은 사람이 직접 정하는 게 아니라, 모델이 학습을 통해 스스로 찾아낸다는 점이다. 처음에는 랜덤한 값으로 시작하지만, 손실 함수(loss function)를 줄이는 방향으로 커널 값들이 점점 조정된다. 그 결과 CNN은 데이터에 맞는 특징 추출기(feature extractor)로 진화한다.</p><p>그다음으로 중요한 개념은 &ldquo;합성곱 연산의 흐름"이다. 94페이지 이미지에서 합성곱 연산이 어떻게 진행되는지 단계별로 보여주고 있다. 예를 들어, 3x3 크기의 커널이 입력 이미지 위를 한 칸씩 옮겨가면서 각 영역에서의 합성곱을 수행한다. 이때 stride가 1이라면 한 칸씩, 2라면 두 칸씩 점프하면서 이동한다. 커널이 이동할 때마다 곱셈과 덧셈 연산을 거쳐 새로운 숫자가 하나씩 생성되고, 이 숫자들이 모여 출력 특징맵이 만들어진다. 이 과정을 통해 입력 이미지보다 작은 크기의 출력이 생성되며, 이 출력은 원래 이미지의 특징을 요약한 것이다.</p><p>하지만 여기서 문제가 하나 생긴다. 커널이 이미지를 돌면서 연산을 하다 보면, 이미지의 가장자리는 연산 대상에서 자연스럽게 제외되게 된다. 즉, 출력의 크기가 입력보다 작아지게 된다. 이 문제를 해결하기 위한 방법이 바로 &ldquo;패딩(Padding)&ldquo;이다.</p><p>95페이지에서는 패딩의 개념을 설명한다. 패딩은 입력 이미지의 테두리에 0을 덧붙여서 인위적으로 크기를 늘려주는 것이다. 예를 들어, 5x5 이미지에 3x3 커널을 적용할 경우, 아무런 패딩이 없으면 출력은 3x3이 된다. 하지만 패딩을 1만큼 주면, 입력은 7x7처럼 확장되고, 출력의 크기를 원래 입력과 동일하게 유지할 수 있다. 이렇게 하면 가장자리에 있는 픽셀도 중심과 똑같이 처리될 수 있어서 정보 손실을 줄일 수 있다.</p><p>패딩은 단순히 크기를 유지하기 위한 도구가 아니다. 사실상 입력 정보가 얼마나 많이 보존될지를 결정짓는 중요한 하이퍼파라미터다. 만약 패딩이 없으면 이미지가 여러 층을 거치면서 점점 작아지고, 결국 정보가 너무 축소돼 버릴 수 있다. 반대로 과도하게 패딩을 주면 오히려 잡음이 생기거나 모델이 쓸데없는 정보까지 학습하게 될 수 있다. 그래서 CNN을 설계할 때, 커널 크기와 stride, padding의 조합을 잘 조절해야 원하는 출력 크기와 성능을 얻을 수 있다.</p><p>#3 p.96-98</p><p>CNN에서 이미지의 특징을 뽑아내는 데 있어 중요한 역할을 하는 층이 바로 Pooling Layer다. 이 층은 ‘무엇이 있는가’를 판단하는 데 필요한 핵심 정보만 남기고, 덜 중요한 정보는 버리는 역할을 한다. 쉽게 말해, 그림을 가까이서 보면 세세한 질감과 점들을 볼 수 있지만, 멀리서 보면 전체 형태만 보인다. Pooling은 바로 이 ‘멀리서 보는’ 효과를 흉내 내는 층이다.</p><p>가장 대표적인 방식은 Max Pooling이다. 이는 입력 이미지의 작은 영역(예: 2×2) 중에서 가장 큰 값 하나만을 선택해 출력을 만든다. 예를 들어 4×4 이미지가 있다면, 2×2 영역을 기준으로 잘라서 각 블록에서 가장 큰 값만 추려내면 2×2의 더 작은 이미지가 만들어진다. 이처럼 Pooling은 이미지의 크기를 줄이면서도 중요한 정보는 유지하도록 설계되어 있다. 특히 Max Pooling은 윤곽선이나 가장자리처럼 가장 두드러진 패턴을 뽑아내기에 적합하다.</p><p>Pooling의 장점은 크게 세 가지다. 첫째, 연산량이 줄어든다. 이미지 크기가 작아지므로 다음 층에서 계산할 양도 줄어든다. 둘째, 과적합(overfitting) 방지에 도움을 준다. 중요하지 않은 세부 정보를 제거함으로써 모델이 핵심 패턴에만 집중하게 되기 때문이다. 셋째, 위치 변화에 덜 민감해진다. 예를 들어 숫자 7이 이미지 중심에서 약간 위로 이동했다고 해서 Max Pooling 후의 출력이 크게 달라지지 않기 때문에, CNN은 위치가 조금 바뀌어도 동일한 숫자라고 인식할 수 있다.</p><p>다음 단계는 Flatten Layer이다. 지금까지 CNN은 입력 이미지를 2차원(또는 3차원) 형태로 처리해왔다. Convolution과 Pooling을 반복하면서 이미지의 크기는 줄어들고, 필터 수는 늘어나며 다차원 배열이 형성되었다. 하지만 이미지 분류의 마지막 단계는 Softmax 함수를 이용해 ‘숫자 3이다’, ‘이건 고양이다’처럼 분류를 내려야 한다. 이를 위해서는 데이터를 1차원 벡터로 바꾸어 완전 연결층(Fully Connected Layer)에 입력할 수 있어야 한다. 이때 사용하는 것이 Flatten Layer다. 이름 그대로 다차원 배열을 납작하게 만들어 벡터로 펼쳐주는 역할을 한다.</p><p>Flatten된 벡터는 이제 Dense Layer, 즉 Fully Connected Layer로 들어가게 되는데, 이때 각 뉴런은 이전 벡터의 모든 값과 연결된다. 이런 구조를 통해 CNN은 이제 이미지의 ‘전체적인 의미’를 분석할 수 있게 된다. 그리고 최종적으로 출력층에 도달하면 Softmax 함수가 등장한다. 이 함수는 Dense Layer의 출력을 확률로 바꿔주는 역할을 한다.</p><p>Softmax는 입력된 값(예: [2.5, 1.3, -0.7, 3.8])을 지수 함수로 변환한 뒤, 전체 합으로 나눠서 01 사이의 값으로 바꾼다. 그 결과는 각 클래스(09 또는 고양이/강아지 등)가 정답일 확률로 해석된다. 예를 들어 Softmax 결과가 [0.01, 0.02, 0.92, 0.05]라면, 모델은 세 번째 클래스(예: 숫자 2)가 정답일 가능성이 가장 높다고 판단한 것이다. 이때 Argmax는 이 확률 중 가장 큰 값을 가진 클래스의 인덱스를 반환한다.</p><p>Softmax는 단순한 분류기 같아 보여도 매우 강력한 역할을 한다. 왜냐하면 모든 클래스의 상대적인 중요도를 함께 고려하기 때문이다. 하나의 출력값만 보지 않고, 모든 클래스에 대해 확률 분포를 고려해 최종 결정을 내린다. 이 덕분에 CNN 모델은 단순히 “이게 가장 맞는 것 같아” 수준이 아니라, “이게 90% 확신이고, 다음 건 8% 정도야”처럼 좀 더 명확한 판단 기준을 제공할 수 있다.</p><p>#4 p.99-100</p><p>CNN의 전체 구조를 이해하는 데 있어 핵심은 각각의 층이 어떤 역할을 수행하는지, 그리고 그 층들이 순차적으로 어떻게 연결되어 최종적으로 분류를 수행하는지 파악하는 것이다. p.99에서는 CNN 아키텍처의 전반적인 흐름을 아래와 같은 형태로 요약하고 있다:</p><p>[(Conv × α + Activation) × β + Pooling] × γ → FC Layer + Dense Layer</p><p>이 식은 수식처럼 보이지만 사실 CNN 아키텍처의 반복 구조를 표현한 간단한 공식이다. 먼저 Conv는 합성곱 층이고, Activation은 보통 ReLU 같은 활성화 함수이며, Pooling은 max pooling과 같은 다운샘플링 계층을 말한다. 이 구조를 여러 번 반복하면서 CNN은 점점 더 복잡한 특징을 뽑아내고, 마지막에는 Fully Connected Layer와 Dense Layer를 통해 분류기로 연결된다.</p><p>p.99의 하단 이미지에서는 이 구조를 LEGO 블록으로 시각화하여 설명하고 있다. 입력층에는 원본 이미지가 들어오고, 그 위로 두 개의 합성곱 층(커널 3x3, 2개의 필터와 2x2, 3개의 필터)이 순서대로 쌓인다. 각 합성곱 층은 ReLU 활성화 함수를 통해 비선형성을 부여하고, 그다음 pooling 계층이 따라온다. 이렇게 형성된 Hidden Layer는 이미지에서 점차 복잡한 특징을 추출하는 역할을 한다. 그 뒤 Flatten Layer가 등장해 이 모든 특징맵을 1차원 벡터로 변환하고, 이 벡터가 Fully Connected Layer와 Dense Layer를 거쳐 최종 Softmax 출력층으로 이어진다.</p><p>p.100에서는 CNN의 마지막 구성 요소인 Softmax 함수와 그 역할을 구체적으로 보여준다. FC Layer(완전 연결층)에서는 여러 개의 노드가 입력 특징들을 종합해 각 클래스에 대한 점수를 산출한다. 이 점수는 실수값으로, 예를 들어 [-0.1, 3.8, 1.1, -0.3]처럼 나타날 수 있다. 이 값들을 Softmax 함수에 넣으면 확률로 바뀐다. Softmax는 모든 값을 지수 함수로 변환한 뒤, 전체 합으로 나누는 방식으로 작동하므로 항상 결과의 총합이 1이 되며, 각 클래스에 속할 확률처럼 해석된다.</p><p>예를 들어, 위와 같은 FC 출력값에 대해 Softmax를 적용하면 [0.02, 0.91, 0.06, 0.01]처럼 변환된다. 이 결과는 “입력 이미지는 두 번째 클래스일 가능성이 91%이다”라는 해석을 가능하게 한다. CNN 모델은 이 중 가장 큰 확률값을 선택하고, 그에 해당하는 클래스를 최종 출력으로 내놓는다. 이때 Argmax 함수가 사용되며, 가장 큰 값의 인덱스를 찾아주는 역할을 한다.</p><p>즉, CNN 전체의 목적은 이미지를 입력으로 받아 여러 단계의 합성곱과 풀링을 통해 의미 있는 특징을 추출하고, 이를 기반으로 Fully Connected Layer에서 결합된 정보를 Softmax를 통해 분류 확률로 바꾸는 것이다. 이 과정은 매우 구조화되어 있으며, 각 층이 맡은 기능은 서로 분업적이다. LEGO처럼 각 층이 단단히 쌓여 전체 네트워크가 작동하는 것이다.</p><h1><a class=anchor href=#>#</a></h1><p>#5 p.104~107</p><p>RNN은 시간을 고려하는 인공 신경망이다. 한마디로, 과거의 정보를 기억하며 현재를 처리하는 모델이다. 예를 들어 누군가가 ‘오늘 날씨는’이라고 말했을 때, 우리는 그다음에 ‘좋다’, ‘비 온다’ 같은 표현이 올 거라고 자연스럽게 예상한다. 왜냐하면 앞에 들은 내용을 기억하고 있기 때문이다. RNN은 바로 이러한 ‘순서에 따라 들어오는 정보의 흐름’을 이해하기 위한 구조다. 이걸 이해하기 쉬운 비유로 설명하자면 ‘일기 쓰기’와 같다.</p><p>사람이 매일 밤 일기를 쓸 때, 단순히 그날의 일만 기록하는 것이 아니라, 전날 혹은 그 전날의 감정이나 사건이 오늘의 일기 내용에 영향을 줄 수 있다. 어제 매우 기쁜 일이 있었다면, 오늘도 기분 좋은 하루를 보내게 되고, 그것이 오늘의 일기에 묻어날 것이다. 반대로, 며칠 전 슬픈 일이 있었다면 며칠 뒤까지 감정이 이어져 글에 영향을 미칠 수 있다. 하지만 너무 오랜 시간이 지나면 그 기억은 흐릿해지거나 잊히게 된다. 바로 이 흐름이 RNN의 핵심이다. 입력이 시간의 흐름을 따라 들어오고, 이전의 정보가 현재에 영향을 미친다. 이와 같이 데이터를 시계열 순서로 이해하고 처리하는 모델이 바로 RNN이다.</p><p>‘Recurrent’라는 말은 반복되거나 순환된다는 의미다. 따라서 RNN은 구조적으로 같은 연산을 시간에 따라 반복한다. 일반적인 인공신경망은 입력을 한 번 받아서 처리하고 끝이지만, RNN은 입력을 연속적으로 받으며 내부 상태를 계속 갱신한다. 이때 이 내부 상태를 ‘은닉 상태(Hidden State)’라고 부른다. 이 은닉 상태는 마치 메모리처럼 이전 정보를 요약해서 담아두고, 다음 입력이 들어왔을 때 이를 참고하여 출력을 만든다.</p><p>좀 더 구조적으로 보자면, RNN은 각 시점마다 하나의 셀(Cell)이라는 단위를 가지고 있으며, 이 셀은 입력값과 이전의 은닉 상태를 받아서 새로운 은닉 상태와 출력값을 만든다. 이 셀 하나는 작은 뇌처럼 작동한다. 예를 들어 시간 t에서의 입력값을 Xt, 이전 시점 t-1의 은닉 상태를 ht-1이라고 하자. 이 둘을 결합해 현재의 은닉 상태 ht를 만든다. 이 ht는 다음 시점에서 ht+1을 만드는 데 또 사용된다. 마치 일기를 쓸 때 오늘의 감정이 내일의 일기에 영향을 미치듯, 정보가 시간 축을 따라 연결되는 것이다.</p><p>이 구조는 시간 순서를 따라 같은 셀 구조를 반복 사용하는 방식으로 구현된다. 사실 하나의 셀을 복제한 것이 아니라, 동일한 파라미터를 공유하는 셀을 시간 순서대로 배열한 형태다. 이때 셀 내부에서 입력값과 이전 은닉 상태는 각각 특정 가중치 행렬과 곱해진다. 예를 들어 Xt는 Wxh라는 가중치와 곱해지고, ht-1은 Whh라는 가중치와 곱해진다. 이 둘의 합은 활성화 함수(예: tanh)를 통해 현재 은닉 상태 ht로 변환된다. 출력값 Yt는 이 ht에 또 다른 가중치 Why를 곱해 산출한다. 이와 같이 시간에 따라 동일한 연산 구조가 반복되며 정보가 흘러간다.</p><p>RNN에서 가장 핵심적인 것은 ‘은닉 상태’다. 이 상태가 바로 과거의 정보를 요약해 담고 있는 부분이다. 이 은닉 상태 덕분에 RNN은 순차적인 정보의 흐름을 학습할 수 있다. 예를 들어, 문장을 이해하려면 각 단어의 의미뿐 아니라, 그 이전 단어들의 맥락을 알아야 한다. ‘나는 오늘 기분이…’라는 문장에서 ‘기분이’ 다음에 나올 단어를 예측하려면 ‘나는’, ‘오늘’, ‘기분이’라는 앞 단어들이 모두 고려되어야 한다. RNN은 이처럼 과거의 입력을 바탕으로 현재를 예측하는 데 유리하다.</p><p>그렇다면 이 구조의 수학적 표현은 어떻게 될까? 현재 시점 t에서의 은닉 상태 ht는 이전 은닉 상태 ht-1과 현재 입력 Xt에 각각 가중치를 곱하고 편향을 더해 tanh 활성화 함수를 적용한 결과다. 수식으로 표현하면 다음과 같다:</p><p>ht = tanh(Whh × ht-1 + Wxh × Xt + bh)</p><p>그리고 출력 Yt는 이 ht에 또 다른 가중치 Why를 곱하고 편향 by를 더해 만든다:</p><p>Yt = Why × ht + by</p><p>이때 중요한 점은, 하나의 층 안에서는 모든 시점에서 같은 가중치 Wxh, Whh, Why를 공유한다는 것이다. 이는 학습해야 할 파라미터 수를 크게 줄여주고, 시간에 따른 일관성을 유지해준다.</p><p>그러나 RNN에는 한 가지 큰 문제점이 있다. 바로 장기 의존성 문제다. 정보가 시간 축을 따라 여러 셀을 지나가면서 은닉 상태를 통해 전파되는데, 이 과정에서 오래된 정보는 점차 사라지게 된다. 예를 들어 t=0 시점의 정보가 t=10까지 영향을 미치기란 쉽지 않다. 왜냐하면 연속된 가중치 곱셈과 비선형 연산(tanh 등)을 반복하다 보면, 역전파 시 그래디언트가 소멸하거나 폭주할 수 있기 때문이다. 이런 현상을 각각 ‘기울기 소실(Vanishing Gradient)’, ‘기울기 폭주(Exploding Gradient)’라고 한다. 이 문제를 해결하기 위해 LSTM(Long Short-Term Memory), GRU(Gated Recurrent Unit) 같은 개선된 RNN 구조가 제안되었다.</p><p>하지만 단순한 RNN 구조도 여전히 텍스트 생성, 음성 인식, 시계열 데이터 예측 같은 문제에서는 유용하다. 특히 짧은 문맥에서 의존성이 필요한 문제에선 RNN이 매우 직관적이고 해석 가능한 모델로 작동한다.</p><p>정리하자면, RNN은 과거의 정보를 은닉 상태라는 내부 메모리 공간에 담아두고, 현재 입력과 결합해 다음 상태와 출력을 만들어내는 구조이다. 이를 통해 단어, 문장, 감정, 음악, 주가 데이터처럼 시간에 따라 의미가 달라지는 데이터의 흐름을 자연스럽게 학습할 수 있다. CNN이 공간 정보를 잘 처리한다면, RNN은 시간 정보를 잘 처리하는 구조라고 볼 수 있다. RNN을 이해하는 핵심은 ‘기억’과 ‘순서’다. 이 두 가지 요소를 네트워크 구조 안에 녹여낸 것이 바로 RNN의 본질이다.</p><p>#6 p.110~112</p><p>RNN이란 시간에 따라 변하는 데이터를 처리하는 데 특화된 신경망이다. 우리가 문장을 읽거나 음악을 들을 때, 앞의 내용이 뒤에 나오는 것에 영향을 미친다. 예를 들어 “나는 자전거를 ___”이라는 문장에서 빈칸에 무엇이 들어갈지를 예측하려면, 앞의 내용을 기억하고 있어야 한다. 이런 맥락 정보의 흐름을 처리하기 위해 RNN은 과거 정보를 기억하고 현재에 반영하는 구조를 갖고 있다. 그런데 실제로 RNN이 내부적으로 어떤 방식으로 작동하는지를 파악하려면 수식, 구조, 역전파의 원리까지 차근차근 짚어야 한다.</p><p>먼저 RNN의 기본 구조를 보자. 입력이 시간 순서대로 들어오면, 각 시점마다 입력값(X₁, X₂, X₃ 등)이 셀(Cell)이라는 연산 유닛에 전달된다. 각 셀은 현재 입력뿐만 아니라, 이전 시점의 은닉 상태(ht-1)를 함께 받아서 새로운 은닉 상태(ht)를 계산한다. 이 은닉 상태는 tanh라는 비선형 함수를 거쳐 생성되며, 다음 시점 셀로 넘겨진다. 동시에 현재 은닉 상태는 출력값(ot)을 만드는 데 사용된다. 출력은 보통 Why 가중치를 통해 ht를 선형 변환한 후 by라는 편향을 더해서 만든다. 수식으로 표현하면 ht = tanh(Whh·ht-1 + Wxh·Xt + bh)이고, ot = Why·ht + by이다.</p><p>이때 tanh 함수는 매우 중요한 역할을 한다. tanh는 -1부터 1 사이의 값을 출력하는 비선형 함수로, 입력값이 매우 작거나 크면 출력이 -1 또는 1로 포화(saturation)된다. 이 함수는 sigmoid와 비슷하지만, 출력이 0을 중심으로 대칭이기 때문에 gradient가 평균적으로 0에 가까워지는 것을 방지할 수 있다. 그러나 여전히 문제가 있다. 만약 시계열이 매우 길어지면, tanh를 여러 번 거치는 과정에서 gradient가 점점 작아져 사라져버리는 현상이 발생한다. 이를 ‘기울기 소실(vanishing gradient)’이라 부른다. 반대로 gradient가 폭발적으로 커지는 경우도 있고, 이를 ‘기울기 폭주(exploding gradient)’라 한다. 이 때문에 RNN은 장기 기억에 약하다는 단점이 있고, 이 문제를 해결하기 위해 LSTM, GRU 같은 구조가 등장하게 된다.</p><p>RNN의 학습은 순전파(Forward Propagation)와 역전파(Backward Propagation)를 통해 이루어진다. 순전파는 입력 데이터를 시간 순서대로 셀에 전달하며 출력값을 계산하는 과정이고, 역전파는 예측값과 실제값의 오차(LOSS)를 바탕으로 가중치를 조정하는 단계다. 이때 RNN의 역전파는 일반 신경망과 조금 다르다. 시간의 흐름을 따라 계산이 이루어지기 때문에, ‘시간을 따라 펼친 구조’에서 역방향으로 그래디언트를 전달한다. 이 과정을 ‘시간에 따른 역전파(Backpropagation Through Time, BPTT)’라고 부른다.</p><p>이 구조를 시각화한 그림을 보면, 각 시점마다 tanh 블록과 선형 연산(+, 가중치 곱)이 연결되어 있다. h₁, h₂, h₃처럼 은닉 상태가 연결되고, 출력 o₁, o₂, o₃가 각각 Softmax로 전달된다. 이 Softmax는 무엇이냐면, 여러 개의 클래스 중 하나를 선택하는 확률 분포를 만든다. 예를 들어 “나는 자전거를 ___”이라는 문장에서, 빈칸에 들어갈 단어 후보가 ‘탄다’, ‘산다’, ‘보낸다’라고 하면, Softmax는 이 후보들에 대해 확률을 할당한다. 예측이 맞으면 해당 단어의 확률이 높게 나와야 하고, 실제 정답과의 차이는 Cross-Entropy Loss로 계산된다. 이 값이 작아지도록 학습을 반복하면 모델이 점점 정확해지는 것이다.</p><p>이제 RNN이 어떻게 계산되는지를 숫자로 확인해보자. Case 1에서는 X₁=200, X₂=300, X₃=400이고, Wxh=0.01, Whh=0.3, b=0.1로 설정되어 있다. h₁은 처음 입력이기 때문에 이전 상태가 0이라서 ht = tanh(0.01·200 + 0.1) = tanh(2.1) ≈ 0.97이 된다. 다음으로 h₂는 이전 h₁과 새로운 입력 300을 바탕으로 계산되고, h₃도 마찬가지로 계산된다. 마지막에 나온 h₃를 기반으로 최종 출력값을 예측하게 되며, Ŷ = 500·0.9997 + 50 ≈ 549.85가 된다. 이는 거의 정답인 550과 유사하다.</p><p>하지만 Case 2처럼 X₂가 줄어들고 X₃도 약해지면, 중간 은닉 상태인 h₂, h₃가 낮아진다. 예를 들어 h₂ ≈ 0.712, h₃ ≈ 0.924로 떨어지며, 최종 출력도 Ŷ ≈ 178.06으로 낮아진다. 실제 Y=180에 근접한 값을 예측한 것이다. 그런데 Case 3처럼 X₂가 음수(-130)일 경우, tanh의 출력이 음수로 변하게 되고, 은닉 상태도 낮아진다. 이때 h₂는 약 -0.721, h₃는 0.366이 되며, Ŷ ≈ 68.1이 출력된다. 이 예시는 tanh 함수의 포화 구간, 음수-양수 출력 영역, 은닉 상태의 누적 효과를 모두 보여준다. 이전 상태가 현재 계산에 얼마나 영향을 주는지를 잘 알 수 있다.</p><p>이 모든 과정을 통해 우리는 RNN이 어떻게 입력의 시간적 순서를 반영해 내부 상태를 업데이트하고, 예측값을 내는지를 이해할 수 있다. tanh는 이 과정에서 입력과 은닉 상태를 적절히 결합하여 비선형적인 표현력을 확보하고, Softmax는 예측된 값들을 정규화해 해석 가능한 확률로 만든다. Cross-Entropy Loss는 이 예측이 얼마나 실제값과 가까운지를 측정해 학습 방향을 제시해준다. 하지만 깊은 시퀀스에서는 정보가 소실되거나 왜곡되기 쉽고, 이런 점이 RNN의 구조적인 한계로 작용한다.</p><p>결론적으로, RNN은 순차적인 입력에 대한 기억을 ‘은닉 상태’로 유지하면서 시간 축을 따라 정보를 전파한다. 이 구조는 텍스트, 음성, 시계열 데이터처럼 순서가 중요한 문제에서 매우 유용하며, 구조의 간단함에도 불구하고 매우 강력한 모델이다. 그러나 장기 기억이 필요한 작업에서는 Gradient Vanishing 문제로 인해 LSTM, GRU 같은 고급 구조로 확장되는 경향이 있다. 그럼에도 불구하고 RNN의 핵심 아이디어는 여전히 현대 딥러닝의 순환 기반 구조의 뼈대를 형성하고 있다.</p></article><footer class=book-footer><div class="flex flex-wrap justify-between"></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments><script src=https://giscus.app/client.js data-repo=yshghid/yshghid.github.io data-repo-id=R_kgDONkMkNg data-category-id=DIC_kwDONkMkNs4CloJh data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=ko crossorigin=anonymous async></script></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents></nav></div></aside></main></body></html>