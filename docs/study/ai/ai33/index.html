<!doctype html><html lang=en-us dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="
  AI #1 ML 방법론 기초
  #

#2025-09-13

#1 ML type (p.31-33)

ML의 학습방법 3가지

지도학습(Supervised)

입력 데이터와 출력 데이터가 모두 제공되고 모델은 입력을 보면 어떤 출력이 나와야 하는지를 배움. 학습한 모델은 새로운 데이터가 들어오면 예측을 하고 -> 결과를 실제 정답과 비교해 정확도 계산.


비지도학습(Unsupervised)

문제는 있지만 정답 라벨이 없음. 비슷한 특징을 가진 학생들을 묶어서 그룹을 만들고 어떤 그룹이 우수한지 알 수 없지만 데이터 안에서 자연스럽게 나타나는 구조를 파악한다(클러스터링)


준지도학습(Semi-Supervised)

라벨이 붙은 소량의 데이터와, 라벨이 없는 대량의 데이터를 동시에 사용하면 더 나은 모델을 만들 수 있다 왜냐하면 100% 라벨링된 데이터가 있을 때만큼 정확하지는 않지만, 현실에서는 라벨링이 부족한 경우가 많고 라벨 없는 데이터가 양은 많아서 데이터 분포를 더 잘 보여주기 때문이다.






  
  #

#2 머신러닝 알고리즘 (p.34)"><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="https://yshghid.github.io/docs/study/ai/ai33/"><meta property="og:site_name" content=" "><meta property="og:title" content="AI #1 ML 방법론 기초"><meta property="og:description" content="AI #1 ML 방법론 기초 # #2025-09-13
#1 ML type (p.31-33)
ML의 학습방법 3가지 지도학습(Supervised) 입력 데이터와 출력 데이터가 모두 제공되고 모델은 입력을 보면 어떤 출력이 나와야 하는지를 배움. 학습한 모델은 새로운 데이터가 들어오면 예측을 하고 -> 결과를 실제 정답과 비교해 정확도 계산. 비지도학습(Unsupervised) 문제는 있지만 정답 라벨이 없음. 비슷한 특징을 가진 학생들을 묶어서 그룹을 만들고 어떤 그룹이 우수한지 알 수 없지만 데이터 안에서 자연스럽게 나타나는 구조를 파악한다(클러스터링) 준지도학습(Semi-Supervised) 라벨이 붙은 소량의 데이터와, 라벨이 없는 대량의 데이터를 동시에 사용하면 더 나은 모델을 만들 수 있다 왜냐하면 100% 라벨링된 데이터가 있을 때만큼 정확하지는 않지만, 현실에서는 라벨링이 부족한 경우가 많고 라벨 없는 데이터가 양은 많아서 데이터 분포를 더 잘 보여주기 때문이다. # #2 머신러닝 알고리즘 (p.34)"><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="docs"><meta property="article:published_time" content="2025-09-13T00:00:00+00:00"><meta property="article:modified_time" content="2025-09-13T00:00:00+00:00"><meta property="article:tag" content="2025-09"><title>AI #1 ML 방법론 기초 |</title><link rel=icon href=/favicon.png><link rel=manifest href=/manifest.json><link rel=canonical href=https://yshghid.github.io/docs/study/ai/ai33/><link rel=stylesheet href=/book.min.30a7836b6a89342da3b88e7afd1036166aeced16c8de12df060ded2031837886.css integrity="sha256-MKeDa2qJNC2juI56/RA2Fmrs7RbI3hLfBg3tIDGDeIY=" crossorigin=anonymous><script defer src=/fuse.min.js></script><script defer src=/en.search.min.ab7853ea0ee8f6ec0345c6b0fbb65819aad61ec16b01dfdc42b3ac27101e888c.js integrity="sha256-q3hT6g7o9uwDRcaw+7ZYGarWHsFrAd/cQrOsJxAeiIw=" crossorigin=anonymous></script></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><img src=/logo.png alt=Logo class=book-icon><span></span></a></h2><div class="book-search hidden"><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><script>document.querySelector(".book-search").classList.remove("hidden")</script><ul><li class=book-section-flat><span>기록</span><ul><li><a href=/docs/hobby/daily/>일상</a><ul></ul></li><li><a href=/docs/hobby/book/>글</a><ul></ul></li></ul></li><li class=book-section-flat><span>공부</span><ul><li><a href=/docs/study/bioinformatics/>Bioinformatics</a><ul></ul></li><li><a href=/docs/study/ai/>AI</a><ul></ul></li><li><a href=/docs/study/sw/>SW</a><ul></ul></li><li><a href=/docs/study/career/>취업</a><ul></ul></li></ul></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu></label><h3>AI #1 ML 방법론 기초</h3><label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><ul><li></li><li></li><li></li></ul></li></ul></nav></aside></header><article class="markdown book-article"><h1 id=ai-1-ml-방법론-기초>AI #1 ML 방법론 기초
<a class=anchor href=#ai-1-ml-%eb%b0%a9%eb%b2%95%eb%a1%a0-%ea%b8%b0%ec%b4%88>#</a></h1><p>#2025-09-13</p><hr><p>#1 ML type (p.31-33)</p><ul><li>ML의 학습방법 3가지<ul><li>지도학습(Supervised)<ul><li>입력 데이터와 출력 데이터가 모두 제공되고 모델은 입력을 보면 어떤 출력이 나와야 하는지를 배움. 학습한 모델은 새로운 데이터가 들어오면 예측을 하고 -> 결과를 실제 정답과 비교해 정확도 계산.</li></ul></li><li>비지도학습(Unsupervised)<ul><li>문제는 있지만 정답 라벨이 없음. 비슷한 특징을 가진 학생들을 묶어서 그룹을 만들고 어떤 그룹이 우수한지 알 수 없지만 데이터 안에서 자연스럽게 나타나는 구조를 파악한다(클러스터링)</li></ul></li><li>준지도학습(Semi-Supervised)<ul><li>라벨이 붙은 소량의 데이터와, 라벨이 없는 대량의 데이터를 동시에 사용하면 더 나은 모델을 만들 수 있다 왜냐하면 100% 라벨링된 데이터가 있을 때만큼 정확하지는 않지만, 현실에서는 라벨링이 부족한 경우가 많고 라벨 없는 데이터가 양은 많아서 데이터 분포를 더 잘 보여주기 때문이다.</li></ul></li></ul></li></ul><h3><a class=anchor href=#>#</a></h3><p>#2 머신러닝 알고리즘 (p.34)</p><ul><li><p>트리 기반 방법(CART)</p><ul><li>결정트리(Decision Tree)<ul><li>데이터를 여러 조건으로 나누어가면서 최종 답을 찾는다 예를 들어 &ldquo;이 과일은 달콤한가?&rdquo; -> &ldquo;색깔은 빨간가?&rdquo; -> &ldquo;크기는 작은가?&rdquo; 같은 질문을 따라가면서 사과, 딸기, 체리처럼 답을 얻는다.</li></ul></li><li>랜덤포레스트(Random Forest)<ul><li>결정트리를 하나만 쓰지 않고 여러 개를 무작위로 만들어서 숲을 형성하고 각각의 나무가 약간씩 다른 조건을 사용하기 때문에 전체적으로는 더 튼튼하고 안정적인 예측을 한다. 여러 명이 각자 판단한 결과를 모아 집단지성을활용함.</li></ul></li></ul></li><li><p>커널 기반 방법(SVM)</p><ul><li>SVM은 통계학자가 아니라 항공우주 연구자들이 만든 알고리즘.</li><li>우주에서 달과 그 주변의 별들을 구분하려 한다면 하늘의 모든 별을 고려할 필요는 없고 달의 경계 근처에 있는 몇몇 별만 봐도 구분 선을 그을 수 있다.<ul><li>SVM은 바로 이 “경계에 가까운 데이터”만 집중해서 보는데 달과 별을 가르는 선을 그을 때 이 선과 가장 가까운 점들과의 거리를 최대화한다 그래서 SVM은 전체 데이터를 다 보지 않고도 효과적으로 두 집단을 구분할 수 있다.</li><li>또한 경계를 그을 때 약간의 오차는 허용하는데 현실 세계 데이터가 완벽하게 나눠지지 않는 경우가 많다는 사실을 고려한 것이다.</li></ul></li></ul></li><li><p>부스팅</p><ul><li>약한 모델들을 모아서 강한 모델을 만드는 전략. 시험을 본다고 하면 한 학생이 문제를 틀린 부분만 복습하고 또 시험을 본다. 또 틀리면 다시 그 부분만 공부한다. 이런 식으로 반복해서 학습하면 점점 더 성적이 오른다.</li><li>XGBoost는 틀린 데이터에 더 높은 가중치를 주면서 여러 약한 트리를 합쳐 성능을 끌어올린다. LightGBM은 XGBoost의 연산 방식을 최적화해서 더 빠르게, 그리고 더 효율적으로 학습할 수 있도록 만든 버전.</li></ul></li><li><p>정규화</p><ul><li>회귀 문제용.</li><li>회귀 모델은 데이터의 입력 변수와 출력 값을 수학적으로 연결하는데 변수가 너무 많으면 모델이 복잡해지고 오히려 예측력이 떨어진다. 정규화는 규칙을 추가해 모델이 과도하게 커지는 것을 막는다.</li><li>LASSO는 회귀 계수 중 일부를 아예 0으로 만들어 변수를 줄이는 방법. Ridge는 모든 변수를 유지하되 크기를 작게 줄이는 방법. 둘 다 모델이 단순해지도록 돕고, 과적합을 막아 예측력을 높인다.</li><li>“너무 많은 변수에 휘둘리지 말고, 꼭 필요한 신호만 잡아내라”라는 규칙을 주입하는 과정.</li></ul></li></ul><h3><a class=anchor href=#>#</a></h3><p>#3 지니계수 & 엔트로피</p><ul><li>불순도 측정방법.<ul><li>불순도는 여러 클래스가 얼마나 섞여 있는지.</li></ul></li><li>지니 계수<ul><li>확률을 가지고 계산. 예를 들어 어떤 마디에 빨간색이 30%, 파란색이 70% 있다고 하면 임의로 두 개를 뽑았을 때 색이 서로 다를 확률을 계산하는데 값이 클수록 섞여 있다는 뜻이고 값이 0에 가까우면 거의 한 가지 색만 있다는 뜻. 즉 무작위로 두 개를 뽑았을 때 다를 확률.</li></ul></li><li>엔트로피<ul><li>숫자를 맞추는 스무고개 게임을 할때. 상대가 생각한 숫자가 1부터 1000까지 중 하나면 그냥 무작정 맞추는 건 비효율적이고 보통은 반으로 나누는 질문을 한다 “500보다 크냐?”, “750보다 크냐?” 이런 식으로 세 번 질문하면 대략 1000개 중 하나를 알아낼 수 있다. 이때 필요한 질문의 횟수가 정뵤량.</li><li>엔트로피는 질문의 평균 횟수를 수학적으로 표현한 값이다 클래스가 균등하게 섞여 있을수록 질문을 많이 해야 하고 한 클래스가 압도적으로 많으면 질문을 거의 안 해도 알 수 있으니까 엔트로피가 낮다.</li></ul></li><li>결론<ul><li>지니 계수는 두 개 뽑았을 때 다를 확률을 계산하는 방식이고 엔트로피는 그 집합을 완전히 구분하려면 평균적으로 몇 번 질문해야 하는가를 계산하는 방식.</li></ul></li></ul><h3><a class=anchor href=#>#</a></h3><p>#4 부스팅</p><ul><li>한두 번은 맞지만 전체적으로는 성능이 낮은 약한 모델을 여러 개 모아 강한 모델을 만들기<ul><li>모델이 틀린 부분에 가중치를 더 주고, 그다음 모델이 그 틀린 부분을 집중적으로 학습하게 만들고를 여러 번 반복한다.</li><li>손실 함수의 기울기를 계산해서 “어느 방향으로, 얼마나 고쳐야 성능이 나아질지”를 봐서 단순히 틀린 데이터를 다시 보는 게 아니라 오차를 줄이는 방향으로 학습 (그래디언트)</li></ul></li></ul><h1><a class=anchor href=#>#</a></h1></article><footer class=book-footer><div class="flex flex-wrap justify-between"></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments><script src=https://giscus.app/client.js data-repo=yshghid/yshghid.github.io data-repo-id=R_kgDONkMkNg data-category-id=DIC_kwDONkMkNs4CloJh data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=ko crossorigin=anonymous async></script></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><ul><li></li><li></li><li></li></ul></li></ul></nav></div></aside></main></body></html>