<!doctype html><html lang=en-us dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="
  TFT #1 입력 시퀀스 생성
  #

#2025-07-23


  1. Load package
  #

%load_ext autoreload
%autoreload 2

import sys
import pandas as pd
import numpy as np
import os
import pickle
import ast

sys.path.append('/data3/projects/2025_Antibiotics/YSH/bin')
from sc import *

os.chdir('/data3/projects/2025_Antibiotics/YSH/workspace')

  2. Load raw data
  #

#data
/data
├── PreprocessedData/
│   └── TimecourseData/
│       └── * (*: patient id)
│           ├── SeverityScore.csv
│           ├── Laboratory_processed.csv 
│           └── Medication.csv
├── PreprocessedData_knuh/
│    └── (PreprocessedData와 동일)
└── 병원체자원은행 균주현황(2014-2024.06)_Sepsis.xlsx

/data_knuch
└── (empty)

/data_knuh
└── (empty)
data_knuch = '/data/PreprocessedData/TimecourseData'
data_knuh = '/data/PreprocessedData_knuh/TimecourseData'

pids = [d for d in os.listdir(data_knuch)] + [d for d in os.listdir(data_knuh)]
len(pids)
13779

  3. Raw data processing
  #

#processing knuch
datadir = '/data/PreprocessedData/TimecourseData'
pids = [d for d in os.listdir(datadir)]

input_dict = make_input(datadir, pids)
input_dict, no_strains = add_strain(input_dict)

outdir = &#34;data_knuch&#34;
with open(f&#34;{outdir}/Input.pkl&#34;, 'wb') as f:
    pickle.dump(input_dict, f)
print(len(list(input_dict.keys())))
print(len(no_strains))
4516
4
#processing knuh
datadir = '/data/PreprocessedData_knuh/TimecourseData'
pids = [d for d in os.listdir(datadir)]

input_dict = make_input(datadir, pids)
input_dict, no_strains = add_strain(input_dict)

outdir = &#34;data_knuh&#34;
with open(f&#34;{outdir}/Input.pkl&#34;, 'wb') as f:
    pickle.dump(input_dict, f)
print(len(list(input_dict.keys())))
print(len(no_strains))
9100
1
#result"><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="https://yshghid.github.io/docs/study/ai/ai5/"><meta property="og:site_name" content=" "><meta property="og:title" content="TFT #1 입력 시퀀스 생성"><meta property="og:description" content="TFT #1 입력 시퀀스 생성 # #2025-07-23
1. Load package # %load_ext autoreload %autoreload 2 import sys import pandas as pd import numpy as np import os import pickle import ast sys.path.append('/data3/projects/2025_Antibiotics/YSH/bin') from sc import * os.chdir('/data3/projects/2025_Antibiotics/YSH/workspace') 2. Load raw data # #data
/data ├── PreprocessedData/ │ └── TimecourseData/ │ └── * (*: patient id) │ ├── SeverityScore.csv │ ├── Laboratory_processed.csv │ └── Medication.csv ├── PreprocessedData_knuh/ │ └── (PreprocessedData와 동일) └── 병원체자원은행 균주현황(2014-2024.06)_Sepsis.xlsx /data_knuch └── (empty) /data_knuh └── (empty) data_knuch = '/data/PreprocessedData/TimecourseData' data_knuh = '/data/PreprocessedData_knuh/TimecourseData' pids = [d for d in os.listdir(data_knuch)] + [d for d in os.listdir(data_knuh)] len(pids) 13779 3. Raw data processing # #processing knuch datadir = '/data/PreprocessedData/TimecourseData' pids = [d for d in os.listdir(datadir)] input_dict = make_input(datadir, pids) input_dict, no_strains = add_strain(input_dict) outdir = &#34;data_knuch&#34; with open(f&#34;{outdir}/Input.pkl&#34;, 'wb') as f: pickle.dump(input_dict, f) print(len(list(input_dict.keys()))) print(len(no_strains)) 4516 4 #processing knuh datadir = '/data/PreprocessedData_knuh/TimecourseData' pids = [d for d in os.listdir(datadir)] input_dict = make_input(datadir, pids) input_dict, no_strains = add_strain(input_dict) outdir = &#34;data_knuh&#34; with open(f&#34;{outdir}/Input.pkl&#34;, 'wb') as f: pickle.dump(input_dict, f) print(len(list(input_dict.keys()))) print(len(no_strains)) 9100 1 #result"><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="docs"><meta property="article:published_time" content="2025-07-23T00:00:00+00:00"><meta property="article:modified_time" content="2025-07-23T00:00:00+00:00"><meta property="article:tag" content="2025-07"><title>TFT #1 입력 시퀀스 생성 |</title><link rel=icon href=/favicon.png><link rel=manifest href=/manifest.json><link rel=canonical href=https://yshghid.github.io/docs/study/ai/ai5/><link rel=stylesheet href=/book.min.6217d077edb4189fd0578345e84bca1a884dfdee121ff8dc9a0f55cfe0852bc9.css integrity="sha256-YhfQd+20GJ/QV4NF6EvKGohN/e4SH/jcmg9Vz+CFK8k=" crossorigin=anonymous><script defer src=/fuse.min.js></script><script defer src=/en.search.min.8e9b1964fa68d3f5d6a592dc2e1440c928aec59b330865c1d3092ba52dc20d05.js integrity="sha256-jpsZZPpo0/XWpZLcLhRAySiuxZszCGXB0wkrpS3CDQU=" crossorigin=anonymous></script></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><img src=/logo.png alt=Logo class=book-icon><span></span></a></h2><div class="book-search hidden"><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><script>document.querySelector(".book-search").classList.remove("hidden")</script><ul><li class=book-section-flat><span>기록</span><ul><li><a href=/docs/hobby/book/>글</a><ul></ul></li><li><a href=/docs/hobby/daily/>일상</a><ul></ul></li><li><a href=/docs/hobby/shopping/>쇼핑</a><ul></ul></li><li><a href=/docs/hobby/youtube/>유튜브</a><ul></ul></li><li><a href=/docs/hobby/music/>음악</a><ul></ul></li><li><a href=/docs/hobby/baking/>베이킹</a><ul></ul></li><li><a href=/docs/hobby/movie/>영화</a><ul></ul></li></ul></li><li class=book-section-flat><span>공부</span><ul><li><a href=/docs/study/ai/>AI</a><ul></ul></li><li><a href=/docs/study/sw/>SW</a><ul></ul></li><li><a href=/docs/study/bioinformatics/>Bioinformatics</a><ul></ul></li><li><a href=/docs/study/algorithm/>코테</a><ul></ul></li><li><a href=/docs/study/career/>취업</a><ul></ul></li><li><a href=/docs/study/github/>깃허브</a><ul></ul></li></ul></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu></label><h3>TFT #1 입력 시퀀스 생성</h3><label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><ul><li><a href=#1-load-package>1. Load package</a></li><li><a href=#2-load-raw-data>2. Load raw data</a></li><li><a href=#3-raw-data-processing>3. Raw data processing</a></li><li><a href=#4-make-input-sequence>4. Make input sequence</a></li></ul></li></ul></nav></aside></header><article class="markdown book-article"><h1 id=tft-1-입력-시퀀스-생성>TFT #1 입력 시퀀스 생성
<a class=anchor href=#tft-1-%ec%9e%85%eb%a0%a5-%ec%8b%9c%ed%80%80%ec%8a%a4-%ec%83%9d%ec%84%b1>#</a></h1><p>#2025-07-23</p><hr><h3 id=1-load-package>1. Load package
<a class=anchor href=#1-load-package>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>%</span>load_ext autoreload
</span></span><span style=display:flex><span><span style=color:#f92672>%</span>autoreload <span style=color:#ae81ff>2</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> sys
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> pandas <span style=color:#66d9ef>as</span> pd
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> os
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> pickle
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> ast
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>sys<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>append(<span style=color:#e6db74>&#39;/data3/projects/2025_Antibiotics/YSH/bin&#39;</span>)
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sc <span style=color:#f92672>import</span> <span style=color:#f92672>*</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>os<span style=color:#f92672>.</span>chdir(<span style=color:#e6db74>&#39;/data3/projects/2025_Antibiotics/YSH/workspace&#39;</span>)
</span></span></code></pre></div><h3 id=2-load-raw-data>2. Load raw data
<a class=anchor href=#2-load-raw-data>#</a></h3><p>#data</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-plain data-lang=plain><span style=display:flex><span>/data
</span></span><span style=display:flex><span>├── PreprocessedData/
</span></span><span style=display:flex><span>│   └── TimecourseData/
</span></span><span style=display:flex><span>│       └── * (*: patient id)
</span></span><span style=display:flex><span>│           ├── SeverityScore.csv
</span></span><span style=display:flex><span>│           ├── Laboratory_processed.csv 
</span></span><span style=display:flex><span>│           └── Medication.csv
</span></span><span style=display:flex><span>├── PreprocessedData_knuh/
</span></span><span style=display:flex><span>│    └── (PreprocessedData와 동일)
</span></span><span style=display:flex><span>└── 병원체자원은행 균주현황(2014-2024.06)_Sepsis.xlsx
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>/data_knuch
</span></span><span style=display:flex><span>└── (empty)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>/data_knuh
</span></span><span style=display:flex><span>└── (empty)
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>data_knuch <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;/data/PreprocessedData/TimecourseData&#39;</span>
</span></span><span style=display:flex><span>data_knuh <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;/data/PreprocessedData_knuh/TimecourseData&#39;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>pids <span style=color:#f92672>=</span> [d <span style=color:#66d9ef>for</span> d <span style=color:#f92672>in</span> os<span style=color:#f92672>.</span>listdir(data_knuch)] <span style=color:#f92672>+</span> [d <span style=color:#66d9ef>for</span> d <span style=color:#f92672>in</span> os<span style=color:#f92672>.</span>listdir(data_knuh)]
</span></span><span style=display:flex><span>len(pids)
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-plain data-lang=plain><span style=display:flex><span>13779
</span></span></code></pre></div><h3 id=3-raw-data-processing>3. Raw data processing
<a class=anchor href=#3-raw-data-processing>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e>#processing knuch</span>
</span></span><span style=display:flex><span>datadir <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;/data/PreprocessedData/TimecourseData&#39;</span>
</span></span><span style=display:flex><span>pids <span style=color:#f92672>=</span> [d <span style=color:#66d9ef>for</span> d <span style=color:#f92672>in</span> os<span style=color:#f92672>.</span>listdir(datadir)]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>input_dict <span style=color:#f92672>=</span> make_input(datadir, pids)
</span></span><span style=display:flex><span>input_dict, no_strains <span style=color:#f92672>=</span> add_strain(input_dict)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>outdir <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;data_knuch&#34;</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>with</span> open(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;</span><span style=color:#e6db74>{</span>outdir<span style=color:#e6db74>}</span><span style=color:#e6db74>/Input.pkl&#34;</span>, <span style=color:#e6db74>&#39;wb&#39;</span>) <span style=color:#66d9ef>as</span> f:
</span></span><span style=display:flex><span>    pickle<span style=color:#f92672>.</span>dump(input_dict, f)
</span></span><span style=display:flex><span>print(len(list(input_dict<span style=color:#f92672>.</span>keys())))
</span></span><span style=display:flex><span>print(len(no_strains))
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-plain data-lang=plain><span style=display:flex><span>4516
</span></span><span style=display:flex><span>4
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e>#processing knuh</span>
</span></span><span style=display:flex><span>datadir <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;/data/PreprocessedData_knuh/TimecourseData&#39;</span>
</span></span><span style=display:flex><span>pids <span style=color:#f92672>=</span> [d <span style=color:#66d9ef>for</span> d <span style=color:#f92672>in</span> os<span style=color:#f92672>.</span>listdir(datadir)]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>input_dict <span style=color:#f92672>=</span> make_input(datadir, pids)
</span></span><span style=display:flex><span>input_dict, no_strains <span style=color:#f92672>=</span> add_strain(input_dict)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>outdir <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;data_knuh&#34;</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>with</span> open(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;</span><span style=color:#e6db74>{</span>outdir<span style=color:#e6db74>}</span><span style=color:#e6db74>/Input.pkl&#34;</span>, <span style=color:#e6db74>&#39;wb&#39;</span>) <span style=color:#66d9ef>as</span> f:
</span></span><span style=display:flex><span>    pickle<span style=color:#f92672>.</span>dump(input_dict, f)
</span></span><span style=display:flex><span>print(len(list(input_dict<span style=color:#f92672>.</span>keys())))
</span></span><span style=display:flex><span>print(len(no_strains))
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-plain data-lang=plain><span style=display:flex><span>9100
</span></span><span style=display:flex><span>1
</span></span></code></pre></div><p>#result</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-plain data-lang=plain><span style=display:flex><span>/data
</span></span><span style=display:flex><span>├── PreprocessedData/
</span></span><span style=display:flex><span>│   └── TimecourseData/
</span></span><span style=display:flex><span>│       └── * (*: patient id)
</span></span><span style=display:flex><span>│           ├── SeverityScore.csv
</span></span><span style=display:flex><span>│           ├── Laboratory_processed.csv 
</span></span><span style=display:flex><span>│           └── Medication.csv
</span></span><span style=display:flex><span>├── PreprocessedData_knuh/
</span></span><span style=display:flex><span>│    └── (PreprocessedData와 동일)
</span></span><span style=display:flex><span>└── 병원체자원은행 균주현황(2014-2024.06)_Sepsis.xlsx
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>/data_knuch
</span></span><span style=display:flex><span>└── Input.pkl
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>/data_knuh
</span></span><span style=display:flex><span>└── Input.pkl
</span></span></code></pre></div><h3 id=4-make-input-sequence>4. Make input sequence
<a class=anchor href=#4-make-input-sequence>#</a></h3><p>#data</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-plain data-lang=plain><span style=display:flex><span>/data
</span></span><span style=display:flex><span>└── all_meds.txt
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>/data_knuch
</span></span><span style=display:flex><span>├── Input.pkl
</span></span><span style=display:flex><span>└── sequence
</span></span><span style=display:flex><span>     └── (empty)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>/data_knuh
</span></span><span style=display:flex><span>├── Input.pkl
</span></span><span style=display:flex><span>└── sequence
</span></span><span style=display:flex><span>     └── (empty)
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>dtype <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;knuh&#39;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>indir <span style=color:#f92672>=</span> <span style=color:#e6db74>f</span><span style=color:#e6db74>&#39;data_</span><span style=color:#e6db74>{</span>dtype<span style=color:#e6db74>}</span><span style=color:#e6db74>&#39;</span>
</span></span><span style=display:flex><span>medinfo <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;/data/all_meds.txt&#39;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>with</span> open(medinfo, <span style=color:#e6db74>&#39;r&#39;</span>) <span style=color:#66d9ef>as</span> f:
</span></span><span style=display:flex><span>    meds <span style=color:#f92672>=</span> [line<span style=color:#f92672>.</span>strip()<span style=color:#f92672>.</span>replace(<span style=color:#e6db74>&#34;/&#34;</span>, <span style=color:#e6db74>&#34;_&#34;</span>) <span style=color:#66d9ef>for</span> line <span style=color:#f92672>in</span> f <span style=color:#66d9ef>if</span> line<span style=color:#f92672>.</span>strip()]
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span><span style=color:#66d9ef>with</span> open(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;</span><span style=color:#e6db74>{</span>indir<span style=color:#e6db74>}</span><span style=color:#e6db74>/Input.pkl&#34;</span>, <span style=color:#e6db74>&#39;rb&#39;</span>) <span style=color:#66d9ef>as</span> f:
</span></span><span style=display:flex><span>        input_dict <span style=color:#f92672>=</span> pickle<span style=color:#f92672>.</span>load(f)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>pids <span style=color:#f92672>=</span> list(input_dict<span style=color:#f92672>.</span>keys())
</span></span><span style=display:flex><span>outdir <span style=color:#f92672>=</span> <span style=color:#e6db74>f</span><span style=color:#e6db74>&#39;data_</span><span style=color:#e6db74>{</span>dtype<span style=color:#e6db74>}</span><span style=color:#e6db74>/sequence&#39;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> med <span style=color:#f92672>in</span> meds:
</span></span><span style=display:flex><span>    make_sequence(med, indir, outdir)
</span></span></code></pre></div><p>#result</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-plain data-lang=plain><span style=display:flex><span>/data
</span></span><span style=display:flex><span>└── all_meds.txt
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>/data_knuch
</span></span><span style=display:flex><span>├── Input.pkl
</span></span><span style=display:flex><span>└── sequence
</span></span><span style=display:flex><span>     └── *.pkl (*: antibiotics)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>/data_knuh
</span></span><span style=display:flex><span>├── Input.pkl
</span></span><span style=display:flex><span>└── sequence
</span></span><span style=display:flex><span>     └── *.pkl (*: antibiotics)
</span></span></code></pre></div><p>#functions</p><details><summary></summary>```python
import pandas as pd
import numpy as np
import os
import pickle
import ast<pre><code>from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
import matplotlib.pyplot as plt
import numpy as np
import math

import warnings

from matplotlib.backends.backend_pdf import PdfPages

os.chdir('/data3/projects/2025_Antibiotics/YSH/')

### 2 ###

def make_input(datadir, pids):
    sev_dict = {}
    sev_dict_filtered = {}

    for pid in pids:
        try:
            # 1. SeverityScore 불러오기
            sev = pd.read_csv(f&quot;{datadir}/{pid}/SeverityScore.csv&quot;)

            # 2. Laboratory 데이터 불러오기 및 병합
            lab = pd.read_csv(f&quot;{datadir}/{pid}/Laboratory_processed.csv&quot;)
            sev = pd.merge(sev, lab, on='Date', how='left')

            # 3. Medication 불러오기
            med = pd.read_csv(f&quot;{datadir}/{pid}/Medication.csv&quot;)
            med_filtered = med[med['Date'].isin(sev['Date'])]
            med_filtered = med_filtered.loc[:, ~med_filtered.columns.str.endswith('_dose')]

            # 4. Medication 관련 열 추가
            sev['med_cnt'] = 0
            sev['med_list'] = &quot;&quot;

            # 5. 날짜별로 약물 정보 병합
            for _, row in med_filtered.iterrows():
                cur_date = row['Date']
                cur_meds_raw = row.iloc[1:]
                cur_meds_clean = cur_meds_raw.dropna().tolist()

                med_freq = {}
                cur_meds = []
                for med in cur_meds_clean:
                    if med not in med_freq:
                        med_freq[med] = 1
                        cur_meds.append(med)
                    else:
                        med_freq[med] += 1
                        cur_meds.append(f&quot;{med}_{med_freq[med]}&quot;)

                cur_med_cnt = len(cur_meds)
                cur_med_str = &quot;;&quot;.join(cur_meds)

                sev_idx = sev[sev['Date'] == cur_date].index
                if len(sev_idx) &gt; 0:
                    sev.loc[sev_idx, 'med_cnt'] = cur_med_cnt
                    sev.loc[sev_idx, 'med_list'] = cur_med_str

            zero_cnt = (sev['med_cnt'] == 0).sum()

        except FileNotFoundError:
            sev['med_cnt'] = &quot;&quot;
            sev['med_list'] = &quot;&quot;
            zero_cnt = &quot;N/A (no med file)&quot;

        if sev.shape[0] == zero_cnt:
            print(pid)

        if zero_cnt == &quot;N/A (no med file)&quot;:
            print(pid, zero_cnt)

        sev_dict[pid] = sev

        # Remove med cnt 0
        if 'med_cnt' not in sev.columns:
            print(f&quot;{pid} - Error: 'med_cnt' column doesn't exist&quot;)
            continue
        sev['med_cnt'] = pd.to_numeric(sev['med_cnt'], errors='coerce')

        if sev['med_cnt'].isna().all():
            continue

        if sev['med_cnt'].fillna(0).eq(0).all():
            continue

        sev_dict_filtered[pid] = sev
        
    return sev_dict_filtered
    
def add_strain(sev_dict_filtered):
    strain_path = '/data3/projects/2025_Antibiotics/data/병원체자원은행 균주현황(2014-2024.06)_Sepsis.xlsx'
    strain_df = pd.read_excel(strain_path)

    valid_columns = strain_df.iloc[0].dropna().index
    strain_legend = strain_df.loc[:1, valid_columns].copy()

    strain_df.columns = strain_df.iloc[1]
    strain_df = strain_df.drop(index=[0, 1])
    strain_df = strain_df[['접수일', '등록번호', '균']]
    strain_df['등록번호'] = strain_df['등록번호'].astype(int)

    valid_ids = [int(k) for k in sev_dict_filtered.keys()]
    #strain_df['접수번호'] = strain_df['접수번호'].astype(str).astype(int)
    strain_df = strain_df[strain_df['등록번호'].isin(valid_ids)].reset_index(drop=True)

    strain_df = strain_df.drop_duplicates(subset=['균', '등록번호'], keep='first').reset_index(drop=True)
    strain_df['접수일'] = pd.to_datetime(strain_df['접수일'])
    strain_df['접수일'] = strain_df['접수일'].dt.strftime('%Y-%m-%d')

    # 등록번호 컬럼을 str로 변환 (딕셔너리 key와 비교하기 위함)
    strain_df['등록번호'] = strain_df['등록번호'].astype(str)

    pid_without_strains = []   

    for cur_key, cur_sev_df in sev_dict_filtered.items():
        cur_key_str = str(cur_key)

        # 등록번호가 현재 key인 행들 필터링
        cur_df = strain_df[strain_df['등록번호'] == cur_key_str]

        if cur_df.empty:
            print(cur_key)
            continue

        # 날짜 변환
        cur_sev_df['Date'] = pd.to_datetime(cur_sev_df['Date'])
        cur_df['접수일'] = pd.to_datetime(cur_df['접수일'])

        for _, row in cur_df.iterrows():
            cur_date = row['접수일']
            cur_strain = row['균']

            # 접수일과 같거나 이후인 첫 행의 인덱스 찾기
            matched_idx = cur_sev_df[cur_sev_df['Date'] &gt;= cur_date].index.min()

            if pd.isna(matched_idx):
                continue  # 매칭된 날짜가 없다면 skip

            # strain 컬럼이 없다면 빈 리스트 생성
            if 'strain' not in cur_sev_df.columns:
                cur_sev_df['strain'] = [[] for _ in range(len(cur_sev_df))]

            # strain 컬럼이 리스트 형식이 아니면 변환
            if not isinstance(cur_sev_df.at[matched_idx, 'strain'], list):
                cur_sev_df.at[matched_idx, 'strain'] = []

            # 중복 방지를 원할 경우 다음 줄에 조건 추가 가능
            cur_sev_df.at[matched_idx, 'strain'].append(cur_strain)

        # strain 컬럼이 없는 경우 스킵
        if 'strain' not in cur_sev_df.columns:
            pid_without_strains.append(cur_key_str)
            continue

        cur_sev_df = cur_sev_df.reset_index(drop=True)

        last_strain = []  # 최근에 발견된 strain 리스트
        for i in range(len(cur_sev_df)):
            current_strain = cur_sev_df.at[i, 'strain']

            if isinstance(current_strain, list) and len(current_strain) &gt; 0:
                # 비어있지 않은 strain 리스트 발견 → 이를 저장
                last_strain = current_strain
            elif isinstance(current_strain, list) and len(current_strain) == 0:
                # 비어있다면 → 가장 최근의 strain 리스트를 할당
                cur_sev_df.at[i, 'strain'] = last_strain.copy()

        # 각 strain 리스트에서 중복 제거
        cur_sev_df['strain'] = cur_sev_df['strain'].apply(
            lambda x: list(set(x)) if isinstance(x, list) else x
        )

        # 다시 딕셔너리에 반영
        sev_dict_filtered[cur_key] = cur_sev_df
        
    return sev_dict_filtered, pid_without_strains

    
### 3 ###

def make_sev_dict(med, indir, outdir):
    with open(f&quot;{indir}/Input.pkl&quot;, 'rb') as f:
        sev_dict_filtered = pickle.load(f)
    
    if med != &quot;total&quot;:
        for pid, cur_df in sev_dict_filtered.items():
            try:
                cur_df['cur_med_list'] = cur_df['med_list'].fillna('').apply(lambda x: x.split(';'))
                cur_df['med_cnt'] = cur_df['cur_med_list'].apply(
                    lambda meds: sum([1 for item in meds if item.startswith(med)])
                )
                #cur_df = cur_df[['Date', 'NEWS', 'med_cnt', 'strain']]
                #print(cur_df.shape)
                sev_dict_filtered[pid] = cur_df
            except KeyError as e:
                print(f&quot;[{pid}] 건너뜀 - 누락 컬럼: {e}&quot;)
                continue
    else:
        for pid, cur_df in sev_dict_filtered.items():
            try:
                #cur_df = cur_df[['Date', 'NEWS', 'med_cnt', 'strain']]
                sev_dict_filtered[pid] = cur_df
            except KeyError as e:
                print(f&quot;[{pid}] 건너뜀 - 누락 컬럼: {e}&quot;)
                continue

    with open(f&quot;{outdir}/{med}.pkl&quot;, 'wb') as f:
        pickle.dump(sev_dict_filtered, f)
    
    return sev_dict_filtered

def summarize_med_cnt(med_cnt_series):
    info_list = []
    if med_cnt_series.empty:
        return info_list

    cur_type = 'm' if med_cnt_series.iloc[0] &gt; 0 else 'n'
    count = 1

    for prev, curr in zip(med_cnt_series[:-1], med_cnt_series[1:]):
        curr_type = 'm' if curr &gt; 0 else 'n'
        if curr_type == cur_type:
            count += 1
        else:
            info_list.append(f&quot;{count}{cur_type}&quot;)
            cur_type = curr_type
            count = 1

    info_list.append(f&quot;{count}{cur_type}&quot;)
    return info_list

def make_timecourse(indir, outdir, med):
    with open(f&quot;{indir}/{med}.pkl&quot;, 'rb') as f:
        sev_dict_filtered = pickle.load(f)

    timecourse_list = []

    for pid, sev in sev_dict_filtered.items():
        if 'med_cnt' not in sev.columns or sev['med_cnt'].isnull().all():
            print(f&quot;{pid} - Error: 'med_cnt' column doesn't exist&quot;)
            continue

        sev['med_cnt'] = pd.to_numeric(sev['med_cnt'], errors='coerce').fillna(0).astype(int)

        info_list = summarize_med_cnt(sev['med_cnt'])

        timecourse_list.append({
            'pid': pid,
            'days': len(sev),
            'info': info_list
        })

    timecourse = pd.DataFrame(timecourse_list)
    timecourse.to_csv(f&quot;{outdir}/{med}.csv&quot;, index=False)
    
    return timecourse

def filter_info(info_list):
    has_m_prefix = any(item.startswith('m') for item in info_list)
    has_m_suffix = any(item.endswith('m') for item in info_list)
    has_n_suffix = any(item.endswith('n') for item in info_list)

    if has_m_prefix:
        return False
    if all(item.endswith('m') for item in info_list):
        return False
    if all(item.endswith('n') for item in info_list):
        return False
    return True

def convert_info_with_repeats(info_list):
    result = ''
    for item in info_list:
        if item.endswith('n'):
            num = int(item[:-1])
            result += '_' * num
        elif item.endswith('m'):
            num = int(item[:-1])
            result += 'm' * num
    return result

def find_valid_start_end(s):
    valid_starts = []
    valid_ends = []
    for i in range(len(s) - 3):
        if s[i:i+4] == '___m':
            end = i + 9
            if end &lt; len(s):
                valid_starts.append(i)
                valid_ends.append(end)
    return pd.Series({'start_idx': valid_starts, 'end_idx': valid_ends})

#def find_valid_start_end(s):
#    valid_starts = []
#    valid_ends = []
#    for i in range(len(s) - 7): 
#        if s[i:i+8] == '_______m':
#            end = i + 13  
#            if end &lt; len(s):
#                valid_starts.append(i)
#                valid_ends.append(end)
#    return pd.Series({'start_idx': valid_starts, 'end_idx': valid_ends})

def make_sev_idx(indir, outdir, med):
    timecourse = pd.read_csv(f&quot;{indir}/{med}.csv&quot;)

    if isinstance(timecourse['info'].iloc[0], str):
        timecourse['info'] = timecourse['info'].apply(ast.literal_eval)

    timecourse = timecourse[timecourse['info'].apply(filter_info)].reset_index(drop=True)
    timecourse['info_timecourse'] = timecourse['info'].apply(convert_info_with_repeats)
    
    if not timecourse.empty:
        timecourse[['start_idx', 'end_idx']] = timecourse['info_timecourse'].apply(find_valid_start_end)
        timecourse = timecourse[~((timecourse['start_idx'].apply(len) == 0) &amp; (timecourse['end_idx'].apply(len) == 0))].reset_index(drop=True)
    
    timecourse.to_csv(f&quot;{outdir}/{med}.csv&quot;, index=False)

    return timecourse


def make_res_dict(indir, indexdir, outdir, med):
    
    with open(f&quot;{indir}/{med}.pkl&quot;, 'rb') as f:
        sev_dict_filtered = pickle.load(f)

    sev_idx = pd.read_csv(f&quot;{indexdir}/{med}.csv&quot;)
    
    res_dict = {}

    if not sev_idx.empty:  
        if isinstance(sev_idx['start_idx'].iloc[0], str):
            sev_idx['start_idx'] = sev_idx['start_idx'].apply(ast.literal_eval)

        if isinstance(sev_idx['end_idx'].iloc[0], str):
            sev_idx['end_idx'] = sev_idx['end_idx'].apply(ast.literal_eval)

        for _, row in sev_idx.iterrows():
            cur_pid = row['pid']
            cur_start_list = row['start_idx']
            cur_end_list = row['end_idx']
            cur_df = sev_dict_filtered[str(cur_pid)]

            for i in range(len(cur_start_list)):
                cur_start_idx = cur_start_list[i]
                cur_end_idx = cur_end_list[i]
                cur_filtered_df = cur_df.iloc[cur_start_idx:cur_end_idx+1].copy()
                key = f&quot;{cur_pid}_{i}&quot;
                res_dict[key] = cur_filtered_df

    with open(f&quot;{outdir}/{med}.pkl&quot;, 'wb') as f:
        pickle.dump(res_dict, f)
        
    return res_dict

def make_sequence(med, indir, outdir):
    sevdir = f'data_{dtype}/temp/sev_dict'
    sev_dict = make_sev_dict(med, indir, sevdir)
    
    timecourse_dir = f'data_{dtype}/temp/timecourse'
    timecourse = make_timecourse(sevdir, timecourse_dir, med)
    
    idx_dir = f'data_{dtype}/temp/sev_idx'
    sev_idx = make_sev_idx(timecourse_dir, idx_dir, med)
    
    res_dict = make_res_dict(sevdir, idx_dir, outdir, med)
    print(f'Sequence saved as {outdir}/{med}.pkl')
</code></pre><pre tabindex=0><code>&lt;/details&gt;


#
</code></pre></article><footer class=book-footer><div class="flex flex-wrap justify-between"></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments><script src=https://giscus.app/client.js data-repo=yshghid/yshghid.github.io data-repo-id=R_kgDONkMkNg data-category-id=DIC_kwDONkMkNs4CloJh data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=ko crossorigin=anonymous async></script></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><ul><li><a href=#1-load-package>1. Load package</a></li><li><a href=#2-load-raw-data>2. Load raw data</a></li><li><a href=#3-raw-data-processing>3. Raw data processing</a></li><li><a href=#4-make-input-sequence>4. Make input sequence</a></li></ul></li></ul></nav></div></aside></main></body></html>