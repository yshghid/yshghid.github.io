<!doctype html><html lang=en-us dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="
  ML #1
  #

#2025-09-10


  1
  #

# !pip install numpy
# !pip install pandas
# !pip install seaborn
# !pip install matplotlib
# !pip install -U scikit-learn
# !pip install xgboost
# !pip install lightgbm

import warnings

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.datasets import load_diabetes
from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    r2_score,
    mean_squared_error,
    root_mean_squared_error,
    mean_absolute_percentage_error,
)

warnings.filterwarnings(&#34;ignore&#34;)
pd.set_option(&#34;display.max_columns&#34;, 100)
pd.set_option(&#34;float_format&#34;, &#34;{:.4f}&#34;.format)
sns.set_style(&#34;whitegrid&#34;)

RANDOM_STATE = 42
# 1. Data Definition
_data = load_diabetes()
print(_data.DESCR)
.. _diabetes_dataset:

Diabetes dataset
----------------

Ten baseline variables, age, sex, body mass index, average blood
pressure, and six blood serum measurements were obtained for each of n =
442 diabetes patients, as well as the response of interest, a
quantitative measure of disease progression one year after baseline.

**Data Set Characteristics:**

:Number of Instances: 442

:Number of Attributes: First 10 columns are numeric predictive values

:Target: Column 11 is a quantitative measure of disease progression one year after baseline

:Attribute Information:
    - age     age in years
    - sex
    - bmi     body mass index
    - bp      average blood pressure
    - s1      tc, total serum cholesterol
    - s2      ldl, low-density lipoproteins
    - s3      hdl, high-density lipoproteins
    - s4      tch, total cholesterol / HDL
    - s5      ltg, possibly log of serum triglycerides level
    - s6      glu, blood sugar level

Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times the square root of `n_samples` (i.e. the sum of squares of each column totals 1).

Source URL:
https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html

For more information see:
Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) &#34;Least Angle Regression,&#34; Annals of Statistics (with discussion), 407-499.
(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)
data = _data[&#34;data&#34;]
feature_names = _data[&#34;feature_names&#34;]

df = pd.DataFrame(data, columns=feature_names)
df[&#34;target&#34;] = _data[&#34;target&#34;]

df.head()
# 2. EDA
# Correlation
plt.figure(figsize=(10, 8))

sns.heatmap(
    data=df.drop(&#34;target&#34;, axis=1).corr(),
    annot=True,
    cmap=&#34;coolwarm&#34;,
)

plt.show()
# 4. Machine Learning Regression
# Dataset Definition
X = df.drop(&#34;target&#34;, axis=1)
y = df[&#34;target&#34;]

# 먼저 train+valid와 test로 분할 (80:20)
X_temp, X_test, y_temp, y_test = train_test_split(
    X, y, test_size=0.2, random_state=RANDOM_STATE
)

# train+valid를 다시 train과 valid로 분할 (75:25)
X_train, X_valid, y_train, y_valid = train_test_split(
    X_temp, y_temp, test_size=0.25, random_state=RANDOM_STATE
)

print(f&#34;데이터 분할 결과:&#34;)
print(f&#34;Train: {len(X_train)} ({len(X_train)/len(X)*100:.1f}%)&#34;)
print(f&#34;Valid: {len(X_valid)} ({len(X_valid)/len(X)*100:.1f}%)&#34;)
print(f&#34;Test: {len(X_test)} ({len(X_test)/len(X)*100:.1f}%)&#34;)
데이터 분할 결과:
Train: 264 (59.7%)
Valid: 89 (20.1%)
Test: 89 (20.1%)
# Model (Vanila)
from sklearn.tree import DecisionTreeRegressor

model = DecisionTreeRegressor(random_state=RANDOM_STATE)
model.fit(X_train, y_train)
model.score(X_train, y_train)
print(model.intercept_, model.coef_)
1.0
# Feature Importance
model.feature_importances_
feature_names
_feature_importances = pd.Series(
    model.feature_importances_,
    index=feature_names,
)

_feature_importances
array([0.08981708, 0.00592253, 0.43861624, 0.08517564, 0.04463861,
       0.04418316, 0.05650334, 0.05949104, 0.13289137, 0.04276099])
['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']
age   0.0898
sex   0.0059
bmi   0.4386
bp    0.0852
s1    0.0446
s2    0.0442
s3    0.0565
s4    0.0595
s5    0.1329
s6    0.0428
dtype: float64
_feature_importances.nlargest().plot(kind=&#34;barh&#34;)
# Prediction
# 각 셋에 대한 예측
y_train_pred = model.predict(X_train)
y_valid_pred = model.predict(X_valid)
y_test_pred = model.predict(X_test)

# 각 셋의 성능 평가
def calculate_metrics(y_true, y_pred, set_name):
    r2 = r2_score(y_true, y_pred)
    mse = mean_squared_error(y_true, y_pred)
    rmse = root_mean_squared_error(y_true, y_pred)
    mape = mean_absolute_percentage_error(y_true, y_pred)
    
    return {
        'Set': set_name,
        'R²': r2,
        'MSE': mse,
        'RMSE': rmse,
        'MAPE': mape
    }

# 모든 셋의 성능 계산
train_metrics = calculate_metrics(y_train, y_train_pred, 'Train')
valid_metrics = calculate_metrics(y_valid, y_valid_pred, 'Valid')
test_metrics = calculate_metrics(y_test, y_test_pred, 'Test')

# 결과를 DataFrame으로 정리
results_df = pd.DataFrame([train_metrics, valid_metrics, test_metrics])
results_df = results_df.set_index('Set')

print(&#34;=== Train/Valid/Test 셋 성능 비교 ===&#34;)
print(results_df.round(4))
=== Train/Valid/Test 셋 성능 비교 ===
           R²       MSE    RMSE   MAPE
Set                                   
Train  1.0000    0.0000  0.0000 0.0000
Valid  0.2095 4330.7978 65.8088 0.3744
Test  -0.2659 6706.9101 81.8957 0.5430
# Metrics
# 과적합 분석
print(f&#34;\n=== 과적합 분석 ===&#34;)
train_valid_r2_diff = train_metrics['R²'] - valid_metrics['R²']
valid_test_r2_diff = valid_metrics['R²'] - test_metrics['R²']

print(f&#34;Train-Valid R² 차이: {train_valid_r2_diff:.4f}&#34;)
print(f&#34;Valid-Test R² 차이: {valid_test_r2_diff:.4f}&#34;)

=== 과적합 분석 ===
Train-Valid R² 차이: 0.7905
Valid-Test R² 차이: 0.4754



임계값 0.1"><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="https://yshghid.github.io/docs/study/ai/ai31/"><meta property="og:site_name" content=" "><meta property="og:title" content="ML #1"><meta property="og:description" content="ML #1 # #2025-09-10
1 # # !pip install numpy # !pip install pandas # !pip install seaborn # !pip install matplotlib # !pip install -U scikit-learn # !pip install xgboost # !pip install lightgbm import warnings import numpy as np import pandas as pd import seaborn as sns import matplotlib.pyplot as plt from sklearn.datasets import load_diabetes from sklearn.model_selection import train_test_split from sklearn.metrics import ( r2_score, mean_squared_error, root_mean_squared_error, mean_absolute_percentage_error, ) warnings.filterwarnings(&#34;ignore&#34;) pd.set_option(&#34;display.max_columns&#34;, 100) pd.set_option(&#34;float_format&#34;, &#34;{:.4f}&#34;.format) sns.set_style(&#34;whitegrid&#34;) RANDOM_STATE = 42 # 1. Data Definition _data = load_diabetes() print(_data.DESCR) .. _diabetes_dataset: Diabetes dataset ---------------- Ten baseline variables, age, sex, body mass index, average blood pressure, and six blood serum measurements were obtained for each of n = 442 diabetes patients, as well as the response of interest, a quantitative measure of disease progression one year after baseline. **Data Set Characteristics:** :Number of Instances: 442 :Number of Attributes: First 10 columns are numeric predictive values :Target: Column 11 is a quantitative measure of disease progression one year after baseline :Attribute Information: - age age in years - sex - bmi body mass index - bp average blood pressure - s1 tc, total serum cholesterol - s2 ldl, low-density lipoproteins - s3 hdl, high-density lipoproteins - s4 tch, total cholesterol / HDL - s5 ltg, possibly log of serum triglycerides level - s6 glu, blood sugar level Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times the square root of `n_samples` (i.e. the sum of squares of each column totals 1). Source URL: https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html For more information see: Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) &#34;Least Angle Regression,&#34; Annals of Statistics (with discussion), 407-499. (https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf) data = _data[&#34;data&#34;] feature_names = _data[&#34;feature_names&#34;] df = pd.DataFrame(data, columns=feature_names) df[&#34;target&#34;] = _data[&#34;target&#34;] df.head() # 2. EDA # Correlation plt.figure(figsize=(10, 8)) sns.heatmap( data=df.drop(&#34;target&#34;, axis=1).corr(), annot=True, cmap=&#34;coolwarm&#34;, ) plt.show() # 4. Machine Learning Regression # Dataset Definition X = df.drop(&#34;target&#34;, axis=1) y = df[&#34;target&#34;] # 먼저 train+valid와 test로 분할 (80:20) X_temp, X_test, y_temp, y_test = train_test_split( X, y, test_size=0.2, random_state=RANDOM_STATE ) # train+valid를 다시 train과 valid로 분할 (75:25) X_train, X_valid, y_train, y_valid = train_test_split( X_temp, y_temp, test_size=0.25, random_state=RANDOM_STATE ) print(f&#34;데이터 분할 결과:&#34;) print(f&#34;Train: {len(X_train)} ({len(X_train)/len(X)*100:.1f}%)&#34;) print(f&#34;Valid: {len(X_valid)} ({len(X_valid)/len(X)*100:.1f}%)&#34;) print(f&#34;Test: {len(X_test)} ({len(X_test)/len(X)*100:.1f}%)&#34;) 데이터 분할 결과: Train: 264 (59.7%) Valid: 89 (20.1%) Test: 89 (20.1%) # Model (Vanila) from sklearn.tree import DecisionTreeRegressor model = DecisionTreeRegressor(random_state=RANDOM_STATE) model.fit(X_train, y_train) model.score(X_train, y_train) print(model.intercept_, model.coef_) 1.0 # Feature Importance model.feature_importances_ feature_names _feature_importances = pd.Series( model.feature_importances_, index=feature_names, ) _feature_importances array([0.08981708, 0.00592253, 0.43861624, 0.08517564, 0.04463861, 0.04418316, 0.05650334, 0.05949104, 0.13289137, 0.04276099]) ['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6'] age 0.0898 sex 0.0059 bmi 0.4386 bp 0.0852 s1 0.0446 s2 0.0442 s3 0.0565 s4 0.0595 s5 0.1329 s6 0.0428 dtype: float64 _feature_importances.nlargest().plot(kind=&#34;barh&#34;) # Prediction # 각 셋에 대한 예측 y_train_pred = model.predict(X_train) y_valid_pred = model.predict(X_valid) y_test_pred = model.predict(X_test) # 각 셋의 성능 평가 def calculate_metrics(y_true, y_pred, set_name): r2 = r2_score(y_true, y_pred) mse = mean_squared_error(y_true, y_pred) rmse = root_mean_squared_error(y_true, y_pred) mape = mean_absolute_percentage_error(y_true, y_pred) return { 'Set': set_name, 'R²': r2, 'MSE': mse, 'RMSE': rmse, 'MAPE': mape } # 모든 셋의 성능 계산 train_metrics = calculate_metrics(y_train, y_train_pred, 'Train') valid_metrics = calculate_metrics(y_valid, y_valid_pred, 'Valid') test_metrics = calculate_metrics(y_test, y_test_pred, 'Test') # 결과를 DataFrame으로 정리 results_df = pd.DataFrame([train_metrics, valid_metrics, test_metrics]) results_df = results_df.set_index('Set') print(&#34;=== Train/Valid/Test 셋 성능 비교 ===&#34;) print(results_df.round(4)) === Train/Valid/Test 셋 성능 비교 === R² MSE RMSE MAPE Set Train 1.0000 0.0000 0.0000 0.0000 Valid 0.2095 4330.7978 65.8088 0.3744 Test -0.2659 6706.9101 81.8957 0.5430 # Metrics # 과적합 분석 print(f&#34;\n=== 과적합 분석 ===&#34;) train_valid_r2_diff = train_metrics['R²'] - valid_metrics['R²'] valid_test_r2_diff = valid_metrics['R²'] - test_metrics['R²'] print(f&#34;Train-Valid R² 차이: {train_valid_r2_diff:.4f}&#34;) print(f&#34;Valid-Test R² 차이: {valid_test_r2_diff:.4f}&#34;) === 과적합 분석 === Train-Valid R² 차이: 0.7905 Valid-Test R² 차이: 0.4754 임계값 0.1"><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="docs"><meta property="article:published_time" content="2025-09-10T00:00:00+00:00"><meta property="article:modified_time" content="2025-09-10T00:00:00+00:00"><meta property="article:tag" content="2025-09"><title>ML #1 |</title><link rel=icon href=/favicon.png><link rel=manifest href=/manifest.json><link rel=canonical href=https://yshghid.github.io/docs/study/ai/ai31/><link rel=stylesheet href=/book.min.30a7836b6a89342da3b88e7afd1036166aeced16c8de12df060ded2031837886.css integrity="sha256-MKeDa2qJNC2juI56/RA2Fmrs7RbI3hLfBg3tIDGDeIY=" crossorigin=anonymous><script defer src=/fuse.min.js></script><script defer src=/en.search.min.7f0ce81f65e879907ead2b116baca369013ed17d14f750dd6a5a339d31f715f7.js integrity="sha256-fwzoH2XoeZB+rSsRa6yjaQE+0X0U91DdaloznTH3Ffc=" crossorigin=anonymous></script></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><img src=/logo.png alt=Logo class=book-icon><span></span></a></h2><div class="book-search hidden"><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><script>document.querySelector(".book-search").classList.remove("hidden")</script><ul><li class=book-section-flat><span>기록</span><ul><li><a href=/docs/hobby/daily/>일상</a><ul></ul></li><li><a href=/docs/hobby/book/>글</a><ul></ul></li></ul></li><li class=book-section-flat><span>공부</span><ul><li><a href=/docs/study/bioinformatics/>Bioinformatics</a><ul></ul></li><li><a href=/docs/study/ai/>AI</a><ul></ul></li><li><a href=/docs/study/sw/>SW</a><ul></ul></li><li><a href=/docs/study/algorithm/>알고리즘</a><ul></ul></li><li><a href=/docs/study/career/>취업</a><ul></ul></li></ul></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu></label><h3>ML #1</h3><label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><ul><li><a href=#1>1</a></li><li></li><li><a href=#2-여러-알고리즘-결과-확인>2. 여러 알고리즘 결과 확인</a></li></ul></li></ul></nav></aside></header><article class="markdown book-article"><h1 id=ml-1>ML #1
<a class=anchor href=#ml-1>#</a></h1><p>#2025-09-10</p><hr><h3 id=1>1
<a class=anchor href=#1>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># !pip install numpy</span>
</span></span><span style=display:flex><span><span style=color:#75715e># !pip install pandas</span>
</span></span><span style=display:flex><span><span style=color:#75715e># !pip install seaborn</span>
</span></span><span style=display:flex><span><span style=color:#75715e># !pip install matplotlib</span>
</span></span><span style=display:flex><span><span style=color:#75715e># !pip install -U scikit-learn</span>
</span></span><span style=display:flex><span><span style=color:#75715e># !pip install xgboost</span>
</span></span><span style=display:flex><span><span style=color:#75715e># !pip install lightgbm</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> warnings
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> pandas <span style=color:#66d9ef>as</span> pd
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> seaborn <span style=color:#66d9ef>as</span> sns
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> matplotlib.pyplot <span style=color:#66d9ef>as</span> plt
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.datasets <span style=color:#f92672>import</span> load_diabetes
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.model_selection <span style=color:#f92672>import</span> train_test_split
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.metrics <span style=color:#f92672>import</span> (
</span></span><span style=display:flex><span>    r2_score,
</span></span><span style=display:flex><span>    mean_squared_error,
</span></span><span style=display:flex><span>    root_mean_squared_error,
</span></span><span style=display:flex><span>    mean_absolute_percentage_error,
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>warnings<span style=color:#f92672>.</span>filterwarnings(<span style=color:#e6db74>&#34;ignore&#34;</span>)
</span></span><span style=display:flex><span>pd<span style=color:#f92672>.</span>set_option(<span style=color:#e6db74>&#34;display.max_columns&#34;</span>, <span style=color:#ae81ff>100</span>)
</span></span><span style=display:flex><span>pd<span style=color:#f92672>.</span>set_option(<span style=color:#e6db74>&#34;float_format&#34;</span>, <span style=color:#e6db74>&#34;</span><span style=color:#e6db74>{:.4f}</span><span style=color:#e6db74>&#34;</span><span style=color:#f92672>.</span>format)
</span></span><span style=display:flex><span>sns<span style=color:#f92672>.</span>set_style(<span style=color:#e6db74>&#34;whitegrid&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>RANDOM_STATE <span style=color:#f92672>=</span> <span style=color:#ae81ff>42</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 1. Data Definition</span>
</span></span><span style=display:flex><span>_data <span style=color:#f92672>=</span> load_diabetes()
</span></span><span style=display:flex><span>print(_data<span style=color:#f92672>.</span>DESCR)
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-plain data-lang=plain><span style=display:flex><span>.. _diabetes_dataset:
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Diabetes dataset
</span></span><span style=display:flex><span>----------------
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Ten baseline variables, age, sex, body mass index, average blood
</span></span><span style=display:flex><span>pressure, and six blood serum measurements were obtained for each of n =
</span></span><span style=display:flex><span>442 diabetes patients, as well as the response of interest, a
</span></span><span style=display:flex><span>quantitative measure of disease progression one year after baseline.
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>**Data Set Characteristics:**
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>:Number of Instances: 442
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>:Number of Attributes: First 10 columns are numeric predictive values
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>:Target: Column 11 is a quantitative measure of disease progression one year after baseline
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>:Attribute Information:
</span></span><span style=display:flex><span>    - age     age in years
</span></span><span style=display:flex><span>    - sex
</span></span><span style=display:flex><span>    - bmi     body mass index
</span></span><span style=display:flex><span>    - bp      average blood pressure
</span></span><span style=display:flex><span>    - s1      tc, total serum cholesterol
</span></span><span style=display:flex><span>    - s2      ldl, low-density lipoproteins
</span></span><span style=display:flex><span>    - s3      hdl, high-density lipoproteins
</span></span><span style=display:flex><span>    - s4      tch, total cholesterol / HDL
</span></span><span style=display:flex><span>    - s5      ltg, possibly log of serum triglycerides level
</span></span><span style=display:flex><span>    - s6      glu, blood sugar level
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times the square root of `n_samples` (i.e. the sum of squares of each column totals 1).
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Source URL:
</span></span><span style=display:flex><span>https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>For more information see:
</span></span><span style=display:flex><span>Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) &#34;Least Angle Regression,&#34; Annals of Statistics (with discussion), 407-499.
</span></span><span style=display:flex><span>(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>data <span style=color:#f92672>=</span> _data[<span style=color:#e6db74>&#34;data&#34;</span>]
</span></span><span style=display:flex><span>feature_names <span style=color:#f92672>=</span> _data[<span style=color:#e6db74>&#34;feature_names&#34;</span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>df <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>DataFrame(data, columns<span style=color:#f92672>=</span>feature_names)
</span></span><span style=display:flex><span>df[<span style=color:#e6db74>&#34;target&#34;</span>] <span style=color:#f92672>=</span> _data[<span style=color:#e6db74>&#34;target&#34;</span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>df<span style=color:#f92672>.</span>head()
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 2. EDA</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Correlation</span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>figure(figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>10</span>, <span style=color:#ae81ff>8</span>))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>sns<span style=color:#f92672>.</span>heatmap(
</span></span><span style=display:flex><span>    data<span style=color:#f92672>=</span>df<span style=color:#f92672>.</span>drop(<span style=color:#e6db74>&#34;target&#34;</span>, axis<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)<span style=color:#f92672>.</span>corr(),
</span></span><span style=display:flex><span>    annot<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>,
</span></span><span style=display:flex><span>    cmap<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;coolwarm&#34;</span>,
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>show()
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 4. Machine Learning Regression</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Dataset Definition</span>
</span></span><span style=display:flex><span>X <span style=color:#f92672>=</span> df<span style=color:#f92672>.</span>drop(<span style=color:#e6db74>&#34;target&#34;</span>, axis<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>y <span style=color:#f92672>=</span> df[<span style=color:#e6db74>&#34;target&#34;</span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 먼저 train+valid와 test로 분할 (80:20)</span>
</span></span><span style=display:flex><span>X_temp, X_test, y_temp, y_test <span style=color:#f92672>=</span> train_test_split(
</span></span><span style=display:flex><span>    X, y, test_size<span style=color:#f92672>=</span><span style=color:#ae81ff>0.2</span>, random_state<span style=color:#f92672>=</span>RANDOM_STATE
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># train+valid를 다시 train과 valid로 분할 (75:25)</span>
</span></span><span style=display:flex><span>X_train, X_valid, y_train, y_valid <span style=color:#f92672>=</span> train_test_split(
</span></span><span style=display:flex><span>    X_temp, y_temp, test_size<span style=color:#f92672>=</span><span style=color:#ae81ff>0.25</span>, random_state<span style=color:#f92672>=</span>RANDOM_STATE
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;데이터 분할 결과:&#34;</span>)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Train: </span><span style=color:#e6db74>{</span>len(X_train)<span style=color:#e6db74>}</span><span style=color:#e6db74> (</span><span style=color:#e6db74>{</span>len(X_train)<span style=color:#f92672>/</span>len(X)<span style=color:#f92672>*</span><span style=color:#ae81ff>100</span><span style=color:#e6db74>:</span><span style=color:#e6db74>.1f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>%)&#34;</span>)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Valid: </span><span style=color:#e6db74>{</span>len(X_valid)<span style=color:#e6db74>}</span><span style=color:#e6db74> (</span><span style=color:#e6db74>{</span>len(X_valid)<span style=color:#f92672>/</span>len(X)<span style=color:#f92672>*</span><span style=color:#ae81ff>100</span><span style=color:#e6db74>:</span><span style=color:#e6db74>.1f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>%)&#34;</span>)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Test: </span><span style=color:#e6db74>{</span>len(X_test)<span style=color:#e6db74>}</span><span style=color:#e6db74> (</span><span style=color:#e6db74>{</span>len(X_test)<span style=color:#f92672>/</span>len(X)<span style=color:#f92672>*</span><span style=color:#ae81ff>100</span><span style=color:#e6db74>:</span><span style=color:#e6db74>.1f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>%)&#34;</span>)
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-plain data-lang=plain><span style=display:flex><span>데이터 분할 결과:
</span></span><span style=display:flex><span>Train: 264 (59.7%)
</span></span><span style=display:flex><span>Valid: 89 (20.1%)
</span></span><span style=display:flex><span>Test: 89 (20.1%)
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># Model (Vanila)</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.tree <span style=color:#f92672>import</span> DecisionTreeRegressor
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> DecisionTreeRegressor(random_state<span style=color:#f92672>=</span>RANDOM_STATE)
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>fit(X_train, y_train)
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>score(X_train, y_train)
</span></span><span style=display:flex><span>print(model<span style=color:#f92672>.</span>intercept_, model<span style=color:#f92672>.</span>coef_)
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-plain data-lang=plain><span style=display:flex><span>1.0
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># Feature Importance</span>
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>feature_importances_
</span></span><span style=display:flex><span>feature_names
</span></span><span style=display:flex><span>_feature_importances <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>Series(
</span></span><span style=display:flex><span>    model<span style=color:#f92672>.</span>feature_importances_,
</span></span><span style=display:flex><span>    index<span style=color:#f92672>=</span>feature_names,
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>_feature_importances
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-plain data-lang=plain><span style=display:flex><span>array([0.08981708, 0.00592253, 0.43861624, 0.08517564, 0.04463861,
</span></span><span style=display:flex><span>       0.04418316, 0.05650334, 0.05949104, 0.13289137, 0.04276099])
</span></span><span style=display:flex><span>[&#39;age&#39;, &#39;sex&#39;, &#39;bmi&#39;, &#39;bp&#39;, &#39;s1&#39;, &#39;s2&#39;, &#39;s3&#39;, &#39;s4&#39;, &#39;s5&#39;, &#39;s6&#39;]
</span></span><span style=display:flex><span>age   0.0898
</span></span><span style=display:flex><span>sex   0.0059
</span></span><span style=display:flex><span>bmi   0.4386
</span></span><span style=display:flex><span>bp    0.0852
</span></span><span style=display:flex><span>s1    0.0446
</span></span><span style=display:flex><span>s2    0.0442
</span></span><span style=display:flex><span>s3    0.0565
</span></span><span style=display:flex><span>s4    0.0595
</span></span><span style=display:flex><span>s5    0.1329
</span></span><span style=display:flex><span>s6    0.0428
</span></span><span style=display:flex><span>dtype: float64
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>_feature_importances<span style=color:#f92672>.</span>nlargest()<span style=color:#f92672>.</span>plot(kind<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;barh&#34;</span>)
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># Prediction</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 각 셋에 대한 예측</span>
</span></span><span style=display:flex><span>y_train_pred <span style=color:#f92672>=</span> model<span style=color:#f92672>.</span>predict(X_train)
</span></span><span style=display:flex><span>y_valid_pred <span style=color:#f92672>=</span> model<span style=color:#f92672>.</span>predict(X_valid)
</span></span><span style=display:flex><span>y_test_pred <span style=color:#f92672>=</span> model<span style=color:#f92672>.</span>predict(X_test)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 각 셋의 성능 평가</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>calculate_metrics</span>(y_true, y_pred, set_name):
</span></span><span style=display:flex><span>    r2 <span style=color:#f92672>=</span> r2_score(y_true, y_pred)
</span></span><span style=display:flex><span>    mse <span style=color:#f92672>=</span> mean_squared_error(y_true, y_pred)
</span></span><span style=display:flex><span>    rmse <span style=color:#f92672>=</span> root_mean_squared_error(y_true, y_pred)
</span></span><span style=display:flex><span>    mape <span style=color:#f92672>=</span> mean_absolute_percentage_error(y_true, y_pred)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> {
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#39;Set&#39;</span>: set_name,
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#39;R²&#39;</span>: r2,
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#39;MSE&#39;</span>: mse,
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#39;RMSE&#39;</span>: rmse,
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#39;MAPE&#39;</span>: mape
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 모든 셋의 성능 계산</span>
</span></span><span style=display:flex><span>train_metrics <span style=color:#f92672>=</span> calculate_metrics(y_train, y_train_pred, <span style=color:#e6db74>&#39;Train&#39;</span>)
</span></span><span style=display:flex><span>valid_metrics <span style=color:#f92672>=</span> calculate_metrics(y_valid, y_valid_pred, <span style=color:#e6db74>&#39;Valid&#39;</span>)
</span></span><span style=display:flex><span>test_metrics <span style=color:#f92672>=</span> calculate_metrics(y_test, y_test_pred, <span style=color:#e6db74>&#39;Test&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 결과를 DataFrame으로 정리</span>
</span></span><span style=display:flex><span>results_df <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>DataFrame([train_metrics, valid_metrics, test_metrics])
</span></span><span style=display:flex><span>results_df <span style=color:#f92672>=</span> results_df<span style=color:#f92672>.</span>set_index(<span style=color:#e6db74>&#39;Set&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#34;=== Train/Valid/Test 셋 성능 비교 ===&#34;</span>)
</span></span><span style=display:flex><span>print(results_df<span style=color:#f92672>.</span>round(<span style=color:#ae81ff>4</span>))
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-plain data-lang=plain><span style=display:flex><span>=== Train/Valid/Test 셋 성능 비교 ===
</span></span><span style=display:flex><span>           R²       MSE    RMSE   MAPE
</span></span><span style=display:flex><span>Set                                   
</span></span><span style=display:flex><span>Train  1.0000    0.0000  0.0000 0.0000
</span></span><span style=display:flex><span>Valid  0.2095 4330.7978 65.8088 0.3744
</span></span><span style=display:flex><span>Test  -0.2659 6706.9101 81.8957 0.5430
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># Metrics</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 과적합 분석</span>
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>=== 과적합 분석 ===&#34;</span>)
</span></span><span style=display:flex><span>train_valid_r2_diff <span style=color:#f92672>=</span> train_metrics[<span style=color:#e6db74>&#39;R²&#39;</span>] <span style=color:#f92672>-</span> valid_metrics[<span style=color:#e6db74>&#39;R²&#39;</span>]
</span></span><span style=display:flex><span>valid_test_r2_diff <span style=color:#f92672>=</span> valid_metrics[<span style=color:#e6db74>&#39;R²&#39;</span>] <span style=color:#f92672>-</span> test_metrics[<span style=color:#e6db74>&#39;R²&#39;</span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Train-Valid R² 차이: </span><span style=color:#e6db74>{</span>train_valid_r2_diff<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Valid-Test R² 차이: </span><span style=color:#e6db74>{</span>valid_test_r2_diff<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-plain data-lang=plain><span style=display:flex><span>
</span></span><span style=display:flex><span>=== 과적합 분석 ===
</span></span><span style=display:flex><span>Train-Valid R² 차이: 0.7905
</span></span><span style=display:flex><span>Valid-Test R² 차이: 0.4754
</span></span></code></pre></div><blockquote><ul><li><p>임계값 0.1</p><ul><li>아래 코드에서 0.1로 비교하는 것은 고정 규칙이 아니라 경험적 가이드 입니다</li><li>모델/데이터별 차이가 있어 동일 기준으로 일관되게 적용할 수 없습니다</li><li>해당 파일에서는 우선적으로 경험적 가이드를 적용하여 진행합니다</li></ul></li><li><p>객관적 판단을 위해서는 &ldquo;데이터 기반 임계값&rdquo; 통한 비교 필요 => (모델 최적화 과정에서 확인)</p><ul><li>k-fold에서 val R^2의 표준편차 σ_val을 구해</li><li>과적합 : (train_mean - val_mean) > max(0.05, 2*σ_val)</li><li>일반화 문제 : |test - val_mean| > 2*σ_val</li></ul></li></ul></blockquote><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>if</span> train_valid_r2_diff <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>0.1</span>:
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#34;⚠️  과적합 가능성: 훈련 데이터와 검증 데이터 간 성능 차이가 큽니다.&#34;</span>)
</span></span><span style=display:flex><span><span style=color:#66d9ef>else</span>:
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#34;✅ 과적합 위험 낮음: 훈련 데이터와 검증 데이터 간 성능이 유사합니다.&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>if</span> valid_test_r2_diff <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>0.1</span>:
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#34;⚠️  일반화 문제: 검증 데이터와 테스트 데이터 간 성능 차이가 큽니다.&#34;</span>)
</span></span><span style=display:flex><span><span style=color:#66d9ef>else</span>:
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#34;✅ 일반화 성능 양호: 검증 데이터와 테스트 데이터 간 성능이 유사합니다.&#34;</span>)
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-plain data-lang=plain><span style=display:flex><span>⚠️  과적합 가능성: 훈련 데이터와 검증 데이터 간 성능 차이가 큽니다.
</span></span><span style=display:flex><span>⚠️  일반화 문제: 검증 데이터와 테스트 데이터 간 성능 차이가 큽니다.
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 모델 설명력 해석</span>
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>=== 모델 설명력 해석 ===&#34;</span>)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;훈련 데이터 R²: </span><span style=color:#e6db74>{</span>train_metrics[<span style=color:#e6db74>&#39;R²&#39;</span>]<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74> (</span><span style=color:#e6db74>{</span>train_metrics[<span style=color:#e6db74>&#39;R²&#39;</span>]<span style=color:#f92672>*</span><span style=color:#ae81ff>100</span><span style=color:#e6db74>:</span><span style=color:#e6db74>.2f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>%)&#34;</span>)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;검증 데이터 R²: </span><span style=color:#e6db74>{</span>valid_metrics[<span style=color:#e6db74>&#39;R²&#39;</span>]<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74> (</span><span style=color:#e6db74>{</span>valid_metrics[<span style=color:#e6db74>&#39;R²&#39;</span>]<span style=color:#f92672>*</span><span style=color:#ae81ff>100</span><span style=color:#e6db74>:</span><span style=color:#e6db74>.2f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>%)&#34;</span>)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;테스트 데이터 R²: </span><span style=color:#e6db74>{</span>test_metrics[<span style=color:#e6db74>&#39;R²&#39;</span>]<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74> (</span><span style=color:#e6db74>{</span>test_metrics[<span style=color:#e6db74>&#39;R²&#39;</span>]<span style=color:#f92672>*</span><span style=color:#ae81ff>100</span><span style=color:#e6db74>:</span><span style=color:#e6db74>.2f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>%)&#34;</span>)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;→ 최종 테스트에서 모델이 </span><span style=color:#e6db74>{</span>test_metrics[<span style=color:#e6db74>&#39;R²&#39;</span>]<span style=color:#f92672>*</span><span style=color:#ae81ff>100</span><span style=color:#e6db74>:</span><span style=color:#e6db74>.1f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>%의 분산을 설명합니다.&#34;</span>)
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-plain data-lang=plain><span style=display:flex><span>=== 모델 설명력 해석 ===
</span></span><span style=display:flex><span>훈련 데이터 R²: 1.0000 (100.00%)
</span></span><span style=display:flex><span>검증 데이터 R²: 0.2095 (20.95%)
</span></span><span style=display:flex><span>테스트 데이터 R²: -0.2659 (-26.59%)
</span></span><span style=display:flex><span>→ 최종 테스트에서 모델이 -26.6%의 분산을 설명합니다.
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 오차 정확도 해석</span>
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>=== 오차 정확도 해석 ===&#34;</span>)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Train RMSE: </span><span style=color:#e6db74>{</span>train_metrics[<span style=color:#e6db74>&#39;RMSE&#39;</span>]<span style=color:#e6db74>:</span><span style=color:#e6db74>.2f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Valid RMSE: </span><span style=color:#e6db74>{</span>valid_metrics[<span style=color:#e6db74>&#39;RMSE&#39;</span>]<span style=color:#e6db74>:</span><span style=color:#e6db74>.2f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Test RMSE: </span><span style=color:#e6db74>{</span>test_metrics[<span style=color:#e6db74>&#39;RMSE&#39;</span>]<span style=color:#e6db74>:</span><span style=color:#e6db74>.2f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Test MAPE: </span><span style=color:#e6db74>{</span>test_metrics[<span style=color:#e6db74>&#39;MAPE&#39;</span>]<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74> (</span><span style=color:#e6db74>{</span>test_metrics[<span style=color:#e6db74>&#39;MAPE&#39;</span>]<span style=color:#f92672>*</span><span style=color:#ae81ff>100</span><span style=color:#e6db74>:</span><span style=color:#e6db74>.2f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>%)&#34;</span>)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;→ 최종 테스트에서 예측값이 실제값에 대해 평균적으로 ±</span><span style=color:#e6db74>{</span>test_metrics[<span style=color:#e6db74>&#39;MAPE&#39;</span>]<span style=color:#f92672>*</span><span style=color:#ae81ff>100</span><span style=color:#e6db74>:</span><span style=color:#e6db74>.1f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>% 정도의 오차를 보입니다.&#34;</span>)
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-plain data-lang=plain><span style=display:flex><span>=== 오차 정확도 해석 ===
</span></span><span style=display:flex><span>Train RMSE: 0.00
</span></span><span style=display:flex><span>Valid RMSE: 65.81
</span></span><span style=display:flex><span>Test RMSE: 81.90
</span></span><span style=display:flex><span>Test MAPE: 0.5430 (54.30%)
</span></span><span style=display:flex><span>→ 최종 테스트에서 예측값이 실제값에 대해 평균적으로 ±54.3% 정도의 오차를 보입니다.
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 시각화: 실제값 vs 예측값 비교</span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>figure(figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>15</span>, <span style=color:#ae81ff>5</span>))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 훈련 데이터</span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>subplot(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>scatter(y_train, y_train_pred, alpha<span style=color:#f92672>=</span><span style=color:#ae81ff>0.6</span>, color<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;blue&#34;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>plot([y_train<span style=color:#f92672>.</span>min(), y_train<span style=color:#f92672>.</span>max()], [y_train<span style=color:#f92672>.</span>min(), y_train<span style=color:#f92672>.</span>max()], <span style=color:#e6db74>&#34;r--&#34;</span>, lw<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>xlabel(<span style=color:#e6db74>&#34;Actual&#34;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>ylabel(<span style=color:#e6db74>&#34;Predicted&#34;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>title(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Train (R² = </span><span style=color:#e6db74>{</span>train_metrics[<span style=color:#e6db74>&#39;R²&#39;</span>]<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>)&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 검증 데이터</span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>subplot(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>2</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>scatter(y_valid, y_valid_pred, alpha<span style=color:#f92672>=</span><span style=color:#ae81ff>0.6</span>, color<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;green&#34;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>plot([y_valid<span style=color:#f92672>.</span>min(), y_valid<span style=color:#f92672>.</span>max()], [y_valid<span style=color:#f92672>.</span>min(), y_valid<span style=color:#f92672>.</span>max()], <span style=color:#e6db74>&#34;r--&#34;</span>, lw<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>xlabel(<span style=color:#e6db74>&#34;Actual&#34;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>ylabel(<span style=color:#e6db74>&#34;Predicted&#34;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>title(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Valid (R² = </span><span style=color:#e6db74>{</span>valid_metrics[<span style=color:#e6db74>&#39;R²&#39;</span>]<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>)&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 테스트 데이터</span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>subplot(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>scatter(y_test, y_test_pred, alpha<span style=color:#f92672>=</span><span style=color:#ae81ff>0.6</span>, color<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;red&#34;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>plot([y_test<span style=color:#f92672>.</span>min(), y_test<span style=color:#f92672>.</span>max()], [y_test<span style=color:#f92672>.</span>min(), y_test<span style=color:#f92672>.</span>max()], <span style=color:#e6db74>&#34;r--&#34;</span>, lw<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>xlabel(<span style=color:#e6db74>&#34;Actual&#34;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>ylabel(<span style=color:#e6db74>&#34;Predicted&#34;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>title(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Test (R² = </span><span style=color:#e6db74>{</span>test_metrics[<span style=color:#e6db74>&#39;R²&#39;</span>]<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>)&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>tight_layout()
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>show()
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 성능 지표 비교 차트</span>
</span></span><span style=display:flex><span>metrics_to_plot <span style=color:#f92672>=</span> [<span style=color:#e6db74>&#39;R²&#39;</span>, <span style=color:#e6db74>&#39;RMSE&#39;</span>, <span style=color:#e6db74>&#39;MAPE&#39;</span>]
</span></span><span style=display:flex><span>fig, axes <span style=color:#f92672>=</span> plt<span style=color:#f92672>.</span>subplots(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>3</span>, figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>15</span>, <span style=color:#ae81ff>5</span>))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> i, metric <span style=color:#f92672>in</span> enumerate(metrics_to_plot):
</span></span><span style=display:flex><span>    values <span style=color:#f92672>=</span> [train_metrics[metric], valid_metrics[metric], test_metrics[metric]]
</span></span><span style=display:flex><span>    sets <span style=color:#f92672>=</span> [<span style=color:#e6db74>&#39;Train&#39;</span>, <span style=color:#e6db74>&#39;Valid&#39;</span>, <span style=color:#e6db74>&#39;Test&#39;</span>]
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    bars <span style=color:#f92672>=</span> axes[i]<span style=color:#f92672>.</span>bar(sets, values, color<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#39;blue&#39;</span>, <span style=color:#e6db74>&#39;green&#39;</span>, <span style=color:#e6db74>&#39;red&#39;</span>], alpha<span style=color:#f92672>=</span><span style=color:#ae81ff>0.7</span>)
</span></span><span style=display:flex><span>    axes[i]<span style=color:#f92672>.</span>set_title(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#39;</span><span style=color:#e6db74>{</span>metric<span style=color:#e6db74>}</span><span style=color:#e6db74>&#39;</span>)
</span></span><span style=display:flex><span>    axes[i]<span style=color:#f92672>.</span>set_ylabel(metric)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># 값 표시</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> bar, value <span style=color:#f92672>in</span> zip(bars, values):
</span></span><span style=display:flex><span>        height <span style=color:#f92672>=</span> bar<span style=color:#f92672>.</span>get_height()
</span></span><span style=display:flex><span>        axes[i]<span style=color:#f92672>.</span>text(bar<span style=color:#f92672>.</span>get_x() <span style=color:#f92672>+</span> bar<span style=color:#f92672>.</span>get_width()<span style=color:#f92672>/</span><span style=color:#ae81ff>2.</span>, height,
</span></span><span style=display:flex><span>                    <span style=color:#e6db74>f</span><span style=color:#e6db74>&#39;</span><span style=color:#e6db74>{</span>value<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>&#39;</span>, ha<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;center&#39;</span>, va<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;bottom&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>tight_layout()
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>show()
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># actual vs predicted</span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>figure(figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>10</span>, <span style=color:#ae81ff>5</span>))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>plot(y_test<span style=color:#f92672>.</span>values, label<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;Actual&#34;</span>, marker<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;o&#34;</span>, color<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;blue&#34;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>plot(y_test_pred, label<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;Predicted&#34;</span>, marker<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;x&#34;</span>, color<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;red&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>title(<span style=color:#e6db74>&#34;Actual vs Predicted Values&#34;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>ylabel(<span style=color:#e6db74>&#34;Disease Progression&#34;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>legend()
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>show()
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># Tree Structure</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.tree <span style=color:#f92672>import</span> plot_tree
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>figure(figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>12</span>, <span style=color:#ae81ff>12</span>))
</span></span><span style=display:flex><span>plot_tree(model, filled<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>show()
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>plt<span style=color:#f92672>.</span>figure(figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>10</span>, <span style=color:#ae81ff>7</span>))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>plot_tree(
</span></span><span style=display:flex><span>    model,
</span></span><span style=display:flex><span>    filled<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>,
</span></span><span style=display:flex><span>    max_depth<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>,
</span></span><span style=display:flex><span>    feature_names<span style=color:#f92672>=</span>feature_names,
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>show()
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># Retraining (feat.Prunning)</span>
</span></span><span style=display:flex><span>models <span style=color:#f92672>=</span> {
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;DecisionTree&#34;</span>: DecisionTreeRegressor(
</span></span><span style=display:flex><span>        max_depth<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>,          <span style=color:#75715e># 트리의 최대 깊이</span>
</span></span><span style=display:flex><span>        min_samples_split<span style=color:#f92672>=</span><span style=color:#ae81ff>5</span>,  <span style=color:#75715e># 노트 분할 시, 최소한 5개의 샘플이 있어야 함</span>
</span></span><span style=display:flex><span>        min_samples_leaf<span style=color:#f92672>=</span><span style=color:#ae81ff>5</span>,   <span style=color:#75715e># 리프 노드에는 최소한 5개의 샘플리 있어야 함</span>
</span></span><span style=display:flex><span>        random_state<span style=color:#f92672>=</span>RANDOM_STATE,
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>fit(X_train, y_train)
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>score(X_train, y_train)
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-plain data-lang=plain><span style=display:flex><span>1.0
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>plt<span style=color:#f92672>.</span>figure(figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>15</span>, <span style=color:#ae81ff>10</span>))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>plot_tree(
</span></span><span style=display:flex><span>    model,
</span></span><span style=display:flex><span>    filled<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>,
</span></span><span style=display:flex><span>    max_depth<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>,  <span style=color:#75715e># 시각화 위해 제한</span>
</span></span><span style=display:flex><span>    feature_names<span style=color:#f92672>=</span>feature_names,
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>show()
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># Feature Importance</span>
</span></span><span style=display:flex><span>_feature_importances <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>Series(
</span></span><span style=display:flex><span>    model<span style=color:#f92672>.</span>feature_importances_,
</span></span><span style=display:flex><span>    index<span style=color:#f92672>=</span>feature_names,
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>_feature_importances
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-plain data-lang=plain><span style=display:flex><span>age   0.0898
</span></span><span style=display:flex><span>sex   0.0059
</span></span><span style=display:flex><span>bmi   0.4386
</span></span><span style=display:flex><span>bp    0.0852
</span></span><span style=display:flex><span>s1    0.0446
</span></span><span style=display:flex><span>s2    0.0442
</span></span><span style=display:flex><span>s3    0.0565
</span></span><span style=display:flex><span>s4    0.0595
</span></span><span style=display:flex><span>s5    0.1329
</span></span><span style=display:flex><span>s6    0.0428
</span></span><span style=display:flex><span>dtype: float64
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>_feature_importances<span style=color:#f92672>.</span>nlargest()<span style=color:#f92672>.</span>plot(kind<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;barh&#34;</span>)
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># Prediction</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 각 셋에 대한 예측</span>
</span></span><span style=display:flex><span>y_train_pred <span style=color:#f92672>=</span> model<span style=color:#f92672>.</span>predict(X_train)
</span></span><span style=display:flex><span>y_valid_pred <span style=color:#f92672>=</span> model<span style=color:#f92672>.</span>predict(X_valid)
</span></span><span style=display:flex><span>y_test_pred <span style=color:#f92672>=</span> model<span style=color:#f92672>.</span>predict(X_test)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 모든 셋의 성능 계산</span>
</span></span><span style=display:flex><span>train_metrics <span style=color:#f92672>=</span> calculate_metrics(y_train, y_train_pred, <span style=color:#e6db74>&#39;Train&#39;</span>)
</span></span><span style=display:flex><span>valid_metrics <span style=color:#f92672>=</span> calculate_metrics(y_valid, y_valid_pred, <span style=color:#e6db74>&#39;Valid&#39;</span>)
</span></span><span style=display:flex><span>test_metrics <span style=color:#f92672>=</span> calculate_metrics(y_test, y_test_pred, <span style=color:#e6db74>&#39;Test&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 결과를 DataFrame으로 정리</span>
</span></span><span style=display:flex><span>results_df <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>DataFrame([train_metrics, valid_metrics, test_metrics])
</span></span><span style=display:flex><span>results_df <span style=color:#f92672>=</span> results_df<span style=color:#f92672>.</span>set_index(<span style=color:#e6db74>&#39;Set&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#34;=== Train/Valid/Test 셋 성능 비교 ===&#34;</span>)
</span></span><span style=display:flex><span>print(results_df<span style=color:#f92672>.</span>round(<span style=color:#ae81ff>4</span>))
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-plain data-lang=plain><span style=display:flex><span>=== Train/Valid/Test 셋 성능 비교 ===
</span></span><span style=display:flex><span>           R²       MSE    RMSE   MAPE
</span></span><span style=display:flex><span>Set                                   
</span></span><span style=display:flex><span>Train  1.0000    0.0000  0.0000 0.0000
</span></span><span style=display:flex><span>Valid  0.2095 4330.7978 65.8088 0.3744
</span></span><span style=display:flex><span>Test  -0.2659 6706.9101 81.8957 0.5430
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 과적합 분석</span>
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>=== 과적합 분석 ===&#34;</span>)
</span></span><span style=display:flex><span>train_valid_r2_diff <span style=color:#f92672>=</span> train_metrics[<span style=color:#e6db74>&#39;R²&#39;</span>] <span style=color:#f92672>-</span> valid_metrics[<span style=color:#e6db74>&#39;R²&#39;</span>]
</span></span><span style=display:flex><span>valid_test_r2_diff <span style=color:#f92672>=</span> valid_metrics[<span style=color:#e6db74>&#39;R²&#39;</span>] <span style=color:#f92672>-</span> test_metrics[<span style=color:#e6db74>&#39;R²&#39;</span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Train-Valid R² 차이: </span><span style=color:#e6db74>{</span>train_valid_r2_diff<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Valid-Test R² 차이: </span><span style=color:#e6db74>{</span>valid_test_r2_diff<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>if</span> train_valid_r2_diff <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>0.1</span>:
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#34;⚠️  과적합 가능성: 훈련 데이터와 검증 데이터 간 성능 차이가 큽니다.&#34;</span>)
</span></span><span style=display:flex><span><span style=color:#66d9ef>else</span>:
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#34;✅ 과적합 위험 낮음: 훈련 데이터와 검증 데이터 간 성능이 유사합니다.&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>if</span> valid_test_r2_diff <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>0.1</span>:
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#34;⚠️  일반화 문제: 검증 데이터와 테스트 데이터 간 성능 차이가 큽니다.&#34;</span>)
</span></span><span style=display:flex><span><span style=color:#66d9ef>else</span>:
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#34;✅ 일반화 성능 양호: 검증 데이터와 테스트 데이터 간 성능이 유사합니다.&#34;</span>)
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-plain data-lang=plain><span style=display:flex><span>=== 과적합 분석 ===
</span></span><span style=display:flex><span>Train-Valid R² 차이: 0.7905
</span></span><span style=display:flex><span>Valid-Test R² 차이: 0.4754
</span></span><span style=display:flex><span>⚠️  과적합 가능성: 훈련 데이터와 검증 데이터 간 성능 차이가 큽니다.
</span></span><span style=display:flex><span>⚠️  일반화 문제: 검증 데이터와 테스트 데이터 간 성능 차이가 큽니다.
</span></span></code></pre></div><h3><a class=anchor href=#>#</a></h3><h3 id=2-여러-알고리즘-결과-확인>2. 여러 알고리즘 결과 확인
<a class=anchor href=#2-%ec%97%ac%eb%9f%ac-%ec%95%8c%ea%b3%a0%eb%a6%ac%ec%a6%98-%ea%b2%b0%ea%b3%bc-%ed%99%95%ec%9d%b8>#</a></h3><blockquote><p>(대상) Decision Tree, randomForest, Lasso, Ridge, XGB, LGBM</p><ol><li>위 알고리즘 중 가장 최적의 예측 성능을 보이는 알고리즘 확인<ul><li>현재 단계에서는 cross validation은 고려하지 않음</li></ul></li><li>최적의 성능을 보이는 알고리즘의 feature importance 확인</li><li>최적의 모델에 대해서만 예측 성능 확인 (RMSE)</li></ol></blockquote><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>models <span style=color:#f92672>=</span> {
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;DecisionTree&#34;</span>: DecisionTreeRegressor(
</span></span><span style=display:flex><span>        max_depth<span style=color:#f92672>=</span><span style=color:#ae81ff>4</span>,              <span style=color:#75715e># 트리 최대 깊이 제한으로 과적합 방지</span>
</span></span><span style=display:flex><span>        min_samples_split<span style=color:#f92672>=</span><span style=color:#ae81ff>10</span>,     <span style=color:#75715e># 노드 분할 시 최소 10개 샘플 필요</span>
</span></span><span style=display:flex><span>        min_samples_leaf<span style=color:#f92672>=</span><span style=color:#ae81ff>5</span>,       <span style=color:#75715e># 리프 노드에는 최소 5개 샘플 필요</span>
</span></span><span style=display:flex><span>        random_state<span style=color:#f92672>=</span>RANDOM_STATE,
</span></span><span style=display:flex><span>    ),
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;RandomForest&#34;</span>: RandomForestRegressor(
</span></span><span style=display:flex><span>        n_estimators<span style=color:#f92672>=</span><span style=color:#ae81ff>100</span>,         <span style=color:#75715e># 100개의 의사결정 트리로 앙상블 구성</span>
</span></span><span style=display:flex><span>        max_depth<span style=color:#f92672>=</span><span style=color:#ae81ff>8</span>,              <span style=color:#75715e># 개별 트리 최대 깊이 </span>
</span></span><span style=display:flex><span>        min_samples_split<span style=color:#f92672>=</span><span style=color:#ae81ff>5</span>,      <span style=color:#75715e># 노드 분할 시 최소 5개 샘플 필요</span>
</span></span><span style=display:flex><span>        min_samples_leaf<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>,       <span style=color:#75715e># 리프 노드에는 최소 2개 샘플 필요</span>
</span></span><span style=display:flex><span>        random_state<span style=color:#f92672>=</span>RANDOM_STATE,
</span></span><span style=display:flex><span>    ),
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;Lasso&#34;</span>: Lasso(
</span></span><span style=display:flex><span>        alpha<span style=color:#f92672>=</span><span style=color:#ae81ff>0.01</span>,               <span style=color:#75715e># 정규화 강도 (작을수록 덜 정규화)</span>
</span></span><span style=display:flex><span>        random_state<span style=color:#f92672>=</span>RANDOM_STATE,
</span></span><span style=display:flex><span>    ),
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;Ridge&#34;</span>: Ridge(
</span></span><span style=display:flex><span>        alpha<span style=color:#f92672>=</span><span style=color:#ae81ff>0.1</span>,                <span style=color:#75715e># 정규화 강도 (작을수록 덜 정규화)</span>
</span></span><span style=display:flex><span>        random_state<span style=color:#f92672>=</span>RANDOM_STATE,
</span></span><span style=display:flex><span>    ),
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;XGBRegressor&#34;</span>: XGBRegressor(
</span></span><span style=display:flex><span>        n_estimators<span style=color:#f92672>=</span><span style=color:#ae81ff>100</span>,         <span style=color:#75715e># 100개의 부스팅 라운드</span>
</span></span><span style=display:flex><span>        max_depth<span style=color:#f92672>=</span><span style=color:#ae81ff>6</span>,              <span style=color:#75715e># 트리 최대 깊이</span>
</span></span><span style=display:flex><span>        learning_rate<span style=color:#f92672>=</span><span style=color:#ae81ff>0.1</span>,        <span style=color:#75715e># 학습률 (작을수록 안정적이지만 느림)</span>
</span></span><span style=display:flex><span>        subsample<span style=color:#f92672>=</span><span style=color:#ae81ff>0.8</span>,            <span style=color:#75715e># 샘플링 비율 (과적합 방지)</span>
</span></span><span style=display:flex><span>        colsample_bytree<span style=color:#f92672>=</span><span style=color:#ae81ff>0.8</span>,     <span style=color:#75715e># 특성 샘플링 비율 (과적합 방지) </span>
</span></span><span style=display:flex><span>        random_state<span style=color:#f92672>=</span>RANDOM_STATE,
</span></span><span style=display:flex><span>    ),
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;LGBMRegressor&#34;</span>: LGBMRegressor(
</span></span><span style=display:flex><span>        n_estimators<span style=color:#f92672>=</span><span style=color:#ae81ff>100</span>,         <span style=color:#75715e># 100개의 부스팅 라운드</span>
</span></span><span style=display:flex><span>        max_depth<span style=color:#f92672>=</span><span style=color:#ae81ff>6</span>,              <span style=color:#75715e># 트리 최대 깊이</span>
</span></span><span style=display:flex><span>        learning_rate<span style=color:#f92672>=</span><span style=color:#ae81ff>0.1</span>,        <span style=color:#75715e># 학습률</span>
</span></span><span style=display:flex><span>        subsample<span style=color:#f92672>=</span><span style=color:#ae81ff>0.8</span>,            <span style=color:#75715e># 샘플링 비율</span>
</span></span><span style=display:flex><span>        colsample_bytree<span style=color:#f92672>=</span><span style=color:#ae81ff>0.8</span>,     <span style=color:#75715e># 특성 샘플링 비율</span>
</span></span><span style=display:flex><span>        random_state<span style=color:#f92672>=</span>RANDOM_STATE,
</span></span><span style=display:flex><span>        force_col_wise<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>,      <span style=color:#75715e># 경고 메시지 방지</span>
</span></span><span style=display:flex><span>    ),
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 모든 모델의 성능을 train, valid, test 셋에서 평가</span>
</span></span><span style=display:flex><span>results <span style=color:#f92672>=</span> {}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> name, model <span style=color:#f92672>in</span> models<span style=color:#f92672>.</span>items():
</span></span><span style=display:flex><span>    model<span style=color:#f92672>.</span>fit(X_train, y_train)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    y_train_pred <span style=color:#f92672>=</span> model<span style=color:#f92672>.</span>predict(X_train)
</span></span><span style=display:flex><span>    y_valid_pred <span style=color:#f92672>=</span> model<span style=color:#f92672>.</span>predict(X_valid)
</span></span><span style=display:flex><span>    y_test_pred  <span style=color:#f92672>=</span> model<span style=color:#f92672>.</span>predict(X_test)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># 성능 기록</span>
</span></span><span style=display:flex><span>    results[name] <span style=color:#f92672>=</span> {
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;Train_R2&#34;</span>: r2_score(y_train, y_train_pred),
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;Valid_R2&#34;</span>: r2_score(y_valid, y_valid_pred),
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;Test_R2&#34;</span>:  r2_score(y_test, y_test_pred),
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;Train_RMSE&#34;</span>: root_mean_squared_error(y_train, y_train_pred),
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;Valid_RMSE&#34;</span>: root_mean_squared_error(y_valid, y_valid_pred),
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;Test_RMSE&#34;</span>:  root_mean_squared_error(y_test, y_test_pred),
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>results_df <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>DataFrame(results)<span style=color:#f92672>.</span>T
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#34;=== 모델별 성능 비교 (R² &amp; RMSE) ===&#34;</span>)
</span></span><span style=display:flex><span>display(results_df<span style=color:#f92672>.</span>round(<span style=color:#ae81ff>4</span>))
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-plain data-lang=plain><span style=display:flex><span>=== 모델별 성능 비교 (R² &amp; RMSE) ===
</span></span><span style=display:flex><span>	Train_R2	Valid_R2	Test_R2	Train_RMSE	Valid_RMSE	Test_RMSE
</span></span><span style=display:flex><span>DecisionTree	0.6137	0.3196	0.3113	49.0068	61.0539	60.4061
</span></span><span style=display:flex><span>RandomForest	0.8542	0.4615	0.4318	30.1061	54.3170	54.8663
</span></span><span style=display:flex><span>Lasso	0.5185	0.5229	0.4514	54.7135	51.1284	53.9115
</span></span><span style=display:flex><span>Ridge	0.5105	0.5201	0.4558	55.1620	51.2744	53.6941
</span></span><span style=display:flex><span>XGBRegressor	0.9978	0.4334	0.3810	3.7360	55.7150	57.2664
</span></span><span style=display:flex><span>LGBMRegressor	0.8889	0.3987	0.4168	26.2792	57.3986	55.5853
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># Metrics</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 모든 모델의 테스트 성능 기준으로 비교</span>
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#34;</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>=== 테스트 성능 기준 모델 비교 (R² &amp; RMSE) ===&#34;</span>)
</span></span><span style=display:flex><span>print(results_df[[<span style=color:#e6db74>&#34;Test_R2&#34;</span>, <span style=color:#e6db74>&#34;Test_RMSE&#34;</span>]]<span style=color:#f92672>.</span>sort_values(by<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;Test_R2&#34;</span>, ascending<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>))
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-plain data-lang=plain><span style=display:flex><span>=== 테스트 성능 기준 모델 비교 (R² &amp; RMSE) ===
</span></span><span style=display:flex><span>               Test_R2  Test_RMSE
</span></span><span style=display:flex><span>Ridge           0.4558    53.6941
</span></span><span style=display:flex><span>Lasso           0.4514    53.9115
</span></span><span style=display:flex><span>RandomForest    0.4318    54.8663
</span></span><span style=display:flex><span>LGBMRegressor   0.4168    55.5853
</span></span><span style=display:flex><span>XGBRegressor    0.3810    57.2664
</span></span><span style=display:flex><span>DecisionTree    0.3113    60.4061
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># Best Model</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 테스트 성능 기준으로 최고 모델 선택</span>
</span></span><span style=display:flex><span>best_model_name <span style=color:#f92672>=</span> results_df[<span style=color:#e6db74>&#34;Test_R2&#34;</span>]<span style=color:#f92672>.</span>idxmax()
</span></span><span style=display:flex><span>best_model <span style=color:#f92672>=</span> models[best_model_name]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>✅ Best Model: </span><span style=color:#e6db74>{</span>best_model_name<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Test R² : </span><span style=color:#e6db74>{</span>results_df<span style=color:#f92672>.</span>loc[best_model_name, <span style=color:#e6db74>&#39;Test_R2&#39;</span>]<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Test RMSE : </span><span style=color:#e6db74>{</span>results_df<span style=color:#f92672>.</span>loc[best_model_name, <span style=color:#e6db74>&#39;Test_RMSE&#39;</span>]<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-plain data-lang=plain><span style=display:flex><span>✅ Best Model: Ridge
</span></span><span style=display:flex><span>Test R² : 0.4558
</span></span><span style=display:flex><span>Test RMSE : 53.6941
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># Feature Importance</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Best Model의 feature importance 분석</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>if</span> hasattr(best_model, <span style=color:#e6db74>&#34;feature_importances_&#34;</span>):  <span style=color:#75715e># 트리 기반 모델</span>
</span></span><span style=display:flex><span>    feature_importances <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>Series(
</span></span><span style=display:flex><span>        best_model<span style=color:#f92672>.</span>feature_importances_,
</span></span><span style=display:flex><span>        index<span style=color:#f92672>=</span>feature_names
</span></span><span style=display:flex><span>    )<span style=color:#f92672>.</span>sort_values(ascending<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#34;</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>=== Feature Importance ===&#34;</span>)
</span></span><span style=display:flex><span>    display(feature_importances)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    feature_importances<span style=color:#f92672>.</span>plot(kind<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;barh&#34;</span>, figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>8</span>, <span style=color:#ae81ff>6</span>), title<span style=color:#f92672>=</span><span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;</span><span style=color:#e6db74>{</span>best_model_name<span style=color:#e6db74>}</span><span style=color:#e6db74> Feature Importance&#34;</span>)
</span></span><span style=display:flex><span>    plt<span style=color:#f92672>.</span>show()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>elif</span> hasattr(best_model, <span style=color:#e6db74>&#34;coef_&#34;</span>):  <span style=color:#75715e># 선형 모델 (Ridge, Lasso)</span>
</span></span><span style=display:flex><span>    feature_importances <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>Series(
</span></span><span style=display:flex><span>        best_model<span style=color:#f92672>.</span>coef_,
</span></span><span style=display:flex><span>        index<span style=color:#f92672>=</span>feature_names
</span></span><span style=display:flex><span>    )<span style=color:#f92672>.</span>sort_values(key<span style=color:#f92672>=</span>abs, ascending<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)  <span style=color:#75715e># 절댓값 기준 정렬</span>
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#34;</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>=== Coefficients (절댓값 기준 중요도) ===&#34;</span>)
</span></span><span style=display:flex><span>    display(feature_importances)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    feature_importances<span style=color:#f92672>.</span>plot(kind<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;barh&#34;</span>, figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>8</span>, <span style=color:#ae81ff>6</span>), title<span style=color:#f92672>=</span><span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;</span><span style=color:#e6db74>{</span>best_model_name<span style=color:#e6db74>}</span><span style=color:#e6db74> Coefficients (Importance)&#34;</span>)
</span></span><span style=display:flex><span>    plt<span style=color:#f92672>.</span>show()
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-plain data-lang=plain><span style=display:flex><span>=== Coefficients (절댓값 기준 중요도) ===
</span></span><span style=display:flex><span>bmi    486.3793
</span></span><span style=display:flex><span>s5     403.8977
</span></span><span style=display:flex><span>bp     281.9268
</span></span><span style=display:flex><span>sex   -201.4770
</span></span><span style=display:flex><span>s3    -185.6912
</span></span><span style=display:flex><span>s4     161.8174
</span></span><span style=display:flex><span>s2    -125.0469
</span></span><span style=display:flex><span>s6     111.1299
</span></span><span style=display:flex><span>s1    -103.1486
</span></span><span style=display:flex><span>age     39.9838
</span></span><span style=display:flex><span>dtype: float64
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># Prediction</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Best Model로 예측 수행</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 데이터셋별 예측</span>
</span></span><span style=display:flex><span>y_train_pred <span style=color:#f92672>=</span> best_model<span style=color:#f92672>.</span>predict(X_train)
</span></span><span style=display:flex><span>y_valid_pred <span style=color:#f92672>=</span> best_model<span style=color:#f92672>.</span>predict(X_valid)
</span></span><span style=display:flex><span>y_test_pred  <span style=color:#f92672>=</span> best_model<span style=color:#f92672>.</span>predict(X_test)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 성능 평가 함수 재사용</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>calculate_metrics</span>(y_true, y_pred, set_name):
</span></span><span style=display:flex><span>    r2 <span style=color:#f92672>=</span> r2_score(y_true, y_pred)
</span></span><span style=display:flex><span>    mse <span style=color:#f92672>=</span> mean_squared_error(y_true, y_pred)
</span></span><span style=display:flex><span>    rmse <span style=color:#f92672>=</span> root_mean_squared_error(y_true, y_pred)
</span></span><span style=display:flex><span>    mape <span style=color:#f92672>=</span> mean_absolute_percentage_error(y_true, y_pred)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> {
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;Set&#34;</span>: set_name,
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;R²&#34;</span>: r2,
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;MSE&#34;</span>: mse,
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;RMSE&#34;</span>: rmse,
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;MAPE&#34;</span>: mape,
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 모든 셋 성능 계산</span>
</span></span><span style=display:flex><span>train_metrics <span style=color:#f92672>=</span> calculate_metrics(y_train, y_train_pred, <span style=color:#e6db74>&#34;Train&#34;</span>)
</span></span><span style=display:flex><span>valid_metrics <span style=color:#f92672>=</span> calculate_metrics(y_valid, y_valid_pred, <span style=color:#e6db74>&#34;Valid&#34;</span>)
</span></span><span style=display:flex><span>test_metrics  <span style=color:#f92672>=</span> calculate_metrics(y_test, y_test_pred, <span style=color:#e6db74>&#34;Test&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 결과 DataFrame 정리</span>
</span></span><span style=display:flex><span>prediction_results <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>DataFrame([train_metrics, valid_metrics, test_metrics])<span style=color:#f92672>.</span>set_index(<span style=color:#e6db74>&#34;Set&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#34;</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>=== Best Model (Ridge) 성능 비교 ===&#34;</span>)
</span></span><span style=display:flex><span>display(prediction_results<span style=color:#f92672>.</span>round(<span style=color:#ae81ff>4</span>))
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-plain data-lang=plain><span style=display:flex><span>=== Best Model (Ridge) 성능 비교 ===
</span></span><span style=display:flex><span>R²	MSE	RMSE	MAPE
</span></span><span style=display:flex><span>Set				
</span></span><span style=display:flex><span>Train	0.5105	3042.8483	55.1620	0.4105
</span></span><span style=display:flex><span>Valid	0.5201	2629.0688	51.2744	0.3042
</span></span><span style=display:flex><span>Test	0.4558	2883.0570	53.6941	0.3663
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># Best Model로 성능 계산</span>
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#34;</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>=== 최적 모델 성능 요약 ===&#34;</span>)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Best Model : </span><span style=color:#e6db74>{</span>best_model_name<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Train R² : </span><span style=color:#e6db74>{</span>train_metrics[<span style=color:#e6db74>&#39;R²&#39;</span>]<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>, RMSE : </span><span style=color:#e6db74>{</span>train_metrics[<span style=color:#e6db74>&#39;RMSE&#39;</span>]<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>, MAPE : </span><span style=color:#e6db74>{</span>train_metrics[<span style=color:#e6db74>&#39;MAPE&#39;</span>]<span style=color:#f92672>*</span><span style=color:#ae81ff>100</span><span style=color:#e6db74>:</span><span style=color:#e6db74>.2f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>%&#34;</span>)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Valid R² : </span><span style=color:#e6db74>{</span>valid_metrics[<span style=color:#e6db74>&#39;R²&#39;</span>]<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>, RMSE : </span><span style=color:#e6db74>{</span>valid_metrics[<span style=color:#e6db74>&#39;RMSE&#39;</span>]<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>, MAPE : </span><span style=color:#e6db74>{</span>valid_metrics[<span style=color:#e6db74>&#39;MAPE&#39;</span>]<span style=color:#f92672>*</span><span style=color:#ae81ff>100</span><span style=color:#e6db74>:</span><span style=color:#e6db74>.2f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>%&#34;</span>)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Test  R² : </span><span style=color:#e6db74>{</span>test_metrics[<span style=color:#e6db74>&#39;R²&#39;</span>]<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>, RMSE : </span><span style=color:#e6db74>{</span>test_metrics[<span style=color:#e6db74>&#39;RMSE&#39;</span>]<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>, MAPE : </span><span style=color:#e6db74>{</span>test_metrics[<span style=color:#e6db74>&#39;MAPE&#39;</span>]<span style=color:#f92672>*</span><span style=color:#ae81ff>100</span><span style=color:#e6db74>:</span><span style=color:#e6db74>.2f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>%&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>👉 최종 Test 성능 기준으로 </span><span style=color:#e6db74>{</span>best_model_name<span style=color:#e6db74>}</span><span style=color:#e6db74> 모델이 선택되었습니다.&#34;</span>)
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-plain data-lang=plain><span style=display:flex><span>=== 최적 모델 성능 요약 ===
</span></span><span style=display:flex><span>Best Model : Ridge
</span></span><span style=display:flex><span>Train R² : 0.5105, RMSE : 55.1620, MAPE : 41.05%
</span></span><span style=display:flex><span>Valid R² : 0.5201, RMSE : 51.2744, MAPE : 30.42%
</span></span><span style=display:flex><span>Test  R² : 0.4558, RMSE : 53.6941, MAPE : 36.63%
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>👉 최종 Test 성능 기준으로 Ridge 모델이 선택되었습니다.
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># actual vs predicted visualization</span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>figure(figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>15</span>, <span style=color:#ae81ff>5</span>))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 1. 산점도: 실제값 vs 예측값</span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>subplot(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>scatter(y_test, y_test_pred, alpha<span style=color:#f92672>=</span><span style=color:#ae81ff>0.6</span>, color<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;red&#34;</span>, edgecolor<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;k&#34;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>plot([y_test<span style=color:#f92672>.</span>min(), y_test<span style=color:#f92672>.</span>max()], [y_test<span style=color:#f92672>.</span>min(), y_test<span style=color:#f92672>.</span>max()], <span style=color:#e6db74>&#34;b--&#34;</span>, lw<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>xlabel(<span style=color:#e6db74>&#34;Actual&#34;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>ylabel(<span style=color:#e6db74>&#34;Predicted&#34;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>title(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;</span><span style=color:#e6db74>{</span>best_model_name<span style=color:#e6db74>}</span><span style=color:#e6db74> - Actual vs Predicted (Test)</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>R² = </span><span style=color:#e6db74>{</span>test_metrics[<span style=color:#e6db74>&#39;R²&#39;</span>]<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>, RMSE = </span><span style=color:#e6db74>{</span>test_metrics[<span style=color:#e6db74>&#39;RMSE&#39;</span>]<span style=color:#e6db74>:</span><span style=color:#e6db74>.2f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 2. 라인 그래프: 시계열 순서 기준 실제 vs 예측 비교</span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>subplot(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>2</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>plot(y_test<span style=color:#f92672>.</span>values, label<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;Actual&#34;</span>, marker<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;o&#34;</span>, color<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;blue&#34;</span>, alpha<span style=color:#f92672>=</span><span style=color:#ae81ff>0.7</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>plot(y_test_pred, label<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;Predicted&#34;</span>, marker<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;x&#34;</span>, color<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;red&#34;</span>, alpha<span style=color:#f92672>=</span><span style=color:#ae81ff>0.7</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>title(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;</span><span style=color:#e6db74>{</span>best_model_name<span style=color:#e6db74>}</span><span style=color:#e6db74> - Actual vs Predicted (Test)&#34;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>ylabel(<span style=color:#e6db74>&#34;Disease Progression&#34;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>legend()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>tight_layout()
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>show()
</span></span></code></pre></div></article><footer class=book-footer><div class="flex flex-wrap justify-between"></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments><script src=https://giscus.app/client.js data-repo=yshghid/yshghid.github.io data-repo-id=R_kgDONkMkNg data-category-id=DIC_kwDONkMkNs4CloJh data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=ko crossorigin=anonymous async></script></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><ul><li><a href=#1>1</a></li><li></li><li><a href=#2-여러-알고리즘-결과-확인>2. 여러 알고리즘 결과 확인</a></li></ul></li></ul></nav></div></aside></main></body></html>