<!doctype html><html lang=en-us dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="
  MutClust 코드 리펙토링 #3 utils
  #

#2025-08-01

MutClust 알고리즘의 코드 구성은 아래와 같은데
MutClust
├── sc/
│    └── lib.py
│    └── arg_parser.py
│    └── utils.py // 전처리 및 분석
└── Test
utils.py는 데이터 전처리 및 분석 함수를 포함한다.
# === Fasta 전처리 ===
def fasta2csv(home_dir, nation_dir, filechunk, ref, outdir):
    for file in filechunk:
        path = os.path.join(home_dir, nation_dir, file)
        filename = os.path.splitext(os.path.basename(file))[0]
        outpath = os.path.join(outdir, f&#34;{filename}.csv&#34;)
        if not os.path.exists(outpath):
            df = DataFrame({'ref': ref.values, 'pos': ref.index})
            seq = ''.join(open(path).readlines()[1:]).strip()
            df['mut'] = [a if a != ref[i] else '' for i, a in enumerate(seq)]
            df.to_csv(outpath, index=False)

def gisaid_fasta2csv(homedir=f&#34;{GISAID_DIR}/Sequence/Preprocessed/&#34;):
    inputdir = os.path.join(homedir, 'MSA_fasta')
    outdir = os.path.join(homedir, 'MSA_mutationinfo')
    Path(outdir).mkdir(exist_ok=True, parents=True)
    core_n = 100
    args_list = []
    for nation_dir in get_dirnames_list(inputdir):
        filelist = get_filenames_list(os.path.join(inputdir, nation_dir))
        for chunk in array_split(filelist, core_n):
            args_list.append((inputdir, nation_dir, chunk, ref_seq, outdir))
    with Pool(core_n) as pool:
        pool.map(fasta2csv, args_list)

# === Nucleotide 전처리 ===
def get_nucleotide_sequence_dict(seq_dir):
    seq_dict = dict()
    seq_list = get_filenames_list(seq_dir)
    for file in seq_list:
        filepath = os.path.join(seq_dir, file)
        df = read_csv(filepath, index_col=0)
        df.name = file.split('.')[0]
        df = df.reset_index(drop=True)
        seq_dict[df.name] = df
    return seq_dict

def getNucleotideRefSeqbyGene():
    return read_csv('/data3/projects/2020_MUTCLUST/Data/Annotation/Nucleotide/covid_annotation.tsv', sep=' ')

def make_nucleotide_mutclust_input(outdir, name, seq_dict=None):
    if not os.path.exists(outdir):
        print(outdir + ' is not exist')
        return

    output_path = os.path.join(outdir, name + '_mutclust_input.tsv')
    freq_df_ATGC_path = os.path.join(outdir, name + '_freq_ATGC.csv') 

    pos_list, freq_list, per_list, entropy_list = [], [], [], []

    if not os.path.exists(freq_df_ATGC_path):
        if seq_dict is None:
            print('load seq_dict')
            return 
        freq_df = DataFrame.from_dict(seq_dict).transpose().fillna(0).astype(int)
        freq_df = freq_df.sort_index()
        freq_df = freq_df[list(IUPAC_CODES.keys())][['A','T','G','C']]
        freq_df.to_csv(freq_df_ATGC_path)
    else:
        freq_df = read_csv(freq_df_ATGC_path, index_col=0)

    for pos in freq_df.index:
        freq = freq_df.loc[pos]
        cnt_n = freq.sum()
        percentage = freq / cnt_n
        entrpy = entropy(percentage, base=2)

        percentage.drop(ref_seq[pos], inplace=True)
        freq.drop(ref_seq[pos], inplace=True)

        pos_list.append(int(pos))
        freq_list.append(freq.sum())
        per_list.append(percentage.sum())
        entropy_list.append(entrpy)

    mutclust_input_df = DataFrame({
        'Position': pos_list,
        'Frequency': freq_list,
        'Percentages': per_list,
        'Entropy': entropy_list
    })
    mutclust_input_df.to_csv(output_path, sep='\t', index=False)
    return mutclust_input_df

# === Mutation 데이터 병렬 처리 ===
def read_thead(filepathlist, return_list, i):
    ref_seq_sr = getNucleotideRefSeq()
    sub_dict = {pos: Counter({k: 0 for k in IUPAC_CODES.keys()}) for pos in ref_seq_sr.index}

    for filepath in filepathlist:
        df = read_csv(filepath, index_col=0).fillna('').reset_index(drop=True)
        for index, mut in enumerate(df['mut']):
            symbol = mut if mut else ref_seq_sr[index + 1]
            if symbol in sub_dict[index + 1]:
                sub_dict[index + 1][symbol] += 1
            else:
                sub_dict[index + 1][symbol] = 1

    return_list.append(sub_dict)
    print(f&#34;{i}th process complete!&#34;)

def merge_thread(poslist, sub_dict_list, return_dict):
    for pos in poslist:
        count_dict = sum([d[pos] for d in sub_dict_list], Counter())
        merged_dict = {k: count_dict.get(k, 0) for k in IUPAC_CODES.keys()}
        return_dict[pos] = merged_dict

def load_mutationinfo(input_dir=COVID19_MUTATIONINFO_DIR, sample_list=None):
    core_n, split_n = 100, 1000 
    sub_dict_list = Manager().list()
    filelist = get_file_paths_recursive(input_dir)
    
    if sample_list:
        filelist = [f for f in filelist if os.path.basename(f).split('.')[0] in sample_list]
    print(f'sample_n: {len(sample_list)}')

    splited_filepaths = array_split(filelist, split_n)
    parameter_list = [(chunk, sub_dict_list, i) for i, chunk in enumerate(splited_filepaths)]
    print('read thread start!')
    multi_processing(read_thead, parameter_list, core_n=core_n)
    print('read thread end!')

    merged_dict = Manager().dict()
    poslist = ref_seq.index
    splited_poslist = array_split(poslist, split_n)
    sub_dict_list = list(sub_dict_list)
    parameter_list = [(pos_chunk, sub_dict_list, merged_dict) for pos_chunk in splited_poslist]

    print('merge thread start!')
    multi_processing(merge_thread, parameter_list, core_n=core_n)
    print('merge thread end!')
    return dict(merged_dict)

# === Matrix 생성 병렬 처리 ===
def make_matrix_thread(file_list):
    clusters_df = pd.read_csv(os.path.join(GISAID_MUTCLUST_OUTPUT_DIR, 'clusters_hscore.txt'), sep='\t')
    column_list = [f&#34;c{i}({row['left_position']},{row['right_position']})&#34; for i, row in clusters_df.iterrows()]
    cluster_df = pd.DataFrame(columns=column_list)

    for path in file_list:
        df = pd.read_csv(path)
        patient_name = os.path.splitext(os.path.basename(path))[0]
        cluster_df.loc[patient_name] = 0
        for pos in df[df['mut'].notnull()]['pos']:
            cluster_idx = clusters_df[(clusters_df['left_position'] <= pos) & (pos <= clusters_df['right_position'])].index
            cluster_df.loc[patient_name][cluster_idx] += 1
    return cluster_df

def make_matrix(mutationinfo_dir, out_dir, tag, cpu_n=60):
    print('starting make matrix!')
    pool = Pool(processes=cpu_n)
    file_list = get_file_paths_recursive(mutationinfo_dir)
    results = pool.map(make_matrix_thread, array_split(file_list, cpu_n))
    pd.concat(results).to_csv(os.path.join(out_dir, f'cluster_matrix_{tag}.csv'))
    pool.close()
    pool.join()

# === H-score 계산 ===
def add_HSCORE():
    df = pd.read_csv(os.path.join(MUTCLUST_INPUT_DIR, 'gisaid_mutclust_input.tsv'), sep='\t')
    df[HSCORE] = df[PER] * df[ENT]
    df.to_csv(os.path.join(MUTCLUST_INPUT_DIR, 'gisaid_mutclust_input_with_score.tsv'), sep='\t', index=False)

# === 주석(Annotation) ===
def annotation():
    import ast
    mapping_df = pd.read_csv(os.path.join(GISAID_METADATA_DIR, 'merged_info.tsv'), sep='\t', index_col=0)
    for i, row in mapping_df.iterrows():
        mapping_df.loc[i] = [ast.literal_eval(val) for val in row]
    print(mapping_df)

def make_clade_divide_mutation():
    clade_dir = './clade_divide_mutation'
    start_dict = getStartDict()
    for file in get_filenames_list(clade_dir):
        df = read_csv(os.path.join(clade_dir, file), sep='\t')
        print(df)

# === 병렬 처리 유틸리티 ===
def multi_processing(func, parameter_list, core_n=100):
    proc, proc_excution, proc_end = [], [], []
    for param in parameter_list:
        proc.append(Process(target=func, args=param))

    while proc or proc_excution:
        for _ in range(len(proc)):
            if len(proc_excution) < core_n:
                p = proc.pop(0)
                p.start()
                proc_excution.append(p)
            else:
                break
        for p in proc_excution[:]:
            if not p.is_alive():
                proc_excution.remove(p)
                p.join()
                p.close()
                proc_end.append(p)

# === 메인 실행 ===
if __name__ == '__main__':
    annotation()
"><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="https://yshghid.github.io/docs/study/algorithm/algo9/"><meta property="og:site_name" content=" "><meta property="og:title" content="MutClust 코드 리펙토링 #3 utils"><meta property="og:description" content="MutClust 코드 리펙토링 #3 utils # #2025-08-01
MutClust 알고리즘의 코드 구성은 아래와 같은데
MutClust ├── sc/ │ └── lib.py │ └── arg_parser.py │ └── utils.py // 전처리 및 분석 └── Test utils.py는 데이터 전처리 및 분석 함수를 포함한다.
# === Fasta 전처리 === def fasta2csv(home_dir, nation_dir, filechunk, ref, outdir): for file in filechunk: path = os.path.join(home_dir, nation_dir, file) filename = os.path.splitext(os.path.basename(file))[0] outpath = os.path.join(outdir, f&#34;{filename}.csv&#34;) if not os.path.exists(outpath): df = DataFrame({'ref': ref.values, 'pos': ref.index}) seq = ''.join(open(path).readlines()[1:]).strip() df['mut'] = [a if a != ref[i] else '' for i, a in enumerate(seq)] df.to_csv(outpath, index=False) def gisaid_fasta2csv(homedir=f&#34;{GISAID_DIR}/Sequence/Preprocessed/&#34;): inputdir = os.path.join(homedir, 'MSA_fasta') outdir = os.path.join(homedir, 'MSA_mutationinfo') Path(outdir).mkdir(exist_ok=True, parents=True) core_n = 100 args_list = [] for nation_dir in get_dirnames_list(inputdir): filelist = get_filenames_list(os.path.join(inputdir, nation_dir)) for chunk in array_split(filelist, core_n): args_list.append((inputdir, nation_dir, chunk, ref_seq, outdir)) with Pool(core_n) as pool: pool.map(fasta2csv, args_list) # === Nucleotide 전처리 === def get_nucleotide_sequence_dict(seq_dir): seq_dict = dict() seq_list = get_filenames_list(seq_dir) for file in seq_list: filepath = os.path.join(seq_dir, file) df = read_csv(filepath, index_col=0) df.name = file.split('.')[0] df = df.reset_index(drop=True) seq_dict[df.name] = df return seq_dict def getNucleotideRefSeqbyGene(): return read_csv('/data3/projects/2020_MUTCLUST/Data/Annotation/Nucleotide/covid_annotation.tsv', sep=' ') def make_nucleotide_mutclust_input(outdir, name, seq_dict=None): if not os.path.exists(outdir): print(outdir + ' is not exist') return output_path = os.path.join(outdir, name + '_mutclust_input.tsv') freq_df_ATGC_path = os.path.join(outdir, name + '_freq_ATGC.csv') pos_list, freq_list, per_list, entropy_list = [], [], [], [] if not os.path.exists(freq_df_ATGC_path): if seq_dict is None: print('load seq_dict') return freq_df = DataFrame.from_dict(seq_dict).transpose().fillna(0).astype(int) freq_df = freq_df.sort_index() freq_df = freq_df[list(IUPAC_CODES.keys())][['A','T','G','C']] freq_df.to_csv(freq_df_ATGC_path) else: freq_df = read_csv(freq_df_ATGC_path, index_col=0) for pos in freq_df.index: freq = freq_df.loc[pos] cnt_n = freq.sum() percentage = freq / cnt_n entrpy = entropy(percentage, base=2) percentage.drop(ref_seq[pos], inplace=True) freq.drop(ref_seq[pos], inplace=True) pos_list.append(int(pos)) freq_list.append(freq.sum()) per_list.append(percentage.sum()) entropy_list.append(entrpy) mutclust_input_df = DataFrame({ 'Position': pos_list, 'Frequency': freq_list, 'Percentages': per_list, 'Entropy': entropy_list }) mutclust_input_df.to_csv(output_path, sep='\t', index=False) return mutclust_input_df # === Mutation 데이터 병렬 처리 === def read_thead(filepathlist, return_list, i): ref_seq_sr = getNucleotideRefSeq() sub_dict = {pos: Counter({k: 0 for k in IUPAC_CODES.keys()}) for pos in ref_seq_sr.index} for filepath in filepathlist: df = read_csv(filepath, index_col=0).fillna('').reset_index(drop=True) for index, mut in enumerate(df['mut']): symbol = mut if mut else ref_seq_sr[index + 1] if symbol in sub_dict[index + 1]: sub_dict[index + 1][symbol] += 1 else: sub_dict[index + 1][symbol] = 1 return_list.append(sub_dict) print(f&#34;{i}th process complete!&#34;) def merge_thread(poslist, sub_dict_list, return_dict): for pos in poslist: count_dict = sum([d[pos] for d in sub_dict_list], Counter()) merged_dict = {k: count_dict.get(k, 0) for k in IUPAC_CODES.keys()} return_dict[pos] = merged_dict def load_mutationinfo(input_dir=COVID19_MUTATIONINFO_DIR, sample_list=None): core_n, split_n = 100, 1000 sub_dict_list = Manager().list() filelist = get_file_paths_recursive(input_dir) if sample_list: filelist = [f for f in filelist if os.path.basename(f).split('.')[0] in sample_list] print(f'sample_n: {len(sample_list)}') splited_filepaths = array_split(filelist, split_n) parameter_list = [(chunk, sub_dict_list, i) for i, chunk in enumerate(splited_filepaths)] print('read thread start!') multi_processing(read_thead, parameter_list, core_n=core_n) print('read thread end!') merged_dict = Manager().dict() poslist = ref_seq.index splited_poslist = array_split(poslist, split_n) sub_dict_list = list(sub_dict_list) parameter_list = [(pos_chunk, sub_dict_list, merged_dict) for pos_chunk in splited_poslist] print('merge thread start!') multi_processing(merge_thread, parameter_list, core_n=core_n) print('merge thread end!') return dict(merged_dict) # === Matrix 생성 병렬 처리 === def make_matrix_thread(file_list): clusters_df = pd.read_csv(os.path.join(GISAID_MUTCLUST_OUTPUT_DIR, 'clusters_hscore.txt'), sep='\t') column_list = [f&#34;c{i}({row['left_position']},{row['right_position']})&#34; for i, row in clusters_df.iterrows()] cluster_df = pd.DataFrame(columns=column_list) for path in file_list: df = pd.read_csv(path) patient_name = os.path.splitext(os.path.basename(path))[0] cluster_df.loc[patient_name] = 0 for pos in df[df['mut'].notnull()]['pos']: cluster_idx = clusters_df[(clusters_df['left_position'] <= pos) & (pos <= clusters_df['right_position'])].index cluster_df.loc[patient_name][cluster_idx] += 1 return cluster_df def make_matrix(mutationinfo_dir, out_dir, tag, cpu_n=60): print('starting make matrix!') pool = Pool(processes=cpu_n) file_list = get_file_paths_recursive(mutationinfo_dir) results = pool.map(make_matrix_thread, array_split(file_list, cpu_n)) pd.concat(results).to_csv(os.path.join(out_dir, f'cluster_matrix_{tag}.csv')) pool.close() pool.join() # === H-score 계산 === def add_HSCORE(): df = pd.read_csv(os.path.join(MUTCLUST_INPUT_DIR, 'gisaid_mutclust_input.tsv'), sep='\t') df[HSCORE] = df[PER] * df[ENT] df.to_csv(os.path.join(MUTCLUST_INPUT_DIR, 'gisaid_mutclust_input_with_score.tsv'), sep='\t', index=False) # === 주석(Annotation) === def annotation(): import ast mapping_df = pd.read_csv(os.path.join(GISAID_METADATA_DIR, 'merged_info.tsv'), sep='\t', index_col=0) for i, row in mapping_df.iterrows(): mapping_df.loc[i] = [ast.literal_eval(val) for val in row] print(mapping_df) def make_clade_divide_mutation(): clade_dir = './clade_divide_mutation' start_dict = getStartDict() for file in get_filenames_list(clade_dir): df = read_csv(os.path.join(clade_dir, file), sep='\t') print(df) # === 병렬 처리 유틸리티 === def multi_processing(func, parameter_list, core_n=100): proc, proc_excution, proc_end = [], [], [] for param in parameter_list: proc.append(Process(target=func, args=param)) while proc or proc_excution: for _ in range(len(proc)): if len(proc_excution) < core_n: p = proc.pop(0) p.start() proc_excution.append(p) else: break for p in proc_excution[:]: if not p.is_alive(): proc_excution.remove(p) p.join() p.close() proc_end.append(p) # === 메인 실행 === if __name__ == '__main__': annotation()"><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="docs"><meta property="article:published_time" content="2025-08-01T00:00:00+00:00"><meta property="article:modified_time" content="2025-08-01T00:00:00+00:00"><meta property="article:tag" content="2025-08"><title>MutClust 코드 리펙토링 #3 utils |</title><link rel=icon href=/favicon.png><link rel=manifest href=/manifest.json><link rel=canonical href=https://yshghid.github.io/docs/study/algorithm/algo9/><link rel=stylesheet href=/book.min.6217d077edb4189fd0578345e84bca1a884dfdee121ff8dc9a0f55cfe0852bc9.css integrity="sha256-YhfQd+20GJ/QV4NF6EvKGohN/e4SH/jcmg9Vz+CFK8k=" crossorigin=anonymous><script defer src=/fuse.min.js></script><script defer src=/en.search.min.578a2d8e6e30e0a0ae3682797882d89ca0cbbf1734d206705396ea76cf57bbb6.js integrity="sha256-V4otjm4w4KCuNoJ5eILYnKDLvxc00gZwU5bqds9Xu7Y=" crossorigin=anonymous></script></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><img src=/logo.png alt=Logo class=book-icon><span></span></a></h2><div class="book-search hidden"><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><script>document.querySelector(".book-search").classList.remove("hidden")</script><ul><li class=book-section-flat><span>기록</span><ul><li><a href=/docs/hobby/book/>글</a><ul></ul></li><li><a href=/docs/hobby/daily/>일상</a><ul></ul></li></ul></li><li class=book-section-flat><span>공부</span><ul><li><a href=/docs/study/bioinformatics/>Bioinformatics</a><ul></ul></li><li><a href=/docs/study/ai/>AI</a><ul></ul></li><li><a href=/docs/study/sw/>SW</a><ul></ul></li><li><a href=/docs/study/algorithm/>알고리즘</a><ul></ul></li><li><a href=/docs/study/career/>취업</a><ul></ul></li></ul></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu></label><h3>MutClust 코드 리펙토링 #3 utils</h3><label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents></nav></aside></header><article class="markdown book-article"><h1 id=mutclust-코드-리펙토링-3-utils>MutClust 코드 리펙토링 #3 utils
<a class=anchor href=#mutclust-%ec%bd%94%eb%93%9c-%eb%a6%ac%ed%8e%99%ed%86%a0%eb%a7%81-3-utils>#</a></h1><p>#2025-08-01</p><hr><p>MutClust 알고리즘의 코드 구성은 아래와 같은데</p><div class=highlight><pre tabindex=0 style=color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-plain data-lang=plain><span style=display:flex><span>MutClust
</span></span><span style=display:flex><span>├── sc/
</span></span><span style=display:flex><span>│    └── lib.py
</span></span><span style=display:flex><span>│    └── arg_parser.py
</span></span><span style=display:flex><span>│    └── utils.py // 전처리 및 분석
</span></span><span style=display:flex><span>└── Test
</span></span></code></pre></div><p>utils.py는 데이터 전처리 및 분석 함수를 포함한다.</p><div class=highlight><pre tabindex=0 style=color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#007f7f># === Fasta 전처리 ===</span>
</span></span><span style=display:flex><span><span style=color:#fff;font-weight:700>def</span> fasta2csv(home_dir, nation_dir, filechunk, ref, outdir):
</span></span><span style=display:flex><span>    <span style=color:#fff;font-weight:700>for</span> file in filechunk:
</span></span><span style=display:flex><span>        path = os.path.join(home_dir, nation_dir, file)
</span></span><span style=display:flex><span>        filename = os.path.splitext(os.path.basename(file))[<span style=color:#ff0;font-weight:700>0</span>]
</span></span><span style=display:flex><span>        outpath = os.path.join(outdir, <span style=color:#0ff;font-weight:700>f</span><span style=color:#0ff;font-weight:700>&#34;</span><span style=color:#0ff;font-weight:700>{</span>filename<span style=color:#0ff;font-weight:700>}</span><span style=color:#0ff;font-weight:700>.csv&#34;</span>)
</span></span><span style=display:flex><span>        <span style=color:#fff;font-weight:700>if</span> not os.path.exists(outpath):
</span></span><span style=display:flex><span>            df = DataFrame({<span style=color:#0ff;font-weight:700>&#39;ref&#39;</span>: ref.values, <span style=color:#0ff;font-weight:700>&#39;pos&#39;</span>: ref.index})
</span></span><span style=display:flex><span>            seq = <span style=color:#0ff;font-weight:700>&#39;&#39;</span>.join(<span style=color:#fff;font-weight:700>open</span>(path).readlines()[<span style=color:#ff0;font-weight:700>1</span>:]).strip()
</span></span><span style=display:flex><span>            df[<span style=color:#0ff;font-weight:700>&#39;mut&#39;</span>] = [a <span style=color:#fff;font-weight:700>if</span> a != ref[i] <span style=color:#fff;font-weight:700>else</span> <span style=color:#0ff;font-weight:700>&#39;&#39;</span> <span style=color:#fff;font-weight:700>for</span> i, a in <span style=color:#fff;font-weight:700>enumerate</span>(seq)]
</span></span><span style=display:flex><span>            df.to_csv(outpath, index=<span style=color:#fff;font-weight:700>False</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#fff;font-weight:700>def</span> gisaid_fasta2csv(homedir=<span style=color:#0ff;font-weight:700>f</span><span style=color:#0ff;font-weight:700>&#34;</span><span style=color:#0ff;font-weight:700>{</span>GISAID_DIR<span style=color:#0ff;font-weight:700>}</span><span style=color:#0ff;font-weight:700>/Sequence/Preprocessed/&#34;</span>):
</span></span><span style=display:flex><span>    inputdir = os.path.join(homedir, <span style=color:#0ff;font-weight:700>&#39;MSA_fasta&#39;</span>)
</span></span><span style=display:flex><span>    outdir = os.path.join(homedir, <span style=color:#0ff;font-weight:700>&#39;MSA_mutationinfo&#39;</span>)
</span></span><span style=display:flex><span>    Path(outdir).mkdir(exist_ok=<span style=color:#fff;font-weight:700>True</span>, parents=<span style=color:#fff;font-weight:700>True</span>)
</span></span><span style=display:flex><span>    core_n = <span style=color:#ff0;font-weight:700>100</span>
</span></span><span style=display:flex><span>    args_list = []
</span></span><span style=display:flex><span>    <span style=color:#fff;font-weight:700>for</span> nation_dir in get_dirnames_list(inputdir):
</span></span><span style=display:flex><span>        filelist = get_filenames_list(os.path.join(inputdir, nation_dir))
</span></span><span style=display:flex><span>        <span style=color:#fff;font-weight:700>for</span> chunk in array_split(filelist, core_n):
</span></span><span style=display:flex><span>            args_list.append((inputdir, nation_dir, chunk, ref_seq, outdir))
</span></span><span style=display:flex><span>    <span style=color:#fff;font-weight:700>with</span> Pool(core_n) <span style=color:#fff;font-weight:700>as</span> pool:
</span></span><span style=display:flex><span>        pool.map(fasta2csv, args_list)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#007f7f># === Nucleotide 전처리 ===</span>
</span></span><span style=display:flex><span><span style=color:#fff;font-weight:700>def</span> get_nucleotide_sequence_dict(seq_dir):
</span></span><span style=display:flex><span>    seq_dict = <span style=color:#fff;font-weight:700>dict</span>()
</span></span><span style=display:flex><span>    seq_list = get_filenames_list(seq_dir)
</span></span><span style=display:flex><span>    <span style=color:#fff;font-weight:700>for</span> file in seq_list:
</span></span><span style=display:flex><span>        filepath = os.path.join(seq_dir, file)
</span></span><span style=display:flex><span>        df = read_csv(filepath, index_col=<span style=color:#ff0;font-weight:700>0</span>)
</span></span><span style=display:flex><span>        df.name = file.split(<span style=color:#0ff;font-weight:700>&#39;.&#39;</span>)[<span style=color:#ff0;font-weight:700>0</span>]
</span></span><span style=display:flex><span>        df = df.reset_index(drop=<span style=color:#fff;font-weight:700>True</span>)
</span></span><span style=display:flex><span>        seq_dict[df.name] = df
</span></span><span style=display:flex><span>    <span style=color:#fff;font-weight:700>return</span> seq_dict
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#fff;font-weight:700>def</span> getNucleotideRefSeqbyGene():
</span></span><span style=display:flex><span>    <span style=color:#fff;font-weight:700>return</span> read_csv(<span style=color:#0ff;font-weight:700>&#39;/data3/projects/2020_MUTCLUST/Data/Annotation/Nucleotide/covid_annotation.tsv&#39;</span>, sep=<span style=color:#0ff;font-weight:700>&#39; &#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#fff;font-weight:700>def</span> make_nucleotide_mutclust_input(outdir, name, seq_dict=<span style=color:#fff;font-weight:700>None</span>):
</span></span><span style=display:flex><span>    <span style=color:#fff;font-weight:700>if</span> not os.path.exists(outdir):
</span></span><span style=display:flex><span>        <span style=color:#fff;font-weight:700>print</span>(outdir + <span style=color:#0ff;font-weight:700>&#39; is not exist&#39;</span>)
</span></span><span style=display:flex><span>        <span style=color:#fff;font-weight:700>return</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    output_path = os.path.join(outdir, name + <span style=color:#0ff;font-weight:700>&#39;_mutclust_input.tsv&#39;</span>)
</span></span><span style=display:flex><span>    freq_df_ATGC_path = os.path.join(outdir, name + <span style=color:#0ff;font-weight:700>&#39;_freq_ATGC.csv&#39;</span>) 
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    pos_list, freq_list, per_list, entropy_list = [], [], [], []
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#fff;font-weight:700>if</span> not os.path.exists(freq_df_ATGC_path):
</span></span><span style=display:flex><span>        <span style=color:#fff;font-weight:700>if</span> seq_dict is <span style=color:#fff;font-weight:700>None</span>:
</span></span><span style=display:flex><span>            <span style=color:#fff;font-weight:700>print</span>(<span style=color:#0ff;font-weight:700>&#39;load seq_dict&#39;</span>)
</span></span><span style=display:flex><span>            <span style=color:#fff;font-weight:700>return</span> 
</span></span><span style=display:flex><span>        freq_df = DataFrame.from_dict(seq_dict).transpose().fillna(<span style=color:#ff0;font-weight:700>0</span>).astype(<span style=color:#fff;font-weight:700>int</span>)
</span></span><span style=display:flex><span>        freq_df = freq_df.sort_index()
</span></span><span style=display:flex><span>        freq_df = freq_df[<span style=color:#fff;font-weight:700>list</span>(IUPAC_CODES.keys())][[<span style=color:#0ff;font-weight:700>&#39;A&#39;</span>,<span style=color:#0ff;font-weight:700>&#39;T&#39;</span>,<span style=color:#0ff;font-weight:700>&#39;G&#39;</span>,<span style=color:#0ff;font-weight:700>&#39;C&#39;</span>]]
</span></span><span style=display:flex><span>        freq_df.to_csv(freq_df_ATGC_path)
</span></span><span style=display:flex><span>    <span style=color:#fff;font-weight:700>else</span>:
</span></span><span style=display:flex><span>        freq_df = read_csv(freq_df_ATGC_path, index_col=<span style=color:#ff0;font-weight:700>0</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#fff;font-weight:700>for</span> pos in freq_df.index:
</span></span><span style=display:flex><span>        freq = freq_df.loc[pos]
</span></span><span style=display:flex><span>        cnt_n = freq.sum()
</span></span><span style=display:flex><span>        percentage = freq / cnt_n
</span></span><span style=display:flex><span>        entrpy = entropy(percentage, base=<span style=color:#ff0;font-weight:700>2</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        percentage.drop(ref_seq[pos], inplace=<span style=color:#fff;font-weight:700>True</span>)
</span></span><span style=display:flex><span>        freq.drop(ref_seq[pos], inplace=<span style=color:#fff;font-weight:700>True</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        pos_list.append(<span style=color:#fff;font-weight:700>int</span>(pos))
</span></span><span style=display:flex><span>        freq_list.append(freq.sum())
</span></span><span style=display:flex><span>        per_list.append(percentage.sum())
</span></span><span style=display:flex><span>        entropy_list.append(entrpy)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    mutclust_input_df = DataFrame({
</span></span><span style=display:flex><span>        <span style=color:#0ff;font-weight:700>&#39;Position&#39;</span>: pos_list,
</span></span><span style=display:flex><span>        <span style=color:#0ff;font-weight:700>&#39;Frequency&#39;</span>: freq_list,
</span></span><span style=display:flex><span>        <span style=color:#0ff;font-weight:700>&#39;Percentages&#39;</span>: per_list,
</span></span><span style=display:flex><span>        <span style=color:#0ff;font-weight:700>&#39;Entropy&#39;</span>: entropy_list
</span></span><span style=display:flex><span>    })
</span></span><span style=display:flex><span>    mutclust_input_df.to_csv(output_path, sep=<span style=color:#0ff;font-weight:700>&#39;</span><span style=color:#0ff;font-weight:700>\t</span><span style=color:#0ff;font-weight:700>&#39;</span>, index=<span style=color:#fff;font-weight:700>False</span>)
</span></span><span style=display:flex><span>    <span style=color:#fff;font-weight:700>return</span> mutclust_input_df
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#007f7f># === Mutation 데이터 병렬 처리 ===</span>
</span></span><span style=display:flex><span><span style=color:#fff;font-weight:700>def</span> read_thead(filepathlist, return_list, i):
</span></span><span style=display:flex><span>    ref_seq_sr = getNucleotideRefSeq()
</span></span><span style=display:flex><span>    sub_dict = {pos: Counter({k: <span style=color:#ff0;font-weight:700>0</span> <span style=color:#fff;font-weight:700>for</span> k in IUPAC_CODES.keys()}) <span style=color:#fff;font-weight:700>for</span> pos in ref_seq_sr.index}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#fff;font-weight:700>for</span> filepath in filepathlist:
</span></span><span style=display:flex><span>        df = read_csv(filepath, index_col=<span style=color:#ff0;font-weight:700>0</span>).fillna(<span style=color:#0ff;font-weight:700>&#39;&#39;</span>).reset_index(drop=<span style=color:#fff;font-weight:700>True</span>)
</span></span><span style=display:flex><span>        <span style=color:#fff;font-weight:700>for</span> index, mut in <span style=color:#fff;font-weight:700>enumerate</span>(df[<span style=color:#0ff;font-weight:700>&#39;mut&#39;</span>]):
</span></span><span style=display:flex><span>            symbol = mut <span style=color:#fff;font-weight:700>if</span> mut <span style=color:#fff;font-weight:700>else</span> ref_seq_sr[index + <span style=color:#ff0;font-weight:700>1</span>]
</span></span><span style=display:flex><span>            <span style=color:#fff;font-weight:700>if</span> symbol in sub_dict[index + <span style=color:#ff0;font-weight:700>1</span>]:
</span></span><span style=display:flex><span>                sub_dict[index + <span style=color:#ff0;font-weight:700>1</span>][symbol] += <span style=color:#ff0;font-weight:700>1</span>
</span></span><span style=display:flex><span>            <span style=color:#fff;font-weight:700>else</span>:
</span></span><span style=display:flex><span>                sub_dict[index + <span style=color:#ff0;font-weight:700>1</span>][symbol] = <span style=color:#ff0;font-weight:700>1</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    return_list.append(sub_dict)
</span></span><span style=display:flex><span>    <span style=color:#fff;font-weight:700>print</span>(<span style=color:#0ff;font-weight:700>f</span><span style=color:#0ff;font-weight:700>&#34;</span><span style=color:#0ff;font-weight:700>{</span>i<span style=color:#0ff;font-weight:700>}</span><span style=color:#0ff;font-weight:700>th process complete!&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#fff;font-weight:700>def</span> merge_thread(poslist, sub_dict_list, return_dict):
</span></span><span style=display:flex><span>    <span style=color:#fff;font-weight:700>for</span> pos in poslist:
</span></span><span style=display:flex><span>        count_dict = <span style=color:#fff;font-weight:700>sum</span>([d[pos] <span style=color:#fff;font-weight:700>for</span> d in sub_dict_list], Counter())
</span></span><span style=display:flex><span>        merged_dict = {k: count_dict.get(k, <span style=color:#ff0;font-weight:700>0</span>) <span style=color:#fff;font-weight:700>for</span> k in IUPAC_CODES.keys()}
</span></span><span style=display:flex><span>        return_dict[pos] = merged_dict
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#fff;font-weight:700>def</span> load_mutationinfo(input_dir=COVID19_MUTATIONINFO_DIR, sample_list=<span style=color:#fff;font-weight:700>None</span>):
</span></span><span style=display:flex><span>    core_n, split_n = <span style=color:#ff0;font-weight:700>100</span>, <span style=color:#ff0;font-weight:700>1000</span> 
</span></span><span style=display:flex><span>    sub_dict_list = Manager().list()
</span></span><span style=display:flex><span>    filelist = get_file_paths_recursive(input_dir)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#fff;font-weight:700>if</span> sample_list:
</span></span><span style=display:flex><span>        filelist = [f <span style=color:#fff;font-weight:700>for</span> f in filelist <span style=color:#fff;font-weight:700>if</span> os.path.basename(f).split(<span style=color:#0ff;font-weight:700>&#39;.&#39;</span>)[<span style=color:#ff0;font-weight:700>0</span>] in sample_list]
</span></span><span style=display:flex><span>    <span style=color:#fff;font-weight:700>print</span>(<span style=color:#0ff;font-weight:700>f</span><span style=color:#0ff;font-weight:700>&#39;sample_n: </span><span style=color:#0ff;font-weight:700>{</span><span style=color:#fff;font-weight:700>len</span>(sample_list)<span style=color:#0ff;font-weight:700>}</span><span style=color:#0ff;font-weight:700>&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    splited_filepaths = array_split(filelist, split_n)
</span></span><span style=display:flex><span>    parameter_list = [(chunk, sub_dict_list, i) <span style=color:#fff;font-weight:700>for</span> i, chunk in <span style=color:#fff;font-weight:700>enumerate</span>(splited_filepaths)]
</span></span><span style=display:flex><span>    <span style=color:#fff;font-weight:700>print</span>(<span style=color:#0ff;font-weight:700>&#39;read thread start!&#39;</span>)
</span></span><span style=display:flex><span>    multi_processing(read_thead, parameter_list, core_n=core_n)
</span></span><span style=display:flex><span>    <span style=color:#fff;font-weight:700>print</span>(<span style=color:#0ff;font-weight:700>&#39;read thread end!&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    merged_dict = Manager().dict()
</span></span><span style=display:flex><span>    poslist = ref_seq.index
</span></span><span style=display:flex><span>    splited_poslist = array_split(poslist, split_n)
</span></span><span style=display:flex><span>    sub_dict_list = <span style=color:#fff;font-weight:700>list</span>(sub_dict_list)
</span></span><span style=display:flex><span>    parameter_list = [(pos_chunk, sub_dict_list, merged_dict) <span style=color:#fff;font-weight:700>for</span> pos_chunk in splited_poslist]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#fff;font-weight:700>print</span>(<span style=color:#0ff;font-weight:700>&#39;merge thread start!&#39;</span>)
</span></span><span style=display:flex><span>    multi_processing(merge_thread, parameter_list, core_n=core_n)
</span></span><span style=display:flex><span>    <span style=color:#fff;font-weight:700>print</span>(<span style=color:#0ff;font-weight:700>&#39;merge thread end!&#39;</span>)
</span></span><span style=display:flex><span>    <span style=color:#fff;font-weight:700>return</span> <span style=color:#fff;font-weight:700>dict</span>(merged_dict)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#007f7f># === Matrix 생성 병렬 처리 ===</span>
</span></span><span style=display:flex><span><span style=color:#fff;font-weight:700>def</span> make_matrix_thread(file_list):
</span></span><span style=display:flex><span>    clusters_df = pd.read_csv(os.path.join(GISAID_MUTCLUST_OUTPUT_DIR, <span style=color:#0ff;font-weight:700>&#39;clusters_hscore.txt&#39;</span>), sep=<span style=color:#0ff;font-weight:700>&#39;</span><span style=color:#0ff;font-weight:700>\t</span><span style=color:#0ff;font-weight:700>&#39;</span>)
</span></span><span style=display:flex><span>    column_list = [<span style=color:#0ff;font-weight:700>f</span><span style=color:#0ff;font-weight:700>&#34;c</span><span style=color:#0ff;font-weight:700>{</span>i<span style=color:#0ff;font-weight:700>}</span><span style=color:#0ff;font-weight:700>(</span><span style=color:#0ff;font-weight:700>{</span>row[<span style=color:#0ff;font-weight:700>&#39;left_position&#39;</span>]<span style=color:#0ff;font-weight:700>}</span><span style=color:#0ff;font-weight:700>,</span><span style=color:#0ff;font-weight:700>{</span>row[<span style=color:#0ff;font-weight:700>&#39;right_position&#39;</span>]<span style=color:#0ff;font-weight:700>}</span><span style=color:#0ff;font-weight:700>)&#34;</span> <span style=color:#fff;font-weight:700>for</span> i, row in clusters_df.iterrows()]
</span></span><span style=display:flex><span>    cluster_df = pd.DataFrame(columns=column_list)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#fff;font-weight:700>for</span> path in file_list:
</span></span><span style=display:flex><span>        df = pd.read_csv(path)
</span></span><span style=display:flex><span>        patient_name = os.path.splitext(os.path.basename(path))[<span style=color:#ff0;font-weight:700>0</span>]
</span></span><span style=display:flex><span>        cluster_df.loc[patient_name] = <span style=color:#ff0;font-weight:700>0</span>
</span></span><span style=display:flex><span>        <span style=color:#fff;font-weight:700>for</span> pos in df[df[<span style=color:#0ff;font-weight:700>&#39;mut&#39;</span>].notnull()][<span style=color:#0ff;font-weight:700>&#39;pos&#39;</span>]:
</span></span><span style=display:flex><span>            cluster_idx = clusters_df[(clusters_df[<span style=color:#0ff;font-weight:700>&#39;left_position&#39;</span>] &lt;= pos) &amp; (pos &lt;= clusters_df[<span style=color:#0ff;font-weight:700>&#39;right_position&#39;</span>])].index
</span></span><span style=display:flex><span>            cluster_df.loc[patient_name][cluster_idx] += <span style=color:#ff0;font-weight:700>1</span>
</span></span><span style=display:flex><span>    <span style=color:#fff;font-weight:700>return</span> cluster_df
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#fff;font-weight:700>def</span> make_matrix(mutationinfo_dir, out_dir, tag, cpu_n=<span style=color:#ff0;font-weight:700>60</span>):
</span></span><span style=display:flex><span>    <span style=color:#fff;font-weight:700>print</span>(<span style=color:#0ff;font-weight:700>&#39;starting make matrix!&#39;</span>)
</span></span><span style=display:flex><span>    pool = Pool(processes=cpu_n)
</span></span><span style=display:flex><span>    file_list = get_file_paths_recursive(mutationinfo_dir)
</span></span><span style=display:flex><span>    results = pool.map(make_matrix_thread, array_split(file_list, cpu_n))
</span></span><span style=display:flex><span>    pd.concat(results).to_csv(os.path.join(out_dir, <span style=color:#0ff;font-weight:700>f</span><span style=color:#0ff;font-weight:700>&#39;cluster_matrix_</span><span style=color:#0ff;font-weight:700>{</span>tag<span style=color:#0ff;font-weight:700>}</span><span style=color:#0ff;font-weight:700>.csv&#39;</span>))
</span></span><span style=display:flex><span>    pool.close()
</span></span><span style=display:flex><span>    pool.join()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#007f7f># === H-score 계산 ===</span>
</span></span><span style=display:flex><span><span style=color:#fff;font-weight:700>def</span> add_HSCORE():
</span></span><span style=display:flex><span>    df = pd.read_csv(os.path.join(MUTCLUST_INPUT_DIR, <span style=color:#0ff;font-weight:700>&#39;gisaid_mutclust_input.tsv&#39;</span>), sep=<span style=color:#0ff;font-weight:700>&#39;</span><span style=color:#0ff;font-weight:700>\t</span><span style=color:#0ff;font-weight:700>&#39;</span>)
</span></span><span style=display:flex><span>    df[HSCORE] = df[PER] * df[ENT]
</span></span><span style=display:flex><span>    df.to_csv(os.path.join(MUTCLUST_INPUT_DIR, <span style=color:#0ff;font-weight:700>&#39;gisaid_mutclust_input_with_score.tsv&#39;</span>), sep=<span style=color:#0ff;font-weight:700>&#39;</span><span style=color:#0ff;font-weight:700>\t</span><span style=color:#0ff;font-weight:700>&#39;</span>, index=<span style=color:#fff;font-weight:700>False</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#007f7f># === 주석(Annotation) ===</span>
</span></span><span style=display:flex><span><span style=color:#fff;font-weight:700>def</span> annotation():
</span></span><span style=display:flex><span>    <span style=color:#fff;font-weight:700>import</span> ast
</span></span><span style=display:flex><span>    mapping_df = pd.read_csv(os.path.join(GISAID_METADATA_DIR, <span style=color:#0ff;font-weight:700>&#39;merged_info.tsv&#39;</span>), sep=<span style=color:#0ff;font-weight:700>&#39;</span><span style=color:#0ff;font-weight:700>\t</span><span style=color:#0ff;font-weight:700>&#39;</span>, index_col=<span style=color:#ff0;font-weight:700>0</span>)
</span></span><span style=display:flex><span>    <span style=color:#fff;font-weight:700>for</span> i, row in mapping_df.iterrows():
</span></span><span style=display:flex><span>        mapping_df.loc[i] = [ast.literal_eval(val) <span style=color:#fff;font-weight:700>for</span> val in row]
</span></span><span style=display:flex><span>    <span style=color:#fff;font-weight:700>print</span>(mapping_df)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#fff;font-weight:700>def</span> make_clade_divide_mutation():
</span></span><span style=display:flex><span>    clade_dir = <span style=color:#0ff;font-weight:700>&#39;./clade_divide_mutation&#39;</span>
</span></span><span style=display:flex><span>    start_dict = getStartDict()
</span></span><span style=display:flex><span>    <span style=color:#fff;font-weight:700>for</span> file in get_filenames_list(clade_dir):
</span></span><span style=display:flex><span>        df = read_csv(os.path.join(clade_dir, file), sep=<span style=color:#0ff;font-weight:700>&#39;</span><span style=color:#0ff;font-weight:700>\t</span><span style=color:#0ff;font-weight:700>&#39;</span>)
</span></span><span style=display:flex><span>        <span style=color:#fff;font-weight:700>print</span>(df)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#007f7f># === 병렬 처리 유틸리티 ===</span>
</span></span><span style=display:flex><span><span style=color:#fff;font-weight:700>def</span> multi_processing(func, parameter_list, core_n=<span style=color:#ff0;font-weight:700>100</span>):
</span></span><span style=display:flex><span>    proc, proc_excution, proc_end = [], [], []
</span></span><span style=display:flex><span>    <span style=color:#fff;font-weight:700>for</span> param in parameter_list:
</span></span><span style=display:flex><span>        proc.append(Process(target=func, args=param))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#fff;font-weight:700>while</span> proc or proc_excution:
</span></span><span style=display:flex><span>        <span style=color:#fff;font-weight:700>for</span> _ in <span style=color:#fff;font-weight:700>range</span>(<span style=color:#fff;font-weight:700>len</span>(proc)):
</span></span><span style=display:flex><span>            <span style=color:#fff;font-weight:700>if</span> <span style=color:#fff;font-weight:700>len</span>(proc_excution) &lt; core_n:
</span></span><span style=display:flex><span>                p = proc.pop(<span style=color:#ff0;font-weight:700>0</span>)
</span></span><span style=display:flex><span>                p.start()
</span></span><span style=display:flex><span>                proc_excution.append(p)
</span></span><span style=display:flex><span>            <span style=color:#fff;font-weight:700>else</span>:
</span></span><span style=display:flex><span>                <span style=color:#fff;font-weight:700>break</span>
</span></span><span style=display:flex><span>        <span style=color:#fff;font-weight:700>for</span> p in proc_excution[:]:
</span></span><span style=display:flex><span>            <span style=color:#fff;font-weight:700>if</span> not p.is_alive():
</span></span><span style=display:flex><span>                proc_excution.remove(p)
</span></span><span style=display:flex><span>                p.join()
</span></span><span style=display:flex><span>                p.close()
</span></span><span style=display:flex><span>                proc_end.append(p)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#007f7f># === 메인 실행 ===</span>
</span></span><span style=display:flex><span><span style=color:#fff;font-weight:700>if</span> __name__ == <span style=color:#0ff;font-weight:700>&#39;__main__&#39;</span>:
</span></span><span style=display:flex><span>    annotation()
</span></span></code></pre></div></article><footer class=book-footer><div class="flex flex-wrap justify-between"></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments><script src=https://giscus.app/client.js data-repo=yshghid/yshghid.github.io data-repo-id=R_kgDONkMkNg data-category-id=DIC_kwDONkMkNs4CloJh data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=ko crossorigin=anonymous async></script></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents></nav></div></aside></main></body></html>