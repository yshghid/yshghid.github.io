---
date : 2025-09-10
tags: ['2025-09']
categories: ['AI']
bookHidden: true
title: "ML #1"
---

# ML #1

#2025-09-10

---

### 1

```python
# !pip install numpy
# !pip install pandas
# !pip install seaborn
# !pip install matplotlib
# !pip install -U scikit-learn
# !pip install xgboost
# !pip install lightgbm

import warnings

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.datasets import load_diabetes
from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    r2_score,
    mean_squared_error,
    root_mean_squared_error,
    mean_absolute_percentage_error,
)

warnings.filterwarnings("ignore")
pd.set_option("display.max_columns", 100)
pd.set_option("float_format", "{:.4f}".format)
sns.set_style("whitegrid")

RANDOM_STATE = 42
```

```python
# 1. Data Definition
_data = load_diabetes()
print(_data.DESCR)
```
```plain text
.. _diabetes_dataset:

Diabetes dataset
----------------

Ten baseline variables, age, sex, body mass index, average blood
pressure, and six blood serum measurements were obtained for each of n =
442 diabetes patients, as well as the response of interest, a
quantitative measure of disease progression one year after baseline.

**Data Set Characteristics:**

:Number of Instances: 442

:Number of Attributes: First 10 columns are numeric predictive values

:Target: Column 11 is a quantitative measure of disease progression one year after baseline

:Attribute Information:
    - age     age in years
    - sex
    - bmi     body mass index
    - bp      average blood pressure
    - s1      tc, total serum cholesterol
    - s2      ldl, low-density lipoproteins
    - s3      hdl, high-density lipoproteins
    - s4      tch, total cholesterol / HDL
    - s5      ltg, possibly log of serum triglycerides level
    - s6      glu, blood sugar level

Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times the square root of `n_samples` (i.e. the sum of squares of each column totals 1).

Source URL:
https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html

For more information see:
Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) "Least Angle Regression," Annals of Statistics (with discussion), 407-499.
(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)
```
```python
data = _data["data"]
feature_names = _data["feature_names"]

df = pd.DataFrame(data, columns=feature_names)
df["target"] = _data["target"]

df.head()
```

```python
# 2. EDA
# Correlation
plt.figure(figsize=(10, 8))

sns.heatmap(
    data=df.drop("target", axis=1).corr(),
    annot=True,
    cmap="coolwarm",
)

plt.show()
```
```python
# 4. Machine Learning Regression
# Dataset Definition
X = df.drop("target", axis=1)
y = df["target"]

# 먼저 train+valid와 test로 분할 (80:20)
X_temp, X_test, y_temp, y_test = train_test_split(
    X, y, test_size=0.2, random_state=RANDOM_STATE
)

# train+valid를 다시 train과 valid로 분할 (75:25)
X_train, X_valid, y_train, y_valid = train_test_split(
    X_temp, y_temp, test_size=0.25, random_state=RANDOM_STATE
)

print(f"데이터 분할 결과:")
print(f"Train: {len(X_train)} ({len(X_train)/len(X)*100:.1f}%)")
print(f"Valid: {len(X_valid)} ({len(X_valid)/len(X)*100:.1f}%)")
print(f"Test: {len(X_test)} ({len(X_test)/len(X)*100:.1f}%)")
```
```plain text
데이터 분할 결과:
Train: 264 (59.7%)
Valid: 89 (20.1%)
Test: 89 (20.1%)
```
```python
# Model (Vanila)
from sklearn.tree import DecisionTreeRegressor

model = DecisionTreeRegressor(random_state=RANDOM_STATE)
model.fit(X_train, y_train)
model.score(X_train, y_train)
print(model.intercept_, model.coef_)
```
```plain text
1.0
```
```python
# Feature Importance
model.feature_importances_
feature_names
_feature_importances = pd.Series(
    model.feature_importances_,
    index=feature_names,
)

_feature_importances
```
```plain text
array([0.08981708, 0.00592253, 0.43861624, 0.08517564, 0.04463861,
       0.04418316, 0.05650334, 0.05949104, 0.13289137, 0.04276099])
['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']
age   0.0898
sex   0.0059
bmi   0.4386
bp    0.0852
s1    0.0446
s2    0.0442
s3    0.0565
s4    0.0595
s5    0.1329
s6    0.0428
dtype: float64
```
```python
_feature_importances.nlargest().plot(kind="barh")
```
```python
# Prediction
# 각 셋에 대한 예측
y_train_pred = model.predict(X_train)
y_valid_pred = model.predict(X_valid)
y_test_pred = model.predict(X_test)

# 각 셋의 성능 평가
def calculate_metrics(y_true, y_pred, set_name):
    r2 = r2_score(y_true, y_pred)
    mse = mean_squared_error(y_true, y_pred)
    rmse = root_mean_squared_error(y_true, y_pred)
    mape = mean_absolute_percentage_error(y_true, y_pred)
    
    return {
        'Set': set_name,
        'R²': r2,
        'MSE': mse,
        'RMSE': rmse,
        'MAPE': mape
    }

# 모든 셋의 성능 계산
train_metrics = calculate_metrics(y_train, y_train_pred, 'Train')
valid_metrics = calculate_metrics(y_valid, y_valid_pred, 'Valid')
test_metrics = calculate_metrics(y_test, y_test_pred, 'Test')

# 결과를 DataFrame으로 정리
results_df = pd.DataFrame([train_metrics, valid_metrics, test_metrics])
results_df = results_df.set_index('Set')

print("=== Train/Valid/Test 셋 성능 비교 ===")
print(results_df.round(4))
```
```plain text
=== Train/Valid/Test 셋 성능 비교 ===
           R²       MSE    RMSE   MAPE
Set                                   
Train  1.0000    0.0000  0.0000 0.0000
Valid  0.2095 4330.7978 65.8088 0.3744
Test  -0.2659 6706.9101 81.8957 0.5430
```
```python
# Metrics
# 과적합 분석
print(f"\n=== 과적합 분석 ===")
train_valid_r2_diff = train_metrics['R²'] - valid_metrics['R²']
valid_test_r2_diff = valid_metrics['R²'] - test_metrics['R²']

print(f"Train-Valid R² 차이: {train_valid_r2_diff:.4f}")
print(f"Valid-Test R² 차이: {valid_test_r2_diff:.4f}")
```
```plain text

=== 과적합 분석 ===
Train-Valid R² 차이: 0.7905
Valid-Test R² 차이: 0.4754
```

> - 임계값 0.1 
>   - 아래 코드에서 0.1로 비교하는 것은 고정 규칙이 아니라 경험적 가이드 입니다 
>   - 모델/데이터별 차이가 있어 동일 기준으로 일관되게 적용할 수 없습니다 
>   - 해당 파일에서는 우선적으로 경험적 가이드를 적용하여 진행합니다 
>     
> - 객관적 판단을 위해서는 "데이터 기반 임계값" 통한 비교 필요 => (모델 최적화 과정에서 확인) 
>   - k-fold에서 val R^2의 표준편차 σ_val을 구해
>   - 과적합 : (train_mean - val_mean) > max(0.05, 2*σ_val)
>   - 일반화 문제 : |test - val_mean| > 2*σ_val

```python
if train_valid_r2_diff > 0.1:
    print("⚠️  과적합 가능성: 훈련 데이터와 검증 데이터 간 성능 차이가 큽니다.")
else:
    print("✅ 과적합 위험 낮음: 훈련 데이터와 검증 데이터 간 성능이 유사합니다.")

if valid_test_r2_diff > 0.1:
    print("⚠️  일반화 문제: 검증 데이터와 테스트 데이터 간 성능 차이가 큽니다.")
else:
    print("✅ 일반화 성능 양호: 검증 데이터와 테스트 데이터 간 성능이 유사합니다.")
```
```plain text
⚠️  과적합 가능성: 훈련 데이터와 검증 데이터 간 성능 차이가 큽니다.
⚠️  일반화 문제: 검증 데이터와 테스트 데이터 간 성능 차이가 큽니다.
```
```python
# 모델 설명력 해석
print(f"\n=== 모델 설명력 해석 ===")
print(f"훈련 데이터 R²: {train_metrics['R²']:.4f} ({train_metrics['R²']*100:.2f}%)")
print(f"검증 데이터 R²: {valid_metrics['R²']:.4f} ({valid_metrics['R²']*100:.2f}%)")
print(f"테스트 데이터 R²: {test_metrics['R²']:.4f} ({test_metrics['R²']*100:.2f}%)")
print(f"→ 최종 테스트에서 모델이 {test_metrics['R²']*100:.1f}%의 분산을 설명합니다.")
```
```plain text
=== 모델 설명력 해석 ===
훈련 데이터 R²: 1.0000 (100.00%)
검증 데이터 R²: 0.2095 (20.95%)
테스트 데이터 R²: -0.2659 (-26.59%)
→ 최종 테스트에서 모델이 -26.6%의 분산을 설명합니다.
```
```python
# 오차 정확도 해석
print(f"\n=== 오차 정확도 해석 ===")
print(f"Train RMSE: {train_metrics['RMSE']:.2f}")
print(f"Valid RMSE: {valid_metrics['RMSE']:.2f}")
print(f"Test RMSE: {test_metrics['RMSE']:.2f}")
print(f"Test MAPE: {test_metrics['MAPE']:.4f} ({test_metrics['MAPE']*100:.2f}%)")
print(f"→ 최종 테스트에서 예측값이 실제값에 대해 평균적으로 ±{test_metrics['MAPE']*100:.1f}% 정도의 오차를 보입니다.")
```
```plain text
=== 오차 정확도 해석 ===
Train RMSE: 0.00
Valid RMSE: 65.81
Test RMSE: 81.90
Test MAPE: 0.5430 (54.30%)
→ 최종 테스트에서 예측값이 실제값에 대해 평균적으로 ±54.3% 정도의 오차를 보입니다.
```
```python
# 시각화: 실제값 vs 예측값 비교
plt.figure(figsize=(15, 5))

# 훈련 데이터
plt.subplot(1, 3, 1)
plt.scatter(y_train, y_train_pred, alpha=0.6, color="blue")
plt.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], "r--", lw=2)
plt.xlabel("Actual")
plt.ylabel("Predicted")
plt.title(f"Train (R² = {train_metrics['R²']:.4f})")

# 검증 데이터
plt.subplot(1, 3, 2)
plt.scatter(y_valid, y_valid_pred, alpha=0.6, color="green")
plt.plot([y_valid.min(), y_valid.max()], [y_valid.min(), y_valid.max()], "r--", lw=2)
plt.xlabel("Actual")
plt.ylabel("Predicted")
plt.title(f"Valid (R² = {valid_metrics['R²']:.4f})")

# 테스트 데이터
plt.subplot(1, 3, 3)
plt.scatter(y_test, y_test_pred, alpha=0.6, color="red")
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], "r--", lw=2)
plt.xlabel("Actual")
plt.ylabel("Predicted")
plt.title(f"Test (R² = {test_metrics['R²']:.4f})")

plt.tight_layout()
plt.show()
```
```python
# 성능 지표 비교 차트
metrics_to_plot = ['R²', 'RMSE', 'MAPE']
fig, axes = plt.subplots(1, 3, figsize=(15, 5))

for i, metric in enumerate(metrics_to_plot):
    values = [train_metrics[metric], valid_metrics[metric], test_metrics[metric]]
    sets = ['Train', 'Valid', 'Test']
    
    bars = axes[i].bar(sets, values, color=['blue', 'green', 'red'], alpha=0.7)
    axes[i].set_title(f'{metric}')
    axes[i].set_ylabel(metric)
    
    # 값 표시
    for bar, value in zip(bars, values):
        height = bar.get_height()
        axes[i].text(bar.get_x() + bar.get_width()/2., height,
                    f'{value:.4f}', ha='center', va='bottom')

plt.tight_layout()
plt.show()
```
```python
# actual vs predicted
plt.figure(figsize=(10, 5))

plt.plot(y_test.values, label="Actual", marker="o", color="blue")
plt.plot(y_test_pred, label="Predicted", marker="x", color="red")

plt.title("Actual vs Predicted Values")
plt.ylabel("Disease Progression")
plt.legend()
plt.show()
```

```python
# Tree Structure
from sklearn.tree import plot_tree

plt.figure(figsize=(12, 12))
plot_tree(model, filled=True)
plt.show()
```
```python
plt.figure(figsize=(10, 7))

plot_tree(
    model,
    filled=True,
    max_depth=1,
    feature_names=feature_names,
)

plt.show()
```
```python
# Retraining (feat.Prunning)
models = {
    "DecisionTree": DecisionTreeRegressor(
        max_depth=3,          # 트리의 최대 깊이
        min_samples_split=5,  # 노트 분할 시, 최소한 5개의 샘플이 있어야 함
        min_samples_leaf=5,   # 리프 노드에는 최소한 5개의 샘플리 있어야 함
        random_state=RANDOM_STATE,
    )
}
model.fit(X_train, y_train)
model.score(X_train, y_train)
```
```plain text
1.0
```
```python
plt.figure(figsize=(15, 10))

plot_tree(
    model,
    filled=True,
    max_depth=2,  # 시각화 위해 제한
    feature_names=feature_names,
)

plt.show()
```
```python
# Feature Importance
_feature_importances = pd.Series(
    model.feature_importances_,
    index=feature_names,
)

_feature_importances
```
```plain text
age   0.0898
sex   0.0059
bmi   0.4386
bp    0.0852
s1    0.0446
s2    0.0442
s3    0.0565
s4    0.0595
s5    0.1329
s6    0.0428
dtype: float64
```
```python
_feature_importances.nlargest().plot(kind="barh")
```
```python
# Prediction
# 각 셋에 대한 예측
y_train_pred = model.predict(X_train)
y_valid_pred = model.predict(X_valid)
y_test_pred = model.predict(X_test)

# 모든 셋의 성능 계산
train_metrics = calculate_metrics(y_train, y_train_pred, 'Train')
valid_metrics = calculate_metrics(y_valid, y_valid_pred, 'Valid')
test_metrics = calculate_metrics(y_test, y_test_pred, 'Test')

# 결과를 DataFrame으로 정리
results_df = pd.DataFrame([train_metrics, valid_metrics, test_metrics])
results_df = results_df.set_index('Set')

print("=== Train/Valid/Test 셋 성능 비교 ===")
print(results_df.round(4))
```
```plain text
=== Train/Valid/Test 셋 성능 비교 ===
           R²       MSE    RMSE   MAPE
Set                                   
Train  1.0000    0.0000  0.0000 0.0000
Valid  0.2095 4330.7978 65.8088 0.3744
Test  -0.2659 6706.9101 81.8957 0.5430
```
```python
# 과적합 분석
print(f"\n=== 과적합 분석 ===")
train_valid_r2_diff = train_metrics['R²'] - valid_metrics['R²']
valid_test_r2_diff = valid_metrics['R²'] - test_metrics['R²']

print(f"Train-Valid R² 차이: {train_valid_r2_diff:.4f}")
print(f"Valid-Test R² 차이: {valid_test_r2_diff:.4f}")

if train_valid_r2_diff > 0.1:
    print("⚠️  과적합 가능성: 훈련 데이터와 검증 데이터 간 성능 차이가 큽니다.")
else:
    print("✅ 과적합 위험 낮음: 훈련 데이터와 검증 데이터 간 성능이 유사합니다.")

if valid_test_r2_diff > 0.1:
    print("⚠️  일반화 문제: 검증 데이터와 테스트 데이터 간 성능 차이가 큽니다.")
else:
    print("✅ 일반화 성능 양호: 검증 데이터와 테스트 데이터 간 성능이 유사합니다.")
```
```plain text
=== 과적합 분석 ===
Train-Valid R² 차이: 0.7905
Valid-Test R² 차이: 0.4754
⚠️  과적합 가능성: 훈련 데이터와 검증 데이터 간 성능 차이가 큽니다.
⚠️  일반화 문제: 검증 데이터와 테스트 데이터 간 성능 차이가 큽니다.
```

###

### 2. 여러 알고리즘 결과 확인

> (대상) Decision Tree, randomForest, Lasso, Ridge, XGB, LGBM
> 1. 위 알고리즘 중 가장 최적의 예측 성능을 보이는 알고리즘 확인 
>     - 현재 단계에서는 cross validation은 고려하지 않음  
> 2. 최적의 성능을 보이는 알고리즘의 feature importance 확인 
> 3. 최적의 모델에 대해서만 예측 성능 확인 (RMSE)

```python
models = {
    "DecisionTree": DecisionTreeRegressor(
        max_depth=4,              # 트리 최대 깊이 제한으로 과적합 방지
        min_samples_split=10,     # 노드 분할 시 최소 10개 샘플 필요
        min_samples_leaf=5,       # 리프 노드에는 최소 5개 샘플 필요
        random_state=RANDOM_STATE,
    ),
    "RandomForest": RandomForestRegressor(
        n_estimators=100,         # 100개의 의사결정 트리로 앙상블 구성
        max_depth=8,              # 개별 트리 최대 깊이 
        min_samples_split=5,      # 노드 분할 시 최소 5개 샘플 필요
        min_samples_leaf=2,       # 리프 노드에는 최소 2개 샘플 필요
        random_state=RANDOM_STATE,
    ),
    "Lasso": Lasso(
        alpha=0.01,               # 정규화 강도 (작을수록 덜 정규화)
        random_state=RANDOM_STATE,
    ),
    "Ridge": Ridge(
        alpha=0.1,                # 정규화 강도 (작을수록 덜 정규화)
        random_state=RANDOM_STATE,
    ),
    "XGBRegressor": XGBRegressor(
        n_estimators=100,         # 100개의 부스팅 라운드
        max_depth=6,              # 트리 최대 깊이
        learning_rate=0.1,        # 학습률 (작을수록 안정적이지만 느림)
        subsample=0.8,            # 샘플링 비율 (과적합 방지)
        colsample_bytree=0.8,     # 특성 샘플링 비율 (과적합 방지) 
        random_state=RANDOM_STATE,
    ),
    "LGBMRegressor": LGBMRegressor(
        n_estimators=100,         # 100개의 부스팅 라운드
        max_depth=6,              # 트리 최대 깊이
        learning_rate=0.1,        # 학습률
        subsample=0.8,            # 샘플링 비율
        colsample_bytree=0.8,     # 특성 샘플링 비율
        random_state=RANDOM_STATE,
        force_col_wise=True,      # 경고 메시지 방지
    ),
}
```
```python
# 모든 모델의 성능을 train, valid, test 셋에서 평가
results = {}

for name, model in models.items():
    model.fit(X_train, y_train)
    
    y_train_pred = model.predict(X_train)
    y_valid_pred = model.predict(X_valid)
    y_test_pred  = model.predict(X_test)
    
    # 성능 기록
    results[name] = {
        "Train_R2": r2_score(y_train, y_train_pred),
        "Valid_R2": r2_score(y_valid, y_valid_pred),
        "Test_R2":  r2_score(y_test, y_test_pred),
        "Train_RMSE": root_mean_squared_error(y_train, y_train_pred),
        "Valid_RMSE": root_mean_squared_error(y_valid, y_valid_pred),
        "Test_RMSE":  root_mean_squared_error(y_test, y_test_pred),
    }

results_df = pd.DataFrame(results).T
print("=== 모델별 성능 비교 (R² & RMSE) ===")
display(results_df.round(4))
```
```plain text
=== 모델별 성능 비교 (R² & RMSE) ===
	Train_R2	Valid_R2	Test_R2	Train_RMSE	Valid_RMSE	Test_RMSE
DecisionTree	0.6137	0.3196	0.3113	49.0068	61.0539	60.4061
RandomForest	0.8542	0.4615	0.4318	30.1061	54.3170	54.8663
Lasso	0.5185	0.5229	0.4514	54.7135	51.1284	53.9115
Ridge	0.5105	0.5201	0.4558	55.1620	51.2744	53.6941
XGBRegressor	0.9978	0.4334	0.3810	3.7360	55.7150	57.2664
LGBMRegressor	0.8889	0.3987	0.4168	26.2792	57.3986	55.5853
```

```python
# Metrics
# 모든 모델의 테스트 성능 기준으로 비교
print("\n=== 테스트 성능 기준 모델 비교 (R² & RMSE) ===")
print(results_df[["Test_R2", "Test_RMSE"]].sort_values(by="Test_R2", ascending=False))
```
```plain text
=== 테스트 성능 기준 모델 비교 (R² & RMSE) ===
               Test_R2  Test_RMSE
Ridge           0.4558    53.6941
Lasso           0.4514    53.9115
RandomForest    0.4318    54.8663
LGBMRegressor   0.4168    55.5853
XGBRegressor    0.3810    57.2664
DecisionTree    0.3113    60.4061
```

```python
# Best Model
# 테스트 성능 기준으로 최고 모델 선택
best_model_name = results_df["Test_R2"].idxmax()
best_model = models[best_model_name]

print(f"\n✅ Best Model: {best_model_name}")
print(f"Test R² : {results_df.loc[best_model_name, 'Test_R2']:.4f}")
print(f"Test RMSE : {results_df.loc[best_model_name, 'Test_RMSE']:.4f}")
```
```plain text
✅ Best Model: Ridge
Test R² : 0.4558
Test RMSE : 53.6941
```


```python
# Feature Importance
# Best Model의 feature importance 분석

if hasattr(best_model, "feature_importances_"):  # 트리 기반 모델
    feature_importances = pd.Series(
        best_model.feature_importances_,
        index=feature_names
    ).sort_values(ascending=False)
    
    print("\n=== Feature Importance ===")
    display(feature_importances)
    
    feature_importances.plot(kind="barh", figsize=(8, 6), title=f"{best_model_name} Feature Importance")
    plt.show()

elif hasattr(best_model, "coef_"):  # 선형 모델 (Ridge, Lasso)
    feature_importances = pd.Series(
        best_model.coef_,
        index=feature_names
    ).sort_values(key=abs, ascending=False)  # 절댓값 기준 정렬
    
    print("\n=== Coefficients (절댓값 기준 중요도) ===")
    display(feature_importances)
    
    feature_importances.plot(kind="barh", figsize=(8, 6), title=f"{best_model_name} Coefficients (Importance)")
    plt.show()
```
```plain text
=== Coefficients (절댓값 기준 중요도) ===
bmi    486.3793
s5     403.8977
bp     281.9268
sex   -201.4770
s3    -185.6912
s4     161.8174
s2    -125.0469
s6     111.1299
s1    -103.1486
age     39.9838
dtype: float64
```

```python
# Prediction
# Best Model로 예측 수행

# 데이터셋별 예측
y_train_pred = best_model.predict(X_train)
y_valid_pred = best_model.predict(X_valid)
y_test_pred  = best_model.predict(X_test)

# 성능 평가 함수 재사용
def calculate_metrics(y_true, y_pred, set_name):
    r2 = r2_score(y_true, y_pred)
    mse = mean_squared_error(y_true, y_pred)
    rmse = root_mean_squared_error(y_true, y_pred)
    mape = mean_absolute_percentage_error(y_true, y_pred)
    
    return {
        "Set": set_name,
        "R²": r2,
        "MSE": mse,
        "RMSE": rmse,
        "MAPE": mape,
    }

# 모든 셋 성능 계산
train_metrics = calculate_metrics(y_train, y_train_pred, "Train")
valid_metrics = calculate_metrics(y_valid, y_valid_pred, "Valid")
test_metrics  = calculate_metrics(y_test, y_test_pred, "Test")

# 결과 DataFrame 정리
prediction_results = pd.DataFrame([train_metrics, valid_metrics, test_metrics]).set_index("Set")

print("\n=== Best Model (Ridge) 성능 비교 ===")
display(prediction_results.round(4))
```
```plain text
=== Best Model (Ridge) 성능 비교 ===
R²	MSE	RMSE	MAPE
Set				
Train	0.5105	3042.8483	55.1620	0.4105
Valid	0.5201	2629.0688	51.2744	0.3042
Test	0.4558	2883.0570	53.6941	0.3663
```

```python
# Best Model로 성능 계산
print("\n=== 최적 모델 성능 요약 ===")
print(f"Best Model : {best_model_name}")
print(f"Train R² : {train_metrics['R²']:.4f}, RMSE : {train_metrics['RMSE']:.4f}, MAPE : {train_metrics['MAPE']*100:.2f}%")
print(f"Valid R² : {valid_metrics['R²']:.4f}, RMSE : {valid_metrics['RMSE']:.4f}, MAPE : {valid_metrics['MAPE']*100:.2f}%")
print(f"Test  R² : {test_metrics['R²']:.4f}, RMSE : {test_metrics['RMSE']:.4f}, MAPE : {test_metrics['MAPE']*100:.2f}%")

print(f"\n👉 최종 Test 성능 기준으로 {best_model_name} 모델이 선택되었습니다.")
```
```plain text
=== 최적 모델 성능 요약 ===
Best Model : Ridge
Train R² : 0.5105, RMSE : 55.1620, MAPE : 41.05%
Valid R² : 0.5201, RMSE : 51.2744, MAPE : 30.42%
Test  R² : 0.4558, RMSE : 53.6941, MAPE : 36.63%

👉 최종 Test 성능 기준으로 Ridge 모델이 선택되었습니다.
```


```python
# actual vs predicted visualization
plt.figure(figsize=(15, 5))

# 1. 산점도: 실제값 vs 예측값
plt.subplot(1, 2, 1)
plt.scatter(y_test, y_test_pred, alpha=0.6, color="red", edgecolor="k")
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], "b--", lw=2)
plt.xlabel("Actual")
plt.ylabel("Predicted")
plt.title(f"{best_model_name} - Actual vs Predicted (Test)\nR² = {test_metrics['R²']:.4f}, RMSE = {test_metrics['RMSE']:.2f}")

# 2. 라인 그래프: 시계열 순서 기준 실제 vs 예측 비교
plt.subplot(1, 2, 2)
plt.plot(y_test.values, label="Actual", marker="o", color="blue", alpha=0.7)
plt.plot(y_test_pred, label="Predicted", marker="x", color="red", alpha=0.7)
plt.title(f"{best_model_name} - Actual vs Predicted (Test)")
plt.ylabel("Disease Progression")
plt.legend()

plt.tight_layout()
plt.show()
```