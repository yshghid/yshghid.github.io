---
date : 2025-08-05
tags: ['2025-08']
categories: ['statistics']
bookHidden: true
title: "데이터 분석 #1 기초통계"
---

# 데이터 분석 #1 기초통계

#2025-08-05

---

### 1. 기술 통계

<mark>#1 IQR</mark> (p.34)

- IQR은? 가운데 50%의 거리.
- 그림 설명 
  
  <img width="265" height="219" alt="image" src="https://github.com/user-attachments/assets/0f803bf5-51b7-4a32-9a75-95672ecfe8be" />
  
  - 그림의 2,3: 각각 IQR의 1.5배 선, median 값 선.
  - 그림의 B: ⚬ 가 많으면 특이값이 많은 것.
  - 그림의 1,2,3: 1,2는 각각 IQR의 1.5배 선이라고 했는데 3과의 거리가 서로 다른 이유는? 1.5배 안쪽에 데이터들이 다 분포해서. 즉max가 1.5배보다 작아서.

###

<mark>#2 변이 계수(Coefficient of Variables)</mark>

- 평균치가 다른 집단 비교.
- 변이 계수 = 표준편차 / 평균.
- 값이 작을수록? 평균 가까이에 분포한다. 
- 평균 관점에서 퍼짐의 해석 -> 이상치에 민감하다. 
  - IQR은? 중앙값 관점에서 퍼짐의 해석 -> 이상치에 강건하다.

#

### 2. 추론 통계

<mark>#1 모집단과 표본집단</mark>

- 모집단의 모수(parameters): 관심의 대상이 되는 특성.
- 표본집단의 통계량(statistics): 표본을 대표하는 값.

###

<mark>#2 확률분포</mark> (이전자료 p.81)

<img width="330" height="212" alt="image" src="https://github.com/user-attachments/assets/b67f82c2-a31c-4e3e-b47c-b58f87c571f2" />

이산형 확률변수 X 
- 확률질량함수(PMF): f(x)=P[X=x] 
  - 시점(x)의 값이 확률.

연속형 확률변수 X 
- 확률밀도함수(PDF): ∫(a,b)f(x)=P[a≤X≤b]
  - 넓이(a~b)가 확률.

###

<mark>#3 확률의 3가지 정의</mark> (p.50)

  <img width="541" height="371" alt="image" src="https://github.com/user-attachments/assets/90eb43a6-ea84-4e15-83f5-cd79406c40ca" />

- 확률이란 어떤 일이 일어날 가능성을 숫자로 표현한 것.

- 라플라스의 정의
  - 동전을 던졌을 때 처럼 가능한 모든 경우가 서로 동등한 기회를 가지고 있다고 보고 사건이 일어나는 경우의 수를 전체 가능한 경우의 수로 나누기. 
  - 예를 들어 동전을 던질 때 앞면이 나올 확률은 두 가지 중 하나니까 1/2.

- 빈도주의적 정의
  - 동전을 100번 던졌는데 앞면이 18번 나왔다면 앞면이 나올 확률은 0.18이라고 추정하듯이 실험을 여러 번 해보는 방식

- 공리적 정의
  - 확률이 어떤 성질을 가져야 하는지(공리)를 정해놓고 그 성질을 만족하는 값을 확률이라고 정의. 
  - 전체 가능한 경우의 집합(표본공간)에 대한 확률은 무조건 1이어야 하고 어떤 사건도 확률이 0보다 작거나 1보다 클 수 없다. 서로 동시에 일어날 수 없는 두 사건이 있을 때 그 둘 중 하나라도 일어날 확률은 각 사건의 확률을 더한 것과 같다(상호배반적). 

###

<mark>#4 68-95-99.7의 법칙 (p.59)</mark>

  <img width="540" height="373" alt="image" src="https://github.com/user-attachments/assets/e9bed523-2623-4c3a-9471-0f45b1746c92" />

- 어떤 데이터를 측정하거나 관찰했을 때 그 값들이 평균을 중심으로 어떻게 퍼져 있는지 그 퍼짐 정도(모양?)가 분포이고
  - 종 모양의 곡선 형태, 평균을 중심으로 좌우 대칭인 형태이면 정규분포.
  - 정규분포에서 평균에서 '얼마나' 떨어져 있는지를 나타내는 지표가 표준편차. 

- 68-95-99.7의 법칙은 평균에서 몇 개의 표준편차 범위 안에 전체 데이터의 몇 퍼센트가 포함되는지를 알려주는 규칙.
  - 평균에서 ±1 표준편차 범위 내에는 전체 데이터의 약 68%가 들어온다. 예를 들어 평균이 100이고 표준편차가 15인 경우에서 100에서 15를 빼고 더한 값인 85부터 115까지의 범위에 전체 데이터의 68%가 몰려 있다.
  - ±2 표준편차 범위 안에는 약 95%의 데이터가 포함된다. 평균이 100이고 표준편차가 15이면 70부터 130 사이에 전체 데이터의 95%가 분포하고 있다.
  - ±3 표준편차 범위에서는 전체 데이터의 99.7%가 들어온다. 평균이 100이고 표준편차가 15인 경우 55부터 145 사이에 전체 데이터의 거의 전부인 99.7%가 존재한다. 

- Z-Score는 어떤 값이 평균에서 몇 개의 표준편차만큼 떨어져 있는지 수치.
  - 어떤 데이터가 평균보다 1 표준편차만큼 크면 Z-Score는 +1
  - 평균보다 2 표준편차만큼 작으면 Z-Score는 -2
  - 정규분포에서 Z-Score가 ±1인 값은 전체의 68%, ±2인 값은 95%, ±3인 값은 99.7%를 포함한다.

###

<mark>#5 불확실성과 표준오차</mark> (p.66)

- 동전을 100번 던져서 앞면이 몇 번 나오는지를 보는 실험을 반복하면 매번 정확히 50번씩 앞면이 나오지 않고 어떤 때는 47번 어떤 때는 52번처럼 약간의 오차가 생기는데 
  - 그 오차가 불확실성, 그 크기를 수학적으로 표현한 것이 표준편차. 

- 한 번의 시행에서 앞면이 나올 확률이 0.5이고, 그것의 표준편차가 0.5라고 했을 때, 100번을 시행하면 표준오차도 0.5에 100을 곱한 50이 될까? 시행횟수에 비례해서 오차의 크기도 똑같이 늘어날까?

  <img width="490" height="222" alt="image" src="https://github.com/user-attachments/assets/dac78dac-feff-4b86-bda5-bb0ae5c208e7" />

  - 여러 번 시행하면 평균값에 더 가까워지는 경향이 있기 때문에 시행 횟수가 많아질수록 오차는 작아진다.
  - 표준오차는 단순히 표준편차에 시행 횟수를 곱하는 것이 아니라, 표준편차를 루트 시행 횟수로 나눈 값으로 변한다. (제곱근의 법칙)

###
 
<mark>#6 제곱근의 법칙</mark> (p.67)

표본의 수가 많아지면 평균은 더 정확해지나?
- 표본이 많아질수록 그 평균은 실제 전체 집단의 평균 즉 모평균에 가까워진다
  - 얼마나 가까워졌는지 알려면 뭔가 수치로 표현할 수 있어야하는데 그게 '표준오차(Standard Error, SE)'이다.
  - 모집단의 표준편차를 알고 있다면 표준오차 SE는 = σ/√n
  - 모집단의 정보를 모른다면 표본의 표준편차 s를 대신 써서 SE = s/√n
    - 보면 표본의 수가 많아질수록 분모에 있는 n이 커지니까 전체 SE 값은 작아지고 평균이 모평균에 더 가까워진다

표본의 수가 늘어나면, 표준오차는 얼마나 줄어들까?
- '제곱근 √n'에 반비례해서 줄어든다
  - 표본의 수가 1일 때는 √1 = 1, 표본 수가 4면 √4 = 2, 9면 √9 = 3, 16이면 √16 = 4처럼 증가. 그래서 표본의 수가 4배여야 표준오차는 절반으로 줄어든다.
  - 그래서 우리가 어떤 평균을 구할 때 표본이 많으면 더 정밀해지는 건 맞지만 그 정밀도는 점점 천천히 좋아짐 마치 10명으로 평균을 구할 때보다 100명으로 구할 때 더 정확해지긴 하는데 그 차이가 그렇게 크진 않은데 왜냐하면 √10은 약 3.16이고, √100은 10이라서 약 3배 차이만 나니까.

68-95-99.7 법칙
- 표준편차가 5인 경우 평균 ± 1σ(표준편차)인 구간, 즉 45-55에는 약 68%의 확률로 데이터가 들어오고, 평균 ± 2σ인 40-60에는 약 95%의 확률로 들어온다는 규칙
- 어떤 동전 던지기 실험을 100번 반복했더니 평균이 50이고 표준오차가 5였다면?
  - 표본 평균이 40에서 60 사이에 있을 확률이 약 95%. (95% 신뢰구간)
    - 나는 평균이 50이라고 믿는데 95% 확률로 진짜 평균은 40~60 사이에 있을 거라고 신뢰가능한구간
- 표본의 크기가 커지면 신뢰구간은 어떻게 될까?
  - 표본이 커지면 표준오차가 줄어들고 신뢰구간도 좁아진다. 즉 우리가 더 많은 데이터를 가지고 있다면 진짜 평균을 더 좁은 범위로 정확히 예측할 수 있다.

###

<mark>#7 중심극한정리</mark> (p.71)

- 동전을 한 번 던지면 앞면이 나오거나 뒷면이 나오고 확률이 50%씩이다.

  <img width="502" height="260" alt="image" src="https://github.com/user-attachments/assets/d2d37f63-d7e4-4216-b463-a2584ff4256e" />

- <실험1> 동전을 5번 던지면
  - 앞면이 5번 중 2번일 수도 있고, 4번일 수도 있고, 완전히 랜덤처럼 보이고 히스토그램으로 그려보면 이상한 모양이 나오는데 표본수가 적어서그렇다.
  - 동전을 500번 던지고 히스토그램으로 그려보면 가운데 몰린 종 모양이 된다.

- <실험2> "동전을 5번 던지고, 앞면이 몇 번 나왔는지를 기록"을 한번 하는게아니라 수백 번 반복하고
  - 마찬가지로 "10번 던지고 기록", "100번 던지고 기록", "500번 던지고 기록"을 히스토그램으로 그리면 횟수가 많아질수록 분포가 가운데 몰린 정규분포 형태가된다. (중심극한정리)

- 중심극한정리
  - 어떤 분포에서 나오는 데이터든지 그 평균값들을 계속해서 모으면, 그 평균들의 분포는 (처음 데이터 자체가 정규분포가 아니더라도) 정규분포를 따른다. 

- 유의점
  - <실험2>에서 500번 던지고 기록한다는건 히스토그램에서 막대가 500개라는게 아니라 500개의 평균을 N번 그려서 막대는 N개이고 엄밀히는 "500번 던지고 N번 기록한다"이다.
  - <실험1>에서 500번 던진 히스토그램이 종 모양이되는건 중심극한정리를 보여주는게 아니라 이항분포의특성을 보여준다.

###

<mark>#8</mark> (p.75-76)

  <img width="498" height="208" alt="image" src="https://github.com/user-attachments/assets/3b679e2b-60b3-4b6a-9dd0-ff29d71eb4ba" />

1이 나온 횟수의 분포
- 주사위를 10번 던지면 1이 나올 수 있는 횟수 분포는 불규칙하고 히스토그램도 불규칙함.
- 주사위 던지기를 600번씩 반복해서 그때마다 '1이 나온 횟수'를 기록하고 그 결과를 모아 히스토그램을 그리면? 
  - 분포는 점점 종 모양 정규분포에 가까워진다. 
  - 평균(x축의)은 대략 전체 횟수의 1/6인 100 근처가 된다.(주사위의 한 면이 나올 확률이 1/6)

여론조사
- 여론조사에서 1,000명에게 물었더니 63%가 어떤 후보를 지지한다고 나왔다고 해보자. 다음에 또 1,000명을 조사하면 정확히 63%가 나올까? 

- <질문1> 재조사 시 동일한 결과는 보장하지 못하지만, 구간을 잡으면 신뢰할 수 있지 않을까?
  - 다음 조사에서 63%를 보장하지 못하지만 표준오차와 중심극한정리를 바탕으로 구간은 찾을수있다. 95% 신뢰수준이라면 “우리가 100번 이런 조사를 반복했을 때 95번은 진짜 값이 이 구간 안에 들어간다”고 말할 수 있다.

- <질문2> 샘플링 불확실성(uncertainty)을 수량화 즉 불확실성의 정량화?
  - 뽑은 표본은 항상 약간씩 다르고 오차가 존재하지만 그 오차가 얼마나 될지를 수식으로 계산해서 수량화할 수 있고 그게 불확실성의 정량적 추론.

- <질문3> 어떻게 구간을 잡을것인가?
  - 표본 비율 ± (임계값 × 표준오차)
  - 95% 신뢰구간을 구하고 싶다면? (z = 1.96 / p = 0.63, n = 1000일때)
    - SE = √(p(1-p)/n) = √(0.63 × 0.37 / 1000) ≈ 0.0153
    - 신뢰구간 = 0.63 ± 1.96 × 0.0153 ≈ (0.600, 0.660)
    - 진짜 지지율은 약 60.0% ~ 66.0% 사이일 것이다.

- <질문4> 95% 신뢰구간의 의미는?
  - 이 사람의 지지율이 95% 확률로 이 구간 안에 있다 (x)
  - 이런 방식으로 표본을 100번 추출해서 구간을 만들면 그 중 약 95번은 진짜 값(모비율)을 포함할 것이다. (표본이 아니라 추정 방법에 대한 신뢰)

###

<mark>#9 유의수준</mark> (p.87)

- 유의수준?
  - 내가 어느 정도 위험을 감수하고 기각할지를 정하는 수치.
  - α = 0.05 면 5% 정도는 내가 틀릴 수도 있다는 걸 감안하고 귀무가설을 기각하겠다 즉 실제로는 귀무가설이 맞는데도 5% 확률로 잘못 기각할 수 있다는 걸 받아들이겠다.
  - α = 0.01로 정했다면? 나는 실수할 확률을 1% 이하로 줄이겠다.

- 유의수준 & 신뢰도
  - α = 0.05는 95% 신뢰도. (95% 확률로 맞을것이다 x 95% 확률로 이 방법을 믿는다 o)
  - α = 0.01이면 99% 신뢰도 / α = 0.1이면 90% 신뢰도.

- 유의수준 & Z-값
  - Z-값: 정규분포에서 얼마나 극단적인 값이 나와야 기각할지를 결정하는 경계값
    - α = 0.1 → Z ≈ 1.645
    - α = 0.05 → Z ≈ 1.96
    - α = 0.01 → Z ≈ 2.575
  - 유의수준 α가 작아질수록 더 멀리 떨어진 극단적인 데이터가 나와야 귀무가설을 기각할 수 있다.


#

<mark>#궁금한점</mark>

#1 중심극한정리는 모든 분포에 다 유효한가? 그러면 분포가 없는 경우에도 유효한가?

- 중심극한정리가 적용되기 위해선 표본들이 서로 독립적으로 추출 / 각 표본은 같은 분포 / 모집단의 유한한 평균과 분산 / 표본의 크기가 충분히 클 것 (n ≥ 30)

- 모집단의 분포가 존재하지 않거나, 분포는 있지만 기댓값이나 분산이 무한하다면, 중심극한정리는 성립하지 않음.
  - Cauchy 분포: 평균, 분산이 정의되지 않아서 중심극한정리 성립 안 함
  - 무한 분산을 가진 분포 (heavy-tailed distributions) 적용 불가

#2 모집단에 분포가 존재한다의 의미?

- 기댓값(평균)과 분산 같은 통계량을 계산할 수 있다.

#3 평균이랑 분산을 계산못할수도있나?

- 평균이 너무 자주 바뀌면 분산이 무한할수있다(=계산할수없다).
- 예시: 가상의 시험에서 대부분 학생은 80~90점 사이인데 한번씩 누가 10만 점, 1억 점을 받는다. 말도 안 되게 큰 점수가 자주 나오면 평균을 구할 수는 있더라도 평균이 계속 바뀌고 평균 근처에서 얼마나 퍼져 있는지를 따지는 분산도 엄청 커져서 계산이 불가해진다.
 
#결론

중심극한정리는 "대부분 학생은 80~90점 사이인데 한번씩 누가 10만 점, 1억 점을 받는다" 같은 상황이나 Cauchy 분포만 아니면 모두 적용된다? (왜냐면 기댓값과 분산은 데이터만 있으면 무조건 계산 가능하므로 언급한 케이스가 아니면 모집단의 분포가 없기는 어려움)

#

