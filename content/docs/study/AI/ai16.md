---
date : 2025-08-06
tags: ['2025-08']
categories: ['statistics']
bookHidden: true
title: "데이터 분석 #2 Preprocessing"
---

# 데이터 분석 #2 Preprocessing

#2025-08-06

---

#1 머신러닝 프로세스 (p.25)

  <img width="499" height="260" alt="image" src="https://github.com/user-attachments/assets/80033421-9fe4-4651-8318-7b6151aa0533" />

- test data가 필요한 이유? 
  - hyperparameter tuning을 하면서 validation data는 모델이 이미 참고했다 즉 간접적으로 학습에 영향을 줬기 때문에 모델 학습 과정에서 한번도 보지않은 데이터가 필요함.

###

#2 Box plot (p.38)

<img width="575" height="331" alt="image" src="https://github.com/user-attachments/assets/ffc57e8d-53a9-4623-a501-1180efdf0a32" />

그림이 7개 차종에서 연비 플롯이라고 가정

- 투입됏을때 예측에 긍정적영향을 줄수잇는건?
  - 납작한애들. 두꺼우면 대표성이 떨어진다. 

- 2번에서 이상치들이 많으니까 잘 처리해야하고
- 만약 그림같지 않고 y축 높이가 다 비슷비슷했다면?
  - 이 변수들이 연비를 결정하는데 큰 영향을 못줌. 

###

#3 조건수 (p.52)

조건수(Condition number)?
- 어떤 계산 문제에서 입력값이 조금만 바뀌어도 결과가 얼마나 크게 바뀌는지를 나타내는 값(민감도 개념). 

조건수가 큰 경우? 
- 데이터에 조금의 노이즈나 오차만 있어도 결과가 달라져버려서 예측이나 계산을 할 때 신뢰하기 어려워진다.
- 머신러닝에서 여러 개의 입력값(피처)이 있을 때 이 피처들 사이에 스케일 차이가 너무 크거나 비슷한 성향을 가지면 조건수가 커진다. 
  - 예를 들어 Feature 1은 0에서 10 사이 값인데 Feature 2는 1,000에서 100,000 사이 값이라면, 둘을 같은 선형 모델에 넣었을 때 Feature 2의 작은 변화가 모델 결과에 훨씬 큰 영향을 줄 수 있어서 값의 Feature 2 쪽이 모델을 지배하게 됨.
  - 이를 방지하기 위해 Feature Scaling이 필요하다.


###

#4 Ideation bin counting (p.60)

Bin Counting?
- 범주형 변수의 값을 단순히 숫자나 벡터로 바꾸는 것이 아니라 그 값이 결과 변수(Target)와 어떤 관련이 있는지를 통계적으로 계산해서 숫자로 바꾸는 방식 

- 학생들의 이름이 있고 이 학생들이 시험을 통과했는지(합격/불합격)를 예측하려고 할 때?
  - 각 학생 이름을 그대로 피쳐로 쓰면(One-hot encoding) 100,000명의 학생 이름마다 새로운 열이 생기고 그러면 데이터가 너무 커지고 희소해져서 계산도 느려지고 모델도 과적합되기 쉬워진다.
  - Bin Counting은 이름마다 그동안 시험에 합격한 비율을 계산한다. 예를 들어 ‘김민수’라는 이름이 10번 나왔고 그 중 7번은 시험에 합격했다면, ‘김민수’라는 값은 0.7이라는 숫자로 바뀐다. 
    - 이름이라는 범주형 값을 단순히 분리해서 다루는 게 아니라, 그 값이 결과 변수와 얼마나 관련이 있는지를 반영한 숫자로 바꾸는 것. (이름 자체는 중요한 의미를 갖는게 아니니깐)

#

