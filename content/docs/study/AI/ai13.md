---
date : 2025-08-04
tags: ['2025-08']
categories: ['AI']
bookHidden: true
title: "RF-SHAP 연구 #2 SHAP 분석"
---

# RF-SHAP 연구 #2 SHAP 분석

#2025-08-04

---

### 1. Load data

```python
import pandas as pd
import numpy as np
import pickle
import joblib
import shap
import matplotlib.pyplot as plt
import seaborn as sns

#Load rf model
with open('/model/rf_model.pkl','rb') as f:
    rf_model = joblib.load(f)

#Load dataset
with open('/preprocessing/processed_data.pickle','rb') as f:
    preproc_data = pickle.load(f)

cytokine_df = preproc_data['cytokine_data']
patient_meta = preproc_data['metadata'] 
patient_info = preproc_data['clinical'] 
```

### 2. Model evaluation - feature importance

```python
# Get feature importances
importances = rf_model.feature_importances_
feature_names = cytokine_df.columns
feature_importances = pd.DataFrame({'feature': feature_names, 'importance': importances})

# Sort the feature importances in descending order and select the top 20
top_20_features = feature_importances.sort_values(by='importance', ascending=False).head(20)

# Plot the top 20 feature importances
plt.figure(figsize=(6, 10))
sns.barplot(x='importance', y='feature', data=top_20_features)
plt.show()
```

<img width="1802" height="1198" alt="image" src="https://github.com/user-attachments/assets/f8c04c4d-eaf1-4dad-9b6f-783ddf073f1b" />

### 3. Model evaluation - SHAP

```python
tree_explainer = shap.TreeExplainer(rf_model) ## TreeExplainer
shap_values = tree_explainer.shap_values(cytokine_df) ## SHAP Value
 
fig = plt.figure(figsize=(8,8))
fig.set_facecolor('white')
ax = fig.add_subplot()
#Plot SHAP as sever probability
shap.summary_plot(shap_values[1], cytokine_df, 
                  cmap='bwr', 
                  show=False, 
                 plot_type='dot')
ax.set_xlabel('SHAP Value')
ax.set_title('SHAP Dot Plot', fontsize=20)
plt.show()
```

<img width="1808" height="1388" alt="image" src="https://github.com/user-attachments/assets/bf1fcf5f-3469-429b-bb7b-cc7491d64682" />

```python
shap_df = pd.DataFrame(shap_values[1],columns = cytokine_df.columns)
shap_df.index = cytokine_df.index
shap_df
```
```plain text
	CXCL9	LIF	CXCL11	IL25	IL12B	IL10	IL13	IL11	IL15	PTX3	...	FURIN	FSTL3	FLT3LG	FAP	FABP4	F3	ESM1	ERBB3	ENPP2	WFDC2
Healthy1	0.0	0.001667	0.0	0.0	-0.008333	0.0	0.0	-0.003333	0.0	0.0	...	0.0	-0.011667	-0.005	-0.013333	0.0	-0.006667	0.0	0.0	0.0	-0.005
Healthy2	0.0	-0.008333	0.0	0.0	0.001667	0.0	0.0	-0.013333	0.0	0.0	...	0.0	-0.011667	-0.005	-0.013333	0.0	-0.006667	0.0	0.0	0.0	-0.005
Patient1_1	0.0	0.001667	0.0	0.0	0.001667	0.0	0.0	-0.013333	0.0	0.0	...	0.0	-0.011667	-0.005	-0.013333	0.0	-0.006667	0.0	0.0	0.0	-0.005
Patient1_2	0.0	0.001667	0.0	0.0	0.001667	0.0	0.0	-0.013333	0.0	0.0	...	0.0	-0.011667	0.005	-0.013333	0.0	-0.006667	0.0	0.0	0.0	-0.005
Patient1_5	0.0	-0.008333	0.0	0.0	0.001667	0.0	0.0	-0.003333	0.0	0.0	...	0.0	-0.011667	-0.005	-0.013333	0.0	-0.006667	0.0	0.0	0.0	-0.005
Patient1_6	0.0	-0.008333	0.0	0.0	0.001667	0.0	0.0	0.006667	0.0	0.0	...	0.0	-0.011667	-0.005	0.006667	0.0	0.003333	0.0	0.0	0.0	-0.005
Patient2_1	0.0	0.001667	0.0	0.0	0.001667	0.0	0.0	0.006667	0.0	0.0	...	0.0	0.008333	0.005	0.006667	0.0	0.003333	0.0	0.0	0.0	0.005
Patient2_2	0.0	0.001667	0.0	0.0	0.001667	0.0	0.0	0.006667	0.0	0.0	...	0.0	0.008333	0.005	0.006667	0.0	0.003333	0.0	0.0	0.0	0.005
Patient2_3	0.0	0.001667	0.0	0.0	0.001667	0.0	0.0	0.006667	0.0	0.0	...	0.0	0.008333	0.005	0.006667	0.0	-0.006667	0.0	0.0	0.0	0.005
Patient2_4	0.0	0.001667	0.0	0.0	0.001667	0.0	0.0	0.006667	0.0	0.0	...	0.0	0.008333	0.005	0.006667	0.0	0.003333	0.0	0.0	0.0	0.005
Patient2_5	0.0	0.001667	0.0	0.0	0.001667	0.0	0.0	0.006667	0.0	0.0	...	0.0	0.008333	-0.005	0.006667	0.0	-0.006667	0.0	0.0	0.0	-0.005
11 rows × 166 columns
```

### 4. UMAP

```python
import umap.umap_ as umap
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

reducer = umap.UMAP()
embedding = reducer.fit_transform(shap_df)

import matplotlib.pyplot as plt

# Extract UMAP coordinates and labels
umap_x = embedding[:, 0]
umap_y = embedding[:, 1]
```

### 5. DBSCAN

```python
from sklearn.cluster import DBSCAN

# Initialize DBSCAN
dbscan = DBSCAN(eps=0.8, min_samples=3) # partial data is too small to set min_sample=20.

# Fit to UMAP data and get cluster labels
clusters = dbscan.fit_predict(embedding)

embedding, clusters
```
```plain text
(array([[16.714314 , -2.0475426],
        [17.279623 , -2.4140635],
        [16.705837 , -3.002305 ],
        [17.19955  , -1.342096 ],
        [17.838465 , -2.021136 ],
        [18.537838 , -1.5079662],
        [21.44188  , -2.1259143],
        [21.123413 , -3.075382 ],
        [20.373632 , -3.0233152],
        [21.83852  , -2.899527 ],
        [20.435349 , -2.2629123]], dtype=float32),
 array([ 0,  0, -1, -1,  0, -1, -1,  1,  1,  1,  1]))
```

### 6. Save result

```python
analyzed_data = {}
analyzed_data['shap_value'] = shap_df
analyzed_data['umap'] = embedding
analyzed_data['cluster'] = clusters

with open('/analysis/analyzed_data.pickle','wb') as f:
    pickle.dump(analyzed_data,f)
```

### 7. Hierarchical dendrogram

```python
from matplotlib.patches import Patch

patient_meta.index = patient_meta.Sample

label_colors_1 = {
   
    'sDP': 'red',
    'mDP': 'orange',
    'sRP': 'purple',
    'mRP': 'green',
}
label_colors_2 = {
   
    4.0: 'orange',
    5.0: 'orange',
    7.0: 'red',
    8.0:'red'
}
label_colors_3 = {
    'DP' :'red',
    'RP' : 'blue',
}

col_colors_1 = patient_meta.Detailed_PPG.map(label_colors_1)
col_colors_2 = patient_meta.Severity.map(label_colors_2)
col_colors_3 = patient_meta.PPG.map(label_colors_3)
col_colors = pd.DataFrame({'PPGs': col_colors_1,'severity':col_colors_2,})
legend_elements_1 = [Patch(facecolor=color, label=label) for label, color in label_colors_1.items()]
legend_elements_2 = [Patch(facecolor=color, label=label) for label, color in label_colors_2.items()]
```
```python
from sklearn.preprocessing import StandardScaler
df = shap_df[~shap_df.index.str.contains('Healthy')]
df_filtered = df.loc[:, (df != 0).any(axis=0)]

scaler = StandardScaler()

try:
    df_scaled = scaler.fit_transform(df_filtered)
    df_scaled = pd.DataFrame(df_scaled, index=df_filtered.index, columns=df_filtered.columns)
except FloatingPointError as e:
    print(f"Error during scaling: {e}")
```
```python
g= sns.clustermap(df_scaled.T, cmap='coolwarm', figsize=(20, 27), col_colors=col_colors)

legend_ax_1 = g.fig.add_axes([1.05, 0.60, 0.3, 0.2])
legend_ax_2 = g.fig.add_axes([1.05, 0.48, 0.3, 0.2])



legend_ax_1.legend(handles=legend_elements_1, title="PPGs", loc="center", fontsize = 15)
legend_ax_1.axis('off')  # Turn off the axis

legend_ax_2.legend(handles=legend_elements_2, title="Sample Severity", loc="center", fontsize = 15)
legend_ax_2.axis('off')  # Turn off the axis

plt.show()
```

<img width="2292" height="1466" alt="image" src="https://github.com/user-attachments/assets/865246b0-f54b-4195-9b2d-ae6fe0231203" />


#

