---
date : 2025-06-26
tags: ['2025-06']
categories: ['AI']
bookHidden: true
title: "#2 Explainable AI"
bookComments: true
---

# #2 Explainable AI

#2025-06-26

---

### 1. Explainable AIë€?

Explainable AIëŠ” ì¸ê³µì§€ëŠ¥(AI) ë˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹(ML) ëª¨ë¸ì´ ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ íŠ¹ì • ê²°ê³¼ë¥¼ ë„ì¶œí–ˆëŠ”ì§€ ì‚¬ëŒì´ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì„¤ëª…í•˜ëŠ” ê¸°ìˆ ê³¼ ë°©ë²•ë¡ .

### 2. XAI ê¸°ë²• ë¶„ë¥˜

ëª¨ë¸ êµ¬ì¡°	
- Intrinsic:	ëª¨ë¸ ìì²´ê°€ ì„¤ëª… ê°€ëŠ¥í•œ êµ¬ì¡° (ì˜ˆ: ì˜ì‚¬ê²°ì •ë‚˜ë¬´, ì„ í˜•íšŒê·€ ë“±)
- Post-hoc:	ëª¨ë¸ í•™ìŠµ í›„ ë³„ë„ë¡œ ì„¤ëª… ìƒì„± (ì˜ˆ: SHAP, LIME)
ëŒ€ìƒ
- Global:	ì „ì²´ ëª¨ë¸ì˜ ì‘ë™ ì›ë¦¬ë¥¼ ì„¤ëª…
- Local:	íŠ¹ì • ìƒ˜í”Œì˜ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì„¤ëª…

### 3. ì£¼ìš” Post-hoc ì„¤ëª… ê¸°ë²•

LIME (Local Interpretable Model-Agnostic Explanations): ì£¼ë³€ ì…ë ¥ì„ ëœë¤í•˜ê²Œ ìƒì„±í•˜ê³ , ë‹¨ìˆœ ëª¨ë¸(ì„ í˜• íšŒê·€ ë“±)ì„ í•™ìŠµí•´ ê·¼ì‚¬

SHAP (SHapley Additive exPlanations): ê²Œì„ ì´ë¡ ì˜ ìƒ¤í”Œë¦¬ ê°’ ê¸°ë°˜
- ê° í”¼ì²˜ê°€ ê¸°ì—¬í•œ ì •ë„ë¥¼ ê³µì •í•˜ê²Œ ë¶„ë°°í•˜ì—¬ ì„¤ëª…
  - ì¥ì : ìˆ˜í•™ì ìœ¼ë¡œ ì •ë‹¹ì„± í™•ë³´, ì¼ê´€ëœ ì„¤ëª… ì œê³µ
  - ë‹¨ì : ê³„ì‚° ë¹„ìš© í¼

Permutation Importance: ì…ë ¥ í”¼ì²˜ë¥¼ ë¬´ì‘ìœ„ë¡œ ì„ì€ í›„ ì˜ˆì¸¡ ì„±ëŠ¥ ê°ì†Œ ì •ë„ ì¸¡ì •
- ì˜ˆì¸¡ ì„±ëŠ¥ì´ í¬ê²Œ ê°ì†Œí•˜ë©´, ì¤‘ìš”í•œ í”¼ì²˜ë¡œ íŒë‹¨

Saliency Maps (ì´ë¯¸ì§€ ë¶„ì•¼)

### 4. SHAPì´ë€?

ê° feature(ì…ë ¥ ë³€ìˆ˜)ê°€ ëª¨ë¸ì˜ ì˜ˆì¸¡ê°’ì— ì–¼ë§ˆë‚˜ ê¸°ì—¬í–ˆëŠ”ì§€ ì •ëŸ‰ì ìœ¼ë¡œ ê³„ì‚°.

ì›ë˜ëŠ” í˜‘ë ¥ ê²Œì„ ì´ë¡ ì—ì„œ
- ì—¬ëŸ¬ í”Œë ˆì´ì–´ê°€ íŒ€ì„ ì´ë¤„ ë³´ìƒì„ ë°›ì•˜ì„ ë•Œ, ê° í”Œë ˆì´ì–´ê°€ ì „ì²´ ë³´ìƒì— ì–¼ë§ˆë‚˜ ê¸°ì—¬í–ˆëŠ”ì§€ë¥¼ ê³„ì‚°í•˜ëŠ” ë°©ë²•ì¸ë°
- ì˜ˆì‹œë¡œ
  - ì¶•êµ¬ ê²Œì„ì„ í•˜ì—¬ íŒ€ ì „ì²´ê°€ 100ì ì„ íšë“í–ˆë‹¤ê³  ê°€ì •
  - íŒ€ì—ëŠ” ì„ ìˆ˜ A, B, Cê°€ ìˆë‹¤
    - ëˆ„ê°€ ë” ì¤‘ìš”í•œ ì„ ìˆ˜ì¸ì§€, ê° ì„ ìˆ˜ê°€ ì ìˆ˜ì— ì–¼ë§ˆë‚˜ ê¸°ì—¬í–ˆëŠ”ì§€ë¥¼ êµ¬í•˜ë ¤ë©´?
    - ìƒ¤í”Œë¦¬ ê°’ì€ ë‹¤ìŒ ìˆœì„œë¡œ ê¸°ì—¬ë„ë¥¼ í‰ê°€:
      1) ê°€ëŠ¥í•œ ëª¨ë“  ìˆœì—´ì„ ê³ ë ¤
      2) ê° ìˆœì—´ì—ì„œ A, B, Cê°€ ì–¸ì œ íŒ€ì— í•©ë¥˜í–ˆëŠ”ì§€
      3) ê·¸ ì„ ìˆ˜ê°€ íŒ€ì— ë“¤ì–´ì˜¤ë©´ì„œ ì–¼ë§ˆë‚˜ ì ìˆ˜ê°€ ëŠ˜ì—ˆëŠ”ì§€ í™•ì¸ -> ê° ì„ ìˆ˜ì˜ ì´ í‰ê·  ê¸°ì—¬ë„ë¥¼ â€œìƒ¤í”Œë¦¬ ê°’â€ì´ë¼ê³  í•¨.

ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì—ì„œ:
- ê° featureê°€ í”Œë ˆì´ì–´ ì—­í• ì„ í•¨
  - ëª¨ë¸ì˜ ì˜ˆì¸¡ê°’ì´ íŒ€ì´ ì–»ì€ ì ìˆ˜ì´ê³ 
    - SHAPì€ "ì´ ì˜ˆì¸¡ê°’ì´ ë‚˜ì˜¤ëŠ” ë°, ê° featureê°€ ì–¼ë§ˆë‚˜ ê¸°ì—¬í–ˆëŠ”ê°€?"ë¥¼ ê³„ì‚°.
    - ì˜ˆë¥¼ ë“¤ì–´ ëª¨ë¸ì´ ì–´ë–¤ í™˜ìì˜ ì‚¬ë§ í™•ë¥ ì„ 80%ë¼ê³  ì˜ˆì¸¡í–ˆì„ ë•Œ
      - ë‚˜ì´: +15%
      - í¡ì—° ì—¬ë¶€: +10%
      - í˜ˆì••: +5%
      - ê¸°ë³¸ê°’: 50%
        - ì´í•©: 50% + 15 + 10 + 5 = 80%
- ì¦‰ SHAPì€ ì˜ˆì¸¡ê°’ì„ base value + ê° featureì˜ ê¸°ì—¬ë„ë¡œ ë¶„í•´í•´ì¤€ë‹¤.

ìˆ˜í•™ì  ê³„ì‚° ê³¼ì •:
- 3ê°œì˜ feature (A, B, C)ì—ì„œ ê°€ëŠ¥í•œ feature ì¡°í•©:
  - {}, {A}, {B}, {C}, {A,B}, {A,C}, {B,C}, {A,B,C}
  - SHAPì€ ëª¨ë“  ì¡°í•©ì— ëŒ€í•´,
    - í•´ë‹¹ featureê°€ ë“¤ì–´ê°”ì„ ë•Œì™€ ì•ˆ ë“¤ì–´ê°”ì„ ë•Œ ì˜ˆì¸¡ê°’ ì°¨ì´ë¥¼ ê³„ì‚°
      - ì´ë¥¼ í‰ê· í•˜ì—¬ ê¸°ì—¬ë„(ìƒ¤í”Œë¦¬ ê°’)ë¡œ ì„¤ì •í•œë‹¤.
        - ë‹¨ì : ì¡°í•© ìˆ˜ê°€ 2^Mì´ë¼ì„œ feature ìˆ˜ê°€ ë§ìœ¼ë©´ ê³„ì‚°ëŸ‰ í­ë°œ

### 5. RFì˜ feature importanceì™€ì˜ ì°¨ì´?

| í•­ëª© | Random Forest Feature Importance | SHAP |
| --- | --- | --- |
| ê¸°ë°˜ ê°œë… | ëª¨ë¸ êµ¬ì¡° ê¸°ë°˜ (gini ê°ì†Œ ë“±) | ê²Œì„ ì´ë¡  ê¸°ë°˜ (ìƒ¤í”Œë¦¬ ê°’) |
| ì„¤ëª… ë°©ì‹ | ì „ì²´ ëª¨ë¸ ìˆ˜ì¤€ (global) | ì „ì²´ + ê°œë³„ ìƒ˜í”Œ ìˆ˜ì¤€ (global + local) |
| ìŒ/ì–‘ êµ¬ë¶„ | ì—†ìŒ (0 ì´ìƒ, í¬ê¸°ë§Œ ì œê³µ) | ìˆìŒ (ì–‘ìˆ˜: ì˜ˆì¸¡ â†‘, ìŒìˆ˜: ì˜ˆì¸¡ â†“) |
| ìƒí˜¸ì‘ìš© ê³ ë ¤ | ë¶€ë¶„ì ìœ¼ë¡œë§Œ ê³ ë ¤ | ì¼ë¶€ ê³ ë ¤ ê°€ëŠ¥ (íŠ¹ì • SHAP variant) |
| ì •í™•ì„± | ëŒ€ëµì ì¸ ì˜í–¥ë„ | ìˆ˜í•™ì ìœ¼ë¡œ ë³´ì¥ëœ ê¸°ì—¬ë„ |
| ë‹¨ì  | bias ìˆìŒ (ë²”ì£¼ ìˆ˜ ë§ì€ ë³€ìˆ˜ ì„ í˜¸ ë“±) | ëŠë¦´ ìˆ˜ ìˆìŒ, ê³„ì‚° ë¹„ìš© ë†’ìŒ |

Random Forestì˜ Feature Importance
- ì‘ë™ ë°©ì‹
- RFëŠ” ë‹¤ìˆ˜ì˜ ê²°ì •íŠ¸ë¦¬ë¥¼ ë§Œë“¤ê³ 
  - ê° íŠ¸ë¦¬ì—ì„œ ì–´ë–¤ featureë¥¼ ìª¼ê°¤ ë•Œ ì˜ˆì¸¡ ì„±ëŠ¥ì´ ì–¼ë§ˆë‚˜ ì¢‹ì•„ì¡ŒëŠ”ì§€(ex: Gini impurity ê°ì†ŒëŸ‰)ë¥¼ ê¸°ë¡.
  - ì—¬ëŸ¬ íŠ¸ë¦¬ì—ì„œ í•´ë‹¹ featureê°€ ì–¼ë§ˆë‚˜ ìì£¼, ì–¼ë§ˆë‚˜ í¬ê²Œ ì„±ëŠ¥ í–¥ìƒì— ê¸°ì—¬í–ˆëŠ”ì§€ë¥¼ í‰ê· í•˜ì—¬ importanceë¡œ ê³„ì‚°
- ë‹¨ì 
  - ë²”ì£¼ ìˆ˜ê°€ ë§ì€ featureê°€ ìœ ë¦¬ (ë” ì˜ ìª¼ê°¤ í™•ë¥  ë†’ìŒ)
  - ìƒí˜¸ì‘ìš© ê³ ë ¤ ë¶€ì¡±
  - ì™œ ì¤‘ìš”í–ˆëŠ”ì§€ ì„¤ëª… ë¶ˆê°€
  - ê°œë³„ ìƒ˜í”Œ ì„¤ëª… ë¶ˆê°€

SHAPì˜ Feature Importance
- SHAPì€ ë‹¤ìŒì„ ì œê³µ:
  - ê° featureê°€ ê°œë³„ ì˜ˆì¸¡ê°’ì— ì–¼ë§ˆë‚˜ ì˜í–¥ì„ ì¤¬ëŠ”ì§€. ì–‘/ìŒ í¬í•¨.
  - ëª¨ë“  ìƒ˜í”Œì— ëŒ€í•´ ê³„ì‚°í•œ í›„ í‰ê· ì„ ë‚´ë©´, global feature importanceê°€ ë¨.
  - ì™œ ì¤‘ìš”í–ˆëŠ”ì§€ ìƒ˜í”Œë³„ë¡œ ì¶”ì  ê°€ëŠ¥

ë¨¼ì†Œë¦°ì§€ ì´í•´ ì•ˆë¼ì„œ.. ì§ê´€ì  ì˜ˆì‹œ.
- Random Forestì˜ Feature ImportanceëŠ” ëˆ„ê°€ ê²°ì • ê³¼ì •ì— ìì£¼ ì°¸ì—¬í–ˆëŠ”ì§€ ë³¸ë‹¤, ë§ˆì¹˜ íšŒì˜ì—ì„œ ë§ì´ ë§í•œ ì‚¬ëŒì„ ì¤‘ìš”í•œ ì‚¬ëŒì´ë¼ê³  ë³´ëŠ” ê²ƒê³¼ ê°™ìŒ.
- SHAPì˜ Feature ImportanceëŠ” ëˆ„ê°€ ì‹¤ì œë¡œ ì˜ì‚¬ê²°ì • ê²°ê³¼ì— ì˜í–¥ì„ ì¤¬ëŠ”ì§€ ë³¸ë‹¤, ë§ˆì¹˜ íšŒì˜ì—ì„œ ì‹¤ì œë¡œ íˆ¬í‘œë¥¼ ë°”ê¿”ë†“ì€ ì‚¬ëŒì„ ì¤‘ìš”í•œ ì‚¬ëŒìœ¼ë¡œ ë³´ëŠ” ê²ƒê³¼ ê°™ìŒ.
  ì¦‰ RFëŠ” ì°¸ì—¬ íšŸìˆ˜, SHAPì€ ê²°ê³¼ì— ê¸°ì—¬í•œ ì •ë„ë¥¼ ë³´ëŠ” ê±°ì˜ˆìš”.

ëª¨ë¸ ì˜ˆì‹œ
- ëª¨ë¸ì´ í™˜ìì˜ ì‚¬ë§ í™•ë¥ ì„ ì˜ˆì¸¡í• ë•Œ
  - í™˜ì ì…ë ¥: ë‚˜ì´ 80ì„¸ / ì²´ì˜¨ 39ë„ / í˜ˆì•• 100 / í¡ì—° ì—¬ë¶€ Yes
- Random ForestëŠ”?
  - 100ê°œì˜ íŠ¸ë¦¬ì—ì„œ ë‚˜ì´ë¡œ 70ë²ˆ ìª¼ê°¬ / ì²´ì˜¨ìœ¼ë¡œ 10ë²ˆ ìª¼ê°¬ / í˜ˆì••ìœ¼ë¡œ 15ë²ˆ ìª¼ê°¬ / í¡ì—° ì—¬ë¶€ë¡œ 5ë²ˆ ìª¼ê°¬
    - ê·¸ë˜ì„œ ë‚˜ì´ê°€ ì œì¼ ì¤‘ìš”í•˜ë‹¤ê³  íŒë‹¨ (ê·¼ë° â€˜ë‚˜ì´â€™ê°€ ì˜ˆì¸¡ê°’ì— ì–¼ë§ˆë‚˜ ì˜í–¥ì„ ì¤¬ëŠ”ì§€ëŠ” ëª¨ë¦„)
- SHAPì€?
  - ì´ í™˜ìì˜ ì˜ˆì¸¡ê°’ì€ 0.80 (ê¸°ë³¸ê°’ì€ 0.50)
  - ê¸°ì—¬ë„: ë‚˜ì´ +0.20 / ì²´ì˜¨: +0.10 / í¡ì—°: +0.08 / í˜ˆì••: -0.08
    - í•©ì¹˜ë©´: 0.50 + 0.20 + 0.10 + 0.08 - 0.08 = 0.80
    - ì¦‰ SHAPì€ ì˜ˆì¸¡ê°’ì´ ì™œ 0.80ì´ ë˜ì—ˆëŠ”ì§€ ëª…í™•í•˜ê²Œ ì„¤ëª….

í•˜ë‚˜ì˜ featureë¼ë„ ê°’ì´ ë†’ì„ ë•Œ ì–´ë–¤ ê²½ìš°ì—” ì˜ˆì¸¡ì„ â†‘ ì–´ë–¤ ê²½ìš°ì—” ì˜ˆì¸¡ì„ â†“ ì‹œí‚¬ ìˆ˜ ìˆë‹¤ ê·¸ë¦¬ê³  ì´ ë³µì¡í•œ ê´€ê³„ë¥¼ ì‹œê°ì ìœ¼ë¡œ í•œ ë²ˆì— ë³´ì—¬ì£¼ëŠ” ê²ƒì´ ë°”ë¡œ SHAPì˜ summary plot.

'ì²´ì˜¨' featureë¡œ ì˜ˆì‹œ.

```plain text
      ì²´ì˜¨  â”€â”€â”€ğŸ”µğŸ”µğŸ”µğŸ”´ğŸ”´ğŸ”´ğŸ”´ğŸ”´ğŸ”µğŸ”µâ”€â”€â–¶
          (SHAP ê°’: ìŒìˆ˜~ì–‘ìˆ˜)
```

ğŸ”´: ì²´ì˜¨ì´ ë†’ì€ ìƒ˜í”Œë“¤
- ì˜¤ë¥¸ìª½(+)ì— ìœ„ì¹˜í•œ ğŸ”´: ì²´ì˜¨ì´ ë†’ì•„ì„œ ì˜ˆì¸¡ê°’(ì‚¬ë§ í™•ë¥ )ì´ ì¦ê°€
- ì™¼ìª½(-)ì— ìœ„ì¹˜í•œ ğŸ”´: ì²´ì˜¨ì´ ë†’ì§€ë§Œ ì˜ˆì¸¡ê°’ì€ ì˜¤íˆë ¤ ê°ì†Œ
ğŸ”µ: ì²´ì˜¨ì´ ë‚®ì€ ìƒ˜í”Œë“¤
- ì˜¤ë¥¸ìª½(+)ì— ìœ„ì¹˜í•œ ğŸ”µ: ì²´ì˜¨ì´ ë‚®ì§€ë§Œ ì˜ˆì¸¡ê°’ì€ ì¦ê°€
- ì™¼ìª½(-)ì— ìœ„ì¹˜í•œ ğŸ”µ: ì²´ì˜¨ì´ ë‚®ê³  ì˜ˆì¸¡ê°’ë„ ë‚®ìŒ

ìƒ˜í”Œë§ˆë‹¤ ê¸°ì—¬ë„ì™€ ë°©í–¥ì´ ë‹¤ë¥¸ ì´ìœ 
- SHAPì€ ëª¨ë“  featureë¥¼ "ë‹¤ë¥¸ featureì™€ í•¨ê»˜ ì¼ì„ ë•Œ"ì˜ ì˜í–¥ë ¥ì„ ë”°ì§„ë‹¤.
  - ê·¸ë˜ì„œ "ì¡°ê±´ë¶€ ê¸°ì—¬ë„"ë¼ê³ ë„ í•¨.
    - ì¦‰ ì²´ì˜¨ì´ ë†’ì•„ë„ ì Šì€ í™˜ìë¼ë©´ ì‚¬ë§ í™•ë¥ ì´ ë‚®ì„ ìˆ˜ ìˆê³  ì²´ì˜¨ì´ ë‚®ì•„ë„ ê¸°ì €ì§ˆí™˜ì´ ì‹¬í•œ í™˜ìë¼ë©´ ì‚¬ë§ í™•ë¥ ì´ ë†’ì„ ìˆ˜ ìˆë‹¤
    - ì´ëŸ° ë³µì¡í•œ ìƒí˜¸ì‘ìš©ì„ ë°˜ì˜í•˜ë‹¤ë³´ë‹ˆ ê°™ì€ featureë¼ë„ ìƒ˜í”Œë§ˆë‹¤ ê¸°ì—¬ ë°©í–¥ì´ ë‹¤ë¥¼ ìˆ˜ ìˆë‹¤. 

### 6. ê²°ë¡ 

ê°™ì€ featureë¼ë„, ìƒ˜í”Œë§ˆë‹¤ ë‹¤ë¥¸ ìƒí™©(context)ì´ê¸° ë•Œë¬¸ì—, ê·¸ featureì˜ ì˜ˆì¸¡ì— ëŒ€í•œ ê¸°ì—¬ ë°©í–¥(â†‘ ë˜ëŠ” â†“)ì´ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆë‹¤.

ì˜ˆë¥¼ ë“¤ì–´
- ë‚˜ì´ = 70ì¸ ì‚¬ëŒì´ë¼ë„
  - ë‹¤ë¥¸ feature(í˜ˆì••, ì²´ì˜¨, ê¸°ì €ì§ˆí™˜ ë“±)ì— ë”°ë¼
    - ì–´ë–¤ ìƒ˜í”Œì—ì„  ì‚¬ë§ í™•ë¥  â†‘ì— ê¸°ì—¬ (ì–‘ì˜ SHAP ê°’)
    - ì–´ë–¤ ìƒ˜í”Œì—ì„  ì‚¬ë§ í™•ë¥  â†“ì— ê¸°ì—¬ (ìŒì˜ SHAP ê°’)
      - ê·¸ë˜ì„œ SHAP summary plotì—ì„œ ê°™ì€ featureì˜ ğŸ”´ì™€ ğŸ”µ ì ë“¤ì´ ì¢Œìš°ë¡œ í©ì–´ì ¸ ìˆë‹¤.

ì •ë¦¬í•˜ë©´?
- SHAPì€ "ê°™ì€ feature"ê°€ "ë‹¤ì–‘í•œ ë§¥ë½ì—ì„œ ì–´ë–»ê²Œ ì‘ìš©í•˜ëŠ”ê°€"ë¥¼ ë³´ì—¬ì£¼ëŠ” ë„êµ¬ì´ë‹¤.

### 7. ì˜ˆì‹œ ì½”ë“œ

```python
import pandas as pd
import numpy as np
import pickle
import joblib
import shap
import matplotlib.pyplot as plt
import seaborn as sns
```
```python
#Load rf model
with open('/model/rf_model.pkl','rb') as f:
    rf_model = joblib.load(f)

#Load dataset
with open('/preprocessing/processed_data.pickle','rb') as f:
    preproc_data = pickle.load(f)

cytokine_df = preproc_data['cytokine_data']
patient_meta = preproc_data['metadata'] 
patient_info = preproc_data['clinical'] 
```
```python
# Get feature importances
importances = rf_model.feature_importances_
feature_names = cytokine_df.columns
feature_importances = pd.DataFrame({'feature': feature_names, 'importance': importances})

# Sort the feature importances in descending order and select the top 20
top_20_features = feature_importances.sort_values(by='importance', ascending=False).head(20)

# Plot the top 20 feature importances
plt.figure(figsize=(6, 10))
sns.barplot(x='importance', y='feature', data=top_20_features)
plt.show()
```
RF ë‚´ë¶€ì˜ feature importanceë¥¼ ì‹œê°í™”
- ì–´ë–¤ ì‚¬ì´í† ì¹´ì¸ì´ ëª¨ë¸ì—ì„œ ìì£¼ ì“°ì˜€ëŠ”ì§€(ì¤‘ìš”í•œì§€)ë¥¼ ë³´ì—¬ì¤Œ
- ì´ ê°’ì€ SHAPì²˜ëŸ¼ "ì˜ˆì¸¡ì— ì–¼ë§ˆë‚˜ ê¸°ì—¬í–ˆëŠ”ê°€"ë¥¼ ë‚˜íƒ€ë‚´ì§€ ì•Šê³ , ë‹¨ìˆœíˆ "ìª¼ê°œëŠ” ë° ë§ì´ ì“°ì˜€ëŠ”ê°€" ê¸°ì¤€.


```python
tree_explainer = shap.TreeExplainer(rf_model) ## TreeExplainer
shap_values = tree_explainer.shap_values(cytokine_df) ## SHAP Value
```
ì´ì§„ ë¶„ë¥˜ ëª¨ë¸(Random Forest, XGBoost ë“±)ì— shap.TreeExplainerë¥¼ ì ìš©í•˜ë©´
- ì´ shap_valuesëŠ” ë¦¬ìŠ¤íŠ¸ 2ê°œë¡œ êµ¬ì„±:
  - shap_values[0]: í´ë˜ìŠ¤ 0 (ìŒì„± í´ë˜ìŠ¤)ì— ëŒ€í•œ SHAP ê°’
  - shap_values[1]: í´ë˜ìŠ¤ 1 (ì–‘ì„± í´ë˜ìŠ¤)ì— ëŒ€í•œ SHAP ê°’



```python
fig = plt.figure(figsize=(8,8))
fig.set_facecolor('white')
ax = fig.add_subplot()
#Plot SHAP as sever probability
shap.summary_plot(shap_values[1], cytokine_df, 
                  cmap='bwr', 
                  show=False, 
                 plot_type='dot')
ax.set_xlabel('SHAP Value')
ax.set_title('SHAP Dot Plot', fontsize=20)
plt.show()
```
shap_values[1]: ì´ì§„ ë¶„ë¥˜ì—ì„œ ì–‘ì„± í´ë˜ìŠ¤ì— ëŒ€í•œ SHAP ê°’

summary plot: ê° featureê°€ ì˜ˆì¸¡ì— ë¯¸ì¹œ ì˜í–¥(ì–‘/ìŒ, ì„¸ê¸°)ì„ ìƒ˜í”Œë³„ë¡œ ì‹œê°í™” (ë¹¨ê°•=ê°’ í¼, íŒŒë‘=ê°’ ì‘ìŒ)

```python
shap_df = pd.DataFrame(shap_values[1],columns = cytokine_df.columns)
shap_df.index = cytokine_df.index
shap_df
```
![image](https://github.com/user-attachments/assets/32d7410b-f67c-4f88-9587-e6b41e8c8276)

```python
import umap.umap_ as umap
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

reducer = umap.UMAP()
embedding = reducer.fit_transform(shap_df)
```
```python
import matplotlib.pyplot as plt

# Extract UMAP coordinates and labels
umap_x = embedding[:, 0]
umap_y = embedding[:, 1]

# Create scatter plot
plt.figure(figsize=(10, 8))
scatter = plt.scatter(umap_x, umap_y, cmap="bwr", s=50, alpha=0.7, edgecolors="w", linewidth=0.5)
```
```python
from sklearn.cluster import DBSCAN

# Initialize DBSCAN
dbscan = DBSCAN(eps=0.8, min_samples=3) # partial data is too small to set min_sample=20.

# Fit to UMAP data and get cluster labels
clusters = dbscan.fit_predict(embedding)
embedding, clusters
```
```python
(array([[16.714314 , -2.0475426],
        [17.279623 , -2.4140635],
        [16.705837 , -3.002305 ],
        [17.19955  , -1.342096 ],
        [17.838465 , -2.021136 ],
        [18.537838 , -1.5079662],
        [21.44188  , -2.1259143],
        [21.123413 , -3.075382 ],
        [20.373632 , -3.0233152],
        [21.83852  , -2.899527 ],
        [20.435349 , -2.2629123]], dtype=float32),
 array([ 0,  0, -1, -1,  0, -1, -1,  1,  1,  1,  1]))
```
```python
plt.figure(figsize=(10, 6))
unique_clusters = np.unique(clusters)

for cluster in unique_clusters:
    idx = clusters == cluster
    plt.scatter(embedding[idx, 0], embedding[idx, 1], label=f'Cluster {cluster}')

plt.title('Scatter Plot of UMAP Colored by Cluster')
plt.xlabel('UMAP_1')
plt.ylabel('UMAP_2')
plt.legend()
plt.grid(True)
plt.show()
```
