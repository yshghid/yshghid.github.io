---
date : 2026-02-27
tags: ['2026-02']
categories: ['DL']
bookHidden: true
title: "Conv1D 기반 DNA 분석 #5 분석 정리"
---

# Conv1D 기반 DNA 분석 #5 분석 정리

#2026-02-27

---

Conv1D 기반 DNA 분석에서 세 가지 실험을 했는데 전사인자 결합 예측, 크로마틴 접근성을 추가한 결합 예측, 그리고 RNAi 효율 예측을 수행했다. 세부 사항은 다 달랐지만 DNA(또는 RNA) 서열을 숫자로 바꾸고, 1차원 합성곱 필터로 패턴을 찾고, 그 패턴들을 종합해서 하나의 답을 내놓는 공통 로직으로 작동한다. 

###

#1 모델 구조

```plain text
DNA 서열 (원-핫 인코딩)
      ↓
Conv1D → ReLU → Dropout   ← 로컬 모티프 탐지
      ↓
Conv1D → ReLU → Dropout   ← 복합 패턴 학습
      ↓
 [Conv1D → ReLU → Dropout] ← (선택적 추가 레이어)
      ↓
   Flatten
      ↓
[+ 크로마틴 접근성]         ← (실험 2만 해당)
      ↓
   Dense(1)
      ↓
  Sigmoid → 출력
```

Conv1D 레이어
- Conv1D를 한 겹만 쓰지 않고 두세 겹을 쌓는다. 첫 번째 레이어가 원본 서열에서 기본 모티프를 찾으면, 두 번째 레이어는 그 모티프들의 조합을 본다. "이 모티프 옆에 저 모티프가 있다"는 식의 더 복잡한 패턴을 학습하는 것이다. 세 번째 레이어가 있으면 한 단계 더 추상적인 패턴까지 잡아낸다.
- 실험마다 레이어 수가 달랐다. 101글자짜리 전사인자 문제에서는 3겹, 21글자짜리 RNAi 문제에서는 2겹을 썼다. 이는 데이터의 복잡도에 맞춘 선택인데 서열이 길고 패턴이 복잡할수록 더 깊은 모델이 필요하고, 서열이 짧고 단순하면 얕은 모델로 충분하다. 모델을 불필요하게 크게 만들면 훈련 데이터의 잡음까지 외워버리는 과적합이 생기고, 너무 작게 만들면 중요한 패턴을 놓치는 과소적합이 생긴다. 그 사이의 적절한 지점을 찾는 것이 모델 설계의 핵심이다.

Flatten-Dense
- Conv1D를 다 통과하면 "서열의 어디에 어떤 패턴이 있는가"를 요약한 특징 맵이 나온다. 전사인자 모델에서는 (101, 15), RNAi 모델에서는 (21, 10) 형태다. Flatten이 이 2차원 구조를 1차원 벡터로 쭉 펼치고, Dense(1)이 그 벡터의 모든 원소에 가중치를 곱해 더해서 숫자 하나를 만든다. Sigmoid가 이 숫자를 0~1 사이로 눌러준다.
- 여기서 크로마틴 접근성 실험(실험 2)만 Flatten 뒤에 접근성 스칼라 하나를 Concatenate로 이어붙여서, Dense가 서열 패턴과 크로마틴 상태를 동시에 고려하게 만들었다. 이건 "같은 모델 구조에 외부 정보를 주입하는 가장 간단한 방법"을 보여주는 사례다. 서열 분석은 Conv1D한테 맡기고, 그 결과와 외부 정보를 최종 판단 직전에 합치는 전략이다.

###

#2 

Conv1D가 DNA 분석에 적절한것은 3가지 이유가 있다.

첫째는 위치 불변성이다. JUND가 좋아하는 모티프 TGACTCA가 서열의 앞쪽에 있든 중간에 있든 끝쪽에 있든, 그건 같은 모티프다. Conv1D의 필터는 서열 전체를 처음부터 끝까지 미끄러지면서 같은 패턴을 찾으므로, 모티프가 어디에 위치하든 놓치지 않는다. 만약 Conv1D 대신 일반 Dense 레이어만으로 모델을 만들었다면, "3번째 위치의 TGACTCA"와 "50번째 위치의 TGACTCA"를 완전히 다른 것으로 취급했을 거다. 같은 패턴을 위치마다 따로따로 배워야 하니 데이터가 훨씬 많이 필요하고 효율이 떨어진다.

둘째는 파라미터 공유다. 필터 하나가 서열의 모든 위치에 동일하게 적용된다. 101개 위치를 훑더라도 필터의 가중치는 하나뿐이다. 이건 메모리와 계산 효율 면에서 엄청난 이점이다. Dense 레이어로 같은 일을 하려면 각 위치에 별도의 가중치가 필요하므로 파라미터 수가 폭발적으로 늘어난다. 파라미터가 적다는 건 적은 데이터로도 잘 학습할 수 있다는 뜻이기도 하다.

셋째는 지역성이다. DNA 모티프는 대부분 5-15개 염기 길이다. JUND의 핵심 결합 모티프는 7-8글자 정도다. kernel_size=10이면 한 번에 10개 염기를 보는 창이니, 이런 모티프를 한 눈에 포착하기에 딱 맞는 크기다. DNA에서 생물학적으로 의미 있는 신호는 대부분 이웃한 염기들 사이의 국소적 패턴이지, 서열의 양 끝에 있는 글자들 사이의 장거리 관계가 아니다. Conv1D는 바로 이 국소적 패턴을 찾도록 설계된 도구다.

이 세 가지 성질이 합쳐져서, Conv1D는 DNA 서열 분석에 거의 이상적인 도구가 된다. 모티프라는 짧고 반복적인 패턴을 서열 어디에서든 효율적으로 찾아낸다.


###



#3 손실 함수 선택 기준

모델의 뼈대는 같지만, 문제가 분류냐 회귀냐에 따라 반드시 바꿔야 하는 부품이 손실 함수와 평가 지표이다.

분류 문제(전사인자 결합)에서는 SigmoidCrossEntropy를 손실로 쓴다. 이 함수는 "정답이 1인데 0에 가깝게 예측하면 엄청나게 벌주고, 정답이 0인데 1에 가깝게 예측해도 엄청나게 벌준다"는 식으로 작동한다. 자신감 있게 틀리는 것에 기하급수적인 페널티를 부과해서, 모델이 양성과 음성을 확실히 구분하도록 밀어붙인다. 평가는 ROC-AUC로 한다. "임의의 양성-음성 쌍에서 양성의 점수가 더 높을 확률"이라는 직관적인 의미를 가진 지표다.

회귀 문제(RNAi 효율)에서는 L2Loss를 쓴다. 예측값과 실제값의 차이를 제곱한 것이 전부다. 큰 오차에 불균형적으로 큰 벌점을 줘서 극단적인 실수를 줄이는 성질이 있다. 평가는 피어슨 상관계수로 한다. 예측값과 실제값이 함께 오르내리는 정도, 즉 선형적 동조 정도를 재는 지표다.

이 선택이 틀리면 모델이 제대로 학습하지 못한다. 회귀 문제에 이진 교차 엔트로피를 쓰면 손실 함수가 연속값을 제대로 처리하지 못하고, 분류 문제에 L2Loss를 쓰면 확률 분포를 최적화하는 데 비효율적이다. 도구를 작업에 맞게 고르는 것, 이것이 딥러닝에서 "설계"라고 부르는 행위의 상당 부분을 차지한다.

| 문제 유형 | 손실 함수 | 평가 지표 |
|---|---|---|
| 이진 분류 (TF 결합) | SigmoidCrossEntropy | ROC-AUC |
| 회귀 (RNAi 효율) | L2Loss (MSE) | Pearson r |

###

#cf 데이터 흐름

```plain text
[DiskDataset 구조]
 shard-0-X.joblib    → DNA 서열 (원-핫, shape: N×101×4 또는 N×21×4)
 shard-0-y.joblib    → 정답 (결합 여부 0/1 또는 효율 0~1)
 shard-0-w.joblib    → 샘플 가중치
 shard-0-ids.joblib  → 게놈 좌표 (예: chr22:20208963-20209064)

         ↓ 배치 단위로 로드 (batch_size=1000)

[모델 입력]
 실험 1, 3: X만 입력
 실험 2: [X, accessibility] 입력 (커스텀 제너레이터)

         ↓ Conv1D × 2~3 → Flatten → Dense(1) → Sigmoid

[출력]
 실험 1, 2: 결합 확률 (0~1)
 실험 3: RNAi 효율 (0~1)

         ↓ 200 에포크 학습 (20반복 × 10에포크)

[평가]
 실험 1, 2: ROC-AUC
 실험 3: Pearson r
```

원본 데이터는 DiskDataset이라는 형태로 디스크에 저장되어 있다. shard라는 조각 파일들로 나뉘어 있고, 각 shard에는 서열(X), 정답(y), 가중치(w), ID(ids)가 들어 있다.

단일 입력 모델(실험 1, 3)에서는 DeepChem의 표준 파이프라인이 알아서 배치를 만들어 모델에 넣어준다. model.fit()을 호출하면 끝이다.
다중 입력 모델(실험 2)에서는 표준 파이프라인이 접근성 데이터를 끼워넣을 방법이 없으므로, 커스텀 제너레이터를 직접 만들었다. 이 제너레이터가 배치를 하나씩 만들 때마다 ID로 접근성 딕셔너리를 조회해서 서열과 접근성을 함께 묶어서 내놓는다. fit_generator가 이 제너레이터에서 배치를 받아 학습한다.

즉 프레임워크의 표준 기능으로 해결되면 그걸 쓰고, 안 되면 직접 만들면 된다. 제너레이터라는 파이썬의 기본 기능 하나로 데이터 파이프라인 전체를 커스터마이즈할 수 있다는 사실이, 이 생태계의 유연함을 잘 보여준다.

###

#cf2 모델링 핵심 요약


서열을 원-핫으로 숫자화하는 건 모든 실험에서 동일하다. 이건 DNA/RNA 서열을 신경망에 넣기 위한 사실상의 표준이다. Conv1D로 모티프를 탐지하는 것도 동일하다. 서열 데이터의 1차원적, 국소적, 위치 독립적 특성에 정확히 맞는 도구이기 때문이다. Flatten과 Dense로 최종 판단을 내리는 구조도 동일하다.
바뀌는 건 세 가지뿐이다. 모델의 크기(레이어 수, 필터 수, Dropout 비율)는 데이터의 복잡도에 맞게 조절한다. 추가 입력이 있으면 Concatenate로 합류시킨다. 손실 함수와 평가 지표는 문제 유형(분류 vs 회귀)에 따라 선택한다.

궁극적으로 목적은 "이 서열 안에 있는 어떤 패턴이 우리가 예측하려는 결과와 관련이 있는가?"이고 Conv1D는 그 패턴을 찾는 돋보기이고, Dense는 찾은 패턴들을 종합해서 답을 내놓는 판사이며, 손실 함수는 판사가 얼마나 틀렸는지를 알려주는 채점관이다. 이 세 부품의 협업이, 서열이라는 문자열 속에 숨겨진 생물학적 신호를 끄집어내는 것이다.
