---
date : 2025-08-01
tags: ['2025-08']
categories: ['SW']
bookHidden: true
title: "Docker #2 netmhcpan 예전 작업 복기"
---

# Docker #2 netmhcpan 예전 작업 복기

#2025-08-01

---


### 1

2024.11.24 MutClust 작업중에 netmhcpan을 돌려야되는 상황이 왓었는데

netmhcpan이 유료였나 그래서 패키지 다운은 안되고.. 서버 뒤지다가 아래 README.txt 파일 발견해서 결과물 저장까진 했던 기억이있다.

<img width="2448" height="1814" alt="image" src="https://github.com/user-attachments/assets/35f962af-822b-4693-8ac2-e320cd263314" />


이때먼가 의문이 들었던게 새로운 conda 환경에 접속한거같은 느낌이 아니라 완전 다른 제2의서버에 접속한 느낌이었는데 이상하게 연구실 디렉토리들은 그대로 접근이 가능해서 혼란스럽지만 그냥 절대경로 다 박고 수행했는데 결과들이 문제없이 저장됐다.

그래서 그뒤로 잊어버리고있었는데 docker 배우고나니까 먼가 이해돼서 이해된김에 정리해보기!


### 2. 도커 이미지 pull 및 수행

#1 도커 이미지 다운로드 


> #당시 chatgpt 응답
> 
> `docker pull * (*: 링크 블라인드 처리)` 명령어는 Docker Hub에서 *의 1.0 버전을 다운로드합니다. 이미지 크기가 953.76 MB이므로, 다운로드에는 네트워크 속도에 따라 몇 분 정도 소요될 수 있습니다.
> 

#2 도커 이미지 수행

> #당시 chatgpt 응답
> 
> 이미지 다운로드 후, 다음과 같은 명령어로 Docker 컨테이너를 생성하고 실행할 수 있습니다. 예를 들어, 로컬 시스템의 특정 디렉토리를 컨테이너에 마운트하고 싶다면:
> 
> `docker run -it -v /path/to/local/datac:/data *`
> 
> 이 명령은 다음과 같은 작업을 수행합니다:
> 
> - `it`: 컨테이너를 대화식 모드로 실행하고 터미널 입력을 위한 인터페이스를 제공합니다.
> - `v /path/to/local/data:/data`: 호스트 시스템의 `/path/to/local/data` 디렉토리를 컨테이너의 `/data` 디렉토리에 마운트합니다. 이렇게 하면 컨테이너 내부에서 호스트 시스템의 데이터에 접근할 수 있습니다.

#3 당시 내 코드

```shell
$ docker run -it -v /data/home/ysh980101/2411/data-mhc:/data *
root@40080ea8207d:/home/RSEM-1.3.3#
```

몰랐는데 호스트 시스템(우리 서버)의 내 작업 디렉토리("/data/home/ysh980101/2411/data-mhc")를 컨테이너에 마운트 했었다.

### 3. netMHCpan 실행

#1 netMHCpan 설치 경로 찾기

> #당시 chatgpt 응답
> 
> 컨테이너가 시작되면 기본적으로 `/home/RSEM-1.3.3` 디렉토리에서 시작되는 것 같습니다. 이 디렉토리는 RSEM 관련 작업을 위한 것으로 보이며, netMHCpan 작업을 수행하려면 적절한 디렉토리로 이동해야 할 수 있습니다.
> 
> 컨테이너 내에서 netMHCpan 설치 디렉토리로 이동하려면, 해당 디렉토리의 경로를 알아야 합니다. netMHCpan의 설치 위치를 확인하고, cd 명령어로 그 위치로 이동합니다.
> 
> `cd /path/to/netMHCpan`

#2 당시 내 코드

```shell
root@40080ea8207d:/home/RSEM-1.3.3# find / -type d -name "netMHCpan*" 2>/dev/null
/netMHCpan-4.1
```

netMHCpan의 설치 디렉토리 /netMHCpan-4.1 를 찾음.


#3 netMHCpan 사용

> #당시 chatgpt 응답
> 
> 디렉토리로 이동: 이제 확인된 설치 경로로 이동하여 작업을 시작합니다.
> 
> `cd /netMHCpan-4.1`
> 
> 작업 실행: netMHCpan을 실행하려면, 해당 디렉토리 내에서 실행 파일을 찾아 해당 명령을 사용합니다. 예를 들어, 다음과 같은 명령어를 사용할 수 있습니다:
> 
> `./netMHCpan -a HLA-A02:01 -l 9 -f your_peptide_file.txt -o output.txt`
> 
> 이 명령은 HLA-A02:01 앨리얼을 대상으로 하는 9-mer 펩타이드를 your_peptide_file.txt에서 읽어들여 output.txt에 결과를 출력합니다.


#4 당시 내 코드

```bash
while IFS= read -r PATIENT_ID
do
```
patient_id.txt에 있는 각 환자 ID에 대해 루프를 돌림

```bash
PEPTIDES_TABLE="$OUT_DIR/$PATIENT_ID/peptides_HLA-I.csv"
cat $PEPTIDES_TABLE | cut -d "," -f 1 | tail -n +2 > $OUT_DIR/$PATIENT_ID/peptides.txt
```

환자별 .csv 파일에서 첫 번째 컬럼(펩타이드 서열)만 추출하고, 헤더를 제거해서 .txt 파일로 만들고

```bash
while IFS= read -r allele
do
    $netMHCpan -BA -p $OUT_DIR/$PATIENT_ID/peptides.txt -a $allele > $OUT_DIR/$PATIENT_ID/raw_predictions/${allele}.txt
done < "$HLA_I_ALLELES_FILE"
```

Affinity prediction하려는 hla allele를 HLA_I_ALLELES_FILE에 저장해놧엇는데 HLA_I_ALLELES_FILE에 대해 루프를 돌림. 각 allele마다 NetMHCpan 실행 결과를 allele 이름으로 된 .txt 파일로 저장.

```bash
python3 sc2.py $OUT_DIR/$PATIENT_ID/raw_predictions/ > $OUT_DIR/$PATIENT_ID/binding_affinities_HLA-I.csv
```

해당 환자의 모든 allele에 대한 결과 파일을 하나의 .csv로 병합.

sc.py는?

```python
import sys
import os

netMHCpan_outdir = sys.argv[1]
print("Allele,Peptide,Affinity")
for fname in sorted(os.listdir(netMHCpan_outdir)):
    netMHCpan_file = open(netMHCpan_outdir + "/" + fname, "r")
    table_started = False
    for line in netMHCpan_file:
        if "Pos" in line:
            table_started = True
            netMHCpan_file.readline()
            continue
        
        if table_started and line[0] == "-":
            break
        
        if not table_started:
            continue

        line = line.split()
        allele = line[1]
        peptide = line[2]
        affinity = int(float(line[15]))
        print("{},{},{}".format(allele, peptide, affinity))
    
    netMHCpan_file.close()
```

대충 이런식인데 최종적으로는 Allele,Peptide,Affinity 컬럼 갖는 테이블을 반환.

전체 bash script는 이랬다

```bash
#!/bin/bash

# Input:
# 1) Cluster name (e.g., c315)
# 2) Number of processes
# Output:
# CSV table with predicted affinities (binding_affinities_HLA-I.csv)

CLUSTER=$1
#NUM_PROC=$2

netMHCpan="/netMHCpan-4.1/netMHCpan"
OUT_DIR="${CLUSTER}"
PATIENT_TXT="patient_id.txt"
HLA_I_ALLELES_FILE="common_mhc.txt"

# Go to the script directory and load config file
cd $(dirname $0)
#source config.bash

# Read each PATIENT_ID from the text file
while IFS= read -r PATIENT_ID
do
    # Create output directory for each patient
    mkdir -p $OUT_DIR/$PATIENT_ID/raw_predictions

    # Select peptides from the first column and remove header
    PEPTIDES_TABLE="$OUT_DIR/$PATIENT_ID/peptides_HLA-I.csv"
    echo $PEPTIDES_TABLE
    cat $PEPTIDES_TABLE | cut -d "," -f 1 | tail -n +2 > $OUT_DIR/$PATIENT_ID/peptides.txt

    # Run netMHCpan for each allele file listed in HLA_I_ALLELES_FILE
    #cat $HLA_I_ALLELES_FILE | \
    #    #parallel -j $NUM_PROC \
    #    $netMHCpan -BA -p $OUT_DIR/$PATIENT_ID/peptides.txt -a {} > $OUT_DIR/$PATIENT_ID/raw_predictions/{}.txt
    
    while IFS= read -r allele
    do
        echo $allele
        $netMHCpan -BA -p $OUT_DIR/$PATIENT_ID/peptides.txt -a $allele > $OUT_DIR/$PATIENT_ID/raw_predictions/${allele}.txt
    done < "$HLA_I_ALLELES_FILE"

    # Aggregate and clean up
    python3 sc2.py $OUT_DIR/$PATIENT_ID/raw_predictions/ > $OUT_DIR/$PATIENT_ID/binding_affinities_HLA-I.csv
    #rm -rf $OUT_DIR/$PATIENT_ID/raw_predictions

done < "$PATIENT_TXT"
```

### 4. Docker 종료

노션 보니까 챗지피티가 이런말도 해줫다.


> 작업이 완료되면, exit 명령어를 입력하여 컨테이너에서 나올 수 있습니다. 컨테이너를 종료하지 않고 나온 경우, 다음과 같이 컨테이너를 다시 시작하거나 종료할 수 있습니다.
> 
> 컨테이너 재시작: `docker start [container_id_or_name]`
> 
> 컨테이너 내부로 들어가기: `docker attach [container_id_or_name]`

이때 이해를못한상태니깐 exit를 하면 그냥 완전 나가기가 된다고 생각했던거같다. 그래서 한 10번 넘게 들어가서 작업했는데 내가 컨테이너를 하나도 종료안해놔서 한 6개월뒤에 ys910111 누구냐고 머라했던기억이 ㅋㅋ ㅠㅠ

그래도 이제 먼가 이해되니깐조은듯

#
