<!doctype html><html lang=en-us dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="https://yshghid.github.io/categories/rag/"><meta property="og:site_name" content=" "><meta property="og:title" content="RAG"><meta property="og:locale" content="en_us"><meta property="og:type" content="website"><title>RAG |</title><link rel=icon href=/favicon.png><link rel=manifest href=/manifest.json><link rel=canonical href=https://yshghid.github.io/categories/rag/><link rel=stylesheet href=/book.min.30a7836b6a89342da3b88e7afd1036166aeced16c8de12df060ded2031837886.css integrity="sha256-MKeDa2qJNC2juI56/RA2Fmrs7RbI3hLfBg3tIDGDeIY=" crossorigin=anonymous><script defer src=/fuse.min.js></script><script defer src=/en.search.min.81e5c1e6cdc68814968b32974bbbcd133060a27825eea4f594876a6b8f189c45.js integrity="sha256-geXB5s3GiBSWizKXS7vNEzBgongl7qT1lIdqa48YnEU=" crossorigin=anonymous></script><link rel=alternate type=application/rss+xml href=https://yshghid.github.io/categories/rag/index.xml title=" "></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><img src=/logo.png alt=Logo class=book-icon><span></span></a></h2><div class="book-search hidden"><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><script>document.querySelector(".book-search").classList.remove("hidden")</script><ul><li class=book-section-flat><span>기록</span><ul><li><a href=/docs/hobby/daily/>일상</a><ul></ul></li><li><a href=/docs/hobby/book/>글</a><ul></ul></li></ul></li><li class=book-section-flat><span>공부</span><ul><li><a href=/docs/study/ai/>AI</a><ul></ul></li><li><a href=/docs/study/bioinformatics/>Bioinformatics</a><ul></ul></li><li><a href=/docs/study/be/>BE</a><ul></ul></li><li><a href=/docs/study/fe/>FE</a><ul></ul></li><li><a href=/docs/study/career/>취업</a><ul></ul></li></ul></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu></label><h3>RAG</h3><label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents></nav></aside></header><article class="markdown book-article"><p><em>2025-07-19</em> ⋯ RAG #3 자동 대화 이력 관리</p><p style=height:4.5em;overflow:hidden><a href=/docs/study/ai/ai3/>1. 자동 대화 이력 관리 `ChatPromptTemplate`을 통해 시스템 메시지를 포함하는 프롬프트를 만든다. 시스템 메시지는 모델에게 “너는 금융 상담사야”라고 역할을 부여하는 것이다. 이어지는 `("placeholder", "{messages}")`는 실제 사용자의 질문과 AI의 답변이 이 자리에 채워질 것이라는 의미다. 이 프롬프트는 `chat = ChatOpenAI(model="gpt-4o-mini")`와 연결되는데, 이는 OpenAI의 gpt-4o-mini 모델을 사용하는 챗 인터페이스이다. 이 프롬프트와 모델을 `prompt | chat`이라는 LCEL 표현으로 묶으면, 하나의 체인이 만들어진다. 이 체인은 주어진 메시지 목록을 받아, GPT 모델에 전달하고 응답을 생성하는 구조다. 이제 이 체인을 사용해 실제 대화를 진행한다. 첫 번째 방법은 단순히 리스트로 과거 대화 내용을 전달하는 것이다. 사람이 “저축을 늘리려면 어떻게 해야 하나요?”라고 묻고, AI가 답하고, 사용자가 다시 “방금 뭐라고 했나요?”라고 재확인 질문을 던진다. 이 때 invoke() 메서드로 전체 메시지 리스트를 넘기면, 모델은 이 대화를 바탕으로 응답을 생성한다. 하지만 이 방식은 매번 메시지를 수동으로 넘겨야 하므로 실전에서는 불편하다. 그래서 등장하는 것이 ChatMessageHistory다. 이 클래스는 이전 대화 내용을 메모리에 저장하고 관리하는 도구이다. add_user_message()와 add_ai_message()를 통해 메시지를 하나씩 저장할 수 있고, 이후에는 .messages를 통해 전체 대화 내용을 꺼낼 수 있다. 이 메시지를 체인에 넘기면, 마치 인간과 대화하듯 연속적인 문맥이 반영된 응답이 나온다. 이 방식은 훨씬 유연하며, 체인과 연결해서 반복적으로 사용할 수 있다. 하지만 여전히 문제는 있다. 대화가 길어지면 모델의 입력 토큰 수가 초과될 수 있고, 세션 별로 기억을 구분해야 하는 요구도 발생한다. 이를 해결하기 위해 RunnableWithMessageHistory가 사용된다. 이 클래스는 체인을 감싸고, 특정 세션 ID에 따라 메시지 기록을 저장하거나 불러올 수 있도록 해준다. 즉, 사용자 A와 B가 서로 다른 대화를 동시에 해도, 각각의 대화가 독립적으로 기억되는 것이다. RunnableWithMessageHistory는 어떤 키를 기준으로 입력 메시지와 대화 이력을 구분할 것인지도 명시할 수 있다. 예를 들어 사용자의 질문은 "input"이라는 키에, 이전 대화는 "chat_history"라는 키에 저장된다. 이제 세션 기반 체인을 실행해보면, 처음 사용자가 "저축을 늘리려면 어떻게 해야 하나요?"라고 질문하고, 이후 "내가 방금 뭐라고 했나요?"라고 하면, 모델은 그 이전에 했던 말을 기억하고 그대로 요약해서 말해준다. 이건 LLM이 마치 실제 사람처럼, “방금 내가 뭐라고 했지?”라는 질문에 자연스럽게 답한다. 하지만 대화가 길어지면 또 다른 문제가 생긴다. 너무 많은 대화가 누적되면 입력 제한 때문에 모델이 다 받아들이지 못할 수 있다. 이를 해결하기 위해 trim_messages가 등장한다. 이 함수는 과거 메시지 중 일부만 남기고 나머지는 제거하는데, 예제에서는 "last" 전략을 사용하고 최대 2개의 메시지만 유지하도록 설정했다. 메시지를 트리밍한 후에는 그 줄어든 메시지를 기반으로 다시 체인을 실행할 수 있다. 이 방식은 마치 인간이 “최근 이야기만 기억하고 과거는 까먹는” 것과 같은 전략이다. 이걸 통해 시스템은 메모리 부담을 줄일 수 있고, 짧고 효율적인 대화를 유지할 수 있다. 더 고급 기능으로는 대화 내용을 ‘요약’해서 기억하는 방식이 있다. summarize_messages() 함수는 현재까지의 대화 내용을 GPT에게 전달해 요약을 요청하고, 요약된 내용을 새로운 시스템 메시지로 저장한다. 이 방식은 메시지를 전부 저장하는 대신 핵심 요약만 기억하게 만드는 전략이다. 마치 비서에게 “지금까지의 대화 요약 좀 해줘”라고 말한 뒤, 그 요약 내용을 기반으로 다음 대화를 이어가는 방식이다. 예를 들어 “저에게 어떤 재정적 조언을 해주셨나요?”라는 질문을 받았을 때, 모델은 이전 대화 전체를 기억하는 대신 그 요약된 내용을 참조하여 응답하게 된다. 이 접근법은 특히 긴 세션을 유지하면서도 중요한 맥락을 잃지 않도록 하기 위해 유용하다. 2. 정리 출처 책 RAG 마스터: 랭체인으로 완성하는 LLM 서비스: 멀티모달, 그래프 RAG, 에이전트, 파인튜닝까지</a></p><hr><p><em>2025-07-19</em> ⋯ RAG #2 출력 파서의 개념, Pydantic/Json 출력 파서</p><p style=height:4.5em;overflow:hidden><a href=/docs/study/ai/ai2/>1. 출력 파서의 개념과 종류 그리고 세가지 주요 메서드 출력 파서(output parser)는 LLM에서 생성된 응답을 받아서 우리가 원하는 형식으로 변환해주는 역할을 한다. 쉽게 말해, LLM은 텍스트만 생성하지만 우리는 그 텍스트를 리스트, 딕셔너리, JSON, 숫자 등 구조화된 데이터로 바꾸어서 프로그램에 넘기거나, 다음 단계 체인으로 활용하길 원할 때가 많다. 출력 파서는 이 연결고리 역할을 한다. 출력 파서는 LLM이라는 기계가 말한 인간 언어를 다시 기계가 이해할 수 있는 언어로 '번역'하는 통역사 같은 존재이다. 예를 들어 LLM이 “답은 아시아입니다”라고 말하면, 이걸 다시 `{"answer": "아시아"}` 같은 JSON 객체로 바꿔주는 게 파서의 역할이다. 반대로 말하면, 출력 파서 없이는 LLM이 말한 결과를 그대로 사람이 읽고 판단하거나 후처리 코드를 추가해야만 한다. 출력 파서에는 다양한 종류가 있다. 가장 기본적인 것이 `StrOutputParser`이다. 이 파서는 LLM이 생성한 응답을 그대로 문자열로 반환한다. 아무런 후처리를 하지 않기 때문에 단순하지만, 그만큼 유연성은 떨어진다. 다음은 `JsonOutputParser`인데, 이 파서는 LLM이 생성한 텍스트가 JSON 형태일 것으로 기대하고, 그것을 Python의 딕셔너리 형태로 파싱해준다. 예를 들어 LLM이 `{"answer": "아시아"}`라는 응답을 내놓았다면, JsonOutputParser는 이걸 `dict(answer="아시아")` 형태로 바꿔주는 것이다. 이때 중요한 것은 LLM이 정말로 JSON 형태로 출력했는지 여부이다. 만약 사람이 말하듯 그냥 “아시아입니다.”라고 하면 파싱에 실패하게 된다. 이때 등장하는 것이 `RetryWithErrorOutputParser`다. 이 파서는 기본 파서(예: JsonOutputParser)에 덧붙여 사용하는 구조로, LLM의 응답이 잘못된 형식일 때 자동으로 LLM에게 “출력을 다시 해주세요. 이 형식에 맞춰서요.”라고 재요청을 보내는 기능을 포함한다. 예를 들어 사용자가 “가장 큰 대륙은?”이라고 물었고, LLM이 “아시아입니다.”라고 대답했는데 우리는 JSON이 필요하다면, RetryWithErrorOutputParser는 이 응답을 보고 “JSON 형식이 아니네요, 다시 해주세요”라고 LLM에게 새로운 요청을 자동으로 보낸다. 즉, 이 파서는 파싱 실패를 감지하고 그것을 LLM에게 피드백으로 주어 재시도하게 만든다는 점에서 매우 실용적이다. 이제 주요 메서드를 살펴보자. 출력 파서의 핵심 기능은 크게 세 가지로 요약할 수 있다. 첫 번째는 `parse()` 메서드다. 이 메서드는 가장 기본적이면서도 핵심적인 함수인데, LLM이 생성한 문자열을 받아서 우리가 원하는 구조로 변환하는 역할을 한다. 예를 들어 JsonOutputParser의 `parse()`는 문자열을 JSON으로 바꾸는 역할을 하고, StrOutputParser의 `parse()`는 그냥 텍스트 그대로 반환한다. 사용자는 이 메서드만 호출하면 LLM의 응답을 쉽게 활용 가능한 형식으로 바꿀 수 있다. 두 번째는 `get_format_instructions()` 메서드다. 이 메서드는 LLM이 어떤 형식으로 출력을 생성해야 하는지 알려주는 설명 텍스트를 반환한다. 예를 들어 JsonOutputParser의 경우 이 메서드는 “출력은 반드시 다음과 같은 JSON 형식이어야 합니다”라는 문장을 반환한다. 이 설명은 보통 프롬프트에 포함되어, LLM이 출력 포맷을 정확하게 지키도록 유도하는 데 쓰인다. 다시 말해, 이 메서드는 LLM과 사용자 사이의 형식적 계약을 정의해주는 문장이다. 프롬프트를 구성할 때 "당신의 응답은 반드시 이 형식에 맞춰야 합니다"라고 할 수 있도록 도와주는 것이다. 세 번째는 `parse_with_prompt()` 메서드다. 이 메서드는 응답을 단순히 파싱하는 것을 넘어서, 어떤 프롬프트에 대해 생성된 응답인지를 함께 받아들이고, 그 문맥을 고려해서 파싱을 수행한다. 특히 RetryWithErrorOutputParser에서 이 메서드는 중요한 역할을 한다. 왜냐하면 LLM에게 재요청을 보낼 때 원래 프롬프트가 무엇이었는지를 같이 알아야 하기 때문이다. 예를 들어, LLM이 “아시아입니다.”라고 잘못된 응답을 내놓았다면, RetryWithErrorOutputParser는 원래의 질문("가장 큰 대륙은?")과 함께 LLM에게 "다시 JSON 형식으로 출력해주세요"라고 재요청할 수 있어야 하는데, 그때 이 `parse_with_prompt()`가 그 문맥을 함께 넘겨주는 역할을 한다. 이 메서드는 LLM이 실수했을 때 '정정 질문'을 만드는 데 필요한 모든 정보를 갖고 있다고 보면 된다. 결국 출력 파서는 단순한 문자열을 넘어서, 구조화된 데이터로의 다리 역할을 해주는 필수 도구이고, LLM을 단순한 텍스트 생성기가 아니라 모듈화된 시스템으로 쓸 수 있게 해주는 핵심 장치이다. 특히 JSON, 리스트, 숫자, 불리언 같은 구체적인 타입이 필요한 downstream task나 체인 구성에서는 출력 파서 없이는 체계적인 처리가 거의 불가능하다. `parse()`, `get_format_instructions()`, `parse_with_prompt()`는 각각 결과 변환, 포맷 명세, 실패 시 재처리의 핵심 기능을 제공하며, LangChain 전체 체인의 견고함과 재사용 가능성을 높이는 데 매우 중요한 역할을 한다. LLM의 응답은 본질적으로 예측이며, 그 예측이 우리가 원하는 구조에 맞지 않을 수 있기 때문에, 출력 파서는 이 예측을 수용 가능한 형식으로 '정제하는 마지막 관문'이라고 할 수 있다. 2. Pydantic 출력 파서 아래 코드는 LangChain에서 LLM의 출력 결과를 구조화된 데이터로 변환하고, 그 데이터가 특정 조건을 만족하는지 검증하는 전체 흐름을 보여주는 예제이다. 핵심적으로는 Pydantic이라는 데이터 모델링 및 검증 도구를 활용하여, LLM이 생성한 텍스트를 일종의 '폼'에 맞게 채우고, 그 값이 유효한지 검사하는 작업이다. 쉽게 말하면, LLM에게 빈칸이 있는 서식을 주고 “이 틀에 맞춰서 정확히 채워줘”라고 요구하고, 심지어 “네가 채운 값이 올바른지 내가 마지막에 확인도 할 거야”라고 하는 방식이다. 이건 마치 LLM을 한 명의 비서라고 가정하고, 우리가 미리 준비해둔 체크리스트에 따라 문서를 작성하게 시키되, 마지막에는 또 다른 직원인 Pydantic에게 이 문서가 규칙에 맞게 작성되었는지 확인하게 만드는 것이다. 먼저 `ChatOpenAI(model_name="gpt-4o", temperature=0.0)`은 OpenAI의 GPT-4o 모델을 초기화하는 부분이다. 여기서 temperature가 0.0이라는 것은 모델의 출력을 가장 결정론적(deterministic)으로 만들겠다는 뜻이다. 즉, 같은 입력에 항상 같은 출력을 내놓도록 하는 설정이다. 금융 조언처럼 신뢰성이 중요한 분야에서는 이런 설정이 흔히 사용된다. 이제 핵심은 `FinancialAdvice`라는 Pydantic 기반의 데이터 클래스다. 이 클래스는 우리가 기대하는 출력 형태를 정의한다. 필드는 두 개다. `setup`은 사용자가 던지는 질문이고, `advice`는 그 질문에 대한 금융 조언이다. 단순히 구조만 정의한 것이 아니라, 그 안에 유효성 검사 로직도 포함되어 있다. `@model_validator`를 사용한 `question_ends_with_question_mark` 함수는 setup이 반드시 물음표(`?`)로 끝나는 문장인지 확인한다. 만약 그렇지 않다면, 즉 “부동산 투자 어떻게 생각해”처럼 평서문이라면, 에러를 발생시키고 실행을 중단한다. 이런 식의 검증은 데이터의 형식적 정확성을 보장하는 데 매우 유용하다. LLM은 아무리 잘 훈련되어 있어도 항상 원하는 형식대로 출력을 내지 않기 때문에, 사후에 이런 검사 절차가 들어가는 것이 매우 중요하다. 이제 `PydanticOutputParser`를 설정한다. 이 파서는 LLM의 응답을 받아 `FinancialAdvice`라는 데이터 모델에 맞춰 자동으로 파싱해주는 역할을 한다. 즉, GPT가 `{ "setup": "어떤 상황이죠?", "advice": "이렇게 하면 좋겠습니다." }`처럼 텍스트를 생성하면, 이 파서가 이를 Python 객체로 바꿔준다. 특히 이 과정에서 위에서 정의한 유효성 검사 함수도 함께 작동한다. 그다음은 프롬프트 템플릿 구성이다. 여기서 중요한 점은 `format_instructions`라는 변수이다. 이것은 PydanticOutputParser의 `get_format_instructions()` 메서드에서 가져온 것으로, “이런 형식으로 출력해 주세요”라는 안내 문장을 LLM에게 보여주기 위한 것이다. 이 지침에는 예를 들어 출력이 JSON이어야 하고, 필드는 어떤 것들이 있어야 하며, 문자열은 따옴표로 감싸야 한다는 등의 구체적인 조건이 담겨 있다. 이런 지침이 없으면 LLM은 “음, 내 마음대로 써야지”라고 생각하고 엉뚱하게 문단을 쓰거나 서술체로 응답할 수도 있다. 따라서 명확한 출력 형식을 미리 보여주는 것은 매우 중요하다. 프롬프트 자체는 `"다음 금융 관련 질문에 답변해 주세요.\n{format_instructions}\n질문: {query}\n"`와 같은 형식이다. LLM은 이 프롬프트를 받으면, 주어진 질문에 대해 `setup`과 `advice`라는 두 개의 항목이 포함된 JSON 형식으로 응답하게 된다. 이 구조는 이후 체인으로 연결된다. 체인은 `prompt | model | parser`의 형태로, 순서대로 프롬프트를 생성하고, 이를 모델에 입력하고, 모델의 출력을 파서에 넘겨 구조화된 객체로 변환하는 연산을 의미한다. 이것은 LangChain Expression Language(LCEL)의 핵심 개념으로, 각 단계를 파이프라인처럼 연결하는 방식이다. 이제 실제로 체인을 실행한다. `chain.invoke({"query": "부동산에 관련하여 금융 조언을 받을 수 있는 질문하여라."})`를 호출하면, 먼저 프롬프트가 구성되고, GPT-4o 모델이 응답을 생성하고, 그 결과가 `FinancialAdvice` 형식에 맞게 파싱된다. 만약 모델이 "부동산에 대해 생각해보는 것이 좋습니다."와 같은 setup을 제공하고, 그것이 `?`로 끝나지 않는다면, 앞서 정의한 유효성 검사에서 실패하게 되고 `ValueError`가 발생한다. 이 오류는 try-except 문에서 잡히고, "오류 발생" 메시지를 출력하게 된다. 이 전체 코드는 단순히 GPT에게 질문을 던지고 응답을 받는 것을 넘어서, 응답의 형식을 규정하고, 그 형식이 제대로 지켜졌는지 검증하며, 결과를 안전하게 사용할 수 있도록 구조화하는 전체 흐름을 보여준다. LLM은 자유롭게 말할 수 있지만, 실제 애플리케이션에서는 그런 자유로운 응답이 문제가 될 수 있다. 예를 들어 API로 전달되는 값은 항상 딕셔너리여야 하거나, 숫자여야 하거나, 특정 포맷을 따라야 할 수도 있다. 이런 상황에서 PydanticOutputParser와 같은 파서는 LLM을 안전하게 시스템 내부로 끌어들이는 '입력 정화 필터'로 작동한다. 사용자는 LLM의 강력한 언어 생성 능력을 활용하면서도, 그 결과가 시스템 전체 흐름을 망가뜨리지 않도록 제어할 수 있는 수단을 갖게 되는 것이다. 3. Json 출력 파서 아래 코드는 LangChain에서 LLM의 응답을 JSON 형식으로 받아올 때 사용할 수 있는 두 가지 출력 파서, 즉 `SimpleJsonOutputParser`와 `JsonOutputParser`의 차이와 사용 예시를 보여준다. 모두 공통적으로 하는 일은 LLM이 생성한 문자열을 Python 프로그램에서 다룰 수 있는 구조화된 JSON 형태로 변환하는 것이다. 하지만 각 파서는 기능과 사용 목적이 조금 다르다. 이 파서들은 마치 사람이 말한 문장을 보고 “이걸 JSON 문서처럼 해석해서 내가 쓸 수 있게 바꿔줄게”라고 말하는 해석기와 같다. 그런데 어떤 해석기는 단순히 `{}`로 된 구조만 확인하고 해석하는 반면, 다른 해석기는 “이건 정확히 어떤 항목이 있어야 하고, 어떤 설명이 붙어야 해”라는 조건까지 점검하고 이해하려고 든다. 바로 이 점이 두 파서의 핵심적인 차이다. 먼저 `SimpleJsonOutputParser`는 말 그대로 단순한 JSON 파서다. LLM이 만들어낸 응답이 단순히 JSON 포맷으로 되어 있다면, 그걸 그대로 `dict`로 변환해주는 기능을 한다. 특별한 데이터 모델을 요구하지 않기 때문에 사용이 간편하다. 이 파서는 사람이 손으로 JSON을 썼을 때처럼 `{ "key": "value" }`와 같이만 구성되어 있으면 문제없이 동작한다. 예를 들어 `"비트코인에 대한 짧은 한문장 설명"`이라는 질문에 대해 모델이 `{"description": "비트코인은 분산형 디지털 통화입니다."}`라고 응답하면, SimpleJsonOutputParser는 이걸 바로 Python의 딕셔너리로 바꿔준다. 중요한 점은 이 파서는 ‘무슨 내용이 있는지’에는 관심이 없고, 오직 JSON 문법을 따르느냐만 본다는 것이다. 특히 `stream()` 메서드는 이 파서를 사용할 때 유용한 기능이다. 이는 LLM의 응답을 스트리밍 방식으로 받아오면서, JSON 조각이 도착할 때마다 실시간으로 구문 분석할 수 있게 해준다. 마치 누군가 JSON 문서를 타이핑하고 있을 때, 한 줄씩 도착하자마자 그걸 실시간으로 읽고 처리하는 것과 비슷하다. 따라서 대용량 출력이나 실시간 피드백이 필요한 시스템에서는 이 스트리밍 방식이 유용하다. 사용자는 `list(json_chain.stream({...}))`과 같이 호출하면, 모델이 출력한 JSON 조각들이 순차적으로 처리되는 과정을 직접 볼 수 있다. 반면 `JsonOutputParser`는 훨씬 더 정교하고 강력한 구조를 갖는다. 이 파서는 Pydantic 모델과 연동되어, LLM의 출력이 특정 데이터 모델에 꼭 맞도록 강제할 수 있다. 예제에서는 `FinancialAdvice`라는 Pydantic 모델을 만들었고, 이 모델은 `setup`이라는 질문 항목과 `advice`라는 답변 항목을 포함한다. 이처럼 JsonOutputParser는 단순히 JSON 문법을 지키는지를 넘어서, “setup이라는 항목이 있어야 하며 그건 문자열이어야 하고, advice도 마찬가지”라는 구조적인 조건까지 검사한다. LLM이 아무리 JSON처럼 보이는 출력을 만들어도, 이 필드가 빠졌거나 형식이 잘못되면 에러가 난다. 따라서 이 파서는 구조적인 안정성이 중요할 때 더 적합하다. 또한 `get_format_instructions()` 메서드는 매우 중요한 역할을 한다. 이 메서드는 “너는 이런 형식으로 응답을 작성해야 해”라고 LLM에게 알려주는 포맷 지침을 자동으로 생성해준다. 즉, 프롬프트 안에 이 지침을 포함시켜, LLM이 정확히 어떤 형식의 JSON을 생성해야 하는지 이해하도록 돕는다. 예제에서 사용한 프롬프트는 `template="다음 금융 관련 질문에 답변해 주세요.\n{format_instructions}\n{query}\n"`와 같이 구성되어 있는데, 이 중 `{format_instructions}` 자리에 이 지침이 삽입된다. 이걸 LLM이 읽고 “아, 나는 setup과 advice라는 필드를 가진 JSON 객체를 만들어야 하는구나”라고 이해하는 것이다. 이제 체인 구성 부분을 보자. `prompt | model | parser`라는 구문은 LangChain의 LCEL 방식으로, 프롬프트 생성 → 모델 응답 → 응답 파싱의 전체 파이프라인을 한 줄로 구성하는 방법이다. 프롬프트는 사용자의 질문을 받아 LLM에 전달할 형태로 바꾸고, 모델은 해당 질문에 답변을 생성하며, 마지막으로 파서는 그 답변이 JSON 형식에 맞게 잘 만들어졌는지를 확인하고 파싱해서 구조화된 데이터로 변환한다. 이 과정을 체인 하나로 묶으면, 개발자는 한 번의 호출로 텍스트 → 구조화 응답이라는 전체 과정을 자동화할 수 있다. `chain.invoke(...)`는 이 전체 체인을 실행하는 명령이다. 여기서는 `"부동산에 관련하여 금융 조언을 받을 수 있는 질문하여라."`라는 문장이 입력되고, LLM은 이에 대해 `{ "setup": "부동산 투자에 있어 어떤 점을 고려해야 할까요?", "advice": "지역 개발 계획과 대출 이자율을 꼼꼼히 따져보세요." }`와 같은 응답을 생성할 것으로 기대된다. 이 응답은 JsonOutputParser를 거쳐 Python 객체로 변환되며, 구조가 올바르지 않으면 예외가 발생하게 된다. 결론적으로 SimpleJsonOutputParser와 JsonOutputParser는 모두 LLM의 출력 결과를 JSON으로 다루기 위한 도구지만, 전자는 단순히 문법만 확인하는 해석기이고, 후자는 구조까지 엄격히 검사하는 검열관 같은 역할을 한다. SimpleJsonOutputParser는 유연하고 빠르지만 구조 안정성이 낮고, JsonOutputParser는 안정적이고 신뢰할 수 있지만, 구조에 어긋난 응답에 대해서는 더 엄격하다. 사용자는 시스템의 목적에 따라 이 두 파서 중 적절한 것을 선택하면 된다. 예를 들어 유저와의 대화에서 간단한 정보만 뽑아낼 때는 SimpleJsonOutputParser가 적합하고, LLM의 출력을 그대로 다음 프로세스로 넘겨야 하는 정형화된 응용에서는 JsonOutputParser가 더 적합하다. 이 두 파서는 LLM을 마치 JSON API처럼 다룰 수 있게 만들어주는 핵심 도구라고 할 수 있다. 출처 책 RAG 마스터: 랭체인으로 완성하는 LLM 서비스: 멀티모달, 그래프 RAG, 에이전트, 파인튜닝까지</a></p><hr><p><em>2025-07-17</em> ⋯ RAG #1 랭체인, LCEL, 프롬프트</p><p style=height:4.5em;overflow:hidden><a href=/docs/study/ai/ai1/>1. 랭체인 생태계의 주요 패키지 랭체인(LangChain)은 LLM(Large Language Model)을 활용한 애플리케이션을 쉽게 만들 수 있도록 돕는 프레임워크이다. 이 생태계는 단일 라이브러리로 구성된 것이 아니라 여러 개의 하위 패키지로 나뉘어 있고, 각각의 역할이 명확하게 분리되어 있다. 랭체인의 주요 목적은 LLM을 단순한 텍스트 생성 도구가 아니라, 여러 시스템과 결합하여 유의미한 작업을 수행하는 "생각하고 행동하는" 에이전트로 만드는 것이다. 이 생태계의 핵심 구성 요소들을 쉽게 설명하자면, 마치 LLM이라는 뇌에 주변 감각기관과 기억장치, 도구들, 그리고 의사결정 능력을 붙여주는 것이라고 보면 된다. 가장 중심이 되는 패키지는 `langchain-core`이다. 이 패키지는 랭체인의 모든 기반 구조를 제공한다. 쉽게 말해, LLM이 다양한 입력을 받아들이고, 체계적으로 이를 가공한 후 출력을 생성할 수 있도록 돕는 클래스들과 프로토콜이 담겨 있다. 예를 들어, 프롬프트 템플릿을 정의하는 기능, 체인(chain)이라고 불리는 논리적 연산 흐름을 정의하는 구조, 그리고 다양한 입출력 변환 도구가 이곳에 속한다. 이 핵심 패키지는 독립적으로 작동할 수는 없지만, 다른 모든 모듈들의 기반이 되는 뼈대라고 할 수 있다. 자동차로 치면 차체 프레임과 같다. 다음으로 중요한 것은 `langchain-openai`이다. 이는 OpenAI의 GPT 모델, 예를 들어 ChatGPT나 GPT-4 같은 모델과 랭체인을 연결해주는 역할을 한다. 이 패키지를 통해 사용자는 OpenAI API 키를 입력하고, 랭체인의 LLM 인터페이스를 이용해 손쉽게 질문을 던지고 응답을 받을 수 있다. 단순한 API 호출 이상의 기능을 제공하는데, 예를 들어 텍스트를 기반으로 함수 호출을 유도하거나, Chat 모델을 Memory나 Agent와 결합하는 식의 고급 기능도 여기에서 가능해진다. LLM을 제대로 쓰기 위해서는 외부 지식과 연동하는 것이 중요하다. 여기서 등장하는 것이 `langchain-community`이다. 이 패키지는 다양한 데이터 소스, 벡터 데이터베이스, 웹 검색 API, 문서 리더 등 수많은 외부 리소스와 연결할 수 있는 커넥터들을 제공한다. PDF를 읽거나, Notion의 내용을 가져오거나, Pinecone, FAISS, Weaviate 같은 벡터 DB에 질의할 수 있는 기능도 모두 여기에 포함된다. 쉽게 말하면 LLM이 세상의 다양한 지식에 손을 뻗을 수 있게 해주는 다리 역할을 한다. 문서 기반 질의 응답 시스템을 만들고 싶다면 `langchain-text-splitters`가 중요하다. 대형 문서를 LLM이 이해할 수 있도록 적절히 쪼개는 기능을 수행한다. 사람이 책을 읽을 때 한 문단씩 끊어서 요약하듯, LLM도 긴 글을 나눠서 이해해야 한다. 이 패키지는 문장을 의미 단위로 자르거나, 특정 길이로 잘라서 겹치게 만드는 등 다양한 전략을 제공한다. 이는 나중에 벡터 DB에 문서를 넣고, 검색을 통해 적절한 조각을 찾아 LLM의 입력으로 넣을 때 필수적인 전처리 단계이다. 벡터 검색은 현대 LLM 응용의 핵심이다. `langchain-embeddings` 패키지는 텍스트를 벡터로 변환하는 다양한 임베딩 모델을 래핑한다. 예를 들어 OpenAI의 text-embedding-3 모델이나 HuggingFace에서 제공하는 임베딩 모델들을 이 모듈을 통해 쉽게 쓸 수 있다. 이렇게 얻은 벡터는 이후 벡터 데이터베이스에 저장되어 유사도 검색에 사용된다. 유저가 입력한 질문과 가장 유사한 문서 조각을 찾아 LLM에게 제공하는 것이 RAG(Retrieval Augmented Generation)의 핵심인데, 그 시작점이 바로 이 임베딩 패키지이다. 이제 검색된 결과를 기반으로 LLM이 응답을 생성하게 하려면 `langchain-chains` 패키지가 필요하다. 이 모듈은 프롬프트 체이닝, 질의 응답 체인, 요약 체인 등 다양한 고수준 작업 흐름을 정의하는 데 쓰인다. 즉, 질문을 프롬프트로 바꾸고, 임베딩을 찾고, 결과를 조합해 응답하는 일련의 흐름을 순차적으로 정의하는데 적합하다. 마치 레고 블록을 조립하듯 체인을 구성하면 복잡한 작업도 쉽게 재사용할 수 있다. 한편, 반복적이고 기억이 필요한 대화를 만들기 위해서는 `langchain-memory` 패키지가 쓰인다. 이 모듈은 사용자의 이전 발화를 기억하여 대화의 문맥을 유지하거나, 요약된 기억을 저장하는 데 사용된다. 장기기억과 단기기억을 구성할 수 있고, 이를 바탕으로 에이전트 기반 응용에도 확장 가능하다. 마지막으로 중요한 것이 `langchain-agents`이다. 이 패키지는 LLM이 단순히 응답하는 수준을 넘어, "도구(tool)"를 호출하고, 스스로 다음 행동을 결정하며, 일련의 작업을 해결하도록 만드는 핵심 모듈이다. 예를 들어 유저가 "내일 서울 날씨 알려줘"라고 하면, 에이전트는 스스로 웹 검색 도구를 호출해 결과를 받아오고, 이를 종합해 LLM이 답변을 생성하게 한다. 이 때 도구(tool)는 `langchain-tools` 패키지에서 정의되며, 검색, 계산, API 호출 등의 기능을 구성할 수 있다. 요약하자면, LangChain 생태계는 단일 LLM을 중심으로 프롬프트, 체인, 메모리, 에이전트, 임베딩, 벡터 검색, 외부 도구 연결을 모듈화한 프레임워크이다. 각 패키지는 뉴런을 감싸는 신경망처럼 유기적으로 결합되어, 단순한 챗봇을 넘어 실제 사용 가능한 AI 서비스로의 확장을 가능하게 한다. LangChain을 이해한다는 것은 결국 LLM이 텍스트 생성뿐 아니라 사고하고, 검색하고, 행동하는 존재로 발전하는 과정을 구성요소 단위로 이해하고 활용하는 것이라고 할 수 있다. 2. 랭체인 표현언어 랭체인 표현언어(LangChain Expression Language, LCEL)는 LLM 기반 애플리케이션을 만들 때 복잡한 구성 요소를 쉽게 조립하고, 재사용 가능하며, 추론 가능한 방식으로 연결할 수 있도록 만든 일종의 "언어"이다. 하지만 여기서 말하는 '언어'는 우리가 흔히 생각하는 프로그래밍 언어나 자연어처럼 텍스트로 명령을 쓰는 형식은 아니다. 대신, 여러 LLM 관련 구성 요소들—예를 들어 프롬프트, LLM 호출, 도구 사용, 조건 분기, 반복 등—을 조합하는 방식을 일관되고 체계적으로 정의한 표현 프레임워크를 의미한다. LCEL은 마치 레고 블록을 조립하듯이 LLM 애플리케이션을 짜기 위한 설계도 같은 것이다. 이 설계도를 이용하면 개별 부품(프롬프트, 툴, 체인)을 이해하지 못해도 전체 시스템을 어떻게 연결하고 동작시키는지는 명확하게 이해할 수 있게 된다. 기본적으로 LCEL은 "Runnable"이라는 추상 개념을 중심으로 작동한다. Runnable은 실행 가능한 어떤 것이라는 뜻인데, 쉽게 말해 입력을 받아 출력을 내놓는 모든 구성 요소를 의미한다. 예를 들어 단순한 텍스트 프롬프트도 하나의 Runnable이고, OpenAI 모델을 호출하는 객체도 Runnable이며, 여러 단계를 거쳐 문서를 요약하고 질문에 답하는 전체 체인도 하나의 Runnable이 된다. 이렇게 정의하면, 어떤 구성 요소든 입력-출력 형태로 다루기만 하면 연결할 수 있기 때문에 시스템 전체를 일관되게 조립할 수 있게 된다. LCEL에서 가장 중요한 특징 중 하나는 `|` 연산자, 즉 파이프라인 연결이다. 이 연산자는 Unix 명령어에서 여러 명령을 연쇄적으로 연결하듯, LCEL에서도 여러 Runnable들을 연결하는 데 쓰인다. 예를 들어, 사용자가 입력한 질문을 프롬프트 템플릿에 넣고, 그것을 LLM에 넣어 응답을 받는 구조는 `PromptTemplate | LLM` 같은 식으로 표현할 수 있다. 더 나아가 이 결과를 요약하거나 다른 도구에 전달하는 것도 `|`로 계속 연결할 수 있다. 즉, LCEL은 LLM 기반 파이프라인을 함수형 스타일로 구성할 수 있게 해주는 방식이다. 흥미로운 점은 LCEL이 단순히 기능을 연결하는 것에 그치지 않고, 각 단계의 타입(입력과 출력 형식)을 자동으로 추론하고 검증할 수 있다는 점이다. 예를 들어 어떤 프롬프트 템플릿이 dictionary 형태의 입력을 받아 string 형태의 프롬프트를 만든다면, 이 Runnable의 타입은 `Runnable[Dict[str, Any], str]` 같은 식으로 정의된다. 이는 다음에 연결될 LLM이 string을 입력으로 받는다는 것을 기대하기 때문에, 두 블록이 잘 맞는지 타입 수준에서 확인할 수 있게 된다. 다시 말해 LCEL은 동작 가능할 뿐 아니라 안전하게 구성된 시스템을 만드는 데 도움을 준다. 또한 LCEL은 분기와 반복 같은 고급 제어 흐름도 지원한다. 예를 들어 특정 조건에 따라 서로 다른 체인을 실행할 수 있게 하는 `Router`, 여러 문서에 대해 반복해서 같은 처리(예: 요약)를 적용하는 `map_runnables` 같은 유틸리티도 LCEL의 표현 언어 구조 안에 포함되어 있다. 이는 LLM 기반 시스템이 단순한 일직선의 흐름을 넘어서, 조건에 따라 다른 행동을 하고, 복수의 입력을 처리하고, 기억을 활용하는 등 복잡한 애플리케이션으로 확장되는 것을 가능하게 한다. LCEL은 구조적으로 정의되기 때문에 디버깅도 쉽고, 시각적으로 표현하기에도 유리하다. 각 Runnable이 무엇을 하고 어떤 입력을 받고 어떤 출력을 내는지를 명확히 추적할 수 있고, 전체 파이프라인을 시각화할 수 있는 도구와도 잘 어울린다. 이런 특성은 LLM 시스템을 팀 단위로 개발할 때 특히 유용한데, 각 구성 요소를 모듈로 나누어 개발하고, 이를 LCEL 표현으로 연결함으로써 협업이 용이해지고 유지보수가 쉬워진다. 또한 LCEL은 back-end에 구애받지 않는다. 예를 들어 프롬프트를 ChatGPT에 넣을 수도 있고, HuggingFace 모델에 넣을 수도 있으며, 심지어 임베딩 벡터 생성기, 툴, API 호출 등의 기능과도 동일한 인터페이스로 연결할 수 있다. LCEL 표현 하나로 다양한 구성 요소가 섞인 복합 시스템을 일관된 방식으로 표현할 수 있는 것이다. 이는 LLM 중심 서비스가 실제 업무 환경에서 쓰일 때 다양한 외부 API, 사용자 입력, 문서, 데이터베이스와 연결되어야 하는 현실적인 요구에 매우 잘 맞는 설계이다. 결국 LCEL은 LangChain 생태계에서 LLM 애플리케이션을 구성하는 기본 문법이자 철학이다. 기존에는 각 기능을 코드로 조합하면서 많은 예외 처리를 해야 했던 작업들을, LCEL은 타입 안전성과 모듈성, 재사용성을 기반으로 구조화된 방식으로 구현할 수 있게 해준다. 이를 통해 개발자는 로우레벨 구현에 빠져들지 않고도 복잡한 LLM 시스템을 설계하고 조립할 수 있다. 마치 블록 쌓기처럼 눈에 보이는 단계를 통해 추론 가능한 시스템을 만들 수 있다는 점에서, LCEL은 LLM을 활용한 AI 개발의 추상화 수준을 한 단계 끌어올린 중요한 도구라고 할 수 있다. 3. 랭체인 프롬프트 탬플릿 아래 코드는 LangChain의 프롬프트 템플릿 시스템을 사용하는 예제이다. LangChain에서는 LLM에 보낼 입력을 단순한 문자열이 아니라 체계적으로 조립하고 재사용 가능한 구조로 만들 수 있도록 `PromptTemplate`이나 `ChatPromptTemplate` 같은 템플릿 클래스를 제공한다. 이 구조는 우리가 매번 LLM에게 보낼 프롬프트를 수작업으로 쓰는 대신, 일정한 형식에 따라 변수만 바꿔서 쓸 수 있도록 도와주는 일종의 '서식 문서' 같은 역할을 한다. 파인만 식으로 설명하자면, 이건 마치 이메일을 쓸 때 "안녕하세요, {이름}님. 오늘은 {주제}에 대해 이야기해볼까요?" 같은 틀을 미리 만들어 놓고, 이름과 주제만 매번 바꿔 쓰는 것과 비슷하다. `PromptTemplate.from_template("주제 {topic}에 대해 금융 관련 짧은 조언을 해주세요")`는 하나의 일반적인 프롬프트 템플릿을 만든다. 여기서 `from_template()`은 문자열 안에 중괄호로 감싼 `{topic}` 같은 변수를 지정할 수 있는 텍스트 포맷팅 기반 템플릿이다. 이 템플릿은 마치 "틀"처럼 작동한다. 나중에 누군가가 "topic"이라는 키를 가진 값을 전달하면, 해당 부분이 채워진 하나의 프롬프트 문자열이 만들어진다. 즉, `invoke({"topic": "투자"})`를 호출하면 실제 모델에 전달되는 프롬프트는 “주제 투자에 대해 금융 관련 짧은 조언을 해주세요”라는 문장이 된다. 여기서 핵심은 이 템플릿을 한 번 정의해두면, 다양한 주제에 대해 반복해서 재사용할 수 있다는 점이다. 그 다음에는 `ChatPromptTemplate`이 등장한다. 이 클래스는 조금 더 복잡한 대화를 모델링할 수 있는 구조를 제공한다. 우리가 단순히 텍스트 한 줄을 주는 것이 아니라, 시스템 메시지와 사용자 메시지를 구분해서 LLM에게 전달하는 방식이다. 예를 들어 `ChatPromptTemplate.from_messages()`를 사용할 경우, `("system", "당신은 유능한 금융 조언가입니다.")`는 시스템 역할의 메시지를 의미하고, 이는 LLM이 자기 자신을 어떻게 행동해야 하는지 정의해주는 '성격 부여' 문장이다. 반면에 `("user", "주제 {topic}에 대해 금융 관련 조언을 해주세요")`는 실제 사용자가 질문한 내용에 해당한다. 이렇게 역할(role)을 명시적으로 구분함으로써, LLM은 자신이 어떤 역할인지 이해하고 그에 맞춰 응답하게 된다. 이후 `invoke({"topic": "주식"})`을 통해 `{topic}` 자리에 "주식"이라는 단어가 들어가게 되고, 전체 메시지는 시스템과 사용자 간의 구성된 대화 구조로 모델에 전달된다. 이제 세 번째 방식은 자리 표시자(placeholder)를 더 유연하게 사용하는 경우이다. `ChatPromptTemplate.from_messages()`를 사용하면서 메시지 중 하나로 `MessagesPlaceholder("msgs")`를 정의한다. 이는 템플릿 안에 단일 메시지가 아닌, 여러 개의 메시지를 묶어서 한 번에 넣을 수 있는 구조를 만든 것이다. 예를 들어 사용자가 이전에 했던 대화 내용 여러 줄을 다시 LLM에 전달하고 싶을 때 유용하다. `invoke({"msgs": [HumanMessage(content="안녕하세요!")]})`처럼 메시지 리스트를 전달하면, 시스템은 자동으로 이 메시지를 하나하나 LLM의 입력으로 포함시킨다. 이건 마치 친구와의 대화 내역을 LLM에게 모두 보여주고 "이제 이 맥락을 바탕으로 대답해줘"라고 말하는 것과 같다. 마지막으로 나오는 방식은 위와 같은 자리 표시자를 `MessagesPlaceholder` 클래스로 정의하지 않고 문자열로 직접 `"placeholder", "{msgs}"`라고 명시하는 것이다. 여기서도 마찬가지로 `"msgs"` 자리에 여러 메시지를 리스트 형태로 전달하면, LangChain은 이를 자동으로 각각의 메시지 형식에 맞춰 변환해 LLM에게 넘겨준다. 이는 내부적으로 `HumanMessage`나 `SystemMessage` 등으로 변환되기 때문에, 입력 데이터가 일관된 메시지 객체라면 둘 다 동일한 방식으로 처리된다. 이 방법은 간단한 경우에 더 직관적으로 사용할 수 있다. 전체적으로 보면 이 코드는 LangChain에서 프롬프트를 어떻게 구조화하고, 다양한 형태의 사용자 입력과 시스템 지시를 조합하여 LLM에게 전달하는지를 보여준다. 중요한 건 단순히 텍스트를 이어 붙이는 것이 아니라, 시스템적인 구조로 대화를 표현함으로써 재사용성, 확장성, 유지보수성을 높이는 것이다. 특히 LCEL이나 체인과 결합할 때 이러한 템플릿들은 모듈화된 요소로써 기능하게 되며, 마치 전자회로에서 부품들을 연결하듯 텍스트 흐름과 LLM 행동을 설계할 수 있게 된다. 즉, 이 프롬프트 시스템은 단순한 문자열 입력을 넘어, LLM을 하나의 에이전트처럼 설계하고 조정하는 핵심적인 도구가 되는 것이다. 출처 책 RAG 마스터: 랭체인으로 완성하는 LLM 서비스: 멀티모달, 그래프 RAG, 에이전트, 파인튜닝까지</a></p><hr></article><footer class=book-footer><div class="flex flex-wrap justify-between"></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents></nav></div></aside></main></body></html>