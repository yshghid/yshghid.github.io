<!doctype html><html lang=en-us dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="https://yshghid.github.io/categories/ai/"><meta property="og:site_name" content=" "><meta property="og:title" content="AI"><meta property="og:locale" content="en_us"><meta property="og:type" content="website"><title>AI |</title><link rel=icon href=/favicon.png><link rel=manifest href=/manifest.json><link rel=canonical href=https://yshghid.github.io/categories/ai/><link rel=stylesheet href=/book.min.30a7836b6a89342da3b88e7afd1036166aeced16c8de12df060ded2031837886.css integrity="sha256-MKeDa2qJNC2juI56/RA2Fmrs7RbI3hLfBg3tIDGDeIY=" crossorigin=anonymous><script defer src=/fuse.min.js></script><script defer src=/en.search.min.4901796e80f0f5fd5ffd564727b259230f9b94faccdcb4c6d9dd465a569283e8.js integrity="sha256-SQF5boDw9f1f/VZHJ7JZIw+blPrM3LTG2d1GWlaSg+g=" crossorigin=anonymous></script><link rel=alternate type=application/rss+xml href=https://yshghid.github.io/categories/ai/index.xml title=" "></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><img src=/logo.png alt=Logo class=book-icon><span></span></a></h2><div class="book-search hidden"><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><script>document.querySelector(".book-search").classList.remove("hidden")</script><ul><li class=book-section-flat><span>기록</span><ul><li><a href=/docs/hobby/daily/>일상</a><ul></ul></li><li><a href=/docs/hobby/book/>글</a><ul></ul></li></ul></li><li class=book-section-flat><span>공부</span><ul><li><a href=/docs/study/ai/>AI</a><ul></ul></li><li><a href=/docs/study/bioinformatics/>Bioinformatics</a><ul></ul></li><li><a href=/docs/study/be/>BE</a><ul></ul></li><li><a href=/docs/study/fe/>FE</a><ul></ul></li><li><a href=/docs/study/career/>취업</a><ul></ul></li></ul></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu></label><h3>AI</h3><label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents></nav></aside></header><article class="markdown book-article"><p><em>2025-08-21</em> ⋯ MLops #1 mlflow 설치 & 실습</p><p style=height:4.5em;overflow:hidden><a href=/docs/study/ai/ai24/>1. mlflow 설치 및 docker 띄우기 로그인햇으면 도커를 켠다음에 다음을 수행. 확인해보면 제대로 떠있다!!
MLflow 서버를 띄웠고 경고창이 뜨는데 호스트 CPU는 ARM64이고 MLflow 공식 이미지는 AMD64여서 플랫폼 불일치 이슈가 있지만 문제되지는 않고 만약에 해결하고싶으면 docker-compose.yml에 아래와같이쓰면 댄다고함. docker ps 해보면 떠있는걸볼수있고 확인후에 http://localhost:5001/ 접속하기 잘들어가있다!! 2. mlflow quick start 튜토리얼 링크 - https://mlflow.org/docs/latest/getting-started/intro-quickstart/index.html 위에서 한 내용이 step1-2여서 step3부터 하면 댄다. - step3는 그냥 사이킷런으로 기본적인 모델 만들기. - step4는 tracking uri를 설정하고 현재 experiment에 대한 name을 MLflow Quickstart로 정한다.
- model_info에 step3에서 만들었던 lr 모델을 보낸다. - model loading을 하고
- loading된 model을 가지고 test dataset을 사용해서 prediction을 한다. 3. mlflow experiments 모델 inference를 하면 mlflow의 experiments에 뜬다. (ui에서 information을 볼수있다) 확인하는원리는?
- compose.yml을 보면 라고 돼있는데 local의 mlruns 디렉토리를 /mlflow/mlruns 도커 이미지 안에 매핑을 시키면 mlruns 디렉토리내 모든 파일들이 도커 이미지로 들어간다. 확인하는법은? - docker 안으로 들어가서 /mlflow/mlruns 들어가기. 여기서 python tutorial.py를 하면 실행된다. - iris 데이터를 가지고 모델을 만들고
- mlflow가 tracking을 하고
- model을 만들어서 tracking-quickstart라는 이름으로 register를 함
- 그리고 result를 출력.
- tracking url은?
- compose.yml에 MLFLOW_TRACKING_URI=http://0.0.0.0:5000 로 돼있어서 자동으로 이쪽으로간다(공식 튜토리얼은 mlflow.set_tracking_uri(uri="http://127.0.0.1:8080") tutorial.py에서 run하는부분 코드를 보면 이렇다 암튼 이렇게 Inference를 했고 UI(http://localhost:5001/)를보면 mlflow quickstart가 왼쪽에 생겻고 클릭하면 inference(prediction)한게 나온다. 해당 experiment를 확인해보면 - 모델에 대한 정보 environment conda, python environment, requirements.txt 등이 다 넘어왔고
- tagging이돼있음
- tracking quickstart 누르면
- register된 모델도 아래처럼 뜬다. 정리하면?
- mlflow를 docker pull해서 설치하고 inference해서 ui에서 어떻게 flow가 뜨는지랑 모델 register를 확인함.</a></p><hr><p><em>2025-08-19</em> ⋯ 데이터 분석 #4 리뷰 데이터 분석</p><p style=height:4.5em;overflow:hidden><a href=/docs/study/ai/ai22/>1. 목적 리뷰 데이터를 보고 - 감성 점수와 평점의 관계 - 리뷰 길이와 감성 점수의 관계 - 카테고리별 감성 차이 - Review_length가 AI 임베딩 유사도에 영향을 줄 수 있는지 인사이트 생성하기. 2. 코드 3. 생각 결측치 처리 - 나는 결측치가 하나라도 있는 샘플은 다 제거했는데 다른 사람들꺼보니깐 review_text 컬럼의 결측값을 'no review'로 대체하는 경우도 있었다. 이게 낫나? - 리뷰랑 상관없는 인사이트 (감성점수 vs 평점, 카테고리별 감성차이)에는 데이터가 확보되니깐 좋고. - 리뷰 길이가 AI 임베딩 유사도에 영향을 줄수있는지 &lt;- 여기서는 오히려 잘못된 데이터 심어주는게 대지않나 싶음. - 리뷰길이 vs 감성점수의 관계도 마찬가지. 이상치 탐지 - 이상치 탐지는 보통 IQR을 쓰던데 나는 IQR 너무 많지 않나 한두개만 제거하면대는데? 생각해서 챗지피티한테 다른거추천해달라니깐 상하위 1% 추천해주길래 그걸로햇다. - 다른사람들 IQR 한거보니 리뷰길이는 3개 단어개수는 2개등 몇개 안되길래 결과는 비슷햇을듯. (나는 6개 제거됏엇던듯) - 근데 rating이 평점같은데 평점은 1점 줄수있지않나? 특이취향을 제거하는셈이 돼버리니깐 이건 제거안하길 잘한거같다. 이상치 box plot - before box plot그리고 after box plot도 그렷으면 더 이뻤겟다. 상관관계 - 나는 감성 점수 vs 평점, 리뷰 길이 vs 감성 점수, 리뷰 길이 vs AI 임베딩 유사도 비교에서 매번 상관계수를 그냥 구햇는데 - correlation matrix 그린 사람도 있어서 그것도 괜찮은듯하다 - 상관관계 전부다 낮게나왓는데 그건 남들도 마찬가지 같아서 다행이엇다. 감성점수 vs 평점 scatter plot - 장르별로 색깔 다르게한사람 좀 있던데 그림자체는 안이쁘지만 좋은접근같았다. category별 평균평점 - 다른사람들도 어쩔수없었겟지만 아쉬운게 y축 max를 모르니깐 플롯이 다 안이뻣다. 멀 말하고자하는지 잘 안보엿다. 아마 max 5였겠지? 근데이건 정보가 없으니깐.. 리뷰 길이 vs AI 임베딩 유사도 - 이거야말로 어케하란건지 모르겠어서 - 처음에는 랜덤하게고른(사실 첫번째) 기준 리뷰와의 유사도를 다 계산하고 리뷰길이 vs 임베딩유사도의 corr을 구했는데 - 목적이 '모든 리뷰 쌍 간의 임베딩 유사도' 또는 '임베딩 모델의 특성상 길이가 의미 표현에 미치는 영향'을 보는건데 - 내가수행한건 '기준 리뷰와의 유사도가 길이에 따라 변하는지' 본거라 데이터셋 전체의 관계를 본게아니라 한 기준점에 대해서만 수행한셈이 되길래, - 각 리뷰가 다른 모든 리뷰와 가지는 평균 임베딩 유사도를 계산하는 방식으로 다시 했었다 - 남들 어케했는지 궁금했는데 - '기준 리뷰와의 유사도가 길이에 따라 변하는지' 본사람도있고 - 임베딩 어케하는지에따라 다르다 그냥이렇게쓴사람도 있고... - 얘는 답을 몰겟음.</a></p><hr><p><em>2025-08-09</em> ⋯ 생성형 AI #2 Prompt Engineering 실습 미리돌려보기</p><p style=height:4.5em;overflow:hidden><a href=/docs/study/ai/ai19/>1. VOC 분석 setting - https://openrouter.ai/ - Model: GPT-5 - Temperature: 0.2 (낮게: 일관성 있는 분류 결과) - Top-k / Top-p: default - Max tokens: 1024 system prompt user prompt result | 번호 | VOC 내용 | 분류 | 판단 근거 | |------|---------|------|----------| | 1 | 복잡한 엑셀 정리에서 해방됐어요. 기존 수작업으로 처리하던 매출/비용 분석을 자동화해 시간 절약 효과를 체감했습니다. | 긍정 | - | | 2 | 회계 비전문가인 마케팅 담당자도 재무 지표의 의미를 쉽게 파악할 수 있었습니다. | 긍정 | - | | 3 | AI 추천 덕분에 세무 위험을 미리 인지했어요. 실제로 부가세 누락 가능성을 사전에 알림 받아, 실제 신고 전에 정정할 수 있었던 점이 유용했습니다. | 긍정 | - | | 4 | 실시간으로 현금흐름을 추적할 수 있어 좋았습니다. 회계팀 없이도 매주 자금 흐름을 파악하고 의사결정에 반영할 수 있었습니다. | 긍정 | - | | 5 | 처음에만 가이드를 받고 나니 반복 작업이 놀랍도록 간단해졌습니다. 설정만 끝나면 이후 반복 업무에서 자동화된 결과물이 기대 이상으로 좋네요. | 긍정 | - | | 6 | 기능은 흥미롭지만, 실제 업무에 어떻게 녹여야 할지 고민이 됩니다. 시스템이 낯설고 기존 워크플로우와 맞물리는 데 시간이 필요해 보입니다. | 부정 | 1. 적용 방법에 대한 명확한 가이드 부족
2. 기존 시스템과의 통합 어려움 | | 7 | 예쁜 그래프가 많긴 하지만 실무상 의미가 뚜렷하게 와 닿지는 않았습니다. | 부정 | 1. 시각적 효과는 있으나 실용성 미흡
2. 구체적인 데이터 분석 기능 부재 | | 8 | AI가 추천해주는 분석은 흥미로웠지만, 최종 결정은 여전히 사람이 해야겠더라고요. 완전한 자동화보다는 보조 도구로 보는 것이 현실적이라 느꼈습니다. | 부정 | 1. AI의 신뢰도 및 정확성 한계
2. 의사결정 과정에서의 자동화 미비 | | 9 | 피벗 기능이나 드릴다운 기능이 있었으면 더 좋을 것 같긴 해요. 보고서 결과는 직관적이지만, 좀 더 상세 데이터를 보고 싶을 때 아쉬움이 있습니다. | 중립 | - | | 10 | 회계 전문가 입장에서는 보안이 필요해 보이지만, 일반 사용자에겐 적합할 수도 있겠네요. 어떤 고객을 주 대상으로 할지 더 명확하면 좋겠습니다. | 중립 | - | | 11 | 일부 기능은 대기업 회계 기준에 맞춰져 있어 간편한 사용을 기대한 소규모 기업에는 과도했습니다. | 부정 | 1. 소규모 기업의 요구사항 미반영
2. 기능의 복잡성으로 인한 사용 장벽 | | 12 | AI 설명이 부족해 불안했어요. AI가 어떤 기준으로 판단했는지, 근거가 불투명해 검토에 시간이 걸렸습니다. | 부정 | 1. AI 프로세스의 투명성 부족
2. 결과 검증에 추가 리소스 소모 | | 13 | 엑셀 연동 시 포맷 오류가 잦았습니다. 업로드한 자료가 표준 포맷이 아닐 경우 오류가 자주 발생했습니다. | 부정 | 1. 데이터 호환성 문제
2. 사용자 입력 오류에 대한 유연성 부족 | | 14 | 초기 세팅에 시간이 좀 걸렸습니다. 계정과목 연결, 은행 계좌 연동 등 초기 설정을 마치기까지 다소 복잡하게 느껴졌습니다. | 부정 | 1. 초기 설정의 복잡성
2. 사용자 편의성 저하 | | 15 | 사용자별 접근 권한 설정이 더 세분화되었으면 합니다. 팀 내 다양한 역할별로 보기 권한을 구분하고 싶었는데 현재는 제한적이었습니다. | 부정 | 1. 권한 관리 기능의 제한성
2. 조직 내 역할별 맞춤형 설정 미지원 | 2. 관리를 위한 규격화된(JSON) 정보 생성 setting - https://openrouter.ai/ - Model: Gemma 3 27B (free) - Temperature: 0.2 - Top-k / Top-p: default - Max tokens: 1024 system prompt user prompt result 3. 컨설팅 리서치 & 전략 수립 setting - https://openrouter.ai/ - Model: Gemma 3 27B (free) - Temperature: 0.2 - Top-k / Top-p: default - Max tokens: 1024 system prompt user prompt result 4. 신상품 출시 프로모션(행사) 기획안 작성 setting - https://openrouter.ai/ - Model: Gemma 3 27B (free) - Temperature: 0.2 - Top-k / Top-p: default - Max tokens: 1024 system prompt user prompt result 5. 이력서 파일 검토 setting - https://openrouter.ai/ - Model: Gemma 3 27B (free) - Temperature: 0.2 - Top-k / Top-p: default - Max tokens: 1024 system prompt user prompt result 6. 비용관리 엑셀 템플릿 생성 setting - https://openrouter.ai/ - Model: Gemma 3 27B (free) - Temperature: 0.2 - Top-k / Top-p: default - Max tokens: 1024 system prompt user prompt result ~*링크가 없는데..*~ 7. 마케팅용 기술 블로그 작성 setting - https://openrouter.ai/ - Model: Gemma 3 27B (free) - Temperature: 0.2 - Top-k / Top-p: default - Max tokens: 2048 (1024하니까 말이 끊김) system prompt user prompt - 근데 첨부할 파일이 없길래 그냥했다. result</a></p><hr><p><em>2025-08-09</em> ⋯ 생성형 AI #1 생성형 AI 기초 및 Prompt Engineering</p><p style=height:4.5em;overflow:hidden><a href=/docs/study/ai/ai18/>RAG (p.27) RAG의 역할? - 질문을 LLM에 던지기 전에 knowledge corpus에 질문을 미리 검색한다(회사 데이터에 대한 지식 벡터 db). - 질문과 연관된 문서를 찾고 적절하게 만들어서 retrieval 던지면 의도대로 답변이 잘 나온다. LLM 출력 구성 (p.42-45) Output Length (Max Tockens) - 500자로 제한을 걸면 500자로 맞춰주는게 아니라 500자 넘으면 출력을 멈춘다. Sampling Controls - LLM은 다음에 올 단어를 고를 때 미리 계산된 사전 확률분포를 가지고 거기서 하나를 뽑는다 - temperature로 무작위성의 정도를 조절. - temperature를 0으로하면 확률이 가장 높은 단어만 거의 항상 선택 - 그림에서 원래의 확률분포가 가운데 그림처럼 생겼더라도 temp를 0으로 낮추면 첫 번째 그림처럼 가장 높은 확률에 몰빵되어 다른 선택지는 거의 배제된다. - 반대로 temperature를 2로 올리면 확률이 평평해져서 원래 1등이 아니었던 단어들도 선택될 가능성이 높아진다. - 이렇게 임의성을 높이면 흔하지 않은 단어가 튀어나올 확률이 커지고 결과가 예측 불가능해지고 창의성이 늘어난다. - TopK - 다음에 올 단어 후보 중에서 확률이 가장 높은 K개만 남기고 나머지는 버림 - K값이 크면 후보 폭이 넓어져서 더 다양한 결과가 나오고 창의성이 높아진다. - K값이 작으면 몇 개의 후보만 남아서 결과가 더 안정적이고 사실적인 방향으로 수렴한다. - TopP - 누적 확률이 특정 값 p에 도달할 때까지의 상위 후보만 남기기 예를 들어 p가 0이면 항상 가장 가능성이 높은 단어 하나만 선택하고, p가 1이면 거의 모든 단어가 후보에 포함. - TopK TopP를 통과하고나서 temperature 값이 적용된다. - temperature가 낮으면 이 후보 중에서 가장 확률이 높은 단어를 고르는 쪽으로 기울어지고, 높으면 확률 분포를 평평하게 만들어 무작위성이 커진다. 낮은 temperature에서는 사실상 Greedy decoding처럼 정답 하나를 뽑는 느낌이고, 높은 temperature에서는 후보 중에서 랜덤하게 섞어 뽑는 Sampling 방식이 된다. - 흐름예시 1. 다음 토큰 후보마다 사전확률을 계산하고 이 후보들을 확률이 높은 순으로 정렬한 뒤 TopK를 적용하면 예를 들어 K=2일 때 가장 높은 두 개만 남기고 나머지는 모두 버린다. TopP를를 쓰면 누적 확률이 p에 도달할 때까지 후보를 남기고 이후는 잘라낸다. 2. 필터링을 하고 남은 후보들에 temperature를 적용한다. temperature가 낮으면 확률 분포가 뾰족해져서 가장 가능성이 높은 후보를 뽑을 확률이 커지고, 높이면 분포가 평평해져서 확률이 낮은 후보도 비슷한 기회로 선택된다.</a></p><hr><p><em>2025-07-28</em> ⋯ MutClust 슈도코드 작성하기</p><p style=height:4.5em;overflow:hidden><a href=/docs/study/ai/ai10/>데이터 집합 D, 파라미터 eps와 minPts가 들어간다. 2. H-중요도 계산 각 데이터포인트에 대해 H-score를 계산한다. 3. 임시 Eps 계산 및 후보 Core 돌연변이 탐색 현재위치 x의 H score 기반으로 임시 eps를 계산한다. 그리고 regionQuery로 eps 내 돌연변이들의 중요도를 확인한다.
조건을 만족하면, CCM(Candidate Core Mutation)으로 처리한다. 4. 클러스터 확장 (CCM일 경우) CCM일 경우 expandCluster를 사용해서 클러스터 확장을 수행한다. 노이즈였지만 현재는 x의 이웃포인트가 된 y는 border point로 재분류해준다.</a></p><hr><p><em>2025-07-28</em> ⋯ DBSCAN: #1 1D 클러스터링의 성능 평가</p><p style=height:4.5em;overflow:hidden><a href=/docs/study/ai/ai8/>1. Problem 클러스터 응집도는 보통 클러스터 내 데이터 간의 평균 거리나 분산, 혹은 실루엣 계수처럼 군집 내 응집도와 군집 간 분리도를 동시에 평가한다. 하지만 1차원 데이터에서는 클러스터 응집도(Cluster Cohesion) 또는 실루엣 계수(Silhouette coefficient) 같은 지표가 잘 작동하지 않는다. 2. 클러스터 응집도 클러스터링 성능을 평가하는 지표 중 하나인 응집도(Cohesion)는 클러스터 내부의 데이터들이 얼마나 서로 가까운지를 측정하는 지표다. 대표적으로는 클러스터 내 모든 점 간의 평균 거리, 클러스터 중심과 각 점 사이의 평균 거리, 혹은 분산을 사용하는 방식 등이 있다. 이와 함께 자주 사용되는 분리도(Separation)는 클러스터 간의 거리가 얼마나 떨어져 있는지를 평가하며, 이 두 지표를 동시에 고려하는 실루엣 계수(Silhouette coefficient) 같은 복합 지표도 존재한다. 이러한 거리 기반의 평가 지표들은 특히 고차원 공간에서 데이터의 분포가 복잡할 때 군집화의 품질을 효과적으로 판단하는 데 유용하지만, 1차원 데이터에서는 근본적인 한계가 있다. 1차원에서는 데이터가 선형적으로 배열되어 있고, 데이터 간의 절대적인 거리 외에 고려할 수 있는 구조적 정보가 거의 없다. 다시 말해, 1차원 데이터에서는 클러스터 간의 공간적 분리나 복잡한 분포 형태, 경계의 불확실성 같은 요소가 존재하지 않는다.
예를 들어, [1, 2, 3]이라는 클러스터와 [10, 11, 12]라는 또 다른 클러스터가 있을 때, 두 클러스터는 각자 내부에서 점들이 밀집되어 있으며, 동시에 클러스터 간의 거리도 매우 크다.
이 경우, 응집도 지표로 보면 내부 응집도는 낮은 거리로 인해 높게 평가되고, 분리도 역시 충분히 큰 거리 차이로 인해 좋게 평가된다. 결국 이 두 클러스터는 매우 이상적인 군집으로 간주되며, 실루엣 계수도 1에 가까운 매우 높은 값을 얻게 된다. 하지만 이는 거리 기반 평가 지표가 본래 측정하고자 했던 군집화의 “품질”을 왜곡할 수 있다. 실루엣 계수가 높다는 것은, 클러스터 내부는 서로 가까우면서 다른 클러스터와는 충분히 떨어져 있다는 뜻인데, 1차원에서는 어느 정도 떨어져 있기만 하면 항상 이런 조건을 쉽게 만족할 수 있다.
즉, 고차원 데이터에서는 이 조건을 만족시키기 위해 정교한 군집 경계 설정이나 복잡한 군집 구조의 이해가 필요하지만, 1차원에서는 단순한 거리 기준만으로도 응집도와 분리도를 동시에 높이는 것이 너무 쉽다.
이러한 특성 때문에 실루엣 계수 같은 지표는 거의 항상 과대 평가되는 경향이 있으며, 이로 인해 군집화가 “잘 되었다”고 착각할 수 있다. 또한, 1차원에서는 데이터가 클러스터의 중심을 기준으로 대칭적으로 분포해 있을 가능성이 높기 때문에, 중심 기반 평가 지표들이 지나치게 이상적인 값을 반환하게 된다.
예를 들어, k-means 알고리즘으로 클러스터링을 수행하고 각 클러스터의 중심을 기준으로 점들을 평가할 때, 각 클러스터가 비슷한 크기와 간격을 가지고 있으면 군집 품질이 매우 좋게 평가된다.
하지만 실제 분석 목적이 예를 들어 데이터의 숨겨진 구조나 경계의 복잡성, 비정상적인 데이터 분포 등을 파악하는 것이라면, 이러한 단순한 평가 기준은 적절하지 않다. 이러한 이유 때문에, 1차원에서는 실루엣 계수나 거리 기반 응집도 지표가 클러스터링 품질을 객관적으로 반영하지 못한다.
다시 말해, 1차원에서는 거의 모든 클러스터링 결과가 높은 응집도와 분리도로 인해 좋은 평가를 받을 수 있기 때문에, 지표 간 차별성이 떨어지고, 모델 간의 성능 비교가 무의미해질 수 있다.
예를 들어, 클러스터 수를 다르게 설정하거나, 군집 경계를 조금씩 조정해도, 응집도 지표는 큰 차이를 보이지 않기 때문에, 최적의 군집 수를 찾기 어렵고, 과적합된 군집 결과도 높은 점수를 받을 수 있다. 한편, 거리 기반 지표가 고차원에서는 데이터 분포의 구조, 군집의 모양, 방향성, 밀도 차이 등을 반영할 수 있지만, 1차원에서는 이런 복잡성이 존재하지 않는다.
따라서 클러스터 간 거리만 멀면 분리도는 항상 높고, 클러스터 내 거리가 작으면 응집도는 항상 높게 측정된다.
이런 구조적 단순성 때문에 거리 기반 지표는 본래 설계된 목적, 즉 클러스터 품질의 차이를 드러내는 데에 실패할 수밖에 없다. 결국 1차원 데이터에서 클러스터링 성능을 평가하기 위해서는 거리 기반 응집도 지표에만 의존하는 것은 위험하며, 대안적인 평가 방식을 고려해야 한다.
예를 들어, 클러스터 내 분산과 클러스터 간 거리의 비율을 이용해 평가하거나, 클러스터 경계에서의 밀도 차이를 분석하거나, 시각화 및 도메인 지식을 활용하여 군집의 타당성을 해석하는 방식이 더 적절할 수 있다.
특히 노이즈가 포함된 1차원 데이터에서 DBSCAN 같은 밀도 기반 알고리즘을 사용할 경우, 군집이 얼마나 의미 있는 구간으로 나뉘었는지를 인간이 직접 시각적으로 검토하는 것이 지표보다 더 신뢰성 있는 평가 방식이 될 수 있다. 요약하자면, 1차원 데이터에서는 거리 기반 응집도 지표가 매우 단순한 거리 정보만을 반영하게 되며, 그 결과 지나치게 높은 품질 점수를 반환하게 되어 클러스터링 성능을 왜곡하는 경향이 있다.
따라서 이러한 지표는 1차원에서는 신뢰도가 낮으며, 클러스터링 결과의 실제 타당성이나 분석 목적을 반영하지 못할 수 있다. 이런 상황에서는 시각화 기반 평가, 분산-거리 비율 계산, 또는 실제 문제의 목적에 맞는 해석 중심의 평가가 필요하다. 3. 실루엣 스코어 실루엣 계수(Silhouette Coefficient)는 클러스터링의 품질을 평가하기 위한 대표적인 내부 지표 중 하나로, 각 데이터 포인트가 자신이 속한 클러스터 내부에서는 얼마나 밀접하게 모여 있는지(응집도), 그리고 다른 클러스터와는 얼마나 잘 분리되어 있는지(분리도)를 동시에 반영한다.
구체적으로, 어떤 점 i에 대해 실루엣 계수를 계산하려면 두 가지 거리 평균을 계산해야 한다. 첫 번째는 a(i), 즉 점 i와 같은 클러스터에 속한 다른 모든 점들과의 평균 거리이며, 이는 클러스터 내부 응집도를 의미한다.
두 번째는 b(i), 점 i와 가장 가까운 다른 클러스터에 있는 모든 점들과의 평균 거리로, 이는 클러스터 간 분리도를 나타낸다.
최종 실루엣 점수는 s(i)= b(i)−a(i) / max(a(i),b(i)) 로 정의되며, -1부터 1 사이의 값을 가진다. 점수가 1에 가까울수록 클러스터링 품질이 좋다는 뜻이다. 이러한 실루엣 계수는 고차원 공간에서 다양한 모양의 클러스터가 형성될 때 매우 유용한 지표가 된다.
예를 들어, 서로 다른 밀도를 가지거나 비대칭적인 분포, 비선형 경계를 가지는 클러스터들이 존재할 경우, 실루엣 계수는 클러스터 내부 밀집도와 외부 분리도를 동시에 반영함으로써 유의미한 평가를 제공한다. 그러나 이 지표는 1차원 데이터에서는 정보 손실이 크고 왜곡된 평가 결과를 내놓는다는 점에서 큰 한계를 가진다.
그 이유는 실루엣 계수가 기반으로 삼고 있는 거리 정보가 1차원에서는 지나치게 단순하기 때문이다.
1차원 데이터는 본질적으로 수직선 위에 점들이 배열된 구조이므로, 두 점 사이의 거리는 단순히 절댓값 차이 하나로 결정된다.
이 절댓값 거리에는 방향성도 없고, 구조적인 특이성도 반영되지 않기 때문에, 다양한 분포 형태나 클러스터의 복잡성, 클러스터 간 경계 모호성 등 실루엣 계수가 원래 평가하고자 하는 핵심적인 특성들이 반영되지 않는다.
즉, 다양한 군집 구조나 모양이 나타나는 고차원 공간에서는 실루엣 계수가 그 구조의 복잡성을 반영할 수 있지만, 1차원에서는 단순히 가까운가 먼가만 판단하기 때문에 정보량이 극단적으로 줄어들게 된다. 이러한 정보 손실은 실루엣 계수가 의미 있는 분포의 차이를 구분하지 못하게 만들고, 결과적으로 항상 높은 값이 나오도록 만든다.
예를 들어, 1차원 상에서 [1.0, 1.1, 1.2], [5.0, 5.1, 5.2], [10.0, 10.1, 10.2]라는 세 개의 클러스터가 있다고 가정하자.
이 데이터는 각 클러스터 내부 응집도가 높고, 클러스터 간 거리는 멀기 때문에 실루엣 계수는 거의 1에 가까운 값을 줄 것이다.
그런데 클러스터의 개수를 3개에서 5개로 늘려 조금 더 세분화하거나, 혹은 노이즈가 섞인 데이터를 추가하더라도 실루엣 점수는 여전히 높을 수 있다. 왜냐하면 각 점이 속한 클러스터 내부 거리와 다른 클러스터와의 평균 거리는 여전히 큰 차이를 유지하기 때문이다. 더 나아가, 1차원에서는 클러스터 간 경계가 명확하게 정의되는 경우가 많아, 대부분의 점이 실루엣 계수 계산 시 자신의 클러스터 내부에서는 매우 가까운 거리 평균을, 외부 클러스터와는 비교적 먼 거리 평균을 가지게 된다. 이로 인해 실루엣 점수가 인위적으로 높게 유지된다.
하지만 이 점수는 반드시 클러스터링이 실제로 의미 있는 구분을 잘 수행했음을 의미하지는 않는다. 예를 들어, 데이터가 실제로는 하나의 연속적인 분포를 가지지만 임의로 여러 개의 클러스터로 나눈 경우에도 실루엣 점수는 인위적으로 높게 나올 수 있다.
이런 경우, 실루엣 계수는 클러스터링이 오히려 과도하게 나누어진(over-segmentation) 상태를 정당화하는 수치로 오용될 수 있다. 실루엣 계수의 또 다른 한계는 노이즈에 대한 민감도다. DBSCAN처럼 노이즈를 탐지하는 알고리즘은 클러스터 외부에 속하는 점들을 -1로 라벨링하고 클러스터링에서 제외한다.
하지만 실루엣 계수는 클러스터에 속하지 않는 노이즈 점들에 대해 정의되지 않거나 무시되는 경우가 많다.
이런 구조에서는 노이즈가 많을수록 오히려 실루엣 점수가 인위적으로 상승하는 경향이 나타난다. 즉, 전체 데이터에서 모호하거나 경계선에 위치한 점들을 제거하면, 남은 데이터는 더 응집되어 보이고 클러스터 간 거리도 상대적으로 더 커지기 때문에 실루엣 점수는 더 높아진다.
그러나 이 역시 클러스터링의 품질을 제대로 반영한 것이라고 보기 어렵다. 실제로는 데이터 전체의 분포를 보존하면서 클러스터링하는 것이 더 중요할 수 있으며, 단지 점수를 높이기 위해 노이즈를 제거하는 것은 정당한 방법이 아니다. 또한 실루엣 계수는 모든 점에 대해 평균을 내어 전체 점수로 활용되는데, 이 평균 역시 1차원에서는 쉽게 왜곡된다.
예를 들어, 중심에 있는 점들은 클러스터 내부 거리도 작고 외부 거리도 크기 때문에 실루엣 값이 1에 가까워지지만, 경계에 있는 점들은 이 값이 작거나 음수가 될 수도 있다.
하지만 전체적으로 중심에 있는 점들이 더 많으면 평균 실루엣 점수는 여전히 높게 나올 수 있다. 이로 인해 일부 클러스터가 실제로는 나쁜 품질을 가지고 있음에도 평균 점수는 좋게 나타나는 문제가 발생한다.
고차원에서는 다양한 방향성과 경계를 고려하여 이런 문제가 부분적으로 완화되지만, 1차원에서는 클러스터 경계가 단순히 "왼쪽/오른쪽"으로 나뉘기 때문에 경계점의 정보가 매우 단조롭게 반영된다. 결국, 실루엣 계수는 고차원에서는 거리 정보와 군집 구조를 반영하여 유용하게 사용될 수 있지만, 1차원에서는 거리 정보 외의 구조적 특성이 존재하지 않기 때문에 그 유용성이 현저히 떨어진다.
다양한 클러스터 모양이나 방향성을 구분할 수 없고, 군집 경계의 모호함이나 데이터의 특수한 분포도 반영하지 못한다.
특히, 실루엣 계수는 클러스터링 알고리즘이 자동으로 학습한 구조에 대한 정량적 평가를 수행하고자 할 때 사용되지만, 1차원에서는 구조 자체가 단순하기 때문에 이러한 목적에 부합하지 않는다. 따라서 1차원 데이터에서 실루엣 계수를 그대로 사용하는 것은 실제 군집 품질에 대한 잘못된 인상을 줄 수 있으며, 이를 보완하기 위해서는 실루엣 계수를 단독으로 사용하기보다는 시각화, 클러스터 간 거리 대비 분산 비율, 도메인 지식 기반 해석 등 보조적 평가 방법과 병행하여 해석하는 것이 필요하다. 1차원에서는 클러스터링 평가를 위한 정량 지표가 제공하는 정보가 제한적이므로, 단순히 점수에 의존하기보다는 클러스터 경계의 타당성과 데이터 분포의 맥락을 함께 고려한 해석 중심 접근이 보다 적합하다. 4. 1차원 데이터에서 클러스터링 성능 평가 방법? 1차원 데이터에서 클러스터링 성능을 평가하려면, 분석 목적과 데이터의 구조에 맞는 평가 지표를 선택하는 것이 중요하다. 특히 정답 레이블(ground truth)이 존재하는 경우와 존재하지 않는 경우에 따라 평가 방식이 크게 달라진다. 우선 정답 레이블이 있는 경우라면, 일반적인 지도학습의 분류 문제처럼 외부 평가 지표를 활용할 수 있다. 이 경우 가장 많이 사용되는 지표는 ARI, NMI, F1-score 등이며, 클러스터링의 정확도와 유사성을 정량적으로 비교할 수 있다는 점에서 매우 유용하다. ARI(Adjusted Rand Index)는 예측된 클러스터링 결과와 실제 정답 라벨 간의 유사도를 측정하는 대표적인 지표다. 단순히 일치 비율만 따지는 것이 아니라, 무작위로 클러스터를 나눴을 때 기대되는 일치 비율을 보정한 값이기 때문에 더 객관적인 평가가 가능하다. 예를 들어, 두 개의 클러스터가 존재하고 정답도 두 개의 그룹으로 되어 있을 때, 클러스터 수가 서로 달라도 ARI는 군집 간 일관성만 맞다면 높은 점수를 줄 수 있다. 따라서 다양한 클러스터 수를 실험할 때 성능 비교 지표로 매우 적합하다. NMI(Normalized Mutual Information)는 정보 이론에 기반한 지표로, 정답 레이블과 예측된 클러스터 간의 상호 정보를 측정한다. 이 지표는 클러스터의 라벨 이름이 달라도, 구조적으로 동일한 군집을 형성했다면 높은 점수를 부여한다는 장점이 있다. 특히 클러스터 수가 많거나 라벨이 복잡할 때도 비교적 안정적인 평가가 가능하다. 예를 들어, 동일한 데이터를 가지고 두 개의 알고리즘이 다른 라벨을 부여했지만 군집 구조가 비슷하다면 NMI는 이를 긍정적으로 평가한다. F1-score는 클러스터링 결과를 분류 문제처럼 간주하여 계산할 수 있다. 각 클러스터를 하나의 클래스처럼 보고, 정답 라벨과의 일치 여부를 precision, recall을 통해 계산한 후 F1 점수로 요약한다. 이 방법은 특히 정답 라벨이 명확하게 주어져 있을 때 각 클러스터의 품질을 파악하는 데 유용하다. 다만, 이 방식은 클러스터의 수가 실제 클래스 수와 유사할 때 잘 작동하며, 군집 간 매칭 문제를 적절히 해결하지 않으면 왜곡된 결과를 낼 수 있다는 점을 주의해야 한다. 이처럼 외부 지표들은 1차원인지 고차원인지에 관계없이 정답 라벨만 있다면 적용 가능하며, 클러스터링의 정량적 평가에 매우 효과적이다. 하지만 현실적으로는 클러스터링 대상 데이터에 정답이 없는 경우가 더 많다. 이럴 때는 내재적 평가 지표 또는 해석 기반의 평가 방식이 필요하다. 그러나 1차원에서는 내재적 지표들이 예상보다 신뢰성이 떨어지거나 의미 없는 수치를 제공할 수 있기 때문에, 보다 조심스럽게 접근해야 한다. 정답 라벨이 없는 경우 사용할 수 있는 한 가지 방법은 클러스터 간 구간 분리도를 측정하는 것이다. 이는 각 클러스터 중심 간의 평균 거리와 클러스터 내부의 평균 분산을 비교하는 방식이다. 예를 들어, 각 클러스터의 중심이 10, 20, 30이고 클러스터 내 표준편차가 2라면, 중심 간 거리는 크고 내부 분산은 작으므로 구분이 잘 된 클러스터라고 볼 수 있다. 이때 사용되는 수식은 보통 separation = 평균 중심 거리 / 평균 클러스터 내 표준편차이며, 이 값이 1보다 크면 기본적으로 “구간이 잘 나뉘었다”고 해석할 수 있다. 이 방식은 실루엣 계수처럼 평균 거리 기반이지만, 보다 단순하고 1차원에 특화된 해석이 가능하다. 또한 클러스터 내 분산을 개별적으로 분석하는 방식도 고려해볼 수 있다. 각 클러스터가 얼마나 응집되어 있는지를 개별적으로 확인하고, 동시에 전체 클러스터 수와 비교함으로써 과적합 여부를 점검하는 것이다. 예를 들어, 클러스터 수가 지나치게 많고 각 클러스터의 분산이 매우 작다면 이는 과도하게 군집이 나뉜 것일 수 있다. 반대로, 클러스터 수가 적지만 분산이 너무 크다면 서로 다른 군집을 하나로 합쳐버린 잘못된 분할일 수 있다. 이처럼 분산 기반 평가는 군집 수 조정과 해석의 균형을 맞추는 데 도움이 된다. 무엇보다도 1차원에서는 데이터의 시각화가 매우 쉬우므로, 직접적인 시각 검토가 가장 효과적일 수 있다. 각 클러스터의 경계를 눈으로 확인하고, 클러스터 간 간격이 얼마나 명확한지, 데이터가 밀집되어 있는 구간과 노이즈가 포함된 영역이 어떻게 나뉘는지를 직접 확인할 수 있다. 예를 들어, 시계열 데이터에서 특정 시점마다 분포가 급격히 달라진다면 이를 시각적으로 포착하여 클러스터 구간을 재조정할 수 있다. 또한, 노이즈가 많은 경우에는 클러스터 외부의 데이터가 어떻게 분포되어 있는지도 판단할 수 있으며, 이러한 시각적 정보는 단순한 수치보다 더 신뢰성 높은 해석을 제공할 수 있다. 요약하자면, 1차원 데이터에서 클러스터링 성능을 평가할 때 정답 레이블이 있다면 외부 지표를 적극 활용하는 것이 가장 바람직하며, ARI, NMI, F1-score 등은 군집 수, 라벨 이름의 차이에 상관없이 비교적 객관적인 판단을 제공한다. 그러나 정답 레이블이 없는 경우에는 클러스터 간 거리 대비 분산 비율, 클러스터 내 분산 분석, 시각적 경계 확인 등 보다 해석 중심의 방법을 병행하여 평가하는 것이 필요하다. 특히 1차원에서는 구조가 단순하고, 거리 기반 지표가 과대평가되는 경향이 있으므로, 수치적 평가보다는 데이터의 실제 분포와 의미를 고려한 통합적 판단이 중요하다.</a></p><hr><p><em>2025-07-28</em> ⋯ DBSCAN #2 슈도코드</p><p style=height:4.5em;overflow:hidden><a href=/docs/study/ai/ai9/>데이터 집합 D, 파라미터 eps와 minPts가 들어간다. 주석 처리 안된 부분만 보기. 먼저 현재위치 x의 eps 내에 데이터 포인트가 몇개인지부터 확인한다. minPts보다 작으면, 노이즈로 처리한다. 아니면? 클러스터 확장을 수행한다. 현재위치 x의 eps 내에 데이터포인트들을 봣을때, 노이즈가 아닌 이웃포인트 y는 regionQuery를 수행해서 반경 내 데이터포인트수가 minPts 보다 크면 반경 내 모든 데이터포인트들을 x의 neighbor로 통합한다. 노이즈였지만 현재는 x의 이웃포인트가 된 y는 border point로 재분류해준다.</a></p><hr><p><em>2025-07-23</em> ⋯ TFT #3 모델 학습</p><p style=height:4.5em;overflow:hidden><a href=/docs/study/ai/ai7/>1. Load package data 2. Load data 3.</a></p><hr><div class=pagination style=margin-top:2rem;display:flex;justify-content:center;align-items:center;gap:1rem><a href=/categories/ai/ style="padding:.5rem 1rem;text-decoration:none">←</a>
<span style=color:#666>2 / 3
</span><a href=/categories/ai/page/3/ style="padding:.5rem 1rem;text-decoration:none">→</a></div></article><footer class=book-footer><div class="flex flex-wrap justify-between"></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents></nav></div></aside></main></body></html>