<!doctype html><html lang=en-us dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="https://yshghid.github.io/categories/ai/"><meta property="og:site_name" content=" "><meta property="og:title" content="AI"><meta property="og:locale" content="en_us"><meta property="og:type" content="website"><title>AI |</title><link rel=icon href=/favicon.png><link rel=manifest href=/manifest.json><link rel=canonical href=https://yshghid.github.io/categories/ai/><link rel=stylesheet href=/book.min.30a7836b6a89342da3b88e7afd1036166aeced16c8de12df060ded2031837886.css integrity="sha256-MKeDa2qJNC2juI56/RA2Fmrs7RbI3hLfBg3tIDGDeIY=" crossorigin=anonymous><script defer src=/fuse.min.js></script><script defer src=/en.search.min.173b9633522e5f435db63a2dec2626e03ef11fa39d2a7de87e716e58ee3be567.js integrity="sha256-FzuWM1IuX0Ndtjot7CYm4D7xH6OdKn3ofnFuWO475Wc=" crossorigin=anonymous></script><link rel=alternate type=application/rss+xml href=https://yshghid.github.io/categories/ai/index.xml title=" "></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><img src=/logo.png alt=Logo class=book-icon><span></span></a></h2><div class="book-search hidden"><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><script>document.querySelector(".book-search").classList.remove("hidden")</script><ul><li class=book-section-flat><span>기록</span><ul><li><a href=/docs/hobby/book/>글</a><ul></ul></li><li><a href=/docs/hobby/daily/>일상</a><ul></ul></li></ul></li><li class=book-section-flat><span>공부</span><ul><li><a href=/docs/study/ai/>AI/Data</a><ul></ul></li><li><a href=/docs/study/dl/>DL</a><ul></ul></li><li><a href=/docs/study/bioinformatics/>Bioinformatics</a><ul></ul></li><li><a href=/docs/study/be/>BE</a><ul></ul></li><li><a href=/docs/study/fe/>FE</a><ul></ul></li><li><a href=/docs/study/career/>취업</a><ul></ul></li></ul></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu></label><h3>AI</h3><label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents></nav></aside></header><article class="markdown book-article"><p><em>2025-08-21</em> ⋯ MLops #1 mlflow 설치 & 실습</p><p style=height:4.5em;overflow:hidden><a href=/docs/study/ai/ai24/>1. mlflow 설치 및 docker 띄우기 로그인햇으면 도커를 켠다음에 다음을 수행. 확인해보면 제대로 떠있다!!
MLflow 서버를 띄웠고 경고창이 뜨는데 호스트 CPU는 ARM64이고 MLflow 공식 이미지는 AMD64여서 플랫폼 불일치 이슈가 있지만 문제되지는 않고 만약에 해결하고싶으면 docker-compose.yml에 아래와같이쓰면 댄다고함. docker ps 해보면 떠있는걸볼수있고 확인후에 http://localhost:5001/ 접속하기 잘들어가있다!! 2. mlflow quick start 튜토리얼 링크 - https://mlflow.org/docs/latest/getting-started/intro-quickstart/index.html 위에서 한 내용이 step1-2여서 step3부터 하면 댄다. - step3는 그냥 사이킷런으로 기본적인 모델 만들기. - step4는 tracking uri를 설정하고 현재 experiment에 대한 name을 MLflow Quickstart로 정한다.
- model_info에 step3에서 만들었던 lr 모델을 보낸다. - model loading을 하고
- loading된 model을 가지고 test dataset을 사용해서 prediction을 한다. 3. mlflow experiments 모델 inference를 하면 mlflow의 experiments에 뜬다. (ui에서 information을 볼수있다) 확인하는원리는?
- compose.yml을 보면 라고 돼있는데 local의 mlruns 디렉토리를 /mlflow/mlruns 도커 이미지 안에 매핑을 시키면 mlruns 디렉토리내 모든 파일들이 도커 이미지로 들어간다. 확인하는법은? - docker 안으로 들어가서 /mlflow/mlruns 들어가기. 여기서 python tutorial.py를 하면 실행된다. - iris 데이터를 가지고 모델을 만들고
- mlflow가 tracking을 하고
- model을 만들어서 tracking-quickstart라는 이름으로 register를 함
- 그리고 result를 출력.
- tracking url은?
- compose.yml에 MLFLOW_TRACKING_URI=http://0.0.0.0:5000 로 돼있어서 자동으로 이쪽으로간다(공식 튜토리얼은 mlflow.set_tracking_uri(uri="http://127.0.0.1:8080") tutorial.py에서 run하는부분 코드를 보면 이렇다 암튼 이렇게 Inference를 했고 UI(http://localhost:5001/)를보면 mlflow quickstart가 왼쪽에 생겻고 클릭하면 inference(prediction)한게 나온다. 해당 experiment를 확인해보면 - 모델에 대한 정보 environment conda, python environment, requirements.txt 등이 다 넘어왔고
- tagging이돼있음
- tracking quickstart 누르면
- register된 모델도 아래처럼 뜬다. 정리하면?
- mlflow를 docker pull해서 설치하고 inference해서 ui에서 어떻게 flow가 뜨는지랑 모델 register를 확인함.</a></p><hr><p><em>2025-08-19</em> ⋯ 데이터 분석 #4 리뷰 데이터 분석</p><p style=height:4.5em;overflow:hidden><a href=/docs/study/ai/ai22/>1. 목적 리뷰 데이터를 보고 - 감성 점수와 평점의 관계 - 리뷰 길이와 감성 점수의 관계 - 카테고리별 감성 차이 - Review_length가 AI 임베딩 유사도에 영향을 줄 수 있는지 인사이트 생성하기. 2. 코드 3. 생각 결측치 처리 - 나는 결측치가 하나라도 있는 샘플은 다 제거했는데 다른 사람들꺼보니깐 review_text 컬럼의 결측값을 'no review'로 대체하는 경우도 있었다. 이게 낫나? - 리뷰랑 상관없는 인사이트 (감성점수 vs 평점, 카테고리별 감성차이)에는 데이터가 확보되니깐 좋고. - 리뷰 길이가 AI 임베딩 유사도에 영향을 줄수있는지 &lt;- 여기서는 오히려 잘못된 데이터 심어주는게 대지않나 싶음. - 리뷰길이 vs 감성점수의 관계도 마찬가지. 이상치 탐지 - 이상치 탐지는 보통 IQR을 쓰던데 나는 IQR 너무 많지 않나 한두개만 제거하면대는데? 생각해서 챗지피티한테 다른거추천해달라니깐 상하위 1% 추천해주길래 그걸로햇다. - 다른사람들 IQR 한거보니 리뷰길이는 3개 단어개수는 2개등 몇개 안되길래 결과는 비슷햇을듯. (나는 6개 제거됏엇던듯) - 근데 rating이 평점같은데 평점은 1점 줄수있지않나? 특이취향을 제거하는셈이 돼버리니깐 이건 제거안하길 잘한거같다. 이상치 box plot - before box plot그리고 after box plot도 그렷으면 더 이뻤겟다. 상관관계 - 나는 감성 점수 vs 평점, 리뷰 길이 vs 감성 점수, 리뷰 길이 vs AI 임베딩 유사도 비교에서 매번 상관계수를 그냥 구햇는데 - correlation matrix 그린 사람도 있어서 그것도 괜찮은듯하다 - 상관관계 전부다 낮게나왓는데 그건 남들도 마찬가지 같아서 다행이엇다. 감성점수 vs 평점 scatter plot - 장르별로 색깔 다르게한사람 좀 있던데 그림자체는 안이쁘지만 좋은접근같았다. category별 평균평점 - 다른사람들도 어쩔수없었겟지만 아쉬운게 y축 max를 모르니깐 플롯이 다 안이뻣다. 멀 말하고자하는지 잘 안보엿다. 아마 max 5였겠지? 근데이건 정보가 없으니깐.. 리뷰 길이 vs AI 임베딩 유사도 - 이거야말로 어케하란건지 모르겠어서 - 처음에는 랜덤하게고른(사실 첫번째) 기준 리뷰와의 유사도를 다 계산하고 리뷰길이 vs 임베딩유사도의 corr을 구했는데 - 목적이 '모든 리뷰 쌍 간의 임베딩 유사도' 또는 '임베딩 모델의 특성상 길이가 의미 표현에 미치는 영향'을 보는건데 - 내가수행한건 '기준 리뷰와의 유사도가 길이에 따라 변하는지' 본거라 데이터셋 전체의 관계를 본게아니라 한 기준점에 대해서만 수행한셈이 되길래, - 각 리뷰가 다른 모든 리뷰와 가지는 평균 임베딩 유사도를 계산하는 방식으로 다시 했었다 - 남들 어케했는지 궁금했는데 - '기준 리뷰와의 유사도가 길이에 따라 변하는지' 본사람도있고 - 임베딩 어케하는지에따라 다르다 그냥이렇게쓴사람도 있고... - 얘는 답을 몰겟음.</a></p><hr><p><em>2025-08-09</em> ⋯ 생성형 AI #2 Prompt Engineering 실습 미리돌려보기</p><p style=height:4.5em;overflow:hidden><a href=/docs/study/ai/ai19/>1. VOC 분석 setting - https://openrouter.ai/ - Model: GPT-5 - Temperature: 0.2 (낮게: 일관성 있는 분류 결과) - Top-k / Top-p: default - Max tokens: 1024 system prompt user prompt result | 번호 | VOC 내용 | 분류 | 판단 근거 | |------|---------|------|----------| | 1 | 복잡한 엑셀 정리에서 해방됐어요. 기존 수작업으로 처리하던 매출/비용 분석을 자동화해 시간 절약 효과를 체감했습니다. | 긍정 | - | | 2 | 회계 비전문가인 마케팅 담당자도 재무 지표의 의미를 쉽게 파악할 수 있었습니다. | 긍정 | - | | 3 | AI 추천 덕분에 세무 위험을 미리 인지했어요. 실제로 부가세 누락 가능성을 사전에 알림 받아, 실제 신고 전에 정정할 수 있었던 점이 유용했습니다. | 긍정 | - | | 4 | 실시간으로 현금흐름을 추적할 수 있어 좋았습니다. 회계팀 없이도 매주 자금 흐름을 파악하고 의사결정에 반영할 수 있었습니다. | 긍정 | - | | 5 | 처음에만 가이드를 받고 나니 반복 작업이 놀랍도록 간단해졌습니다. 설정만 끝나면 이후 반복 업무에서 자동화된 결과물이 기대 이상으로 좋네요. | 긍정 | - | | 6 | 기능은 흥미롭지만, 실제 업무에 어떻게 녹여야 할지 고민이 됩니다. 시스템이 낯설고 기존 워크플로우와 맞물리는 데 시간이 필요해 보입니다. | 부정 | 1. 적용 방법에 대한 명확한 가이드 부족
2. 기존 시스템과의 통합 어려움 | | 7 | 예쁜 그래프가 많긴 하지만 실무상 의미가 뚜렷하게 와 닿지는 않았습니다. | 부정 | 1. 시각적 효과는 있으나 실용성 미흡
2. 구체적인 데이터 분석 기능 부재 | | 8 | AI가 추천해주는 분석은 흥미로웠지만, 최종 결정은 여전히 사람이 해야겠더라고요. 완전한 자동화보다는 보조 도구로 보는 것이 현실적이라 느꼈습니다. | 부정 | 1. AI의 신뢰도 및 정확성 한계
2. 의사결정 과정에서의 자동화 미비 | | 9 | 피벗 기능이나 드릴다운 기능이 있었으면 더 좋을 것 같긴 해요. 보고서 결과는 직관적이지만, 좀 더 상세 데이터를 보고 싶을 때 아쉬움이 있습니다. | 중립 | - | | 10 | 회계 전문가 입장에서는 보안이 필요해 보이지만, 일반 사용자에겐 적합할 수도 있겠네요. 어떤 고객을 주 대상으로 할지 더 명확하면 좋겠습니다. | 중립 | - | | 11 | 일부 기능은 대기업 회계 기준에 맞춰져 있어 간편한 사용을 기대한 소규모 기업에는 과도했습니다. | 부정 | 1. 소규모 기업의 요구사항 미반영
2. 기능의 복잡성으로 인한 사용 장벽 | | 12 | AI 설명이 부족해 불안했어요. AI가 어떤 기준으로 판단했는지, 근거가 불투명해 검토에 시간이 걸렸습니다. | 부정 | 1. AI 프로세스의 투명성 부족
2. 결과 검증에 추가 리소스 소모 | | 13 | 엑셀 연동 시 포맷 오류가 잦았습니다. 업로드한 자료가 표준 포맷이 아닐 경우 오류가 자주 발생했습니다. | 부정 | 1. 데이터 호환성 문제
2. 사용자 입력 오류에 대한 유연성 부족 | | 14 | 초기 세팅에 시간이 좀 걸렸습니다. 계정과목 연결, 은행 계좌 연동 등 초기 설정을 마치기까지 다소 복잡하게 느껴졌습니다. | 부정 | 1. 초기 설정의 복잡성
2. 사용자 편의성 저하 | | 15 | 사용자별 접근 권한 설정이 더 세분화되었으면 합니다. 팀 내 다양한 역할별로 보기 권한을 구분하고 싶었는데 현재는 제한적이었습니다. | 부정 | 1. 권한 관리 기능의 제한성
2. 조직 내 역할별 맞춤형 설정 미지원 | 2. 관리를 위한 규격화된(JSON) 정보 생성 setting - https://openrouter.ai/ - Model: Gemma 3 27B (free) - Temperature: 0.2 - Top-k / Top-p: default - Max tokens: 1024 system prompt user prompt result 3. 컨설팅 리서치 & 전략 수립 setting - https://openrouter.ai/ - Model: Gemma 3 27B (free) - Temperature: 0.2 - Top-k / Top-p: default - Max tokens: 1024 system prompt user prompt result 4. 신상품 출시 프로모션(행사) 기획안 작성 setting - https://openrouter.ai/ - Model: Gemma 3 27B (free) - Temperature: 0.2 - Top-k / Top-p: default - Max tokens: 1024 system prompt user prompt result 5. 이력서 파일 검토 setting - https://openrouter.ai/ - Model: Gemma 3 27B (free) - Temperature: 0.2 - Top-k / Top-p: default - Max tokens: 1024 system prompt user prompt result 6. 비용관리 엑셀 템플릿 생성 setting - https://openrouter.ai/ - Model: Gemma 3 27B (free) - Temperature: 0.2 - Top-k / Top-p: default - Max tokens: 1024 system prompt user prompt result ~*링크가 없는데..*~ 7. 마케팅용 기술 블로그 작성 setting - https://openrouter.ai/ - Model: Gemma 3 27B (free) - Temperature: 0.2 - Top-k / Top-p: default - Max tokens: 2048 (1024하니까 말이 끊김) system prompt user prompt - 근데 첨부할 파일이 없길래 그냥했다. result</a></p><hr><p><em>2025-08-09</em> ⋯ 생성형 AI #1 생성형 AI 기초 및 Prompt Engineering</p><p style=height:4.5em;overflow:hidden><a href=/docs/study/ai/ai18/>RAG (p.27) RAG의 역할? - 질문을 LLM에 던지기 전에 knowledge corpus에 질문을 미리 검색한다(회사 데이터에 대한 지식 벡터 db). - 질문과 연관된 문서를 찾고 적절하게 만들어서 retrieval 던지면 의도대로 답변이 잘 나온다. LLM 출력 구성 (p.42-45) Output Length (Max Tockens) - 500자로 제한을 걸면 500자로 맞춰주는게 아니라 500자 넘으면 출력을 멈춘다. Sampling Controls - LLM은 다음에 올 단어를 고를 때 미리 계산된 사전 확률분포를 가지고 거기서 하나를 뽑는다 - temperature로 무작위성의 정도를 조절. - temperature를 0으로하면 확률이 가장 높은 단어만 거의 항상 선택 - 그림에서 원래의 확률분포가 가운데 그림처럼 생겼더라도 temp를 0으로 낮추면 첫 번째 그림처럼 가장 높은 확률에 몰빵되어 다른 선택지는 거의 배제된다. - 반대로 temperature를 2로 올리면 확률이 평평해져서 원래 1등이 아니었던 단어들도 선택될 가능성이 높아진다. - 이렇게 임의성을 높이면 흔하지 않은 단어가 튀어나올 확률이 커지고 결과가 예측 불가능해지고 창의성이 늘어난다. - TopK - 다음에 올 단어 후보 중에서 확률이 가장 높은 K개만 남기고 나머지는 버림 - K값이 크면 후보 폭이 넓어져서 더 다양한 결과가 나오고 창의성이 높아진다. - K값이 작으면 몇 개의 후보만 남아서 결과가 더 안정적이고 사실적인 방향으로 수렴한다. - TopP - 누적 확률이 특정 값 p에 도달할 때까지의 상위 후보만 남기기 예를 들어 p가 0이면 항상 가장 가능성이 높은 단어 하나만 선택하고, p가 1이면 거의 모든 단어가 후보에 포함. - TopK TopP를 통과하고나서 temperature 값이 적용된다. - temperature가 낮으면 이 후보 중에서 가장 확률이 높은 단어를 고르는 쪽으로 기울어지고, 높으면 확률 분포를 평평하게 만들어 무작위성이 커진다. 낮은 temperature에서는 사실상 Greedy decoding처럼 정답 하나를 뽑는 느낌이고, 높은 temperature에서는 후보 중에서 랜덤하게 섞어 뽑는 Sampling 방식이 된다. - 흐름예시 1. 다음 토큰 후보마다 사전확률을 계산하고 이 후보들을 확률이 높은 순으로 정렬한 뒤 TopK를 적용하면 예를 들어 K=2일 때 가장 높은 두 개만 남기고 나머지는 모두 버린다. TopP를를 쓰면 누적 확률이 p에 도달할 때까지 후보를 남기고 이후는 잘라낸다. 2. 필터링을 하고 남은 후보들에 temperature를 적용한다. temperature가 낮으면 확률 분포가 뾰족해져서 가장 가능성이 높은 후보를 뽑을 확률이 커지고, 높이면 분포가 평평해져서 확률이 낮은 후보도 비슷한 기회로 선택된다.</a></p><hr><div class=pagination style=margin-top:2rem;display:flex;justify-content:center;align-items:center;gap:1rem><a href=/categories/ai/ style="padding:.5rem 1rem;text-decoration:none">←</a>
<span style=color:#666>2 / 2</span></div></article><footer class=book-footer><div class="flex flex-wrap justify-between"></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents></nav></div></aside></main></body></html>