<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>AI on Lifelog 2025</title><link>https://yshghid.github.io/categories/ai/</link><description>Recent content in AI on Lifelog 2025</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Thu, 26 Jun 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://yshghid.github.io/categories/ai/index.xml" rel="self" type="application/rss+xml"/><item><title>#2 Explainable AI</title><link>https://yshghid.github.io/docs/study/etc/etc2/</link><pubDate>Thu, 26 Jun 2025 00:00:00 +0000</pubDate><guid>https://yshghid.github.io/docs/study/etc/etc2/</guid><description>&lt;h1 id="2-explainable-ai">
 #2 Explainable AI
 &lt;a class="anchor" href="#2-explainable-ai">#&lt;/a>
&lt;/h1>
&lt;p>#2025-06-26&lt;/p>
&lt;hr>
&lt;h3 id="1-explainable-ai란">
 1. Explainable AI란?
 &lt;a class="anchor" href="#1-explainable-ai%eb%9e%80">#&lt;/a>
&lt;/h3>
&lt;p>Explainable AI는 인공지능(AI) 또는 머신러닝(ML) 모델이 어떤 방식으로 특정 결과를 도출했는지 사람이 이해할 수 있도록 설명하는 기술과 방법론.&lt;/p>
&lt;h3 id="2-xai-기법-분류">
 2. XAI 기법 분류
 &lt;a class="anchor" href="#2-xai-%ea%b8%b0%eb%b2%95-%eb%b6%84%eb%a5%98">#&lt;/a>
&lt;/h3>
&lt;p>모델 구조&lt;/p>
&lt;ul>
&lt;li>Intrinsic:	모델 자체가 설명 가능한 구조 (예: 의사결정나무, 선형회귀 등)&lt;/li>
&lt;li>Post-hoc:	모델 학습 후 별도로 설명 생성 (예: SHAP, LIME)
대상&lt;/li>
&lt;li>Global:	전체 모델의 작동 원리를 설명&lt;/li>
&lt;li>Local:	특정 샘플의 예측 결과를 설명&lt;/li>
&lt;/ul>
&lt;h3 id="3-주요-post-hoc-설명-기법">
 3. 주요 Post-hoc 설명 기법
 &lt;a class="anchor" href="#3-%ec%a3%bc%ec%9a%94-post-hoc-%ec%84%a4%eb%aa%85-%ea%b8%b0%eb%b2%95">#&lt;/a>
&lt;/h3>
&lt;p>LIME (Local Interpretable Model-Agnostic Explanations): 주변 입력을 랜덤하게 생성하고, 단순 모델(선형 회귀 등)을 학습해 근사&lt;/p></description></item><item><title>#3 Random Forest</title><link>https://yshghid.github.io/docs/study/etc/etc3/</link><pubDate>Thu, 26 Jun 2025 00:00:00 +0000</pubDate><guid>https://yshghid.github.io/docs/study/etc/etc3/</guid><description>&lt;h1 id="3-random-forest">
 #3 Random Forest
 &lt;a class="anchor" href="#3-random-forest">#&lt;/a>
&lt;/h1>
&lt;p>#2025-06-26&lt;/p>
&lt;hr>
&lt;h3 id="1-random-forest의-분류와-회귀">
 1. Random Forest의 분류와 회귀
 &lt;a class="anchor" href="#1-random-forest%ec%9d%98-%eb%b6%84%eb%a5%98%ec%99%80-%ed%9a%8c%ea%b7%80">#&lt;/a>
&lt;/h3>
&lt;p>랜덤 포레스트(Random Forest)는&lt;/p>
&lt;ul>
&lt;li>RandomForestClassifier: 분류용&lt;/li>
&lt;li>RandomForestRegressor: 회귀용 이다.&lt;/li>
&lt;/ul>
&lt;p>분류와 회귀의 핵심 차이는&lt;/p>
&lt;ul>
&lt;li>분류는 각 leaf node에 속한 클래스의 비율을 기반으로 확률 예측&lt;/li>
&lt;li>회귀는 leaf node에 있는 target 값들의 평균을 예측값으로 사용&lt;/li>
&lt;/ul>
&lt;p>랜덤 포레스트의 트리 구조(= 리프 분기 방식)는 분류나 회귀나 똑같고&lt;/p>
&lt;ul>
&lt;li>단지 리프 노드에 어떤 데이터 형식이 들어가느냐에 따라
&lt;ul>
&lt;li>분류이면 라벨 비율(확률 분포)&lt;/li>
&lt;li>회귀이면 값의 평균으로 예측을 내놓는다&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="2-트리-기반-모델과-클러스터링의-차이">
 2. 트리 기반 모델과 클러스터링의 차이
 &lt;a class="anchor" href="#2-%ed%8a%b8%eb%a6%ac-%ea%b8%b0%eb%b0%98-%eb%aa%a8%eb%8d%b8%ea%b3%bc-%ed%81%b4%eb%9f%ac%ec%8a%a4%ed%84%b0%eb%a7%81%ec%9d%98-%ec%b0%a8%ec%9d%b4">#&lt;/a>
&lt;/h3>
&lt;p>랜덤 포레스트(혹은 결정 트리)의 리프 분기 방식은 &amp;lsquo;거리 기반&amp;rsquo;이 아님&lt;/p></description></item></channel></rss>