<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Ray on</title><link>https://yshghid.github.io/categories/ray/</link><description>Recent content in Ray on</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Mon, 15 Sep 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://yshghid.github.io/categories/ray/index.xml" rel="self" type="application/rss+xml"/><item><title>Ray #1 Batch Prediction with Ray Core</title><link>https://yshghid.github.io/docs/study/be/be6/</link><pubDate>Mon, 15 Sep 2025 00:00:00 +0000</pubDate><guid>https://yshghid.github.io/docs/study/be/be6/</guid><description>&lt;h1 id="ray-1-batch-prediction-with-ray-core"&gt;
 Ray #1 Batch Prediction with Ray Core
 &lt;a class="anchor" href="#ray-1-batch-prediction-with-ray-core"&gt;#&lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;#2025-09-15&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;스터디때 준비해갔던 Ray Core를 사용해서 batch prediction 수행하는 예제!!&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;batch prediction이 batch를 예측하는건줄알았는데(..) batch로 prediction하는것이었다.&lt;/li&gt;
&lt;li&gt;순서는 1. Task 기반 batch prediction 2. Actor 기반 batch prediction 3. GPU 기반 수행 코드&lt;/li&gt;
&lt;li&gt;출처는 Ray Document의 &lt;a href="https://docs.ray.io/en/latest/ray-core/examples/batch_prediction.html"&gt;Batch Prediction with Ray Core&lt;/a&gt;이다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=""&gt;
 
 &lt;a class="anchor" href="#"&gt;#&lt;/a&gt;
&lt;/h3&gt;
&lt;h3 id="0-개요"&gt;
 0. 개요
 &lt;a class="anchor" href="#0-%ea%b0%9c%ec%9a%94"&gt;#&lt;/a&gt;
&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;목적
&lt;ul&gt;
&lt;li&gt;Parquet 형식의 대규모 데이터셋을 Ray를 이용해 분산 처리하며, 더미 모델을 로딩하여 배치 예측(batch prediction) 을 수행한다.&lt;/li&gt;
&lt;li&gt;Task와 Actor 두 가지 실행 방식을 비교하고, CPU/GPU 자원 활용 차이를 이해한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;설계
&lt;ul&gt;
&lt;li&gt;데이터셋 분할: S3에 저장된 Parquet 파일(12 shards)을 불러와 분산 태스크 단위로 처리&lt;/li&gt;
&lt;li&gt;모델 로딩: 더미 모델(load_model)을 정의하고 ray.put()을 통해 오브젝트 스토어에 1회 저장&lt;/li&gt;
&lt;li&gt;배치 예측(Task 기반): @ray.remote 태스크로 각 shard를 병렬 예측, 결과 크기 반환&lt;/li&gt;
&lt;li&gt;배치 예측(Actor 기반): BatchPredictor 클래스를 Ray Actor로 등록하고, ActorPool을 이용해 shard 분산 예측&lt;/li&gt;
&lt;li&gt;자원 활용(CPU/GPU): CPU 환경에서는 기본 Task 실행, GPU 환경에서는 @ray.remote(num_gpus=1)를 사용해 GPU에서 모델을 실행하도록 구성&lt;/li&gt;
&lt;li&gt;결과 확인: 각 shard에 대해 예측된 결과 크기를 출력하여 병렬 처리 동작을 검증&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=""&gt;
 
 &lt;a class="anchor" href="#"&gt;#&lt;/a&gt;
&lt;/h3&gt;
&lt;h3 id="1-코드"&gt;
 1. 코드
 &lt;a class="anchor" href="#1-%ec%bd%94%eb%93%9c"&gt;#&lt;/a&gt;
&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#75715e"&gt;# 0. 환경 준비&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#960050;background-color:#1e0010"&gt;!&lt;/span&gt;pip &lt;span style="color:#f92672"&gt;-&lt;/span&gt;q install ray pandas pyarrow s3fs torch
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#75715e"&gt;# 1. Ray 초기화&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#f92672"&gt;import&lt;/span&gt; ray
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;ray&lt;span style="color:#f92672"&gt;.&lt;/span&gt;init()
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#75715e"&gt;# 2. 더미 모델 정의&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#f92672"&gt;import&lt;/span&gt; pandas &lt;span style="color:#66d9ef"&gt;as&lt;/span&gt; pd
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#f92672"&gt;import&lt;/span&gt; numpy &lt;span style="color:#66d9ef"&gt;as&lt;/span&gt; np
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#66d9ef"&gt;def&lt;/span&gt; &lt;span style="color:#a6e22e"&gt;load_model&lt;/span&gt;():
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#75715e"&gt;# A dummy model&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#66d9ef"&gt;def&lt;/span&gt; &lt;span style="color:#a6e22e"&gt;model&lt;/span&gt;(batch: pd&lt;span style="color:#f92672"&gt;.&lt;/span&gt;DataFrame) &lt;span style="color:#f92672"&gt;-&amp;gt;&lt;/span&gt; pd&lt;span style="color:#f92672"&gt;.&lt;/span&gt;DataFrame:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; model&lt;span style="color:#f92672"&gt;.&lt;/span&gt;payload &lt;span style="color:#f92672"&gt;=&lt;/span&gt; np&lt;span style="color:#f92672"&gt;.&lt;/span&gt;zeros(&lt;span style="color:#ae81ff"&gt;100_000_000&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#66d9ef"&gt;return&lt;/span&gt; pd&lt;span style="color:#f92672"&gt;.&lt;/span&gt;DataFrame({&lt;span style="color:#e6db74"&gt;&amp;#34;score&amp;#34;&lt;/span&gt;: batch[&lt;span style="color:#e6db74"&gt;&amp;#34;passenger_count&amp;#34;&lt;/span&gt;] &lt;span style="color:#f92672"&gt;%&lt;/span&gt; &lt;span style="color:#ae81ff"&gt;2&lt;/span&gt; &lt;span style="color:#f92672"&gt;==&lt;/span&gt; &lt;span style="color:#ae81ff"&gt;0&lt;/span&gt;})
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#66d9ef"&gt;return&lt;/span&gt; model
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;실습에서는 분산 처리 흐름을 보는 것이 핵심이기 때문에 실제 모델이 갖는 특성을 갖는 더미 모델을 생성해준다.
&lt;ul&gt;
&lt;li&gt;실제 모델이 갖는 특성 = 정확히는 실제 모델이 갖는 특성 중 분산 처리에 관여하는 특성.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;실제 모델이 갖는 특성 2가지?
&lt;ol&gt;
&lt;li&gt;큰 메모리 용량. 실제 머신러닝 모델, 특히 딥러닝 모델은 수백 MB에서 수 GB에 달하는 가중치 파라미터를 담고 있다 예를 들어 BERT나 GPT 같은 모델은 엄청난 수의 파라미터를 갖기 때문에, 한 노드에서 다른 노드로 옮길 때 그 자체로 데이터 전송 비용이 크므로 이를 구현해준다.&lt;/li&gt;
&lt;li&gt;입력 데이터를 받아서 변환된 출력을 만듭니다. 실제 모델은 어떤 입력(이미지, 텍스트, 테이블 데이터 등)을 받아서 예측값을 내놓으므로, 이를 구현해줍니다.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;구현 방법?
&lt;ol&gt;
&lt;li&gt;model.payload = np.zeros(100_000_000)&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;큰 메모리의 가중치 파라미터를 담고 있음을 모방하는 코드. 모델이 내부적으로 “큰 덩어리” 데이터를 가진 객체처럼 보이며 이를 통해 Ray가 이 모델을 여러 노드에 배포할 때 진짜처럼 부담을 준다.&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start="2"&gt;
&lt;li&gt;{&amp;ldquo;score&amp;rdquo;: batch[&amp;ldquo;passenger_count&amp;rdquo;] % 2 == 0}&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;입력값을 받아서 예측값을 내놓음을 모방하는 코드. 모델은 dataframe을 input으로 받아 승객 수가 짝수냐 홀수냐를 판별한다 즉 “입력 데이터를 보고 뭔가 계산해서 새로운 결과를 만든다”라는 모델의 핵심 행위만 구현한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=""&gt;
 
 &lt;a class="anchor" href="#"&gt;#&lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;&lt;mark&gt;1. Task 기반 batch prediction&lt;/mark&gt;&lt;/p&gt;</description></item></channel></rss>