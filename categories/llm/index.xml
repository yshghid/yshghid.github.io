<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>LLM on</title><link>https://yshghid.github.io/categories/llm/</link><description>Recent content in LLM on</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Tue, 19 Aug 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://yshghid.github.io/categories/llm/index.xml" rel="self" type="application/rss+xml"/><item><title>LLM #2 LLM과 AI 기술요소를 활용하여 비즈니스 서비스 기획안 작성</title><link>https://yshghid.github.io/docs/study/be/be8/</link><pubDate>Tue, 19 Aug 2025 00:00:00 +0000</pubDate><guid>https://yshghid.github.io/docs/study/be/be8/</guid><description>&lt;h1 id="llm-2-llm과-ai-기술요소를-활용하여-비즈니스-서비스-기획안-작성"&gt;
 LLM #2 LLM과 AI 기술요소를 활용하여 비즈니스 서비스 기획안 작성
 &lt;a class="anchor" href="#llm-2-llm%ea%b3%bc-ai-%ea%b8%b0%ec%88%a0%ec%9a%94%ec%86%8c%eb%a5%bc-%ed%99%9c%ec%9a%a9%ed%95%98%ec%97%ac-%eb%b9%84%ec%a6%88%eb%8b%88%ec%8a%a4-%ec%84%9c%eb%b9%84%ec%8a%a4-%ea%b8%b0%ed%9a%8d%ec%95%88-%ec%9e%91%ec%84%b1"&gt;#&lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;#2025-08-19&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id="1-목적"&gt;
 1. 목적
 &lt;a class="anchor" href="#1-%eb%aa%a9%ec%a0%81"&gt;#&lt;/a&gt;
&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;등기부등본/건축물대장 업로드 시 AI가 자동으로 문서를 분석하여 전세사기 위험 요소를 탐지하고 수치화한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=""&gt;
 
 &lt;a class="anchor" href="#"&gt;#&lt;/a&gt;
&lt;/h3&gt;
&lt;h3 id="2-모델-구성도"&gt;
 2. 모델 구성도
 &lt;a class="anchor" href="#2-%eb%aa%a8%eb%8d%b8-%ea%b5%ac%ec%84%b1%eb%8f%84"&gt;#&lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;#1 데이터 수집및 정규화&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;기술요소: PaddleOCR&lt;/li&gt;
&lt;li&gt;선택 이유: 한국어 인식 정확도와 속도가 좋고, 오픈소스+온프레미스 운영 가능(비용·보안 유리), 표 레이아웃/좌표 추출 지원.&lt;/li&gt;
&lt;li&gt;입력
&lt;ul&gt;
&lt;li&gt;파일: PDF/스캔 이미지(JPG/PNG)&lt;/li&gt;
&lt;li&gt;매개변수: lang=&amp;ldquo;korean&amp;rdquo;, det+rec 사용, dpi(≥300)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;출력
&lt;ul&gt;
&lt;li&gt;텍스트 블록: [{page, bbox, text}]&lt;/li&gt;
&lt;li&gt;정규화 결과: 주소/금액/날짜/권리유형 표준화(JSON)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;#2 위험 특약/권리 분석&lt;/p&gt;</description></item><item><title>LLM #1 LLM 이해와 Transformer</title><link>https://yshghid.github.io/docs/study/be/be7/</link><pubDate>Mon, 18 Aug 2025 00:00:00 +0000</pubDate><guid>https://yshghid.github.io/docs/study/be/be7/</guid><description>&lt;h1 id="llm-1-llm-이해와-transformer"&gt;
 LLM #1 LLM 이해와 Transformer
 &lt;a class="anchor" href="#llm-1-llm-%ec%9d%b4%ed%95%b4%ec%99%80-transformer"&gt;#&lt;/a&gt;
&lt;/h1&gt;
&lt;p&gt;#2025-08-11&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id="1-llm-기본이해"&gt;
 1. LLM 기본이해
 &lt;a class="anchor" href="#1-llm-%ea%b8%b0%eb%b3%b8%ec%9d%b4%ed%95%b4"&gt;#&lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;&lt;mark&gt;#1 Word Embedding&lt;/mark&gt; (p.27-28)&lt;/p&gt;
&lt;p&gt;Word Embedding&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;핵심 아이디어는 단어가 어떤 맥락에서 자주 함께 등장하는지를 학습.&lt;/li&gt;
&lt;li&gt;“you say goodbye and I say hello”에서
&lt;ul&gt;
&lt;li&gt;‘goodbye’주변에는 ‘you’, ‘say’, ‘and’, ‘I’ 같은 단어가 함께 등장하고 그 관계를 학습하도록 신경망을 훈련시킨다.&lt;/li&gt;
&lt;li&gt;학습이 반복되면 각 단어는 벡터로 표현되고 의미가 비슷한 단어일수록 벡터 공간에서 가깝게 위치한다.&lt;/li&gt;
&lt;li&gt;Input이 ‘goodbye’이고 Target이 ‘you’, ‘say’, ‘and’, ‘I’여도 된다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Word Embedding - 신경망 구조 그림&lt;/p&gt;</description></item></channel></rss>