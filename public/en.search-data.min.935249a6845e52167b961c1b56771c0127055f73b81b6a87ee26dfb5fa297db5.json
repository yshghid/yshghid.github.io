[{"id":0,"href":"/docs/hobby/book/","title":"책","section":"기록","content":" 책 # 루틴의 힘 | 댄 애리얼리, 그레첸 루빈, 세스 고딘 외 # 2024-12-31 # 자신의 존재에 대해 사과하지 말 것 | 카밀라 팡 # 2024-12-31 # 물고기는 존재하지 않는다 | 룰루 밀러 # 2024-12-31 # 당신의 특별한 우울 | 린다 개스크 # 2024-12-31 # 일론 머스크 | 월터 아이작슨 # 2024-12-31 # 불변의 법칙 | 모던 하우절 # 2024-12-31 # 우리가 빛의 속도로 갈 수 없다면 | 김초엽 # 2024-12-31 # 세이노의 잔소리 # 2024-12-31 # 콜 미 바이 유어 네임 | 안드레 애치먼 # 2024-12-31 # 지적 생활의 즐거움 | P.G.해머튼 # 2024-12-31 # "},{"id":1,"href":"/docs/hobby/movie/","title":"영화","section":"기록","content":" 영화 # 콜 미 바이 유어 네임 (2023) # 2024-12-31 # "},{"id":2,"href":"/docs/hobby/study/","title":"공부","section":"기록","content":" 공부 # [딥러닝] 혼자 공부하는 딥러닝 | ANN # 2024.12.31 # [딥러닝] 딥러닝을 이용한 자연어 처리 입문 | BERT # 2024.12.31 # [딥러닝] 구글 BERT의 정석 | 트랜스포머 입문 # 2024.12.31 # [딥러닝] 구글 BERT의 정석 | BERT 입문 # 2024.12.31 # [딥러닝] 구글 BERT의 정석 | BERT의 파생 모델: ALBERT, RoBERTa, ELECTRA, SpanBERT # 2024.12.31 # [깃허브] 깃허브 오류 There was an error committing your changes: File could not be edited # 2024.12.31 # [깃허브] 깃허브 블로그 만들기 # 2024.12.31 # [연구] EndNote 사용법 # 2024.12.31 # [코드] DESeq2 # 2024.12.31 # [코드] Sleuth # 2024.12.31 # [코드] ChIP-seq 프로세싱 # 2024.12.31 # [코드] RNA-seq Quantile normalization # 2024.12.31 # [코드] Pathway 분석 bubble plot # 2024.12.31 # [코드] Mutclust 코드 정리 # 2024.12.31 # [코드] Mutclust 파라미터 테스트 # 2024.12.31 # [코드] GC subtype RF 분류기 생성 (인공지능융합응용과제) # 2024.12.31 # [취준] 대학원생 면접대비캠프 # 2024.12.31 # "},{"id":3,"href":"/docs/hobby/daily/","title":"일상","section":"기록","content":" 일상 # [여행] Club Med Kiroro☃️ # 2025.02.20 # 블로그 시작 (부제: 제발열심히살자..) # 2024.12.31 # [여행] 경주☘️ # 2024.12.31 # [여행] 진도🌾 # 2024.12.31 # [여행] 수원/여주🦜🧡 # 2024.12.31 # [여행] 제주🏝️ # 2024.12.31 # [여행] 엄마랑 갑자기 서울!! # 2024.12.31 # 졸업식 2023 # 2024.12.31 # "},{"id":4,"href":"/docs/hobby/daily/daily1/","title":"일상","section":"일상","content":" 블로그 시작 (부제: 제발열심히살자..) # 2024.12.31 # 최근에 무기력한 기분이 너무 오래가서\u0026hellip; 느슨해지다못해 일시정지해버린 일상에 긴장감을 주기 위해 블로그를 시작한다. 공부도 하기싫고 취준도 하기싫고 구냥 아무것도 하고싶지않다 ㅠㅠ\n오늘도 사실 랩미팅 피피티만들어야되는데 하기싫어서, 전에 오류나서 엎었던 블로그 다시 만들었다. 정말이지 일하는것빼고 다 재밌는듯.\n그리고 독감걸린동안 아무것도 안했는데 내일이면 휴가 끝나니까 그것도 너무 두렵다. 이제 몸은 안아픈데 정신이 아픈거같음.. ㅋㅋ\n일단 지금 해야되는일은\nSQL 공부 (시험일: 3.8) 빅분기 필기 공부 (시험일: 4.5) ODE 모델 논문 찾아놓은거 읽고 피피티 만들기 (제일 급함) TCR-bert 모델 논문 보내주신거 읽기 (제일 많음) 면접대비캠프 신청해놓음 (1.7-1.11) 이정도이고\n이번주 토요일 오전에 미용실가야하고 헬스장은 2일 연속 갔으니까 오늘은 안가도되지만 안가면 내일도 안갈거같긴한데 모르겠다. 근데 피피티 내일 하루만에 만들수있나? 절대 못만들거같은데 오늘은 안하고싶다.\n그래두 앉아서 뭐라도하니깐 무기력한기분은 조금 가시는것같다. 넘조급하지말고 할수있는일을 하자..!!\n"},{"id":5,"href":"/docs/hobby/daily/blog34/","title":"일상","section":"일상","content":" 경주🍀 # 2024-11-03 # "},{"id":6,"href":"/docs/hobby/daily/blog33/","title":"일상","section":"일상","content":" 진도🌾 # 2024-08-26 # "},{"id":7,"href":"/docs/hobby/daily/blog32/","title":"일상","section":"일상","content":" 수원/여주🦜🧡 # 2024-06-21 # "},{"id":8,"href":"/docs/hobby/daily/blog31/","title":"일상","section":"일상","content":" 제주🏝️ # 2024-05-01 # "},{"id":9,"href":"/docs/hobby/daily/blog35/","title":"일상","section":"일상","content":" 엄마랑 갑자기 서울!! # 2024-03-09 # "},{"id":10,"href":"/docs/hobby/daily/blog36/","title":"일상","section":"일상","content":" 졸업식 # 2023-08-18 # "},{"id":11,"href":"/docs/hobby/study/bi1/","title":"공부","section":"공부","content":" DESeq2 워크플로우 # 2024-12-31 # Load package # suppressMessages({ library(\u0026#34;DESeq2\u0026#34;) library(pheatmap) library(withr) #library(tidyverse) library(RColorBrewer) library(gplots) library(dplyr) }) Set path # setwd(\u0026#34;/data-blog/bi1\u0026#34;) getwd() \u0026#39;/data-blog/bi1\u0026#39; Run DESeq2 # S1 \u0026lt;- \u0026#39;33\u0026#39; S2 \u0026lt;- \u0026#39;150\u0026#39; countdata \u0026lt;- read.csv(\u0026#34;results.csv\u0026#34;, header=TRUE, sep=\u0026#39;,\u0026#39;) colnames(countdata) \u0026lt;- c(\u0026#39;GeneID\u0026#39;,\u0026#39;150-1\u0026#39;,\u0026#39;150-2\u0026#39;,\u0026#39;150-3\u0026#39;,\u0026#39;33-1\u0026#39;,\u0026#39;33-2\u0026#39;,\u0026#39;33-3\u0026#39;,\u0026#39;con-1\u0026#39;,\u0026#39;con-2\u0026#39;,\u0026#39;con-3\u0026#39;) countdata \u0026lt;- countdata[, c(\u0026#39;GeneID\u0026#39;,\u0026#39;150-1\u0026#39;,\u0026#39;150-2\u0026#39;,\u0026#39;150-3\u0026#39;,\u0026#39;33-1\u0026#39;,\u0026#39;33-2\u0026#39;,\u0026#39;33-3\u0026#39;,\u0026#39;con-1\u0026#39;,\u0026#39;con-2\u0026#39;,\u0026#39;con-3\u0026#39;)] selected_columns \u0026lt;- paste(c(\u0026#39;GeneID\u0026#39;,paste0(S2,\u0026#34;-1\u0026#34;), paste0(S2,\u0026#34;-2\u0026#34;), paste0(S2,\u0026#34;-3\u0026#34;),paste0(S1,\u0026#34;-1\u0026#34;), paste0(S1,\u0026#34;-2\u0026#34;), paste0(S1,\u0026#34;-3\u0026#34;)), sep=\u0026#34;\u0026#34;) countdata \u0026lt;- countdata[, selected_columns] countdata \u0026lt;- countdata[rowSums(countdata[, -1]) != 0, ] sample.names \u0026lt;- paste(c(paste0(S2,\u0026#34;-1\u0026#34;), paste0(S2,\u0026#34;-2\u0026#34;), paste0(S2,\u0026#34;-3\u0026#34;),paste0(S1,\u0026#34;-1\u0026#34;), paste0(S1,\u0026#34;-2\u0026#34;), paste0(S1,\u0026#34;-3\u0026#34;)), sep=\u0026#34;\u0026#34;) conditions \u0026lt;- factor(c(S2,S2,S2,S1,S1,S1)) metadata \u0026lt;- data.frame(Sample = sample.names, group = conditions) metadata N \u0026lt;- dim(countdata)[[2]] cData = countdata[,2:N] GeneID = countdata[,1] rownames(cData) = GeneID dds \u0026lt;- DESeqDataSetFromMatrix(countData = cData, colData = metadata, design = ~group) dds$group \u0026lt;- relevel(dds$group, ref = S1) colData(dds) dds \u0026lt;- DESeq(dds) vsd \u0026lt;- vst(dds, blind=FALSE) rld \u0026lt;- rlogTransformation(dds, blind=FALSE) res \u0026lt;- results(dds, contrast = c(\u0026#34;group\u0026#34;, S2, S1)) res_tbl \u0026lt;- as.data.frame(res) res_tbl$GeneID \u0026lt;- rownames(res_tbl) res_tbl \u0026lt;- res_tbl[order(res_tbl$padj), ] NM_no_NA \u0026lt;- na.omit(res) res_cut \u0026lt;- NM_no_NA[NM_no_NA$padj\u0026lt;0.05,] res_cut # padj val_str \u0026lt;- \u0026#39;padj\u0026#39; cutoff \u0026lt;- 0.05 cutoff_str \u0026lt;- as.character(cutoff) sig_res \u0026lt;- dplyr::filter(res_tbl, padj \u0026lt; cutoff) sig_res \u0026lt;- dplyr::arrange(sig_res, padj) sig_res_file \u0026lt;- paste0(\u0026#39;res_\u0026#39;, S2, \u0026#39;_\u0026#39;, S1, \u0026#39;_\u0026#39;, val_str, cutoff_str, \u0026#39;.csv\u0026#39;) #write.csv(sig_res, file = sig_res_file) print(paste0(S2, \u0026#39; vs \u0026#39;, S1, \u0026#39; | \u0026#39;, val_str, \u0026#39;\u0026lt;\u0026#39;, cutoff_str)) sig_idx \u0026lt;- res$padj \u0026lt; cutoff \u0026amp; !is.na(res$padj) sig_dat \u0026lt;- assay(rld)[sig_idx, ] annC \u0026lt;- data.frame(condition = conditions) rownames(annC) \u0026lt;- colnames(sig_dat) heat_colors \u0026lt;- brewer.pal(6, \u0026#34;RdYlGn\u0026#34;) heat_colors_reversed \u0026lt;- rev(heat_colors) ann_colors \u0026lt;- list(condition = setNames(c(\u0026#34;#F7819F\u0026#34;, \u0026#34;#58D3F7\u0026#34;), c(S2, S1))) A data.frame: 6 x 2 Sample\tgroup \u0026lt;chr\u0026gt;\t\u0026lt;fct\u0026gt; 150-1\t150 150-2\t150 150-3\t150 33-1\t33 33-2\t33 33-3\t33 DataFrame with 6 rows and 2 columns Sample group \u0026lt;character\u0026gt; \u0026lt;factor\u0026gt; 150-1 150-1 150 150-2 150-2 150 150-3 150-3 150 33-1 33-1 33 33-2 33-2 33 33-3 33-3 33 estimating size factors estimating dispersions gene-wise dispersion estimates mean-dispersion relationship final dispersion estimates fitting model and testing log2 fold change (MLE): group 150 vs 33 Wald test p-value: group 150 vs 33 DataFrame with 205 rows and 6 columns baseMean log2FoldChange lfcSE stat pvalue padj \u0026lt;numeric\u0026gt; \u0026lt;numeric\u0026gt; \u0026lt;numeric\u0026gt; \u0026lt;numeric\u0026gt; \u0026lt;numeric\u0026gt; \u0026lt;numeric\u0026gt; ABHD2 50.721 1.352060 0.431587 3.13276 1.73168e-03 4.00143e-02 ADAM12 706.120 -0.571960 0.168494 -3.39454 6.87431e-04 2.03489e-02 ADD2 1819.643 0.868228 0.148791 5.83521 5.37230e-09 9.73246e-07 AIF1L 144.513 1.168923 0.283764 4.11935 3.79938e-05 2.07318e-03 AKAP5 1042.005 -0.637445 0.202189 -3.15271 1.61761e-03 3.81572e-02 ... ... ... ... ... ... ... ZNF655 774.2459 -0.910286 0.198632 -4.58277 4.58855e-06 3.52229e-04 ZNF682 59.7573 -1.382049 0.438336 -3.15295 1.61632e-03 3.81572e-02 ZNF77 76.0271 -1.231188 0.388382 -3.17004 1.52417e-03 3.71126e-02 ZRANB3 536.2301 -0.878732 0.179932 -4.88367 1.04128e-06 9.22422e-05 ZSCAN25 1257.3596 -0.460023 0.149161 -3.08408 2.04184e-03 4.57797e-02 [1] \u0026#34;150 vs 33 | padj\u0026lt;0.05\u0026#34; 출처 # Bioconductor - DESeq2 https://bioconductor.org/packages/release/bioc/html/DESeq2.html\nadditional data # 코드에 사용된 데이터 정보는 github에서 확인 가능하다.\n"},{"id":12,"href":"/docs/hobby/study/bi12/","title":"공부","section":"공부","content":" 대학원생 면접대비캠프 # 대학원생 대상으로 면접대비 강의가 있길래 신청해봤다!\n화수목은 5시부터 9시이구 금요일은 1시부터 6시반이라서 금요일은 일찍 퇴근할수있으면 퇴근하고 듣는게 좋을듯. 토요일은 10시부터 오프라인으로 한다.\n이번주 랩미팅이 목요일 2시에 있고 논문 미팅은 금요일 아침 9시라서 크게 겹치지는 않아 매우 다행이다!!\n커리큘럼 # 1일차 - 면접 기초 \u0026raquo;\n2일차 - 면접유형별 대응 전략 \u0026raquo;\n3일차 - 면접답변 노하우 \u0026raquo;\n4일차 - 모의면접(PT, 세미나) \u0026raquo;\n5일차 - 모의면접(직무, 인성) \u0026raquo;\ncf) # 원래 이런문자 다 무시하는데 ㅋㅋ 갑자기 눈에 들어와서 신청함..\n1일차 - 면접 기초 # 1.9 오후 7시에 질문 받음. 1.10은 논문 기반 세미나 pt 면접 시뮬레이션. 목요일에 신청받는다. 토요일 모의면접 일정(오늘 9시에 신청) -\u0026gt; 경북대학교 복지관 4층. https://www.onoffmix.com/event/315732\n채용트렌드 분석과 면접 준비전략\n직무관련 경험을 제일 중요하게 본다. 석사는 학위시절의 경험과 연구주제를 가지고 판단함.\n인턴이 가져야할 역량을 단어적 표현으로 정해놓고 이 표현이 많으면 높은점수 줬다. 걸러진 인원을 사람이 최종평가함. 글자수 채우는것도 중요하다. 챗지피티 자소서 vs 합격자 자소서 구별하기 어렵다. AI면접은 일관성만 있으면 붙는다.\n실제면접은 ai면접 기반으로 예상질문이 면접관한테 이런식으로 주어짐. 인재상. 공동작업에서 나랑 다른견해를 가진 사람과 공동의 성과를 얻으려면 커뮤니케이션이 중요함. 그리고 책임감 키워드로 설명하면 좋음. 문제 정답은? 4번이 맞지않나? -\u0026gt; 4번이었음 ㅎ\n이미지메이킹으로 만들어지는 인성면접\n면접은 역량면접, 인성면접. 면접관으로 누가 참여하는지가 다르다. -\u0026gt; 조직에 융화되는 책임감이 제일 중요하다.\n내가 이 연구에서 얼마나 열심히 수행했는지 말고 왜 이연구를 했는지, 우리 회사의 업무를 보는데 어떻게 활용되는지를 어필해야함.\n인성면접에서 중요한것.\n첫인상 좋게주는게 인성면접에서는 매우중요. 첫번째 질문은 1분자기소개 or 지원동기인데 첫번째 질문으로 첫인상이 결정된다. 완벽준비를 해가야한다. 어필포인트가 정리돼있어야한다. 어떤방식으로 문제해결하는 사람인지? 책임감을 바탕으로/소통과 협업으로 등등. 연계되는 경험이 붙어야 한다. 2가지 모습을 정하고 들어가야한다. 책임감있는사람 성실한사람 등등. 책임감을 추천함. 자소서에서 질문포인트 예측하고 정리해야함. 기업에 대한 이해 필수. 기업의 최근 이슈 사항. 이 연구가 인상적이고 내가 어떤역할을 할수있고 등등.-\u0026gt; 연구실 컨텍 메일 썰 풀기. 답변길이는 30초가 적당. 말이 길어지면 앞뒤논리가 안맞을수있고 한문장으로 답변하면 싫어함 점수화 질문이 있고 떨어뜨릴사람 찾는 질문이 있다. -\u0026gt; 얘는 점수화 질문.\n1-\u0026gt; 키워드를 던져줄수있어야한다. 살아오면서 가장 힘들었던 경험이 뭐냐고 하면 거기도 키워드를 던져야함. 석사학위 논문을 낼때 힘들었는데 분석력 책임감 성실함의 중요성을 알수잇었다. 답변은 두괄식으로 해야함. 4-5문장으로 답변. -\u0026gt; 얘는 합불질문이므로 뻔한답변을 하고 넘어가야함.\n1-\u0026gt; 법적 윤리적 지시가 아닌경우 상사의 지시를 따른다. 신입이므로 노하우를 잘 모를수있기때문에 적극적으로 따르고 우려하던 부당한 부분이 추후에 나타난다면 그때 물어본다. 이전에 그런일이 있었는데 어쩌고.\n2-\u0026gt; 상사의 행동을 공유한다. 내규나 메뉴얼을 찾아서 어떻게 대응하면되는지 찾고 찾지못하면 높은 직급의 상사에게 물어본다. 직접 판단하지 않고 조직에서 해당 상사에 대한 판단을 맡기겠다.\n3-\u0026gt; 야근은 필연적으로 발생할수밖에 없으므로 야근을 해서 적극적으로 참여하고 상사과 야근식사를 하고 적극적으로 친해지겠다.\n1분자기소개 만들기 초안 keyword와 직무가 들어가는 글. 청자지향 커뮤니케이션: 2개 키워드/두괄식 중요한거 강약조절로 말의리듬을 살려야한다 \u0026lsquo;솔\u0026rsquo;톤으로 \u0026lsquo;웃으면서\u0026rsquo; 말해야한다. 말안할때는 안웃어도됨.. 예상질문. -\u0026gt; 이 질문의 정답은 \u0026lsquo;나\u0026rsquo;가 아닌 조직과 팀의 관점에서 답변. 다른 연구원들이 춝근하는 시간을 보고 선배들과 소통하기 좋은 시간을 선택하겠다. -\u0026gt; 회사는 조직이라서 약속을 지키는게 중요해서 기한 지키기가 당연히 중요함. -\u0026gt; 업무지시의 순응도를 봄. -\u0026gt; 정당한 사유 없이 업무지시 거부하면 해고사유. -\u0026gt; 협업작업이 중요하다. FAQ 면접관이 평가할때 가장 중요하게 생각하는것은? 시간관리 질문이든 뭐든 혼자하는거 좋아한다고 하지말기. 2일차 - 면접유형별 대응 전략 # AI면접, 비대면면접\n비대면 면접 주의점 학점이 안좋다는 질문이 들어오면 일단 공감하고 하지만 다른부문으로 고치려고해봤다(자기견해)고 어필하기. 처음부터 어필하려하면안됨. 반박하는게 제일안좋다.\nPT면접\nPT면접 종류 pt면접, ap면접, 세미나 pt면접이 있다.\n전공pt면접준비할때. 이런식으로 챗지피티에 쳐서 대상 기업에서 다루는 메인 공정 얻고\n이런식으로 전공 특이적으로 답변 얻고\n공정이슈 상위 3개 얻고\n제시된 이슈상황을 바탕으로 면접질문화한다.\n3일차 - 면접답변 노하우 # 이력서 자소서 2부씩 출력해오기.\n세미나pt면접\n10페이지. 석사는 내가 한 과제들이 회사의 어떤 연구과제와 연계가 된다.라는거는 보여주면됨. 관련성도 중요하지만 해당 연구가 어떤 목적성으로 진행됐는지 어떤 기술/학문적 요소를 사용해서 성장이 있었는지. 한페이지에서 얘기하고자하는게 정해져있어야함. 그리고 확장성도 얘기해야한다. 향후에 어떤 연구를 진행하겠다. 갑자기 크림빵 먹고싶당..\n프로세스. 학문/분야적으로 어떤 목적성이 있었는지 제시돼야한다. 두세가지면 123을 두세번 반복하고 45는한번. 자기소개pt\n이 기업이 어떤사업을 하고 어떤상품서비스를 만드는지 이 직무는 어떤역할을 하는지 명확한 이해에서 시작해야함. 특정 모습이 있어야된다. 직업적 핵심포인트. 그걸 함양하기위한 경험적 요소 나열. 챗지피티로 사업현황, 사업구조 분석. 공정로직까지 분석해서 알려준다.\n예시 예시2 세미나 면접이나 자기소개pt나 중요한것은 한페이지마다 전달하고싶은 메시지가 명확해야함.\n면접질문\n질문의도는 해당 직무로 뽑아도 오겠느냐는 의도. 다른회사의 같은직무도 지원했냐는 꼬리질문이 있을수있음. 학부시절부터 이 직무에 관심이 있었기 때문에 지원하게되었다. 경쟁기업의 동일한 직무에도 지원했다. 이 직무로 경력개발 하고싶다. 석사는 도움이 되기위해 했다. 다른 직무로 가지않을것이다. / 석사과정동안 여러 연구를 하면서 여러 소재 개발에 흥미를 느꼈으나 회사에서는 개발한 소재가 합리적인 공정을 거쳐 최적의 생산이 이루어져야하는게 중요하다는걸 알게되엇고 현장에서 역할을 하고자하기위해 지원했다. 제품의 퀄리티가 개발의 성과를 보여주는것이라고 생각해서 품질 축면에서 컨트롤하는 역할을 하고싶어서 왔다. 방어적인 논리가 필요하다.\n내가 수행한 연구과제가 이런 연관성이 있기 때문에 지원했다. 직무적으로 어떤역할을 하는지 이해하지못한거같을때 이런 질문이 나온다. 혁신 도전 변화 이런단어 들어가면 안좋다.\n자기회사의 브랜드가치에 대해 어떻게 생각하는지. lg가 이렇게 물어봄. 내가 연구한 분야가 이 회사랑 더관련성이 높다고 생각한다. 아예모른다 생각도안해봣다 이런말은 안됨. 이 회사의 브랜드/연구과제적인 가치가 더 높다고 생각한다. 입사의지를 강력하게 표명하기.\n살면서 힘들었던 경험으로부터 가치관이 형성되니까 납득할수있는 힘듦을 말해야한다. 석사는 다힘들다. 힘들었떤 경험이 지금 나의 어떤 모습을 형성하는데 도움됐는지 말하기. 성장과정을 물어보는거랑 동일하다.\n남들보다 로지스틱 회귀모형잘한다 등. 의사소통 스킬 경청 이런거 말하면 안된다. 구체적인 지식이 필요함.\n내 이름으로 출판된 연구가 몇개 이상 되게 하고싶다. 연구자로서의 성장계획. 직책을 말하라는게 아니고 어느정도의 연구를 수행하고싶은지. 박사하고싶다. 이런말하면 큰일남.\n단점이 없을수없으므로 양면성을 갖는 대답해야함. 순진하게 답변했다가 떨어질수있음. 일처리가 늦는게 단점이다 이런말하면안됨. 빨리 이 질문을 탈피하는게 중요함. 말이 많고 수다가 많다는게 단점 대화에 빠져든다 이런식의 답변은 안됨. 완벽을 추구하다보니 개인적으로 스트레스를 많이 받는다. 개선하기위해 나만의 스트레스 해소법을 가지려고 노력하고있고 어떻게보면 업무적 성과와 신뢰를 만들수있는 요소라고 생각한다.\n스트레스 안푸는사람들이 자거나 넷플릭스보거나 주말에 집에있는다. 취미를 물어보는거고 평소에 시간관리를 어떻게하고 적극성이 어케되는지를 물어보는것임. 여가시간에 뭐하냐는 질문임.\n경쟁력. 기술적인 요소를 물어보는게 아니라 어떤 성향의 사람인지 물어보는것. 답변의 방향성은 협업에 적합한 사람들을 선호하므로 책임감 뛰어나다 성실하다 사교성이 뛰어나다 등등. 직무에 따라 좀 다르다.\n계획한대로 잘 안됐던 사례. 설득을 어떻게 했다. 이런식. 일 학습 병행을 잘할수있을줄알고 알바랑 학업 같이했는데 생각보다 어렵고 시간관리 잘하는줄 알았는데 어려웠고 학점이 떨어져서 손해봣다. 시간관리가 중요함을 알았고 그뒤로는 할수있는일인지 아닌지 판단하고 결정했다.\n갈등을 설득으로 해결하는 방법. 갈등은 생각/성향의 차이에서 발생하고 상대방에 대한 수용성, 이해를 바탕으로 적절한 지점을 잡아가는 해결을 제시. 상대는 A안을 제안하고 나는 B안일때 합리적인 안을 제시하는게 이루어졌고 자료기반으로 의사결정했다. 성향의 경우 나는 적극적인데 상대는 신중한 성향일경우 상대방에 대한 이해, 나와 상대방이 어떻게 생각했는지에 대한 적정 포인트를 잡아서 공감했다. 이런 답변 하기.\n세대간 소통스킬이 있는지. 예뻐해주셧다 이렇게말하면 안되고 세대간 소통스킬을 물어보는걸 알고 어떻게 지내는지 대답하기.\n면접관이 충분히 그렇게 바라볼수있을것같고 학점관리 반성중이다. 낮은학점 보완하기위해 어떤 노력이 있었다.\n뭐 잘하는지 말해봐라.\n관련분야 책 말고 하나정도 준비해가기. 북튜버보고 정해가기.\n내 연구과제가 직무랑 잘 맞아서 준비했다. 붙으면 어디갈거냐 물어보면 회사의 로열티를 강조하면서 마무리하면댄다.\n갈등이 발생하지 않는 경우는 공산당이다. 생산성이 있으려면 갈등은 반드시 존재한다. 저사람을 최대한 맞춰주고 피햇다 이런 대답은 안된다. 생산성을 위해, 일이 진행되게하기위해 어떤 일을 했는지.\n없다고하면 안되고 갈등이 있을때도 어떤 성과를 낼것인가. 나는 다 피하는 사람이다 이런건 안좋다.\n조직이라는것에 대해 생각. 조직이기 때문에 납득이 안되는 일이 있어도 틀렷더라도 우선은 따르겠다고 말하기. 신입으로서 해당 분야에 대한 노하우가 부족하다고 생각하기 때문. 잘못된 방향인것 같으면 그때 얘기한다. 조직생활에 있어서 맞지않는 부분이라고 생각한다.\n기존과 다른 방식, 발전적인 변화 등을 말하면됨.\n보고 후 조치를 취한다.\n뻔한 답변 하고 넘어가기. 부모님 여자친구 선물사주겟다. 여행금지. 자기계발 투자하겠다 금지.\n복기하겠다고 답변하면 안됨. 이회사 또지원하겠다!도 안됨. 이 직무에서 사회생활을 하고싶은 진로를 결정했기 때문에 왜 떨어졌는지 생각해보면서 동일한 직무 다른 회사로 지원해서 이 직무에서 경험을 시작하기 위해 노력하는 계기로 삼겠다.\n이 회사가 잘될거기때문에 이회사 주식을 사겠다.\n엄마 아빠 친척 지도교수 안됨. 역사속인물 안됨. 업계 사람으로. 누구나 알수있는사람.\n모르면 인테리어 관점으로 접근하고 논리력이 좋으면 물리력 등을 사용하면됨.\n구체화. 회사와 관련없는 뜬구름잡는 이야기 안하기. 사회적으로 선한 영향력 이런거 말고. 직급에 따라 그 연차에서 달성할수있는 업무적 성과 말하기(챗지피티 사용)\n친화력 스킬. 경청, 배려 이딴거 얘기하면 안좋아한다. 경험 베이스로 본인만의 스킬. 공감 기반 리액션이 중요한것같다. 상황에 맞는 리액션을 잘해서 좋은 결과 낸적있다.\n적응력 질문. 어차피 독립해야하므로 어디든 상관없을것같다.\n둘다중요하다고 생각합니다? 단체에 처음 소속햇을때는 팔로우형이엇을것이고 후에 리더형 포지션이 되면 맡은바를 다하겠다. 환경, 시기에 따라 필요한 역할을 잘 수행하겠다.\n후자를 선택하면 안댐. 많은 사람과 협업해야하는데 혼자하는 자기계발보다는 사회적 관계를 통해 성장하는것이 품질관리 직무에 중요하다고 생각한다.\n단기적으로는 개인차원에서 회사에 적응, 일하는 방법 배우고 전문성 높이기. 장기적으로는 협업하고 조직 역량을 키워주기.\n기회있다고하면 좋아할까?를 생각해야함. 현실적으로 생각했을때 이지역에서 끝까지 성장하고싶다. 지역의 스페셜리스트가 되고싶다. 혹시라도 가야하는 상황이라면 받아들이겟지만 선택해서 가지는 않겟다.\n업무에 지장이 없는 범위 내에서 잘 응하겠다.\n당연히 출근하는거.\n프로젝트가 뭔지 알아야 답변가능..\n해당 직무를 찾아보다보니 기술경쟁력으로 승부하는 회사가 여기라고 생각했다. 이런 제품, 서비스에서 함께 r\u0026amp;d 하면서 함께 성장하고싶어서 지원했다.\n직무에 따라 다른 답변.\n사소한 리스크가 안전문제로 사망사고가 나면 큰 위험이 나타나는거기 떼문에 철저하게 법을 지키고 안전한 환경을 구성해서 작업하겠다. 넘기겠다고 하면 안되고 규정에 맞게 하겠다고 해야함.\n4일차 - 모의면접(PT, 세미나) # 모의면접은 신청자에 한해서 진행했는데, 뭣도 모르고 신청했다가 세미나 pt 준비 해야한대서 당일날 매우 low quality인 피피티 만들었다🥲\n피드백 해주실것도 없을거같은 퀄이었는데 그래두 목소리가 너무 작고 말이 빠르다/아이스브레이킹이 너무 없다 등등의 피드백은 해주셨음\n피피티도 어떤형식으로갈지 모르겠는데 감각도 없어서 ㅠㅠㅠ 그냥 5300원주고 포맷 샀다.ㅋㅋ\nhttps://kmong.com/gig/568376 여기걸로 삼. 근데 나쁘지 않았던거같다.\n5일차 - 모의면접(직무, 인성) # 이날 모의면접두 신청자에 한해서 진행했는데 진짜 취준하고있는사람만 대상으로 했던거같음 ㅠㅠ 나는 작성해둔 이력서나 자소서도 없어서 전날 저녁에 삼양 bioinformatics 공고 보고 거기에 맞춰서 급하게 써갔다\n퍼컬-\u0026gt;직무-\u0026gt;인성 순으로 봤는데 기억남는건\n퍼컬-나는 쿨톤이었다 직무-어설프게 아는거 적어넣으면 면접때 무조건 발각될것같으니 애매한건 무조건 공부해가자. 직무-목소리 크게하고 눈쳐다보면서 얘기하자. 직무-어필포인트를 확실하게 잡아서 그것만 심도있게 얘기하자. 그래야 전문적으로 보이는듯. 인성-예상질문 한 50개 만들어서 답다만들어놓자. 이정도\u0026hellip; 사실 준비가 너무 안된채로가서 면접봐주신분들한테 죄송할 지경이었지만 그래두 신청하길 잘한거같다. 내가얼마나 부족한지 잘알수있었다🥲🥲\n"},{"id":13,"href":"/docs/hobby/study/bi16/","title":"공부","section":"공부","content":" EndNote 사용법 # 2024-12-31 # 1. EndNote 설치 및 계정 설정 # 계정 설정: 공식 웹사이트에서 End note 계정을 생성한다.\n설치: 나의 경우 여기에서 다운로드해줬다.\n2. 레퍼런스 추가 방법 # Google Scholar에 논문 제목을 검색해서 인용\u0026gt;EndNote를 클릭하면 .enw 파일이 다운로드된다. 3. 레퍼런스 관리 # Endnote에 접속한다. Collect\u0026gt;Import References로 들어간다 파일 선택\u0026gt;아까 저장한 .enw 파일을 선택해준다 Import Option\u0026gt;EndNote Import를 선택해준다 To\u0026gt;New Group을 하면 논문 주제별로 그룹을 생성하여 정리 가능. 생성한 그룹이 이미 있으면 원하는 그룹 선택해준다. Import 해준다 2025EMM_Mutclust 그룹에 45개 레퍼런스를 넣었고 이렇게 뜬다!\n4. Word에서 레퍼런스 인용 # 위에서 EndNote를 설치해줬다면 Word의 상단 탭에 EndNote가 뜬다. 레퍼런스를 넣고싶은 자리에 커서를 두고 EndNote\u0026gt;Insert Citation을 선택해준다. 넣고싶은 논문의 제목 일부나 저자 이름을 넣고 검색\u0026gt;Insert 해준다. 47번째 줄에 성공적으로 레퍼런스가 달렸다! 본문 맨아래를 확인하면 citation도 자동으로 달려있다.\ncf) 만약 citation 형식을 바꾸고 싶으면 Select Other Style로 들어가서 형식을 바꿔주면 된다.\n나는 Last name(full name) \u0026gt; First name(약어) \u0026gt; 제목 \u0026gt; 저널(기울임체) \u0026gt; 버전(bold) \u0026gt; 페이지, 발행년도 순으로 나오고 / 6명 이상인 경우 주저자 1명만 + et al.로 표기되는 형식을 써줘야했고 Nature immunology 포맷을 사용해줬다.\n참고 자료 # EndNote 활용 가이드 https://library.korea.ac.kr/wp-content/uploads/2020/03/EndNote_X9_manualKorean.pdf\n"},{"id":14,"href":"/docs/hobby/study/cs1/","title":"공부","section":"공부","content":" [깃허브] Hugo로 깃허브 블로그 만들기 # 목록 # 사이트 생성, 깃허브 배포\nFavicon 변경, Giscus 댓글창 추가\n사이트 생성, 깃허브 배포 # 2024-12-31 # Hugo 설치 # $ brew install hugo $ hugo version hugo v0.131.0+extended darwin/arm64 BuildDate=2024-08-02T09:03:48Z VendorInfo=brew Hugo v0.112.0 이상인지 확인하면 된다.\nHugo 사이트 생성 # 작업하고 싶은 위치에 Hugo 디렉토리를 만들어준다.\n$ mkdir Hugo $ cd Hugo Hugo로 들어가서 hugo 사이트 틀을 생성해준다. 나는 blog라는 이름으로 생성하였다.\n$ pwd /Users/yshmbid/Hugo $ hugo new site blog blog 디렉토리에 빈 Git 저장소를 초기화한다.\n$ cd blog $ pwd /Users/yshmbid/Hugo/blog $ git init hint: Using \u0026#39;master\u0026#39; as the name for the initial branch. This default branch name hint: is subject to change. To configure the initial branch name to use in all hint: of your new repositories, which will suppress this warning, call: hint: hint: git config --global init.defaultBranch \u0026lt;name\u0026gt; hint: hint: Names commonly chosen instead of \u0026#39;master\u0026#39; are \u0026#39;main\u0026#39;, \u0026#39;trunk\u0026#39; and hint: \u0026#39;development\u0026#39;. The just-created branch can be renamed via this command: hint: hint: git branch -m \u0026lt;name\u0026gt; /Users/yshmbid/Hugo/blog/.git/ 안의 빈 깃 저장소를 다시 초기화했습니다 위에서 Using \u0026lsquo;master\u0026rsquo; as the name for the initial branch. 언급이 나온다. 여기서 확인해줘야 할 부분이 있다.\n레포지토리 생성 페이지에서 Add a README file.을 체크하면 This will set main as the default branch.라는 안내가 뜬다. 이를 통해 default가 main임을 확인할수있다.\n따라서 위의 경우에는 master가 아닌 main으로 바꿔줘야 한다.\n$ pwd /Users/yshmbid/Hugo/blog $ git config --global init.defaultBranch main $ git branch -m main 다음으로 선택한 테마를 Git 서브모듈로 프로젝트에 추가한다. 나는 hugo-book이라는 테마를 사용했다.\n$ pwd /Users/yshmbid/Hugo/blog $ git submodule add https://github.com/alex-shpak/hugo-book themes/hugo-book 다음으로, 블로그의 기본 설정들을 세팅해준다. blog 디렉토리 내 파일들은 대략적으로 아래와 같이 구성되어 있다.\n$ ls archetypes\tdata\ti18n\tresources assets\thugo.toml\tlayouts\tstatic content\tpublic\tthemes 이 중에서 content와 hugo.toml만 수정할것이다. content에는 작성한 게시물이 들어가고, hugo.toml에는 기본 세팅을 위한 config 변수들이 들어간다.\nhugo-book 테마의 경우에는 content에 대해 이와 같이 언급하고 있다. 해당 테마는 국가별로 여러 content 디렉토리가 존재해서, 그 중 main이 되는 content.en의 내용만을 시키는대로 복사해준다.\n$ cp -R themes/hugo-book/exampleSite/content.en/* ./content 다음으로 hugo.toml에 선택한 테마를 설정해주고 열어서 확인해본다.\n$ echo \u0026#34;theme = \u0026#39;hugo-book\u0026#39;\u0026#34; \u0026gt;\u0026gt; hugo.toml $ view hugo.toml 1 baseURL = \u0026#39;https://example.org/\u0026#39; 2 languageCode = \u0026#39;en-us\u0026#39; 3 title = \u0026#39;My New Hugo Site\u0026#39; 4 theme = \u0026#39;hugo-book\u0026#39; 여기서 base가 되는 내용만 수정해줬다.\n1 baseURL = \u0026#39;https://yshghid.github.io/\u0026#39; 2 languageCode = \u0026#39;en-us\u0026#39; 3 title = \u0026#39;\bLifelog 2025\u0026#39; 4 theme = \u0026#39;hugo-book\u0026#39; # i를 누르면 편집모드로 전환된다. # 편집이 끝났으면 esc를 누르고 :wq!를 입력하면 완료된다. 기본적인 설정이 끝났으므로 로컬에서 실행시켜보자! http://localhost:1313에 접속하면 local 환경에서 어떻게 실행 중인지 확인할수있다.\n$ hugo server 이쁘게 잘 나온다 ㅎㅎ\n변경 사항을 픽스하려면 hugo를 수행해서 public 디렉토리에 static site 코드를 생성해준다.\n$ pwd /Users/yshmbid/Hugo/blog $ hugo Start building sites … hugo v0.131.0+extended darwin/arm64 BuildDate=2024-08-02T09:03:48Z VendorInfo=brew WARN Expand shortcode is deprecated. Use \u0026#39;details\u0026#39; instead. | EN -------------------+----- Pages | 58 Paginator pages | 0 Non-page files | 0 Static files | 78 Processed images | 0 Aliases | 11 Cleaned | 0 Total in 66 ms Hugo 사이트 배포 # hugo로 만든 static site를 github page를 활용해서 배포할것이다. 이를 위해서 \u0026lt;user-id\u0026gt;.github.io 리포지토리를 생성해준다.\n이때 Add a README file 을 선택할 경우 push 할때 오류가 날 수 있으므로 체크 해제해서 생성해주는게 좋다.\n다음으로, .github/workflows 경로에 gh-pages.yml 파일을 만들어준다. gh-pages.yml은 GitHub Actions 워크플로우를 정의하여 코드가 커밋되거나 푸시될 때 자동으로 Hugo 사이트를 빌드하고 GitHub Pages에 배포할 수 있도록 하는 파일이다.\n$ pwd /Users/yshmbid/Hugo/blog $ mkdir -p .github/workflows $ cd .github/workflows $ touch gh-pages.yml 아래 내용은 HUGO 공식 문서에서 제공한 워크플로우인데, 나의 경우에는 오류가 났다.\n# Sample workflow for building and deploying a Hugo site to GitHub Pages name: Deploy Hugo site to Pages on: # Runs on pushes targeting the default branch push: branches: - main # Allows you to run this workflow manually from the Actions tab workflow_dispatch: # Sets permissions of the GITHUB_TOKEN to allow deployment to GitHub Pages permissions: contents: read pages: write id-token: write # Allow only one concurrent deployment, skipping runs queued between the run in-progress and latest queued. # However, do NOT cancel in-progress runs as we want to allow these production deployments to complete. concurrency: group: \u0026#34;pages\u0026#34; cancel-in-progress: false # Default to bash defaults: run: shell: bash jobs: # Build job build: runs-on: ubuntu-latest env: HUGO_VERSION: 0.128.0 steps: - name: Install Hugo CLI run: | wget -O ${{ runner.temp }}/hugo.deb https://github.com/gohugoio/hugo/releases/download/v${HUGO_VERSION}/hugo_extended_${HUGO_VERSION}_linux-amd64.deb \\ \u0026amp;\u0026amp; sudo dpkg -i ${{ runner.temp }}/hugo.deb - name: Install Dart Sass run: sudo snap install dart-sass - name: Checkout uses: actions/checkout@v4 with: submodules: recursive fetch-depth: 0 - name: Setup Pages id: pages uses: actions/configure-pages@v5 - name: Install Node.js dependencies run: \u0026#34;[[ -f package-lock.json || -f npm-shrinkwrap.json ]] \u0026amp;\u0026amp; npm ci || true\u0026#34; - name: Build with Hugo env: HUGO_CACHEDIR: ${{ runner.temp }}/hugo_cache HUGO_ENVIRONMENT: production TZ: America/Los_Angeles run: | hugo \\ --gc \\ --minify \\ --baseURL \u0026#34;${{ steps.pages.outputs.base_url }}/\u0026#34; - name: Upload artifact uses: actions/upload-pages-artifact@v3 with: path: ./public # Deployment job deploy: environment: name: github-pages url: ${{ steps.deployment.outputs.page_url }} runs-on: ubuntu-latest needs: build steps: - name: Deploy to GitHub Pages id: deployment uses: actions/deploy-pages@v4 위의 워크플로우를 사용한다면 line 8의 main를 확인해주자면 default가 master라면 master로 바꿔줘야 한다.\n나의 경우는 위 워크플로우로는 오류가 났어서 아래의 수정된 내용을 넣어줬다.\nname: github pages on: push: branches: - main # Set a branch to deploy pull_request: jobs: deploy: runs-on: ubuntu-20.04 steps: - uses: actions/checkout@v3 with: submodules: true # Fetch Hugo themes (true OR recursive) fetch-depth: 0 # Fetch all history for .GitInfo and .Lastmod - name: Create .nojekyll run: echo \u0026#39;\u0026#39; \u0026gt; .nojekyll - name: Setup Hugo uses: peaceiris/actions-hugo@v3 with: hugo-version: \u0026#39;latest\u0026#39; # extended: true - name: Build run: hugo --minify - name: Deploy uses: peaceiris/actions-gh-pages@v4 if: github.ref == \u0026#39;refs/heads/main\u0026#39; with: github_token: ${{ secrets.GH_TOKEN }} publish_dir: ./public 이어서 GH_TOKEN를 정의해줘야 하는데\n리포지토리의 Settings -\u0026gt; Secretes and Variables -\u0026gt; Actions 에서 Repository secretes와 Repository variables를 생성해준다.\nSecret 자리에 토큰을 입력해주면 된다.\n작성이 완료되었다면, 생성한 \u0026lt;user-id\u0026gt;.github.io 리포지토리에 연결한 후 커밋, 푸시해준다.\n$ pwd /Users/yshmbid/Hugo/blog $ git remote add origin https://github.com/yshghid/yshghid.github.io.git $ git add . $ git commit -m \u0026#34;first commit\u0026#34; $ git push origin main 마무리 # 이로써 블로그 생성과 배포는 끝이지만!! 추가로 확인하면 좋은 부분이 있다.\nActions Actions에서 초록색 체크박스가 뜨는지 확인하기. 오류가 난다면 해당 오류의 로그를 읽어보고 그에 맞게 수정해주면 된다.\nSources, Branch 공식 문서에서는 Deploy from a branch에서 Github Actions로 바꿔주라고 나온다. 바꿔도 상관없으나 나는 그냥 뒀다.\n브랜치는 보통은 gh-pages 브랜치가 기본 Github Pages 브랜치로 설정되어 있지만 혹시 안되어 있다면 gh-pages로 바꿔주면 된다.\n구조 /Users/yshmbid/Hugo/blog ├── hugo.toml ├── content/ ├── layouts/ ├── static/ └── .github/ └── workflows/ └── gh-pages.yml blog 디렉토리가 이와 같은 구조를 띤다면 제대로 작성된 것이다.\n참고한 블로그 및 문서 # HUGO 공식 문서 - https://gohugo.io/getting-started/quick-start/ HUGO 공식 문서2 - https://gohugo.io/hosting-and-deployment/hosting-on-github/ hugo-book github - https://github.com/alex-shpak/hugo-book.git https://c11oud.tistory.com/entry/GitHub-깃허브-블로그-만들기1 https://github.com/Integerous/Integerous.github.io https://kzeoh.github.io/posts/make-blog/ Favicon 변경, Giscus 댓글창 추가 # 2024-12-31 # Favicon 변경 # Hugo-book 테마의 github에서 README 파일을 읽어보면, logo와 favicon 이미지의 경로 정보를 찾을 수 있다.\n(logo 정보) (favicon 정보) 확인 결과 static 디렉토리에 각각 logo.png, favicon.png로 저장해두면 반영되는것 같다.\n참고로 Hugo-book 테마의 오리지널 웹사이트는 아래와 같이 디자인되어있고\n최상단 탭에 들어가는 이미지가 logo.png, 블로그 이름 옆에 들어가는 이미지가 favicon.png이다.\n먼저 static 디렉토리에 넣고 싶은 로고와 파비콘을 logo.png, favicon.png 로 저장해준다.\n다음으로, hugo.toml 파일을 열어 아래 내용을 추가해준다.\n# (Optional, default none) Set the path to a logo for the book. If the logo is # /static/logo.png then the path would be \u0026#39;logo.png\u0026#39; BookLogo = \u0026#39;logo.png\u0026#39; 블로그를 들어가보면 설정한 로고와 파비콘이 잘 들어간것을 확인할 수 있다.\nGiscus 댓글창 추가 # Giscus 댓글 시스템을 Hugo 기반 블로그에 연동하기 위해서는 Giscus에 블로그 리포지토리를 연결한 후, js script를 작성하여 블로그 리포지토리의 layouts 디렉토리에 저장하면 된다고 한다.\n이때 연결할 리포지토리는 다음 3가지 조건을 만족해야 한다.\nPublic이어야 함. giscus 앱이 설치되어 있어야 함. Discussions 기능이 해당 저장소에서 활성화되어 있어야 함. 공개 저장소 확인\n블로그 리포지토리의 Settings \u0026gt; General의 맨 하단을 보면 Danger Zone에서 public인지 private인지 확인이 가능하다.\npublic이므로 다음으로 넘어간다.\nGiscus 앱 설치\nhttps://github.com/apps/giscus 에 접속하여 install, configure를 진행하면 쉽게 설치된다.\nRepository access는 All repositories 로 설정했다.\nDiscussion 기능 활성화\n블로그 리포지토리의 Settings \u0026gt; General을 스크롤해보면 Discussions 체크박스가 생긴 것을 확인할 수 있다. 이를 체크해준다.\n위로 스크롤해보면 상단에 Discussions 탭이 생겼다.\n이제 블로그 리포지토리가 Giscus에 연결할 3가지 조건을 만족하였고 블로그를 Giscus로 연결해주면 된다. 연결해주려면 아래 형식의 js 스크립트를 작성하여 layouts/partials/comments.html에 추가해주면 된다.\njs 스크립트는 https://giscus.app/ko에서 파라미터를 선택하면 적절하게 생성해준다!\n\u0026lt;script src=\u0026#34;https://giscus.app/client.js\u0026#34; data-repo=\u0026#34;yshghid/yshghid.github.io\u0026#34; data-repo-id=\u0026#34;R_kgDONkMkNg\u0026#34; data-category-id=\u0026#34;DIC_kwDONkMkNs4CloJh\u0026#34; data-mapping=\u0026#34;pathname\u0026#34; data-strict=\u0026#34;0\u0026#34; data-reactions-enabled=\u0026#34;1\u0026#34; data-emit-metadata=\u0026#34;0\u0026#34; data-input-position=\u0026#34;bottom\u0026#34; data-theme=\u0026#34;preferred_color_scheme\u0026#34; data-lang=\u0026#34;ko\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34; async\u0026gt; \u0026lt;/script\u0026gt; 해당 내용을 복사해서 블로그 리포지토리의 layouts/partials/docs/comments.html로 생성해주었다.\n성공적으로 댓글창이 추가되었다!!\n참고한 블로그 # https://parker1609.github.io/post/creating-my-blog-with-hugo/\n"},{"id":15,"href":"/docs/hobby/study/cs12/","title":"공부","section":"공부","content":" [딥러닝] 혼자 공부하는 딥러닝 | ANN # 목록 # 간단한 인공 신경망 모델 만들기\n인공 신경망에 층을 추가하여 심층 신경망 만들어 보기\n인경 신경망 모델 훈련의 모범 사례 학습하기\n17. 간단한 인공 신경망 모델 만들기 # 2024-12-31 # 데이터 준비 fashion_mnist 데이터셋에서 학습과 테스트용 이미지 데이터를 가져온다. 학습 데이터는 60,000개의 28x28 픽셀 이미지, 테스트 데이터는 10,000개의 28x28 픽셀 이미지. train_target과 test_target은 각 이미지에 해당하는 레이블(0~9)을 갖고있다.\nfrom tensorflow import keras (train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data() print(train_input.shape, train_target.shape) print(test_input.shape, test_target.shape) Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz 29515/29515 [==============================] - 0s 3us/step Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz 26421880/26421880 [==============================] - 2s 0us/step Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz 5148/5148 [==============================] - 0s 0us/step Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz 4422102/4422102 [==============================] - 0s 0us/step (60000, 28, 28) (60000,) (10000, 28, 28) (10000,) 데이터 시각화 첫 10개의 이미지 샘플을 출력하기.\nimport numpy as np import matplotlib.pyplot as plt fig, axs = plt.subplots(1, 10, figsize=(10,10)) for i in range(10): axs[i].imshow(train_input[i], cmap=\u0026#39;gray_r\u0026#39;) axs[i].axis(\u0026#39;off\u0026#39;) plt.show() print([train_target[i] for i in range(10)]) print(np.unique(train_target, return_counts=True)) [9, 0, 0, 3, 0, 2, 7, 2, 5, 5] (array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8), array([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])) np.unique()로 레이블 분포를 확인해보니 각 클래스에 6,000개씩 균일하게 분포해있다.\n로지스틱 회귀 이미지를 0~255의 픽셀 값을 [0, 1] 범위로 정규화한다. 그리고 데이터를 2D 배열로 펼친다. (60000, 28, 28) → (60000, 784). 즉 각 이미지를 784차원 벡터로 변환한다.\nfrom sklearn.linear_model import SGDClassifier from sklearn.model_selection import cross_validate train_scaled = train_input / 255.0 train_scaled = train_scaled.reshape(-1, 28*28) print(train_scaled.shape) 로지스틱 회귀모델을 학습한다. 손실함수는 로지스틱 손실함수를 사용한다.\nsc = SGDClassifier(loss=\u0026#39;log\u0026#39;, max_iter=5, random_state=42) scores = cross_validate(sc, train_scaled, train_target, n_jobs=-1) print(np.mean(scores[\u0026#39;test_score\u0026#39;])) (60000, 784) 0.8195666666666668 학습 결과 테스트 세트 정확도는 81.96%이다.\n케라스 신경망 모델 생성 from sklearn.model_selection import train_test_split train_scaled, val_scaled, train_target, val_target = train_test_split( train_scaled, train_target, test_size=0.2, random_state=42) print(train_scaled.shape, train_target.shape) print(val_scaled.shape, val_target.shape) (38400, 784) (38400,) (9600, 784) (9600,) 학습 데이터를 학습 세트와 검증 세트로 나눴다. 학습 세트는 (38400, 784) 검증 세트는 (9600, 784).\ndense = keras.layers.Dense(10, activation=\u0026#39;softmax\u0026#39;, input_shape=(784,)) model = keras.Sequential(dense) 2025-01-23 17:30:40.924465: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2025-01-23 17:30:40.934329: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. Dense Layer는 각 입력 뉴런이 모든 출력 뉴런에 연결되는 신경망의 기본 층이다. Dense(10)으로 10개의 뉴런을 가지는 층을 만들어줬다. 입력 데이터는 784차원 벡터이고, 활성화 함수는 softmax 함수가 사용되었다. keras.Sequential(dense)는 하나의 Dense 층으로 이루어진 간단한 순차 모델을 정의한다.\n다시 말해, Dense Layer는 784차원 입력을 10개 클래스의 출력으로 변환하며, 각 출력은 Softmax를 통해 확률로 계산된다\n모델 컴파일 model.compile(loss=\u0026#39;sparse_categorical_crossentropy\u0026#39;, metrics=\u0026#39;accuracy\u0026#39;) print(train_target[:10]) /data1/home/ysh980101/miniconda3/envs/workspace/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:165: FutureWarning: The loss \u0026#39;log\u0026#39; was deprecated in v1.1 and will be removed in version 1.3. Use `loss=\u0026#39;log_loss\u0026#39;` which is equivalent. warnings.warn( /data1/home/ysh980101/miniconda3/envs/workspace/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:704: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit. [9 4 9 0 4 9 3 6 4 7] 모델을 학습하기 전에 손실 함수, optimizer, 평가 지표(metric)을 설정. 모델이 학습 과정에서 어떻게 성능을 평가하고 손실을 줄이고 가중치를 업데이트할지 정의한다.\n손실 함수 (Loss Function)는 모델의 예측값과 정답 사이의 차이를 측정함. sparse_categorical_crossentropy는 레이블이 정수 형태로 제공되는 경우 즉 다중 클래스 분류 문제(Multi-class Classification)에 사용된다. (원 핫 인코딩 아니라)\n모델의 출력값은 softmax 활성화 함수를 통해 각 클래스에 대한 확률 분포를 반환하는데 손실 함수는 정답 클래스와 예측된 확률 분포 간의 교차 엔트로피(Cross Entropy)를 계산한다.\nLoss = $- \\sum_{i=1}^C y_i \\cdot \\log(\\hat{y}_i)$\n$y_i$은정답 레이블의 원-핫 인코딩 값 (sparse일 경우 해당 위치만 1), $\\hat{y}_i$: 모델의 예측 확률값, $C$: 클래스의 총 개수이다. 확률값이 정답 클래스에 가까울수록 손실이 작아진다. 모델의 전체 동작 흐름\n모델은 마지막 Dense 층에서 softmax를 사용해 10개의 클래스 확률을 출력 손실 함수는 정답 레이블(예: 2)과 예측 확률(0.7)의 차이를 교차 엔트로피로 계산. 예측 클래스(가장 높은 확률을 가진 클래스)가 정답 레이블과 일치하면 평가 지표 accuracy 즉 모델이 정확하게 예측한 비율이 높아진다. 손실 값이 최소화되도록 가중치(모델 파라미터)가 옵티마이저에 의해 업데이트된다. 모델 훈련 model.fit(train_scaled, train_target, epochs=5) Epoch 1/5 1200/1200 [==============================] - 3s 2ms/step - loss: 0.6326 - accuracy: 0.7853 Epoch 2/5 1200/1200 [==============================] - 3s 3ms/step - loss: 0.4910 - accuracy: 0.8344 Epoch 3/5 1200/1200 [==============================] - 3s 3ms/step - loss: 0.4656 - accuracy: 0.8444 Epoch 4/5 1200/1200 [==============================] - 3s 3ms/step - loss: 0.4512 - accuracy: 0.8499 Epoch 5/5 1200/1200 [==============================] - 3s 3ms/step - loss: 0.4417 - accuracy: 0.8526 \u0026lt;keras.callbacks.History at 0x7fa1e4c12be0\u0026gt; 학습 반복(Epoch)은 5회로 설정되었다. 각 Epoch 결과 손실은 0.6326 → 0.4417로 감소, 정확도(accuracy)는 78.5% → 85.3%로 증가했다. 모델 평가 model.evaluate(val_scaled, val_target) 300/300 [==============================] - 1s 3ms/step - loss: 0.4335 - accuracy: 0.8590 [0.4334854781627655, 0.8589583039283752] 검증 데이터에서 모델 평가 결과 손실은 0.4335, 정확도는 85.9%.\n손실 값(0.4335)은 모델의 예측이 검증 데이터에서 큰 오류를 범하지 않았음을 보여주고 정확도(85.9%)**는 모델이 Fashion MNIST 데이터셋에서 상당히 높은 성능을 보였으며, 의류 이미지를 잘 분류할 수 있음을 나타낸다.\n손실과 정확도는 상관관계가 있지만 동일하지 않음. 손실은 모델의 예측이 얼마나 잘 정답 분포를 따르는지(확률 수준)를 나타내며, 확률이 높은 정답일수록 손실 값이 낮아진다.\n정확도는 모델이 정답을 맞췄는지 여부(0 또는 1)를 측정한다. 손실이 감소해도 정확도는 일정 범위에서 정체될 수 있다. 이는 모델이 정답 분포를 더 잘 학습했지만, 예측 결과가 다른 클래스에 대한 잘못된 선택으로 여전히 분류 문제를 일으킬 수 있기 때문.\n사이킷런-케라스 비교 로지스틱 회귀(SGDClassifier): 정확도 약 81.96%. 단순한 선형 모델. 케라스 신경망 모델: 정확도 약 85.9%. 더 높은 성능을 보였으며, 신경망의 유연성 덕분에 복잡한 데이터를 잘 학습했다. 요약 데이터 준비 → 정규화 → 펼침. 간단한 신경망 모델(1개 층, 10개 뉴런) 설계. 로지스틱 회귀와 비교해 신경망이 더 나은 성능을 보였다. 강의 링크\nhttps://www.youtube.com/watch?v=ZiP9erf5Fo0\u0026list=PLVsNizTWUw7HpqmdphX9hgyWl15nobgQX\u0026index=17 18. 인공 신경망에 층을 추가하여 심층 신경망 만들기 # 2024-12-31 # 데이터 가져오기 from tensorflow import keras (train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data() print(train_input.shape, train_target.shape) print(test_input.shape, test_target.shape) from sklearn.linear_model import SGDClassifier from sklearn.model_selection import cross_validate train_scaled = train_input / 255.0 print(train_scaled.shape) (60000, 28, 28) (60000,) (10000, 28, 28) (10000,) (60000, 28, 28) 심층 신경망 dense1 = keras.layers.Dense(100, activation=\u0026#39;sigmoid\u0026#39;, input_shape=(784,)) dense2 = keras.layers.Dense(10, activation=\u0026#39;softmax\u0026#39;) model = keras.Sequential([dense1, dense2]) cf) 층을 추가하는 다른 방법\nmodel = keras.Sequential([ keras.layers.Dense(100, activation=\u0026#39;sigmoid\u0026#39;, input_shape=(784,), name=\u0026#39;hidden\u0026#39;), keras.layers.Dense(10, activation=\u0026#39;softmax\u0026#39;, name=\u0026#39;output\u0026#39;) ], name = \u0026#39;패션 MNIST 모델\u0026#39;) model = keras.Sequential() model.add(keras.layers.Dense(100, activation=\u0026#39;sigmoid\u0026#39;, input_shape=(784,))) model.add(keras.layers.Dense(10, activation=\u0026#39;softmax\u0026#39;)) 렐루 함수와 Flatten 층 model = keras.Sequential() model.add(keras.layers.Flatten(input_shape=(28,28))) model.add(keras.layers.Dense(100, activation=\u0026#39;relu\u0026#39;)) model.add(keras.layers.Dense(10, activation=\u0026#39;softmax\u0026#39;)) model.summary() Model: \u0026#34;sequential_2\u0026#34; Model: \u0026#34;sequential_3\u0026#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= flatten (Flatten) (None, 784) 0 dense_5 (Dense) (None, 100) 78500 dense_6 (Dense) (None, 10) 1010 ================================================================= Total params: 79,510 Trainable params: 79,510 Non-trainable params: 0 _________________________________________________________________ 옵티마이저 model.compile(optimizer=\u0026#39;sgd\u0026#39;, loss=\u0026#39;sparse_categorical_crossentropy\u0026#39;, metrics=\u0026#39;accuracy\u0026#39;) sgd = keras.optimizers.SGD() model.compile(optimizer=sgd, loss=\u0026#39;sparse_categorical_crossentropy\u0026#39;, metrics=\u0026#39;accuracy\u0026#39;) sgd = keras.optimizers.SGD(learning_rate=0.1) sgd = keras.optimizers.SGD(momentum=0.9, nesterov=True) model = keras.Sequential() model.add(keras.layers.Flatten(input_shape=(28,28))) model.add(keras.layers.Dense(100, activation=\u0026#39;relu\u0026#39;)) model.add(keras.layers.Dense(100, activation=\u0026#39;softmax\u0026#39;)) model.compile(optimizer=\u0026#39;adam\u0026#39;, loss=\u0026#39;sparse_categorical_crossentropy\u0026#39;, metrics=\u0026#39;accuracy\u0026#39;) model.fit(train_scaled, train_target, epochs=5) model.evaluate(val_scaled, val_target) Epoch 1/5 1500/1500 [==============================] - 59s 39ms/step - loss: 0.8167 - accuracy: 0.7495 Epoch 2/5 1500/1500 [==============================] - 39s 26ms/step - loss: 0.4167 - accuracy: 0.8520 Epoch 3/5 1500/1500 [==============================] - 32s 21ms/step - loss: 0.3710 - accuracy: 0.8665 Epoch 4/5 1500/1500 [==============================] - 33s 22ms/step - loss: 0.3345 - accuracy: 0.8790 Epoch 5/5 1500/1500 [==============================] - 51s 34ms/step - loss: 0.3218 - accuracy: 0.8816 375/375 [==============================] - 4s 11ms/step - loss: 0.3423 - accuracy: 0.8785 [0.34229394793510437, 0.8784999847412109] 강의 링크\nhttps://www.youtube.com/watch?v=JskWW5MlzOg\u0026list=PLVsNizTWUw7HpqmdphX9hgyWl15nobgQX\u0026index=18 19. 인경 신경망 모델 훈련의 모범 사례 학습하기 # 2024-12-31 # 손실 곡선 model.compile(loss=\u0026#34;sparse_categorical_crossentropy\u0026#34;, metrics=\u0026#34;accuracy\u0026#34;) history = model.fit(train_scaled, train_target, epochs=5, verbose=0) print(history.history.keys()) dict_keys([\u0026#39;loss\u0026#39;,\u0026#39;accuracy\u0026#39;]) plt.plot(history.history[\u0026#39;loss\u0026#39;]) plt.xlabel(\u0026#39;epoch\u0026#39;) plt.ylabel(\u0026#39;epoch\u0026#39;) plt.show() plt.plot(history.history[\u0026#39;accuracy\u0026#39;]) plt.xlabel(\u0026#39;epoch\u0026#39;) plt.ylabel(\u0026#39;accuracy\u0026#39;) plt.show() cf) 더 많은 에포크?\nhistory = model.fit(train_scaled, train_target, epochs=20, verbose=0) plt.plot(history.history[\u0026#39;loss\u0026#39;]) plt.xlabel(\u0026#39;epoch\u0026#39;) plt.ylabel(\u0026#39;loss\u0026#39;) plt.show() 검증 손실 history = model.fit(train_scaled, train_target, epochs=20, verbose=0, validation_data=(val_scaled, val_target)) print(history.history.keys()) plt.plot(history.history[\u0026#39;loss\u0026#39;]) plt.plot(history.history[\u0026#39;val_loss\u0026#39;]) plt.xlabel(\u0026#39;epoch\u0026#39;) plt.ylabel(\u0026#39;loss\u0026#39;) plt.legend([\u0026#39;train\u0026#39;,\u0026#39;val\u0026#39;]) plt.show() 드롭아웃 model = keras.Sequential() model.add(keras.layers.Flatten(input_shape=(28,28))) model.add(keras.layers.Dense(100, activation=\u0026#39;relu\u0026#39;)) model.add(keras.layers.Dropout(0.3)) model.add(keras.layers.Dense(10, activation=\u0026#39;softmax\u0026#39;)) model.summary() 모델 저장과 복원 model.save_weights(\u0026#39;model-weights.h5\u0026#39;) model.load_weights(\u0026#39;model-weights.h5\u0026#39;) model.save(\u0026#39;model-whole.h5\u0026#39;) model = keras.models.load_model(\u0026#39;model-whole.h5\u0026#39;) val_labels = np.argmax(model.predict(val_scaled), axis=-1) print(np.mean(val_labels == val_target)) 콜백 checkpoint_cb = keras.callbacks.ModelCheckpoint(\u0026#39;best-model.h5\u0026#39;) model.fit(train_scaled, train_target, epochs=20, verbose=0, validation_data=(val_scaled, val_target), callbacks=[checkpoint_cb]) model = keras.models.load_model(\u0026#39;best-model.h5\u0026#39;) 조기종료 checkpoint_cb = keras.callbacks.ModelCheckpoint(\u0026#39;best-model.h5\u0026#39;) early_stopping_cb = keras.callbecks.EarlyStopping(patience=2, restore_best_weights=True) history = model.fit(train_scaled, train_target, epochs=20, verbose=0, validation_data=(val_scaled, val_target), callbacks=[checkpoint_cb, early_stopping_cb]) print(early_stopping_cb.stopped_epoch) plt.plot(history.history[\u0026#39;loss\u0026#39;]) plt.plot(history.history[\u0026#39;val_loss\u0026#39;]) plt.xlabel(\u0026#39;epoch\u0026#39;) plt.ylabel(\u0026#39;loss\u0026#39;) plt.legend([\u0026#39;train\u0026#39;, \u0026#39;val\u0026#39;]) plt.show() 강의 링크\nhttps://www.youtube.com/watch?v=2by0Fz3XC84\u0026list=PLVsNizTWUw7HpqmdphX9hgyWl15nobgQX\u0026index=19 (여기 코드 왤케 오류 많이나지 ㅠㅠ\u0026hellip;)\n"},{"id":16,"href":"/docs/hobby/study/cs14/","title":"공부","section":"공부","content":" [딥러닝] 딥러닝을 이용한 자연어 처리 입문 | BERT # 목록 # 17-02 버트(Bidirectional Encoder Representations from Transformers, BERT)\n17-03 구글 BERT의 마스크드 언어 모델\n17-04 한국어 BERT의 마스크드 언어 모델\n17-05 구글 BERT의 다음 문장 예측\n17-06 한국어 BERT의 다음 문장 예측\n17-02 버트(Bidirectional Encoder Representations from Transformers, BERT) # 2024-12-31 # BERT?\nBERT는 문맥 정보를 반영한 임베딩(Contextual Embedding)을 사용함. 이는 단어의 의미가 문맥에 따라 달라질 수 있음을 모델이 학습하도록 설계된 방식. 입/출력 구조 입력은 각 단어를 768차원의 임베딩 벡터로 변환한 것. ex) [CLS], I, love, you → 각각 768차원의 벡터로 변환. 출력은 BERT의 내부 연산을 거쳐, 문맥을 반영한 768차원의 벡터로 변환된 것. 문맥 반영? 입력된 단어의 벡터에 대한 출력 임베딩은 입력 문장의 모든 단어 정보를 반영한 벡터. [CLS] 벡터는 문장의 전체 정보를 요약한 벡터로 활용된다. 구조와 연산 BERT는 트랜스포머 인코더를 12층 쌓아 올린 구조. 각 층에서 멀티헤드 셀프 어텐션(Multi-Head Self-Attention)**과 포지션 와이즈 피드포워드 네트워크(Position-wise Feed Forward Network) 연산을 수행해서 입력 단어가 다른 모든 단어와 상호작용하여 문맥 정보를 반영하도록 한다. BERT의 서브워드 토크나이저: WordPiece\n서브워드 토크나이저: 자주 등장하는 단어는 단어 단위로, 드물게 등장하는 단어는 서브워드(subword) 단위로 분리하는 방식의 토크나이저. WordPiece의 작동 원리 훈련 데이터로부터 단어 집합을 생성하는데, 자주 등장하는 단어는 단어 단위로 추가하고 드물게 등장하는 단어는 더 작은 단위(서브워드)로 쪼개어 추가한다. 토큰화: 단어가 단어 집합에 존재하면 그대로 사용하고 단어가 단어 집합에 없으면 서브워드로 분리한다. ex) 단어 \u0026ldquo;embeddings\u0026quot;가 단어 집합에 없으면 서브워드로 분리: em, ##bed, ##ding, #s. ##는 단어의 중간이나 끝에서 온 서브워드라는 표시이다. BERT는 서브워드 단위로 토큰화를 수행한 입력 데이터를 받아 문맥 정보를 반영한 임베딩을 생성한다. 요약\nBERT는 모든 단어가 서로를 참고하도록 트랜스포머 인코더(셀프 어텐션)를 활용해 문맥 정보를 포함한 임베딩을 생성한다. WordPiece 토크나이저는 단어를 자주 등장 여부에 따라 단어 또는 서브워드로 분리하여 토큰화를 수행하는데 서브워드 표기(##)를 통해 단어 복원이 가능하며, 단어 집합의 크기를 줄이면서 표현력을 높인다. transformers 패키지를 사용하여 BERT 토크나이저 사용하기 import pandas as pd from transformers import BertTokenizer tokenizer = BertTokenizer.from_pretrained(\u0026#34;bert-base-uncased\u0026#34;) # Bert-base의 토크나이저 result = tokenizer.tokenize(\u0026#39;Here is the sentence I want embeddings for.\u0026#39;) print(result) print(tokenizer.vocab[\u0026#39;here\u0026#39;]) #print(tokenizer.vocab[\u0026#39;embeddings\u0026#39;]) [\u0026#39;here\u0026#39;, \u0026#39;is\u0026#39;, \u0026#39;the\u0026#39;, \u0026#39;sentence\u0026#39;, \u0026#39;i\u0026#39;, \u0026#39;want\u0026#39;, \u0026#39;em\u0026#39;, \u0026#39;##bed\u0026#39;, \u0026#39;##ding\u0026#39;, \u0026#39;##s\u0026#39;, \u0026#39;for\u0026#39;, \u0026#39;.\u0026#39;] 2182 \u0026lsquo;Here is the sentence I want embeddings for.\u0026lsquo;라는 문장을 BERT의 토크나이저가 어떻게 토큰화하는지 확인하기. embeddings라는 단어는 단어 집합에 존재하지 않으므로 em, ##bed, ##ding, #s로 분리되었다. BERT의 단어 집합에 \u0026ldquo;here\u0026quot;가 있는지 조회 -\u0026gt; 단어 here이 정수 인코딩을 위해서 단어 집합 내부적으로 2182라는 정수로 맵핑되어져 있다. \u0026ldquo;embeddings\u0026quot;가 있는지 조회 -\u0026gt; KeyError: \u0026rsquo;embeddings\u0026rsquo; 발생. # BERT의 단어 집합을 vocabulary.txt에 저장 with open(\u0026#39;vocabulary.txt\u0026#39;, \u0026#39;w\u0026#39;) as f: for token in tokenizer.vocab.keys(): f.write(token + \u0026#39;\\n\u0026#39;) df = pd.read_fwf(\u0026#39;vocabulary.txt\u0026#39;, header=None) print(\u0026#39;단어 집합의 크기 :\u0026#39;,len(df)) 단어 집합의 크기 : 30522 자료 출처\nhttps://wikidocs.net/115055\n17-03 구글 BERT의 마스크드 언어 모델 # 2024-12-31 # from transformers import TFBertForMaskedLM, AutoTokenizer model = TFBertForMaskedLM.from_pretrained(\u0026#39;bert-large-uncased\u0026#39;) tokenizer = AutoTokenizer.from_pretrained(\u0026#34;bert-large-uncased\u0026#34;) TFBertForMaskedLM: 마스크드 언어 모델(Masked Language Model, MLM)을 위한 BERT 구조 AutoTokenizer: 해당 모델 학습 시 사용된 토크나이저. inputs = tokenizer(\u0026#39;Soccer is a really fun [MASK].\u0026#39;, return_tensors=\u0026#39;tf\u0026#39;) print(inputs[\u0026#39;input_ids\u0026#39;]) tf.Tensor([[ 101 4715 2003 1037 2428 4569 103 1012 102]], shape=(1, 9), dtype=int32) 사전 학습된 BERT로 마스크드 언어 모델 생성함. 예제 문장: \u0026lsquo;Soccer is a really fun [MASK].\u0026lsquo;에 대해 토크나이저로 정수 인코딩을 수헹. [MASK] 토큰 예측하기? from transformers import FillMaskPipeline pip = FillMaskPipeline(model=model, tokenizer=tokenizer) pip(\u0026#39;Soccer is a really fun [MASK].\u0026#39;) [{\u0026#39;score\u0026#39;: 0.7621169686317444, \u0026#39;token\u0026#39;: 4368, \u0026#39;token_str\u0026#39;: \u0026#39;sport\u0026#39;, \u0026#39;sequence\u0026#39;: \u0026#39;soccer is a really fun sport.\u0026#39;}, {\u0026#39;score\u0026#39;: 0.2034207135438919, \u0026#39;token\u0026#39;: 2208, \u0026#39;token_str\u0026#39;: \u0026#39;game\u0026#39;, \u0026#39;sequence\u0026#39;: \u0026#39;soccer is a really fun game.\u0026#39;}, {\u0026#39;score\u0026#39;: 0.01220863126218319, \u0026#39;token\u0026#39;: 2518, \u0026#39;token_str\u0026#39;: \u0026#39;thing\u0026#39;, \u0026#39;sequence\u0026#39;: \u0026#39;soccer is a really fun thing.\u0026#39;}, {\u0026#39;score\u0026#39;: 0.001863038633018732, \u0026#39;token\u0026#39;: 4023, \u0026#39;token_str\u0026#39;: \u0026#39;activity\u0026#39;, \u0026#39;sequence\u0026#39;: \u0026#39;soccer is a really fun activity.\u0026#39;}, {\u0026#39;score\u0026#39;: 0.0013354964321479201, \u0026#39;token\u0026#39;: 2492, \u0026#39;token_str\u0026#39;: \u0026#39;field\u0026#39;, \u0026#39;sequence\u0026#39;: \u0026#39;soccer is a really fun field.\u0026#39;}] 모델과 토크나이저를 파이프라인에 지정. FillMaskPipeline을 사용하여 문장에서 [MASK] 위치에 들어갈 단어를 예측 결과는 [MASK]에 들어갈 가능성이 높은 단어 5개와 각 단어의 관련 정보 예제 결과 sport가 가장 높은 확률 0.7621을 가짐. 문장이 자연스럽고 문맥상 가장 적합하기 때문에 MLM 모델이 이를 첫 번째 후보로 예측했다. game은 두 번째로 높은 확률 0.2034을 가짐. thing, activity, field는 1.2%, 0.19, 0.13% 확률을 가짐. 자료 출처\nhttps://wikidocs.net/153992\n17-04 한국어 BERT의 마스크드 언어 모델 # 2024-12-31 # \u0026lsquo;축구는 정말 재미있는 [MASK]다\u0026rsquo;를 마스크드 언어 모델의 입력으로 넣으면, 마스크드 언어 모델은 [MASK]의 위치에 해당하는 단어를 예측한다.\nfrom transformers import TFBertForMaskedLM from transformers import AutoTokenizer model = TFBertForMaskedLM.from_pretrained(\u0026#39;klue/bert-base\u0026#39;, from_pt=True) tokenizer = AutoTokenizer.from_pretrained(\u0026#34;klue/bert-base\u0026#34;) inputs = tokenizer(\u0026#39;축구는 정말 재미있는 [MASK]다.\u0026#39;, return_tensors=\u0026#39;tf\u0026#39;) print(inputs[\u0026#39;input_ids\u0026#39;]) print(inputs[\u0026#39;token_type_ids\u0026#39;]) print(inputs[\u0026#39;attention_mask\u0026#39;]) tf.Tensor([[ 2 4713 2259 3944 6001 2259 4 809 18 3]], shape=(1, 10), dtype=int32) tf.Tensor([[0 0 0 0 0 0 0 0 0 0]], shape=(1, 10), dtype=int32) tf.Tensor([[1 1 1 1 1 1 1 1 1 1]], shape=(1, 10), dtype=int32) klue/bert-base의 토크나이저를 사용해서 \u0026lsquo;축구는 정말 재미있는 [MASK]다\u0026rsquo;를 변환. 토크나이저로 변환된 결과: inputs input_ids: 정수로 변환된 토큰 시퀀스. token_type_ids: 문장 구분 (한 개 문장이므로 모두 0). attention_mask: 패딩 토큰 구분 (패딩 없음 → 모두 1). from transformers import FillMaskPipeline pip = FillMaskPipeline(model=model, tokenizer=tokenizer) pip(\u0026#39;축구는 정말 재미있는 [MASK]다.\u0026#39;) [{\u0026#39;score\u0026#39;: 0.8963565230369568, \u0026#39;token\u0026#39;: 4559, \u0026#39;token_str\u0026#39;: \u0026#39;스포츠\u0026#39;, \u0026#39;sequence\u0026#39;: \u0026#39;축구는 정말 재미있는 스포츠 다.\u0026#39;}, {\u0026#39;score\u0026#39;: 0.025957893580198288, \u0026#39;token\u0026#39;: 568, \u0026#39;token_str\u0026#39;: \u0026#39;거\u0026#39;, \u0026#39;sequence\u0026#39;: \u0026#39;축구는 정말 재미있는 거 다.\u0026#39;}, {\u0026#39;score\u0026#39;: 0.010034064762294292, \u0026#39;token\u0026#39;: 3682, \u0026#39;token_str\u0026#39;: \u0026#39;경기\u0026#39;, \u0026#39;sequence\u0026#39;: \u0026#39;축구는 정말 재미있는 경기 다.\u0026#39;}, {\u0026#39;score\u0026#39;: 0.007924459874629974, \u0026#39;token\u0026#39;: 4713, \u0026#39;token_str\u0026#39;: \u0026#39;축구\u0026#39;, \u0026#39;sequence\u0026#39;: \u0026#39;축구는 정말 재미있는 축구 다.\u0026#39;}, {\u0026#39;score\u0026#39;: 0.007844261825084686, \u0026#39;token\u0026#39;: 5845, \u0026#39;token_str\u0026#39;: \u0026#39;놀이\u0026#39;, \u0026#39;sequence\u0026#39;: \u0026#39;축구는 정말 재미있는 놀이 다.\u0026#39;}] FillMaskPipeline으로 [MASK] 위치에 들어갈 수 있는 상위 5개 후보 단어 예측. \u0026ldquo;스포츠\u0026quot;가 문맥상 가장 적합한 단어로 높은 점수를 받았다. 자료 출처\nhttps://wikidocs.net/152922\n17-05 구글 BERT의 다음 문장 예측 # 2024-12-31 # import tensorflow as tf from transformers import TFBertForNextSentencePrediction, AutoTokenizer model = TFBertForNextSentencePrediction.from_pretrained(\u0026#39;bert-base-uncased\u0026#39;) tokenizer = AutoTokenizer.from_pretrained(\u0026#39;bert-base-uncased\u0026#39;) prompt = \u0026#34;In Italy, pizza served in formal settings, such as at a restaurant, is presented unsliced.\u0026#34; next_sentence = \u0026#34;pizza is eaten with the use of a knife and fork. In casual settings, however, it is cut into wedges to be eaten while held in the hand.\u0026#34; encoding = tokenizer(prompt, next_sentence, return_tensors=\u0026#39;tf\u0026#39;) print(encoding[\u0026#39;input_ids\u0026#39;]) print(tokenizer.cls_token, \u0026#39;:\u0026#39;, tokenizer.cls_token_id) print(tokenizer.sep_token, \u0026#39;:\u0026#39; , tokenizer.sep_token_id) print(tokenizer.decode(encoding[\u0026#39;input_ids\u0026#39;][0])) print(encoding[\u0026#39;token_type_ids\u0026#39;]) tf.Tensor( [[ 101 1999 3304 1010 10733 2366 1999 5337 10906 1010 2107 2004 2012 1037 4825 1010 2003 3591 4895 14540 6610 2094 1012 102 10733 2003 8828 2007 1996 2224 1997 1037 5442 1998 9292 1012 1999 10017 10906 1010 2174 1010 2009 2003 3013 2046 17632 2015 2000 2022 8828 2096 2218 1999 1996 2192 1012 102]], shape=(1, 58), dtype=int32) [CLS] : 101 [SEP] : 102 [CLS] in italy, pizza served in formal settings, such as at a restaurant, is presented unsliced. [SEP] pizza is eaten with the use of a knife and fork. in casual settings, however, it is cut into wedges to be eaten while held in the hand. [SEP] tf.Tensor( [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]], shape=(1, 58), dtype=int32) 모델과 토크나이저를 로드하고, 토크나이저로 두 문장을 정수 인코딩했다. input_ids는 정수로 변환된 토큰 시퀀스이다. 여기서 101과 102는 특별 토큰인 [CLS] 토큰과 [SEP] 토큰이다. 정수 인코딩 결과를 다시 디코딩해서 현재 입력의 구성을 확인해보면 BERT에서 두 개의 문장이 입력으로 들어갈 경우에 맨 앞에는 [CLS] 토큰, 문장이 끝나면 [SEP] 토큰, 두번째 문장이 종료되었을 때 다시 [SEP] 토큰이 추가된다 token_type_ids는 두 문장을 구분하기 위한 세그먼트 인코딩이다. 첫 번째 문장은 0, 두 번째 문장은 1. logits = model(encoding[\u0026#39;input_ids\u0026#39;], token_type_ids=encoding[\u0026#39;token_type_ids\u0026#39;])[0] softmax = tf.keras.layers.Softmax() probs = softmax(logits) print(probs) print(\u0026#39;최종 예측 레이블 :\u0026#39;, tf.math.argmax(probs, axis=-1).numpy()) tf.Tensor([[9.9999714e-01 2.8381860e-06]], shape=(1, 2), dtype=float32) 최종 예측 레이블 : [0] 다음 문장 예측하기 BERT 모델에 입력 데이터를 넣어 logits(예측 점수)를 반환 소프트맥스를 적용해 각 레이블(0 또는 1)에 대한 확률 계산. 예측 결과 이어지는 문장일 확률(레이블 0): 99.9997% 이어지지 않는 문장일 확률(레이블 1) 0.00028% 최종 예측은 레이블 0으로써 두 문장이 이어진다고 판단함. # 상관없는 두 개의 문장 prompt = \u0026#34;In Italy, pizza served in formal settings, such as at a restaurant, is presented unsliced.\u0026#34; next_sentence = \u0026#34;The sky is blue due to the shorter wavelength of blue light.\u0026#34; encoding = tokenizer(prompt, next_sentence, return_tensors=\u0026#39;tf\u0026#39;) logits = model(encoding[\u0026#39;input_ids\u0026#39;], token_type_ids=encoding[\u0026#39;token_type_ids\u0026#39;])[0] softmax = tf.keras.layers.Softmax() probs = softmax(logits) print(\u0026#39;최종 예측 레이블 :\u0026#39;, tf.math.argmax(probs, axis=-1).numpy()) 최종 예측 레이블 : [1] 이어지지 않는 두 개의 문장으로 테스트 예측 결과: 이어지지 않는다고 판단. 자료 출처\nhttps://wikidocs.net/156767\n17-06 한국어 BERT의 다음 문장 예측 # 2024-12-31 # import tensorflow as tf from transformers import TFBertForNextSentencePrediction from transformers import AutoTokenizer model = TFBertForNextSentencePrediction.from_pretrained(\u0026#39;klue/bert-base\u0026#39;, from_pt=True) tokenizer = AutoTokenizer.from_pretrained(\u0026#34;klue/bert-base\u0026#34;) # 이어지는 두 개의 문장 prompt = \u0026#34;2002년 월드컵 축구대회는 일본과 공동으로 개최되었던 세계적인 큰 잔치입니다.\u0026#34; next_sentence = \u0026#34;여행을 가보니 한국의 2002년 월드컵 축구대회의 준비는 완벽했습니다.\u0026#34; encoding = tokenizer(prompt, next_sentence, return_tensors=\u0026#39;tf\u0026#39;) logits = model(encoding[\u0026#39;input_ids\u0026#39;], token_type_ids=encoding[\u0026#39;token_type_ids\u0026#39;])[0] softmax = tf.keras.layers.Softmax() probs = softmax(logits) print(\u0026#39;최종 예측 레이블 :\u0026#39;, tf.math.argmax(probs, axis=-1).numpy()) 최종 예측 레이블 : [0] 모델과 토크나이저 로드\nTFBertForNextSentencePrediction.from_pretrained(\u0026lsquo;BERT 모델 이름\u0026rsquo;)을 넣으면 두 개의 문장이 이어지는 문장 관계인지 여부를 판단하는 BERT 구조를 로드. AutoTokenizer.from_pretrained(\u0026lsquo;모델 이름\u0026rsquo;)을 넣으면 해당 모델이 학습되었을 당시에 사용되었던 토크나이저를 로드. 예측 결과: 두 문장이 이어진다고 판단.\n# 상관없는 두 개의 문장 prompt = \u0026#34;2002년 월드컵 축구대회는 일본과 공동으로 개최되었던 세계적인 큰 잔치입니다.\u0026#34; next_sentence = \u0026#34;극장가서 로맨스 영화를 보고싶어요\u0026#34; encoding = tokenizer(prompt, next_sentence, return_tensors=\u0026#39;tf\u0026#39;) logits = model(encoding[\u0026#39;input_ids\u0026#39;], token_type_ids=encoding[\u0026#39;token_type_ids\u0026#39;])[0] softmax = tf.keras.layers.Softmax() probs = softmax(logits) print(\u0026#39;최종 예측 레이블 :\u0026#39;, tf.math.argmax(probs, axis=-1).numpy()) 최종 예측 레이블 : [1] 이어지지 않는 두 개의 문장으로 테스트 예측 결과: 이어지지 않는다고 판단. 자료 출처\nhttps://wikidocs.net/156774\n"},{"id":17,"href":"/docs/hobby/study/cs15/","title":"공부","section":"공부","content":" [딥러닝] 구글 BERT의 정석 | 트랜스포머 입문 # 목록 # 1.2 트랜스포머의 인코더 이해하기\n1.3 트랜스포머의 디코더 이해하기\n1.2 트랜스포머의 인코더 이해하기 # 2024-12-31 # 셀프 어텐션 # 셀프 어텐션은 문장 내 단어들이 서로 얼마나 중요한지를 계산하는 과정. 트랜스포머는 이를 위해 입력 단어를 쿼리(Query), 키(Key), 밸류(Value) 세 가지 벡터로 변환하여 연관성을 구한다. 어텐션 점수 계산 예제 # \u0026ldquo;The cat sat on the mat.\u0026rdquo;\n각 단어 벡터(예: 512차원)를 가중치 행렬과 곱하여 쿼리(Q), 키(K), 밸류(V)벡터를 생성한다. 어떤 단어가 다른 단어와 얼마나 연관되는지를 측정하기 위해, Q와 K벡터 간의 내적(dot product)을 계산한다. 단어 The cat sat on the mat Query: \u0026ldquo;cat\u0026rdquo; 0.2 1.0 0.8 0.1 0.3 0.5 \u0026ldquo;cat\u0026quot;의 쿼리 벡터와 모든 단어의 키 벡터를 곱해서 점수를 계산하는 경우. 여기서 \u0026ldquo;cat\u0026quot;은 \u0026ldquo;sat\u0026quot;과 가장 연관이 높고(0.8), \u0026ldquo;on\u0026quot;과는 거의 연관이 없다(0.1). 소프트맥스 적용 단어 The cat sat on the mat Softmax 값 0.05 0.4 0.35 0.02 0.08 0.1 위에서 구한 점수에 대해 소프트맥스를 적용하여 확률로 변환 이제 \u0026ldquo;cat\u0026quot;은 \u0026ldquo;sat\u0026rdquo;(0.35)과 \u0026ldquo;cat\u0026rdquo; 자체(0.4)에 높은 가중치를 부여함. 각 단어의 밸류(V) 벡터를 위의 확률로 가중합하여 최종 어텐션 출력을 얻는다. 멀티 헤드 어텐션 # 단어 간의 관계를 한 가지 방식으로만 학습하면, 문맥을 완전히 반영하지 못할 수 있음. 예를 들어, 단어 \u0026ldquo;cat\u0026quot;은 문장에서 다음과 같은 다양한 방식으로 다른 단어와 관계를 맺을 수 있다.\n문법적 관계(Head 1): \u0026ldquo;cat\u0026rdquo; → \u0026ldquo;sat\u0026rdquo; (주어와 동사의 관계) 의미적 관계(Head 2): \u0026ldquo;cat\u0026rdquo; → \u0026ldquo;mat\u0026rdquo; (동물과 사물이 놓여 있는 관계) 위치적 관계(Head 3): \u0026ldquo;on\u0026rdquo; → \u0026ldquo;mat\u0026rdquo; (\u0026ldquo;on\u0026quot;이 \u0026ldquo;mat\u0026quot;과 어떤 방식으로 연결되는지) 만약 하나의 어텐션만 사용한다면, 위 관계 중 하나만 학습할 수 있다. 멀티 헤드 어텐션은 여러 개의 독립적인 어텐션 연산을 수행하여, 이러한 다양한 패턴을 동시에 학습하는 역할을 함.\n멀티헤드 어텐션 수행 과정 # 문장을 입력하면, 각 단어는 일정한 차원의 벡터(예: 512차원)로 변환된다. 각 단어의 벡터를 이용하여 쿼리(Q), 키(K), 밸류(V)를 생성한다.\n여러 개의 어텐션 헤드 생성\n멀티 헤드 어텐션에서는 각 단어 벡터를 여러 개의 서로 다른 가중치 행렬을 사용하여 여러 개의 쿼리(Q), 키(K), 밸류(V)로 변환한다.\n각 헤드는 서로 다른 관계를 학습할 수 있도록 다른 가중치를 가진다.\n각 헤드는 독립적으로 셀프 어텐션(Self-Attention)을 수행한다. 소프트맥스를 적용하여 확률값으로 변환한 후, 밸류(V)에 가중합하여 최종 출력을 생성한다. 어텐션 점수 계산 각 헤드에서 나온 결과를 병합(Concatenation)한 후, 최종적으로 선형 변환을 적용한다. 즉, 여러 개의 어텐션을 병렬로 수행하고, 최종적으로 선형 변환을 적용하여 하나의 벡터로 변환하는 것. 선형 변환 위치 인코딩 # 트랜스포머는 문장을 한 번에 입력받아 병렬로 처리하는 구조이다. 이러한 구조는 속도 면에서 유리하지만, 단어들의 순서(sequence)를 직접적으로 학습할 수 없다. 따라서 위치 정보를 인코딩하여 단어의 순서를 반영하는 기법이 필요함. 즉, 특정 단어의 위치 pos와 벡터의 차원 위치 i에 따라 사인과 코사인 값을 계산하여 각 차원별 위치 인코딩 값을 생성함으로써 위치 정보를 반영한다. 위치 인코딩 예제 # \u0026ldquo;The cat sat on the mat.\u0026rdquo;\n단어 벡터를 4차원으로 설정한다고 가정하고 각 단어에 대해 위치 인코딩 값 계산하기. 첫 번째 차원 (i=0) 계산 (짝수이므로 sin 사용)\n두 번째 차원 (i=1) 계산 (홀수이므로 cos 사용)\n생성된 각 단어의 위치 인코딩 벡터\n단어 위치 인코딩 벡터 (4차원) The [0.000, 1.000, 0.841, 0.540] cat [0.841, 0.540, 0.909, -0.416] sat [0.909, -0.416, 0.141, -0.990] on [0.141, -0.990, -0.757, -0.654] the [-0.757, -0.654, -0.958, 0.283] mat [-0.958, 0.283, -0.279, 0.750] 단어의 임베딩 벡터와 더하면, 위치 정보가 반영된 최종 벡터가 생성된다.\n피드포워드 네트워크(Feedforward Network, FFN) # FFN은 트랜스포머의 각 단어 벡터에 대해 독립적으로 적용되는 두 개의 선형 변환(fully connected layer)과 활성화 함수(ReLU)로 구성된 신경망. 과정 첫 번째 선형 변환 (Fully Connected Layer 1): 입력 벡터를 확장된 차원(2048)의 벡터로 변환한다. ReLU 활성화 함수 적용: 비선형성을 추가하여 복잡한 관계를 학습 두 번째 선형 변환 (Fully Connected Layer 2): 다시 원래 차원(512)으로 축소하여 출력 트랜스포머 인코더 블록에서 FFN의 위치 # 피드포워드 네트워크는 어텐션 이후에 적용됨. 멀티 헤드 어텐션(Self-Attention) 수행\n각 단어가 다른 단어들과의 관계를 학습 어텐션 가중치를 통해 정보를 집계 Add \u0026amp; Norm (Residual Connection + Layer Normalization) 적용 피드포워드 네트워크(FFN) 적용\n개별 단어의 의미 표현을 강화 (독립적인 변환 수행) ReLU를 활용하여 비선형성을 추가 Add \u0026amp; Norm (Residual Connection + Layer Normalization) 적용 Add \u0026amp; Norm # 트랜스포머는 매우 깊은 신경망이다. 깊은 신경망을 학습할 때 흔히 발생하는 문제가 기울기 소실(Vanishing Gradient)과 기울기 폭발(Exploding Gradient). 또한, 모델이 과도하게 변화하면 학습이 불안정해진다. Residual Connection을 사용하면 원래 정보를 유지하면서 학습할 수 있다. Layer Normalization을 사용하면 값의 스케일을 맞추어 학습을 안정화할 수 있다. 트랜스포머 인코더 전체 과정 # 입력 벡터(임베딩 + 위치 인코딩) 생성 멀티 헤드 어텐션 수행하여 단어 간 관계를 학습 Residual Connection 적용 (입력 + 어텐션 출력 더하기) Layer Normalization 적용하여 학습 안정화 피드포워드 네트워크(FFN) 적용하여 단어별 정보를 강화 Residual Connection 적용 (입력 + FFN 출력 더하기) Layer Normalization 적용 다음 인코더 블록으로 전달하여 반복 수행 1.3 트랜스포머의 디코더 이해하기 # 2024-12-31 # 디코더의 구조 # 트랜스포머 디코더는 인코더와 함께 동작할 수도 있고(Google의 원래 Transformer 모델, BART), 독립적으로 동작할 수도 있다(GPT 시리즈). N개의 디코더 블록(stack)이 쌓여 있는 형태로 구성. 디코더 핵심 연산 # Masked Multi-Head Self-Attention 입력 시퀀스 내에서 이전 단어까지만 참고하여 다음 단어를 예측해야 하므로, 일반적인 Multi-Head Self-Attention과 다르게 미래 정보를 차단(masking) 한다. 이를 위해 Casual Masking(Look-Ahead Masking)을 사용하여, 현재 위치 t에서 t+1, t+2, \u0026hellip; 등 미래의 단어들을 보지 못하도록 만든다. 계산 과정 Q, K, V를 입력에서 생성 어텐션 스코어 계산 마스킹 적용: 미래 단어의 스코어를 −∞로 설정하여 Softmax에서 0이 되도록 만듦. Softmax \u0026amp; 가중합하여 최종 출력을 생성. Cross-Attention 인코더에서 생성된 컨텍스트 정보를 활용하는 모듈. 인코더의 출력을 Key \u0026amp; Value로 사용하고, 디코더의 출력을 Query로 사용해서 Attention을 수행. 작동 방식 디코더에서 나온 Query(Q)와 인코더에서 생성된 Key(K) 및 Value(V)를 활용하여 Multi-Head Attention 수행. 이를 통해 코더가 인코더의 정보를 반영하여 다음 토큰을 예측하는 데 도움을 준다. Feed Forward Network (FFN) 각 디코더 블록에는 FFN이 포함되어 있으며, 두 개의 완전 연결층(fully connected layers)으로 구성된다. 구조 입력 차원 dmodel 중간 차원 dff(보통 4dmodel) 활성화 함수 ReLU 또는 GELU 출력 차원 dmodel Residual Connection \u0026amp; Layer Normalization 잔차 연결(Residual Connection): 각 서브 레이어의 입력을 더해줌. Layer Normalization: 학습 안정성을 높이고, 학습 속도를 향상. 디코더의 출력 (Output Processing) # 마지막 디코더 블록에서 나온 결과는 완전 연결층(Dense layer)를 거쳐 차원을 조정한다. 소프트맥스(Softmax) 를 적용하여 단어 확률 분포를 계산한다. 가장 확률이 높은 단어를 선택하여 출력한다. "},{"id":18,"href":"/docs/hobby/study/cs16/","title":"공부","section":"공부","content":" [딥러닝] 구글 BERT의 정석 | BERT 입문 # 목록 # 2.3 BERT의 구조\n2.4 BERT 사전 학습\n2.3 BERT의 구조 # 2024.12.31 # BERT의 전체 구조 # 트랜스포머의 인코더(Encoder) 블록을 여러 개 쌓은 형태. 입력: 문장 (토큰화된 형태) 내부 구조: N개의 Transformer Encoder Blocks (기본 모델은 12개, 큰 모델은 24개) 출력: 각 토큰의 벡터 표현 (Contextual Embedding) cf) BERT의 대표적인 모델 크기\n모델 # 인코더 층 숨겨진 차원 (dmodel) 어텐션 헤드 수 파라미터 수 BERT-Base 12 768 12 110M BERT-Large 24 1024 16 340M BERT의 입력 처리 # 입력 토큰 (Token Embedding) WordPiece Tokenization을 사용하며, 단어를 서브워드(subword) 단위로 분할하고 각 토큰은 고유한 임베딩 벡터로 변환된다. ex) \u0026ldquo;playing\u0026rdquo; -\u0026gt; [\u0026ldquo;play\u0026rdquo;, \u0026ldquo;##ing\u0026rdquo;] 문장 구분 정보 (Segment Embedding) BERT는 두 개의 문장을 함께 입력할 수 있으며, 이때 각 문장이 어디에 속하는지를 구분하기 위해 Segment Embedding을 추가한다. ex) 문장 A: 0 (Segment A) / 문장 B: 1 (Segment B) 위치 정보 (Position Embedding) 트랜스포머는 순서를 고려하지 않는 구조이므로, 단어 순서를 반영하기 위해 위치 임베딩을 추가한다. BERT는 고정된 학습 가능한 위치 임베딩을 사용하며, 트랜스포머에서 사용되는 사인(sine) 및 코사인(cosine) 위치 임베딩을 사용하지 않음. 최종 입력 형식\n[CLS] 문장1 단어1 단어2 \u0026hellip; [SEP] 문장2 단어1 단어2 \u0026hellip; [SEP]\n[CLS]: 문장 전체를 대표하는 분류(Classification) 토큰 (첫 번째 위치) [SEP]: 문장 구분(Sentence Separation) 역할 BERT의 내부 구조 (Transformer Encoder Block) # 트랜스포머 인코더 블록을 여러 개 쌓은 구조.\nMulti-Head Self-Attention BERT는 문장의 양방향 문맥을 학습하기 위해 Multi-Head Self-Attention을 사용한다. 각 단어(토큰)는 문장의 다른 모든 단어와 어텐션을 수행하며, 관계를 학습한다. 즉 장의 다른 모든 단어와 어텐션 스코어를 계산하는데, 스코어가 크면 토큰 간 관계가 강한 것으로 간주된다. BERT는 12~16개의 어텐션 헤드를 사용한다. Feed Forward Network (FFN) 각 어텐션 층을 통과한 결과는 두 개의 완전 연결층(Fully Connected Layers) 을 통과하여 변환된다. 첫 번째 레이어: 선형 변환 + 활성화 함수 (ReLU 또는 GELU) 두 번째 레이어: 최종 출력 변환 FFN은 각 토큰에 대해 독립적으로 작동하며, 모델의 표현력을 증가시키는 역할을 한다. Layer Normalization \u0026amp; Residual Connection Residual Connection: 입력과 출력을 더해줌 (Gradient Flow 안정화) Layer Normalization: 네트워크 안정성 유지, 학습 속도 향상 이 과정을 총 N번 반복하여 최종적으로 컨텍스트 정보를 포함한 벡터가 생성된다.\nBERT의 출력 # BERT의 출력은 크게 두 가지 형태로 활용됨. 문장 수준 출력 ([CLS] 토큰) [CLS] 토큰의 벡터를 활용하여 문장 분류(Classification) 및 회귀(Task-Specific Head) 를 수행. ex) 감성 분석(Sentiment Analysis), 자연어 추론(NLI) 단어 수준 출력 (Token-Level Embeddings) 각 토큰의 벡터를 활용하여 개체명 인식(Named Entity Recognition, NER), 문장 생성 등의 태스크 수행. 2.4 BERT 사전 학습 # 2024.12.31 # 사전 학습 단계에서는 BERT가 대량의 텍스트 데이터를 학습하면서 일반적인 언어 패턴과 문맥(Contextual Representation)을 이해한다.\nMasked Language Model (MLM, 마스킹된 언어 모델) # MLM 기본 개념 입력 문장에서 랜덤하게 15%의 단어를 [MASK]로 바꾼 후, 이를 예측하는 방식. BERT는 문장의 양방향(Bidirectional) 컨텍스트를 활용하여 [MASK]된 단어를 예측한다. 일반적인 언어 모델(예: GPT)은 이전 단어들만 참고하는 단방향 방식이지만, BERT의 MLM은 좌우 문맥을 모두 활용할 수 있다. MLM의 토큰 마스킹 마스킹된 15%의 단어는 다음과 같은 비율로 변환된다.\n80% → [MASK] 토큰으로 변경 10% → 랜덤한 다른 단어로 변경 10% → 원래 단어를 유지 ex) \u0026ldquo;I love deep learning because it is powerful.\u0026ldquo;은 BERT의 입력으로 변환하면 \u0026ldquo;I love [MASK] learning because it is powerful.\u0026ldquo;이고 모델의 목표는 \u0026ldquo;[MASK]\u0026rdquo; → \u0026ldquo;deep\u0026quot;이다.\n일반적인 자동 회귀(autoregressive) 모델은 단방향(Left-to-Right 또는 Right-to-Left)으로 단어를 예측함. 하지만, BERT는 양방향(Bidirectional) 문맥을 고려해야 하므로, 단어 일부를 가려놓고 전체 문맥을 기반으로 예측하는 방식이 적합하다.\nNext Sentence Prediction (NSP, 문장 관계 예측) # NSP 기본 개념 두 개의 문장을 입력으로 받아서, 두 번째 문장이 첫 번째 문장의 다음 문장인지 아닌지를 예측하는 방식. 이는 문장 간 관계를 학습하는 데 유용하며, 질의응답(QA) 및 자연어 추론(NLI) 태스크에 도움됨. NSP의 데이터 구성 학습할 때 두 개의 문장을 선택하여 다음과 같이 구성한다. 50%의 경우 → 실제 연속된 문장 (Positive Example) 50%의 경우 → 무작위로 선택된 문장 (Negative Example) BERT는 [CLS] 토큰을 활용하여 두 문장이 이어지는지 여부를 판단하는 분류 태스크를 수행한다. 이를 통해 질의응답(QA) 및 문장 간 논리적 연결성을 고려하는 태스크에서 강한 성능을 발휘할 수 있다.\nBERT의 사전 학습 과정 (Pre-training Process) # 데이터 준비 BERT는 대량의 비지도 학습 데이터를 사용하여 사전 학습된다. 각 문장을 WordPiece Tokenizer를 이용해 서브워드(subword) 단위로 변환한다. 토큰 임베딩 생성 입력 문장은 다음과 같은 3가지 임베딩을 결합하여 벡터로 변환된다. Token Embedding: 각 단어에 해당하는 임베딩 벡터 Segment Embedding: 문장 A/B를 구분하는 임베딩 Position Embedding: 문장 내 단어의 위치 정보를 나타내는 임베딩 Transformer 인코더 통과 BERT의 본체인 Transformer Encoder (12~24개 블록) 를 통해 입력을 변환한다. MLM 태스크를 위해 일부 토큰이 [MASK] 처리된 상태에서 어텐션(Self-Attention)이 수행됨. NSP 태스크를 위해 [CLS] 토큰의 출력이 사용됨. 두 가지 출력 MLM 출력: [MASK] 위치에 올바른 단어를 예측 NSP 출력: [CLS] 토큰을 사용하여 두 문장이 연속된 문장인지 예측 BERT의 최종 손실(Loss Function) 계산. BERT의 사전 학습 이후 (Fine-tuning) # BERT는 사전 학습을 마친 후, 특정 태스크에 맞춰 미세 조정(Fine-tuning)한다.\n사전 학습된 BERT 모델을 기반으로 특정 태스크 수행 텍스트 분류 (Sentiment Analysis) 질의응답 (SQuAD, Question Answering) 개체명 인식 (NER, Named Entity Recognition) 자연어 추론 (NLI, Natural Language Inference) 미세 조정 방식 사전 학습된 가중치를 초기화한 후, 해당 태스크에 맞게 라벨이 있는 데이터로 추가 학습을 진행한다. [CLS] 토큰을 활용한 분류 태스크 [MASK] 토큰을 활용한 MLM 기반 태스크 "},{"id":19,"href":"/docs/hobby/study/cs17/","title":"공부","section":"공부","content":" [딥러닝] 구글 BERT의 정석 | BERT의 파생 모델: ALBERT, RoBERTa, ELECTRA, SpanBERT # 목록 # 4.1 ALBERT\n4.3 RoBERTa\n4.4 ELECTRA\n4.1 ALBERT # 2024-12-31 # ALBERT (A Lite BERT)는 BERT 모델의 성능을 유지하면서도 파라미터 수를 줄이고, 더 효율적인 학습을 목표로 한 모델.\n크로스 레이어 변수 공유 # BERT는 각 Transformer 레이어마다 별도의 가중치와 바이어스를 갖는다. ALBERT는 동일한 파라미터 집합을 여러 레이어에 걸쳐 사용하여 모델의 파라미터 수를 크게 줄인다. 펙토라이즈 임베딩 변수화 # BERT는 vocab_size x hidden_size 크기의 임베딩 행렬을 사용하여, vocab_size와 hidden_size에 비례하는 수의 파라미터를 필요로 한다. ALBERT는 임베딩 행렬을 두 개의 더 작은 행렬로 분해하여, 파라미터 수를 줄인다(임베딩 팩토라이제이션). 행렬1: vocab_size x embedding_size 행렬2: embedding_size x hidden_size 문장 순서 예측 # BERT에서는 Masked Language Modeling (MLM)과 Next Sentence Prediction (NSP)을 사용.\nNSP은 두 문장이 연속적으로 존재하는지를 예측하는 태스크. 문장 간 관계를 학습하는 데 사용됨. ALBERT는 문장 순서 예측 (SOP, Sentence Order Prediction) 라는 새로운 학습 태스크를 도입.\n두 문장이 주어졌을 때, 두 문장의 순서가 올바른지를 예측함. SOP는 문장 간의 순서 관계를 이해하는 데 NSP보다 적합하다.\nALBERT와 BERT 비교 # 크로스 레이어 변수 공유: ALBERT는 여러 레이어에서 파라미터를 공유하여 파라미터 수를 크게 줄임. BERT는 각 레이어마다 독립적인 파라미터 집합을 사용. 펙토라이즈 임베딩: ALBERT는 임베딩 행렬을 분해하여 파라미터 수를 줄임. BERT는 한 번에 큰 임베딩 행렬을 사용. 문장 순서 예측 (SOP): ALBERT는 NSP 대신 SOP를 사용하여 문장 순서를 더 잘 예측할 수 있게 하여, 문장 간 관계 학습을 개선. ALBERT에서 임베딩 추출 # 단어 임베딩\n입력 텍스트의 각 단어를 vocab_size x embedding_size 크기의 행렬을 사용하여 고차원 벡터로 변환함. 이 벡터는 각 단어의 의미를 반영하는 고차원적인 특징을 갖고있다. 레벨 별 임베딩 추출 (Layer-wise Embedding Extraction)\n입력 텍스트가 Transformer 모델을 통과하면서 각 레이어에서 벡터 표현이 점진적으로 변환된다. ALBERT에서는 주로 첫 번째 레이어 또는 최종 레이어에서 추출된 임베딩을 사용할 수 있음. 첫 번째 레이어에는 주로 단어의 기본적인 의미와 구조적 특징 정보. 최종 레이어에는 문장 전체의 복합적인 의미와 문맥이 결합되어, 더 구체화되고 세부적인 정보. 중간 레이어에서의 임베딩 추출\nALBERT는 다중 레이어 구조를 갖기 때문에, 중간 레이어의 출력도 사용할 수 있음. 문장 내 특정 단어의 문맥을 더 잘 반영하는 중간 레이어의 임베딩을 추출할 수 있다. 사용자가 수행하는 작업에 따라, 특정 작업에 적합한 레이어의 출력을 선택. 예를 들어, 문장 분류 작업에서는 모델의 최종 레이어에서 추출된 임베딩이 더 중요할 수 있으며, 개체명 인식(NER) 작업에서는 중간 레이어에서 나온 임베딩이 더 유용할 수 있다. 4.3 RoBERTa # 2024-12-31 # 정적 마스크 대신 동적 마스크 사용 # BERT는 정적 마스크 (Static Masking) 방식을 사용하여 훈련함. 훈련 데이터에서 마스킹할 단어를 고르고, 그 마스크를 모든 훈련 단계에서 동일하게 유지한다. 즉 같은 단어가 훈련 내내 계속 마스크된다. RoBERTa는 동적 마스크 (Dynamic Masking) 방식을 사용. 즉, 각 훈련 배치마다 문장에서 마스크되는 단어가 랜덤하게 변경된다. 정적 마스크에서는 동일한 문맥을 반복해서 학습하므로, 모델이 특정 단어의 패턴을 암기할 수 있는데, 동적 마스크에서는 훈련마다 마스크가 달라져 모델이 더 다양한 방식으로 문맥을 학습할 수 있도록 돕고, 일관된 마스크 패턴에 의한 편향을 줄여 모델이 더 일반화된 특징을 학습할 수 있게 해준다. NSP 테스크 제거 # BERT 모델은 훈련 과정에서 MLM, NSP 테스크를 사용한다. RoBERTa는 NSP 대신 MLM만을 사용하여 훈련을 진행. NSP 제거의 이유는 문장 간의 관계 학습에 NSP가 크게 기여하지 않으며 제거 시 훈련이 더 간단해지고, 모델이 더욱 집중해서 문맥을 학습할 수 있음. 더 많은 데이터로 학습 # RoBERTa는 BERT보다 훨씬 더 많은 데이터로 훈련. BERT는 16GB 크기의 BooksCorpus와 English Wikipedia로 훈련되었지만, RoBERTa는 여기에 추가로 Common Crawl 데이터, CC-News, OpenWebText, Stories 등의 더 많은 데이터를 포함하여 훈련됨. 큰 배치 크기로 학습 # RoBERTa는 훈련에 더 큰 배치 크기를 사용합니다. BERT는 일반적으로 배치 크기를 32 또는 64로 설정하여 훈련하지만, RoBERTa는 배치 크기 8,000까지 사용하여 훈련했습니다. 큰 배치 크기?\n배치가 크면 모델이 더 많은 데이터를 한 번에 처리할 수 있게 해주고, 훈련 속도를 높이는 데 기여함. 학습 안정성을 높여, 학습 과정에서 발생할 수 있는 불안정한 그래디언트 문제를 완화하는 데 도움을 줌. BBPE 토크나이저 사용 # BERT는 WordPiece 토크나이저를 사용하여 텍스트를 서브워드 단위로 분할. RoBERTa는 BBPE (Byte Pair Encoding) 토크나이저를 사용. 단어를 자주 발생하는 문자쌍으로 분할하여 서브워드 토큰을 만든다. 이는 드문 단어나 외래어가 포함된 텍스트에서 더욱 효과적임. BBPE는 단어를 더 작은 조각으로 나누고, 이를 더 자주 사용되는 문자쌍으로 합치는 방식으로 작동함. 효과: 어휘 집합 크기를 줄이면서도 다양한 단어를 처리할 수 있게 해주며, 모델의 효율성을 높이고, 모든 언어에서 유연한 처리가 가능. 4.4 ELECTRA # 2024-12-31 # 교체한 토큰 판별 테스크 # BERT와 같은 기존 모델들은 일부 단어를 마스킹하고 예측하는 방식(Masked Language Modeling, MLM)을 사용해서 모델을 학습. 이 방식은 마스크된 단어의 예측이 실제 문맥을 잘 반영하지 않게 될 수 있다는 단점이 있다. ELECTRA는 교체한 토큰 판별 테스크 (Replaced Token Detection) 를 사용. 이 방식은 문장을 구성하는 각 토큰이 원래의 문장에서 그대로 있었는지 아니면 다른 토큰으로 교체되었는지를 구분하는 문제이며 이렇게 하면 모델은 교체된 단어를 구별하는 법을 배운다. ELECTRA의 생성자와 판별자 # ELECTRA는 두 가지 모델로 구성된다. 생성자 (Generator)\n기존 BERT와 같은 Masked Language Model (MLM) 구조. 입력 문장에서 일부 단어를 [MASK]로 변환한 후, 이를 생성자의 예측 값으로 대체함. 판별자 (Discriminator)\n문장 내 각 토큰이 진짜인지(fake) 가짜인지(real)를 분류하는 이진 분류(Binary Classification) 문제를 해결. ELECTRA 모델 학습 # 생성자 학습\n문장에서 일부 단어를 마스킹한 후, 생성자가 그 단어를 예측. 예측된 단어는 원래 단어 대신 교체된 단어(replaced token)로 사용됨. 판별자 학습\n생성자가 만든 교체된 단어를 포함한 문장을 입력받음. 판별자는 문장 내 각 단어가 원래 단어인지, 교체된 단어인지 판별하는 작업을 수행. 판별자가 더 정확한 예측을 할수록 모델의 언어 이해 능력이 향상됨. 손실 함수 계산\n생성자는 Cross-Entropy Loss (MLM 방식) 판별자는 Binary Classification Loss (Replaced Token Detection 방식) 반복 학습\n생성자의 성능이 향상될수록 판별자의 분류 작업이 더 어려워짐. 결국 판별자가 더 정교한 문맥 이해 능력을 갖도록 최적화됨. 효율적인 학습 방법 탐색 # ELECTRA 모델을 효율적으로 학습시키기 위해서 생성자와 판별자의 가중치를 공유한다.\n기존 BERT는 마스킹된 토큰만 학습에 사용하지만, ELECTRA는 모든 토큰을 판별 작업에 사용하여 훨씬 더 높은 학습 데이터 활용률을 가짐.\n기존의 MLM 방식보다 80% 적은 연산량으로 동일한 성능을 유지, 동일한 연산량을 사용했을 때 BERT보다 2~4배 더 빠르게 학습 가능.\n생성자는 BERT와 같은 크기를 사용할 필요가 없어서, 생성자를 작은 크기의 모델로 설정하여 연산량을 절감.\nELECTRA-Small (14M parameters) → BERT-Small보다 86% 더 높은 성능 / ELECTRA-Large는 BERT-Large보다 적은 연산량으로 더 높은 성능을 보임.\n"},{"id":20,"href":"/docs/hobby/study/cs5/","title":"공부","section":"공부","content":" [깃허브] 깃허브 오류 There was an error committing your changes: File could not be edited # 2024-12-31 # 갑자기 모든 파일의 수정이 안되고 page deployment도 오류가 났다. 브라우저 캐시 문제인가 해서 방문기록이랑 캐시를 모두 삭제해보았다. 그래도 오류가 났다. 구글링하니까 내 경우랑 맞아떨어지는 한국인 블로그글이 있어서 시키는대로 https://www.githubstatus.com/에 들어가봤다. 블로그 글이랑 같은 창이 떴는데 그냥 기다려야된다길래 그냥 기다림. 2시간 뒤에 들어가니까 이 창으로 바뀌었다. 그리고 된다. 또 블로그 부셔진줄\u0026hellip; 다행이다\u0026hellip;.\n"},{"id":21,"href":"/docs/hobby/movie/movie2/","title":"영화","section":"영화","content":" 콜 미 바이 유어 네임 (2017) # 여름 감성 최고봉 영화! 특히 ost가 너무 좋다.\n목록 # 플레이리스트 | Sufjan Stevens - Mystery of Love\n원작 소설\n플레이리스트 # 2024-12-31 # https://www.youtube.com/watch?v=n50Z3HGj4QE\nSufjan Stevens - Mystery of Love https://www.youtube.com/watch?v=XPPp0Gn45_8\n| 𝐩𝐥𝐚𝐲𝐥𝐢𝐬𝐭 | 𝐬𝐨𝐦𝐞𝐰𝐡𝐞𝐫𝐞 𝐢𝐧 𝐧𝐨r𝐭𝐡𝐞𝐫𝐧 𝐢𝐭𝐚𝐥𝐲 🌳🍃 이건 비슷한 감성을 느끼고 싶을때 듣기 좋은 플리.\n원작 소설 # 2024-12-31 # 콜 미 바이 유어 네임 - 안드레 애치먼 \u0026raquo;\n얼굴 개연성(..)으로만 설명되었던 빠져드는 계기가 천천히 설명되어서 좋았다. 그리고 올리버의 불안정함이 다른 어른들의 시각에 비추어서 어느정도 더 설명되니까 그것도 좋았다.\n감성은 영화랑 비등비등. 영화-\u0026gt;소설 순으로 감상한 건 운이 좋았다!\ncf) 위 소설은 리마스터판이고 이전 버전은 \u0026lt;그해, 여름 손님\u0026gt;이라는 제목으로 출판되었다.\n"},{"id":22,"href":"/docs/hobby/book/book11/","title":"책","section":"책","content":" 우리가 빛의 속도로 갈 수 없다면 | 김초엽 # 가볍게 읽기 좋은 SF 소설.\n필요 이상으로 개연성을 설명하려하거나 등장인물이 많은 작품 별로 안좋아하는데 둘다 해당하지 않아서 읽기 편했다!\n목록 # [북마크] 순례자들은 왜 돌아오지 않는가\n[북마크] 스펙트럼\n[북마크] 공생 가설\n[북마크] 감정의 물성\n순례자들은 왜 돌아오지 않는가 # 2024-12-31 # 소피. 마지막으로 한 가지 말할 것이 남았어. 내가 처음으로 마을에 대해 의문을 품게 되었던 계기, 그 오두막 뒤에 있던 귀환자 말야. 정해진 성년식보다 조금 더 빨리 지구에 가기로 결심했을 때 나는 그 남자에게 몰래 찾아가 물었어. 혹시 지구에서 무슨 일이 있었던 거냐고.\n그는 슬픈 진실을 말해주었지. 지구에서 그가 사랑했던 사람과 그의 쓸쓸한 죽음에 관해. 그가 남겼던, 행복해지라는 유언에 관해.\n나는 말했어. 당신의 마지막 연인을 위해 당신이 할 수 있는 일이 있지 않겠냐고. 나는 그에게 지구로 다시 함께 가겠냐고 물었어.\n떠나겠다고 대답할 때 그는 내가 보았던 그의 수많은 불행의 얼굴들 중 가장 나은 미소를 짓고 있었지.\n그때 나는 알았어.\n우리는 그곳에서 괴로울 거야.\n하지만 그보다 많이 행복할 거야.\n소피, 이제 내가 먼저 떠나는 이유를 이해해줄 거라고 믿어.\n그럼 언젠가 지구에서 만나자.\n그날을 고대하며,\n데이지가.\n스펙트럼 # 2024-12-31 # 1\n할머니는 마지막 순간들에 대해 구체적으로 이야기하지 않았다. 그때의 일을 다시 떠올리는 것이 너무나 괴롭기 때문이라고 했다. 하지만 나는 할머니가 그 이상으로 무언가를 숨기고 싶어 한다는 느낌을 지울 수 없었다.\n마지막 이야기에는 거짓이 있다. 할머니는 그 행성에서 구조 신호를 발신한 적이 없다. 할머니의 셔틀이 구조된 장소는 망망대해 같은 우주의 진공 한가운데였다. 할머니는 무리인들의 행성에서 10년을 보냈다고 했지만, 실제로 할머니가 구조된 건 조난 이후 40년 만이었다. 시공간 여행의 시차를 고려하더라도 할머니는 20년 이상을 다시 혼자가 되어 떠돌았다는 이야기가 된다. 그 오랜 시간동안 할머니는 대체 무엇을 한 걸까? 어쩌면 할머니는 어떻게든 행성에서 멀리 떠날 방법을 찾아냈던 것인지도 모른다. 그리고 누구도 그 행성의 위치를 추적할 수 없을 장소에 도달한 다음에야 마침내 구조 신호를 보낸 것인지도.\n어쨌든 모든 것은 추측에 불과하다. 할머니는 단 한 번도 그 시간의 빈틈에 대해서는 이야기해준 적이 없다. “루이는 정말로 죽었을까요?” 그런 질문에도 할머니는 빙긋 미소만 지었을 뿐이다.\n2\n행성의 위치에 대해 어떤 단서조차 내놓지 않겠다는 할머니의 고집은 이해할 수 없을 정도로 완고했다. 정부와 기업, 연구소에서 수도 없이 사람을 보내 할머니를 설득했지만 할머니는 굳게 입을 다물었다. 수십 년의 고독과 외로움에 지쳐 상상 속에서 허구의 세계를 만들어낸 것이라고 사람들이 수군거렸던 것도 그렇게 이상한 일만은 아닌 셈이었다.\n3\n우리가 그들을 다시 만날 때는, 우리는 더는 유약한 이방인이 아닐 것이다. 루이와 할머니의 관계는 재현될 수 없을 것이다. 나는 할머니를 이해할 수 있었다. 마지막 탈출 때 할머니가 협곡에서 가지고 올 수 있었던 것은 오직 한 뭉치의 종이뿐이었다. 할머니의 말대로 종이 위의 색채들은 마치 누군가 수백 종의 물감을 흩뿌려놓은 것처럼 다채로웠다. “이건 루이가 나를 기록하고 관찰한 일기였어. 일종의 연구노트라고 할까. 내가 그들을 관찰하고 탐색한 것처럼 루이에게도 나는 연구대상이었던 셈이지. 어쩌면 그들은 내가 아주 먼 곳에서 온, 도구가 없어 무력한 학자임을 이미 알고 있었는지도 몰라.” 할머니는 나에게 루이가 쓴 기록의 내용을 읽어주셨다. 지구에 돌아온 이후로 할머니는 여생을 색채 언어의 해석에만 몰두했다. 내용의 대부분은 그렇게까지 시간을 들여가며 알아낼 필요가 있었을까 싶을 정도로 정말 평범한 관찰 기록이었다. 그러나 그중 잊히지 않는 한 문장만큼은 지금도 떠오른다. “이렇게 쓰여 있구나.” 할머니는 그 부분을 읽을 때면 늘 미소를 지었다. “그는 놀랍고 아름다운 생물이다.”\n숨을 거두기 전 할머니는 연구노트의 처분을 나에게 맡겼다. 나는 기록의 사본을 남기고, 원본은 할머니와 함께 화장했다. 찬란했던 색채들이 한 줌의 재로 모였다. 나는 할머니의 유해를 우주로 실어 보내 별들에게 돌려주었다.\n공생 가설 # 2024-12-31 # 만약에 뇌 속의 ‘그들’이 인간에게 태생적으로 존재하는 것이 아니라 외부에서 유입되는 것이라면 어떨까? 마치 기생충이나 미생물이 사람에게서 다른 사람으로 전염되듯 말이다. 그들은 공기 중에 분포해 있거나, 바이러스처럼 환경에 널리 퍼져 있을 수도 있다. 하지만 어느 쪽이든 감염을 위한 최초의 접촉이 필요할 것이다. 그렇기에 상자 속의 아이들이 밖으로 나오기 전까지 ‘그들’을 받아들일 기회가 없었던 것이라면? 어쩌면 가장 중요한 특성은 인간 밖에서 오는 것인지도 모른다. 수빈은 그 증거를 확인하려 하고 있었다.\n수빈은 영상에서 소리 데이터를 추출해서 전환기에 넣었다. 그냥 듣기에는 다른 평범한 아기들과 별반 다를 바 없는 울음이었다. 그러나 만약 ‘그들’의 유무가 아기들에게 영향을 미친다면, 여기서는 다른 결과가 나타날 것이다. 그들의 대화가 아닌 아기들의 욕구를 확인하게 될 것이다.\n「배고파」 「졸려」 「무서워」\n수빈은 다음에 일어난 일 역시 알고 있었다. 그 아기들은 사람들이 기대한 대로 성장하지 않았다. 상자 속의 아기들은 이타성을 획득하지 못했다.\n*재밌게 읽어서 하는 말이지만 인간의 \u0026lsquo;이타성\u0026rsquo;이 \u0026lsquo;그들\u0026rsquo; 즉 외부로부터 온다는 가정을 증명하는 위 부분에서 \u0026lt;태어난 아이들을 상자 속에 집어넣는 실험\u0026gt; 설정은 좀 거슬린다. \u0026lt;태어난 아이들을 충분히 빨리 상자 속에 집어넣음 -\u0026gt; 접촉이 일어나지 않음\u0026gt;인건데 거슬리는 부분은 \u0026lsquo;충분히\u0026rsquo;이다. 얼마나 빨리 집어넣었길래 혹은 접촉이 어떻게 일어나길래? 미토콘드리아처럼 공생한다고 했으면 의문이 안들었을것 같음. 빈틈없는 논리를 중요하게 생각하지 않는 편인데 내 눈에 보이는거면 매끄럽지 않은 진행이 맞는 듯하지만. 뭐 중요한가? 사실 이 말도 재밌게 읽었기 때문에 하는 말이다. ㅎ\n우리가 빛의 속도로 갈 수 없다면 # 2024-12-31 # 기술 발전만 보고 달리니까 다른 중요한 가치를 인간이 따라가지 못하는 것에 대한 비판. 예전에 유튜브에서 돌고래와 소통하는 실험을 봤던 게 생각났다.\nhttps://youtu.be/1NfgR7LZ3sI?si=q9eMkyp5v9k_bI03 감정의 물성 # 2024-12-31 # 나는 보현의 서랍장 위에서 수십 개의 감정의 물성 제품들을 발견했다. 하나같이 전부 ‘우울’이었다. 그 옆에는 병원에서 처방받아 온 항우울제가 있었다. 나는 이제 그녀가 우울에 빠져 죽고 싶은 것인지, 아니면 살아남고 싶은 것인지 도저히 알 수가 없었다.\n“널 이해 못 하겠어.” 보현은 딜레마에 빠져 있었다. 발목이 잡혀 있었다. 한때 사랑했던 사람들이 그녀를 억압하고 있었다. 그렇다고 이런 방식으로 해결하려는 건 더더욱 이해할 수 없었다. ‘우울체’가 그녀의 슬픔을 어떻게 해결해주는가? “물론 모르겠지, 정하야. 너는 이 속에 살아본 적이 없으니까. 하지만 나는 내 우울을 쓰다듬고 손 위에 두기를 원해. 그게 찍어 맛볼 수 있고 단단히 만져지는 것이었으면 좋겠어.” 테이블 위의 휴대폰이 울렸다. 보현은 말을 이어갔다. “어떤 문제들은 피할 수가 없어. 고체보다는 기체에 가깝지. 무정형의 공기 속에서 숨을 들이쉴 때마다 폐가 짓눌려. 나는 감정에 통제받는 존재일까? 아니면 지배하는 존재일까? 나는 허공중에 존재하는 것 같기도 아닌 것 같기도 해. 그래. 네 말대로 이것들은 그냥 플라시보이거나, 집단 환각일 거야. 나도 알아.” 보현은 우울체를 손으로 한 번 쥐었다가 탁자에 놓았다. 우울체는 단단하고 푸르며 묘한 향기가 나는, 부드러운 질감을 가진, 동그랗고 작은 물체였다. “하지만 고통의 입자들은 산산이 흩어져 내 폐 속으로 들어오겠지. 이 환각이 끝나면.” 우울체 하나가 탁자 위를 굴러 바닥으로 툭 떨어졌다. “그게 더 나은 결론일까.”\n나는 시선을 피했고 그 순간 보현이 어떤 표정을 지었는지는 알 수 없었다. 이어지는 진동 소리가 짧은 비명 같았다. 잠시 뒤 그녀가 몸을 돌려 밖으로 나갔다. 문이 달칵 닫혔다. 휴대폰의 진동이 멈췄다. 나는 고개를 들었다. 이제 허공을 가득 채운 침묵이 느껴졌다. 보현을 무슨 말로 위로해야 했을까? 나는 순간 보현을 위로할 수 있는 어떤 언어도 나에게 없다는 사실을 깨달았다. 무언가 중요한 것이 가슴속에서 빠져나가버린 듯 싸늘했고, 나는 그게 생각이나 관념이 아닌 실재하는 감각임을 알았다. 그제야 어설프게 그녀를 이해할 수 있었다. 잠시 머물렀다 사라져버린 향수의 냄새. 무겁게 가라앉는 공기. 문 너머에서 들려오는 흐느끼는 소리. 오래된 벽지의 얼룩. 탁자의 뒤틀린 나뭇결. 현관문의 차가운 질감. 바닥을 구르다 멈춰버린 푸른색의 자갈. 그리고 다시, 정적.\n물성은 어떻게 사람을 사로잡는가. 나는 닫힌 문을 가만히 바라보다 시선을 떨구었다.\n*결말이 이해가 안돼서 여러번 읽었는데 그래도 이해가 안된다. ㅠㅠ\n"},{"id":23,"href":"/docs/hobby/book/book12/","title":"책","section":"책","content":" 불변의 법칙 | 모던 하우절 # 세상 모든 일은 예측 불가능한 방식으로 서로 영향을 주고받고, 혼합되고, 그 결과가 증폭된다. 세상은 운과 우연에 이토록 취약하다.\n목록 # [북마크] 북마크1\n플레이리스트\n[관련 영상] 김지민 생일 Birthday - 쿠쿠크루(Cuckoo Crew)\n북마크1 # 2024-12-31 # 💛1 # 오늘의 세상 모습이 어떻든, 무엇이 당연해 보이든, 내일이 되면 그 누구도 생각하지 못한 작은 우연 때문에 모든 게 달라질 수 있다. 돈과 마찬가지로 사건도 복리 효과를 낸다. 그리고 복리 효과의 가장 주요한 특징은 미약하게 시작된 뭔가가 나중에 얼마나 거대해질 수 있는지를 처음에는 직관적으로 느낄 수가 없다는 사실이다.\n(1 이토록 아슬아슬한 세상)\n2 # 세상은 정보로 넘쳐난다. 사람들은 그 모든 정보를 꼼꼼하고 차분하게 살펴보면서 가장 합리적의고 옳은 답을 찾기 어렵다.\n완벽한 세상에서라면 정보의 중요성이 그 정보 전달자의 스토리텔링 능력에 의존하지 않는다. 그러나 우리가 살고 있는 이 세상 사람들은 쉽게 지루함을 느끼고, 인내심이 부족하며, 감정에 쉽게 지배당하고, 복잡한 정보가 마치 스토리의 한 장면처럼 이해하기 쉬워지기를 원한다.\n(6 뛰어난 스토리가 승리한다)\n💛3 # 비극은 우리에게 고통과 괴로움, 충격, 슬픔, 혐오감을 안겨 준다. 그러나 마법 같은 변화를 초래하는 동력이 되기도 한다.\n똑같은 지적 능력을 지닌 사람들이라도 어떤 상황에 놓이느냐에 따라 잠재적 발휘 수준이 완전히 달라진다. 그리고 가장 큰 혁신이 일어나는 것은 대개 불안과 두려움에 휩싸인 상황, 해결책 발견에 미래가 달려 있어서 빨리 행동해야 한다는 절박함을 느끼는 상황이다. 쇼퍼파이 창립자 토비 뤼트게는 말했다. \u0026ldquo;모든 것이 순조롭고 아무 문제가 없을 때는 진정한 회복력을 키울 수 없다.\u0026rdquo; 나심 탈레브는 말했다. \u0026ldquo;역경에 과잉 반응할 때 분출되는 엄청난 에너지가 혁신을 만들어낸다.\u0026rdquo; 고통은 평화와 달리 우리의 집중력을 발휘시킨다. 늑장과 망설임을 허용하지 않는다. 해결해야 할 문제를 우리의 턱밑에 들이밀어 당장 그리고 모든 역량을 동원해 해결하지 않을 수 없게 만든다.\n(10 마법이 일어나는 순간)\n💛4 # \u0026lsquo;모든 측면\u0026rsquo;에서 완벽하도록 진화하는 종은 없다. 하나의 능력이나 특성이 완벽해지면 결국 생존에 필수적인 다른 능력이나 특성을 잃기 때문이다. 진화 논리는 자연 세계의 모든 종이 완벽하지는 않되 생존에 필요한 적당한 수준의 특성들을 갖게 만들어놓았다.\n시간을 낭비하는 것이 오히려 현명한 일이 될 수 있다. 심리학자 아모스 트버스키는 \u0026ldquo;훌륭한 연구 성과를 내는 비결은 항상 조금씩 덜 일하는 것이다\u0026quot;라고 했다. 창의력을 발휘해 어려운 문제를 해결해야 하는 사람이라면, 공원을 거닐거나 소파에서 아무 생각 없이 빈둥거리는 시간이 대단히 중요할 수 있다.\n알베르토 아인슈타인은 이렇게 말했다. \u0026ldquo;나는 시간을 내서 해변을 오래 산책한다. 내 머릿속에서 일어나는 일에 귀를 기울이기 위해서다. 연구가 풀리지 않을 때는 방 안에 누워 천장을 멍하니 응시하면서 머릿속 상태를 마음속에 시각적으로 그려본다.\u0026rdquo;\n찰리 멍거는 워런 버핏의 성공 비결에 대해 이렇게 답했다. \u0026ldquo;그는 깨어 있는 시간의 절반을 그저 휴식을 취하며 책을 읽는 데 보냅니다.\u0026rdquo; 버핏은 생각할 시간이 무척 많았다.\n나심 탈레브는 \u0026ldquo;나는 성공의 유일한 지표가 자유롭게 쓸 수 있는 시간이 얼마나 되느냐고 생각한다\u0026quot;라고 말했다.\n정확성을 추구하면 할수록 큰 그림을 보여주는 원칙에 집중할 시간이 줄어든다. 정확성보다는 원칙이 더 중요할 가능성이 높음에도 말이다.\n(14 완벽함의 함정)\n💛5 # 영화 \u0026lt;아라비아의 로렌스\u0026gt;를 보면 이런 장면이 나온다. 로렌스가 뜨거운 성냥불을 아무렇지 않게 손가락으로 잡아서 끈다. 그러자 그걸 지켜본 다른 사내가 똑같이 따라 했다가 깜짝 놀라 비명을 지른다. \u0026ldquo;뜨겁잖아요! 대체 어떻게 한 거죠?\u0026rdquo; 그가 묻는다. 그러자 로렌스가 대답한다. \u0026ldquo;뜨거워도 개의치 않는 거지.\u0026rdquo; 이는 인생에 꼭 필요한 능력 중 하나다. 고통을 피해갈 쉬운 해결책이나 지름길부터 찾기보다는 필요한 때에 고통을 참아내는 능력 말이다.\n우리는 빠르고 쉬운 길에 혹하기 쉽다. 고생하지 않고 성공할 수 있을 것 같으니까. 하지만 실제로 그런 길은 거의 없다. 찰리 멍거는 이렇게 말했다. \u0026ldquo;원하는 것을 얻는 가장 확실한 방법은 그것을 누릴 자격을 갖춘 사람이 되는 것이다. 간단하다. 이것은 황금률이다. 사람들에게 뭔가 제공할 때는 당신이 상대방이라 해도 만족할 만한 것을 제공하라.\u0026rdquo;\n목표로 삼을 가치가 있는 것 중에 공짜는 없다. 모든 것에는 비용이 따르며, 대개 그 비용은 잠재적 보상의 크기와 비례한다.\n(15 모든 여정은 원래 힘들다)\n6 # 적절한 행동을 아는 것과 적절하다고 생각하는 조언을 제공하며 생계를 유지하는 것은 다른 문제일 수 있다. 투자나 법률, 의료 서비스 분야가 특히 그렇다. 사실은 \u0026lsquo;아무것도 하지 마라\u0026rsquo;가 가장 적절한 조언인데도 \u0026lsquo;뭔가를 하라\u0026rsquo;고 조언하는 것은 직업적 인센티브가 작동한 결과다.\n(19 인센티브: 세상에서 가장 강력한 힘)\n7 # 인간의 행동에는 참으로 별난 구석이 있다. 복잡한 것, 지적 호기심을 자극하며 고도의 두뇌 활동이 필요한 일에 마음이 끌리고, 복잡하지만 효과가 덜한 것이 아니라 단순하지만 효과가 좋은 것을 무시한다는 점이다.\n(22 복잡함과 단순함 Trying Too Hard)\n플레이리스트 # 2024-12-31 # https://youtu.be/XstIT_dY6eE?si=fbXi6ohmBhTIVztz 들으면서 타이핑하니까 딱이다!!\n관련 영상 # 2024-12-31 # https://youtu.be/5f_Lx-RbrJc?si=imPXt3rVSR3GOq_R\n[일상] 김지민 생일 Birthday - 쿠쿠크루(Cuckoo Crew) Q) 뜨겁잖아요! 대체 어떻게 한 거죠?\n??) 뜨거워도 개의치 않는 거지.\nㅋㅋㅋ\n"},{"id":24,"href":"/docs/hobby/book/book13/","title":"책","section":"책","content":" 루틴의 힘 | 댄 애리얼리, 그레첸 루빈, 세스 고딘 외 # 흔들리지 않고 끝까지 계속하게 만드는 루틴의 힘\n목록 # [북마크] 전문가의 세상으로 나가는것에 대한 두려움\n사람들이 장기적으로 실천하는 데 어려움을 겪는 이유는 세상에 나오는 것에 대한 두려움 때문입니다. 이는 곧 자신이 하는 일을 속속들이 아는 사람들이 있는 곳으로 나서는 것이며 비판에 자신을 내놓고 앞으로 평생 자신의 일에 능통한 전문가가 되겠다고 선언하는 것이나 다름없기 때문입니다.\n[북마크] 진전의 가시화\n일이 진척된다는 감각은 한눈에 파악되지 않습니다. 그러니 제 생각에 관건은, “어떻게 하면 자신이 발전하고 있다는 것을 느낄 수 있는가?”인 겁니다. 일의 진전 여부를 가시화할 수 있다면 다른 많은 것은 작은 장애물에 지나지 않는다고 생각합니다. 쉽게 말해, 펜으로 적으면서 일을 한다면 자신이 처리한 일의 증거물이 남습니다. 자신이 밟아 온 경로를 볼 수 있는 거죠. 이처럼 발전의 기록이 눈에 보이도록 하는 방법들을 생각할 수 있을 겁니다.\n전문가의 세상으로 나가는것에 대한 두려움 # 2024-12-31 # 1 # 자주 하면, 부담이 줄어든다. 일주일 동안의 결과물이 겨우 한 페이지, 블로그 포스팅 한 건, 스케치 하나라면 당연히 \u0026lsquo;특출나게 잘해야 한다\u0026rsquo;는 생각이 들고 작업물의 질에 대해 조바심을 내게 된다. 반면 매일 쓰면 하루치 정도는 그다지 중요하지 않다. 불안감이 사라진 덕분에 결과적으로 일을 더 즐기게 되고, 새로운 실험을 해 보거나 위험을 기꺼이 감수할 수도 있다. 괜찮은 결과물이 나오지 않아도 시간은 충분하니까 다른 방법을 시도하면 되는 것이다. 하지만 하루하루 시간은 지나는데 아무것도 완성되지 않으면 불안과 절망감이 엄습한다. 일을 미룸으로써 발생한 불안감 때문에 도리어 일에 매진하지 못하는 것은 직업 생활의 씁쓸한 아이러니다.\n2 # 사람마다 효율적인 일상의 모습은 각기 다르다. 자기 능력과 성향에 따른 맞춤식이어야 루틴의 효과가 배가된다. 따라서 위에서 소개한 탄탄한 루틴 형성법을 직접 실험해 보고 어떤 조합이 최고의 성과를 내는 데 가장 좋은지 살펴라. 매일의 스케줄이 단조로운 일상이 아닌 창의적인 의식처럼 느껴지기 시작한다면 효과적인 조합이라고 할 수 있을 것이다.\n3 # 단기적인 실천 습관 역량을 가진 사람들이 장기적으로 실천하는 데 어려움을 겪는 이유는, 십중팔구 두려움 때문입니다. 두려움의 저항력은 상당히 은밀하게 작용하죠. 겉으로 봐서는 흔적이 뚜렷하게 남지 않습니다. 그러나 영화계에 파란을 일으킬 단편 영화는 만들 수 있어도 장편 영화 제작에 필요한 자금을 조성하지 못하는 사람, 여기저기서 규모가 작은 프리랜서 일은 하지만 그 일을 제대로 된 직업으로 전환할 줄은 모르는 사람, 이런 사람들은 일종의 자기 파괴 행위를 하는 셈입니다.\n이처럼 이들이 스스로를 망가뜨리는 이유는, 세상에 나온다는 것은 곧 자신이 하는 일을 속속들이 아는 사람들이 있는 곳으로 나서는 것이기 때문이죠. 세상에 나왔을 때 사기꾼으로 비춰질까 봐 두려운 것이죠. 이사회나 회의장에서, 또는 그저 동료 앞에 서서 “저는 이 일에 대해 잘 압니다. 자, 제 작업을 보시죠. 1년 만에 해낸 일입니다. 멋지지 않나요?”라고 말하는 건 그들에게 정말 어려운 일입니다.\n그 이유는 두 가지인데요. 첫째, 비판에 자신을 내놓는 일이기 때문입니다. 둘째, 자신의 일을 속속들이 아는 사람들의 세상으로 나온다는 건, 앞으로 평생 자신의 일에 능통한 전문가가 되겠다고 선언하는 것이나 다름없기 때문입니다.\n4 # 우리의 역량은 한정돼 있다. 하지만 우리가 에너지를 관리하는 방식에는 변화를 줄 수 있다. 능숙하게 에너지를 관리하면 좀 더 지속적으로, 한층 수준 높게, 그것도 좀 더 짧은 시간에 많은 일을 해낼 수 있다.\n그 방법을 두 가지 중요한 과학 연구 결과에서 찾을 수 있다. 첫째는 ‘수면이 음식 섭취보다 중요하다’는 것이다. 우리는 일주일 동안 아무것도 먹지 않아도 버틸 수 있다. 다만 몸무게를 좀 잃게 될 뿐이다. 하지만 단 이틀이라도 잠을 안 자면? 완전히 망가진다. 이런데도 우리는 1시간의 수면을 너무 쉽게 포기한다. 그 1시간만큼 생산성이 더 올라갈 거라는 잘못된 믿음 때문이다. 실상은 수면이 아주 조금만 부족해도, 우리의 인지 능력은 상당한 피해를 입는다. 매우 짧은 수면을 취하고도 제대로 일을 해낼 수 있다는 일부의 얘기는 보통 미신에 불과하다. 인구 40명당 한 사람, 전체 인구의 2.5퍼센트 미만의 사람만 하루 7~8시간의 수면을 취하고도 충분하다고 느낀다.\n두 번째 중요한 연구 결과는 ‘우리 신체는 주기적 리듬을 따른다’는 것이다. 즉 우리 몸은 90분 주기로, 일을 처리할 수 있는 최고 수준의 역량 한계점에 도달한다. 커피나 설탕에 의존하거나 스트레스 호르몬을 자극해서 90분 이상 자신을 밀어붙일 수는 있지만, 그러면 생리적으로 필요한 휴식과 회복의 시간을 무시하는 셈이다. 결국 그렇게 한계점까지 자신을 밀어붙이면 대가를 치러야 한다.\n5 # 요즘 같은 세상에 고독을 찾는 것은 꼭 필요한 일이다. 고독이 주는 교훈을 배울 수 있고, 오롯이 집중하고 창조할 수 있는 공간을 찾을 수 있으며, 고요 속에서 내면의 목소리에 귀 기울일 수 있기 때문이다.\n하루에 20분~1시간만이라도 고독을 위한 시간을 비워 두면 어마어마한 변화가 찾아온다. 이 시간, 고요한 평온 속에서 우리 마음은 나무 위의 원숭이처럼 활기가 넘치게 된다. 마음에 고요가 찾아오면 무엇이 진짜 중요한지 파악할 수 있고, 매일의 업무와 인터넷 생활의 불협화음 속에서 잃어버렸던 자신만의 창조적 목소리에 다시 귀 기울일 수 있다.\n진전의 가시화 # 2024-12-31 # 1 # Q. 우리가 시간 관리를 좀 더 잘하기 위해서는 무엇에 집중해야 할까요?\nA. 저는 가장 중요한 요소가 ‘진전의 가시화’라고 생각합니다. 대개의 경우 일이 얼마나 진척됐는지 확인하기가 쉽지 않죠. 그런데 이메일 답장 같은 쉬운 일이라면, 1000통의 이메일에 답장한다고 해도 자신이 답장한 이메일을 한눈에 파악할 수 있습니다. 반면 어려운 문제를 처리할 때는 마치 30시간은 헛되이 보냈고 마지막 30분만 유용했던 것처럼 느껴집니다. 왜냐하면 마지막 30분 동안에 아이디어가 떠올랐기 때문이죠.\n일이 진척된다는 감각은 한눈에 파악되지 않습니다. 그러니 제 생각에 관건은, “어떻게 하면 자신이 발전하고 있다는 것을 느낄 수 있는가?”인 겁니다. 일의 진전 여부를 가시화할 수 있다면 다른 많은 것은 작은 장애물에 지나지 않는다고 생각합니다. 쉽게 말해, 펜으로 적으면서 일을 한다면 자신이 처리한 일의 증거물이 남습니다. 자신이 밟아 온 경로를 볼 수 있는 거죠. 이처럼 발전의 기록이 눈에 보이도록 하는 방법들을 생각할 수 있을 겁니다.\n2 # 어떤 일에서 탁월함의 경지에 오르기 위해서는 궁극적으로 관찰과 정련, 적응과 인내가 요구된다. 저명한 소설가인 무라카미 하루키가 자신의 작품을 완성하기 위해 스스로에게 적용하는 자제력 이야기에 귀 기울여 보기 바란다. 저는 소설 쓰기 모드에 돌입했을 때 새벽 4시에 일어나 5-6시간 동안 작업합니다. 오후에는 10킬로미터 달리기나 1500미터 수영을 한 다음(혹은 두 가지를 모두 한 다음), 책을 읽거나 음악을 감상하지요. 밤 9시에는 잠자리에 들고요. 이런 루틴을 변화 없이 매일 지속합니다. 반복 자체가 중요합니다. 반복은 일종의 최면이니까요. 제 자신의 깊은 내면에 접근하기 위해 스스로에게 최면을 거는 겁니다. 하지만 6개월-1년이라는 긴 시간 동안 이런 반복적 생활을 유지하려면 엄청난 정신력과 체력이 요구되지요. 이런 의미에서 장편 소설을 쓴다는 건 생존 훈련과도 같습니다. 예술적 감성만큼 체력이 절실한 일이지요. 창의적인 사람이 되기 위해서는 가장 혼란스러운 환경 속에서도 집중력을 단련하고 창의적 에너지를 모으는 법을 배워야만 한다.\n3 # 자신이 어떤 분야에 관심을 쏟는지가 그 사람의 정체성을 대변한다.\n"},{"id":25,"href":"/docs/hobby/book/book2/","title":"책","section":"책","content":" 당신의 특별한 우울 | 린다 개스크 # 목록 # [북마크] 애통해할 수 있게 되면 잃어버린 사람을 그 사람 그대로 기억할 수 있게 된다.\n[북마크] 불행한 것과 우울한 것.\n[관련 영상] 결핍과 그에 대한 애도의 기간(라디오스타 김영철)\n애통해할 수 있게 되면 잃어버린 사람을 그 사람 그대로 기억할 수 있게 된다. # 2024-12-31 # 1 # 지금까지 의사로 일하면서, 인생 계획을 완벽하게 할 수 있다고 생각하는 사람들을 많이 보았다. 그런 사람은 자녀들 인생까지도 그런 식으로 계획하려고 한다. 그리 생각하는 게 무리가 아닐지도 모른다. 살면서 정말 나쁜 일을 당해본 적이 한 번도 없고 모든 일이 기대한 대로 풀린 사람이라면 그럴 수 있다. 그러다가 상실을 경험하게 되면 그것이 본인의 자아정체감이나 인생의 이정표와 관련이 클수록 받아들이기가 더 힘들어진다. 나는 시험에 떨어지면서 계획이 일시적으로 틀어졌다. 주도면밀하게 그려놓았던 인생 계획이 어그러졌다. 누가 만들어준 계획은 분명히 아니었다. 오로지 내 생각만으로 만든 계획이라고 믿었다. 나도 어쩌면 대니얼처럼, 아버지의 마음에 들려고 애쓰고 있는 건지도 모른다는 사실은 무시했다. 게다가 이미 돌아가시고 세상에 있지도 않은 아버지였으니. 지금 생각해보면 나는 그때, 아버지가 돌아가신 후로 계속 나타나고 있던 균열을 적당히 땜질만 하며 수습하고 있었다. 그때는 길을 잠깐 잃었다가 다시 찾았다고만 생각했고, 다른 생각은 하지 못했다. 하지만 내게 정말 필요했던 약은, 운명이라 생각했던 길에서 완전히 탈선하는 것이었을지도 모른다. 후에 깨달았지만, 삶이라는 열차가 탈선하여 내달리는 그 혼돈의 순간에는 때로 중요한 메시지가 담겨 있다. 앞으로 무엇을 바꾸면서 살아야 할지, 너무 늦기 전에 생각해보라는 메시지다. 그런 의문에 답할 수 있다면, 자신만의 목표를 향해 다시 앞으로 나아갈 수 있다. 자신이 스스로 정한 목표는 이룰 가능성도 더 높은 법이다.\n2 # 생각해보면 그때부터 나는 깨닫기 시작했던 것 같다. 내 모든 결점과 허물까지 있는 그대로 받아들이지 않고서는, 삶을 다시 살아갈 수 없다는 것을. 심리치료사들은 자기애에 대해 이야기한다. 간혹 자기애를 이기심과 같은 것으로 오해하기도 하지만 둘은 다르다. 진부하게 들릴 수도 있겠지만, 진정으로 남을 아껴줄 수 있으려면 자신을 먼저 사랑할 줄 알아야 한다는 말이 백 번 틀리지 않다. 자신만의 장점을 인정하고, 단점을 시인하고, 받아들이며, 그 모든 것을 평온하게 바라볼 줄 알아야 한다. 나는 이미 저지른 실수를 반복하지 않으려면 지금까지 살아오면서 해온 선택들에 책임을 져야 한다는 것을 차츰 깨달았다. 그렇다고 해서 잘못된 선택을 더 이상 하지 않는 건 물론 아니었다. 특히 연애에 성급히 빠져드는 문제는 고쳐지지 않았다. 하지만 조금씩 달라질 수 있을 듯 했다.\n3 # 아버지가 돌아가신 후 내 결혼 생활의 부족한 점을 직시하지 못했던 건 외로움에 대한 두려움 때문이었다는 사실도 차츰 깨달았다. 내 삶도 정서적으로 \u0026lsquo;보류된\u0026rsquo; 상태였던 것이다. 미래가 뒤로 미루어진 상태였다.\n나는 물방앗간 집 옆 바위에 앉아 풍경을 바라보며 제니퍼를 생각했다. 바람에 이는 파도의 물보라, 바다 건너편에 수면과 맞닿아 있는 자줏빛 산들, 넋을 빼앗길 만큼 아름다운 풍경이었다. 나는 외로움의 아픔이 어떤 것인지 안다. 그것은 남은 평생을 혼자 살게 되리라는 두려움이었다. 아침에 옆에서 자는 연인의 따뜻한 체온을 느끼며 눈을 뜰 일이 없게 되리라는 두려움이었다. 이제 저녁 식탁에서 내가 정치인들이 의료제도를 개악하고 있다고 불만을 터뜨릴 때 공감해줄 사람도, 나를 안아주면서 일 이야기는 그만하고 어서 식기 전에 먹으라고 말해주는 사람도 없으리라는 두려움이었다. 고독사가 두려웠다. 혼자 사는 할머니가 집 주방에서 몇 주 만에 발견되었는데 \u0026lsquo;자연사\u0026rsquo;한 것으로 보이지만 배고픈 고양이들이 물어뜯어서 정확한 사망 원인은 알 수 없다는 따위의 이야기가 남 이야기가 아닐 것 같았다.\n내 환자들이 많이 그랬듯, 나도 세상으로부터 고립되고 단절될까봐 두려웠다. 고립, 외로움, 우울은 서로 밀접한 관련이 있다. 사람들과 떨어지면 그로 인해 우울해질 수 있고 회복 또한 더뎌질 수 있다. 문제는 우울해지면 남들과 대화하기도, 함께 있기도 힘들고 남들을 믿지도 못하니 스스로를 적극적으로 고립시키곤 한다는 것이다. 그 결과 고립이 심해지고 그에 따라 기분이 더 가라앉는 악순환이 일어난다. 이럴 때는 단순히 사람을 다시 만나는 것이 꼭 해결책이라고도 볼 수 없다. 천성이 사교적인 사람은 다시 사람을 만나고 싶은 마음이 상대적으로 크지만, 내향적인 사람은 상호작용 과다로 인한 스트레스에서 회복하려면 혼자 있는 시간이 필요할 수도 있다. 내 경우도 물론 후자 쪽이다. 우울한 사람은 세상 속에 나가 남들과 어울린다는 것에 대단히 양면적인 감정을 갖기 쉽다.\n숙소 밖에 앉아 주변 경관을 응시하면서, 혼자라는 두려움과 맞닥뜨릴 방법을 조금씩 알 것 같았다. 그 두려움을 어떻게 끌어안고 견뎌내고, 이해해야 할지 조금씩 깨달았다. 글을 읽거나 쓰거나 창작하는 등의 활동을 하려면 꼭 혼자 시간을 보내야 하는 사람들이 많다. 앤서니 스토는 \u0026lsquo;고독의 위로\u0026rsquo;라는 책에서 창작을 하는 사람이건 아니건 혼자 있는 능력이야말로 그 사람의 성숙도를 보여주는 징표이며, 모든 사람이 인간관계를 훌륭하게 영위해야만 삶에서 행복을 얻을 수 있는 것은 아니라는 이야기를 했다. 불교의 사상과 수행에서 유래한 \u0026lsquo;마음챙김\u0026rsquo;이라는 개념이 있다. 마음을 활짝 열고 우리 내면의 자아를 좀 더 잘 알기 위해, 괴로운 생각을 억누르려 하지 말고 그대로 관찰하면서 현재에 집중하는 것이다. 그 당시 나는 마음챙김에 대해 전혀 알지 못했지만, 이곳에서 생활하면서 그날그날 반복되는 일과에 집중하다 보니 - 내가 먹을 음식을 만들고, 3킬로미터 거리의 가게를 걸어서 다녀오고, 창가 책상에 앉아 독서하고 글 쓰고, 바다 풍경을 스케치하고 하면서 - 나도 모르게 마음챙김 기법을 실천하고 있었다. 그리고 그 과정에서, 혼자라는 게 사실 그렇게 나쁘지 않다는 걸 깨달았다.\n많은 사람이 외로움을 두려워한다. 누구나 정도의 차이는 있을지언정 남들과 어울리면서 감정을 나누고 걱정과 근심을 터놓고자 하는 욕구가 있다. 그러지 못한다면 제니퍼처럼 우울해지고, 또 우울에서 벗어나지 못하게 된다. 하지만 나는 고독이라는 것 역시 끌어안을 수 있고, 심지어 즐길 수도 있다고 생각한다. \u0026lsquo;자기 자신과 함께하는\u0026rsquo; 법을 배운다면 가능하다. 그렇게 함으로써 세상 속에서 내가 어떤 사람인지, 또 내가 남들에게 무엇을 줄 수 있는지 더 잘 알 수 있다. 우리는 친밀과 고독 사이에서 누구나 각자의 이상적인 균형점을 찾아내야 한다.\n4 # 나는 마지못해 그의 말이 맞다는 걸 인정했지만, 그런 공포스러운 감정에 사로잡힐 때 어떻게 벗어나야 할지 도무지 알 수 없었다. 가끔 기분이 가라앉고 몸이 녹초일 때는, 무거운 추가 가슴을 짓눌러 몸을 옴싹달싹할 수 없는 느낌이었다. 그런가 하면 어떤 때는 무엇이든 가능할 것 같은 기분이 들었다. 존의 말이 맞았다. 그럴 때 나는 정말로 통제력을 잃고 현실을 벗어나 버리는 듯 했다. 대개는 잠깐이었지만, 그럴 때면 자살 충동도 다시 느껴졌다. 나는 엘리자베스 워첼이 \u0026lsquo;프로작 네이션\u0026rsquo;이라는 책에서 묘사한, 끝없는 정서적 혼돈 상태가 무엇을 말하는지 너무나 잘 안다. 내가 특히 공감한 부분은, 저자가 원하는 치료사란, 어른답게 행동할 수 있도록 도와줄 사람, 그리고 우울증이 심해 전화 요금도 내지 못하는 이용자의 사정 따위는 전화 회사가 신경쓰지 않는 세상에서, 살아갈 방법을 알려줄 사람이라고 한 대목이었다.\n5 # \u0026ldquo;지금 어머니에 대해서는 어떤 감정이세요?\u0026rdquo; 내가 물었다.\n\u0026ldquo;제 어머니예요. 그러니까 물론 사랑하지요\u0026hellip;\u0026rdquo; 그녀는 그렇게 말하고는 잠시 생각하더니 입을 열었다. \u0026ldquo;하지만 밉기도 해요. 정말, 진짜 미워요.\u0026rdquo; 그리고 나를 보며 얼굴을 살짝 붉혔다. \u0026ldquo;제가 어떻게 그런 나쁜 말을\u0026hellip; 신부님에게 고해성사해야 할 것 같아요.\u0026rdquo; \u0026ldquo;아니요, 전혀 나쁜 말 같지 않은데요. 본인의 감정인 걸요. 이제 그 감정을 안고 살아갈 방법을 찾아봐야죠.\u0026rdquo;\n6 # 세상에 단일한 진실이란 없다. 저마다 몇 개의 안경 너머로 각자의 삶을 바라보는 다양한 관점이 있을 뿐이다. 남들의 기억과 인식과 가치관을 자기 것으로 삼아야 할 이유는 없다. 사람은 자기 필요에 맞는 진실을 만들어간다. 좋건 나쁘건 본인이 생각하는 자신의 모습과 자신의 스토리에 부합되는 방향으로 친구들과 이야기하면서, 일기를 쓰면서, 심리치료를 받으면서 만들어간다. 그러면서 우리는 과거를 조금씩 되돌아볼 수 있고, 과거가 어떻게 지금의 우리를 만들었는지 차츰 이해할 수 있다. 그리고 마침내는, 지금도 우리를 이리저리 휘두르는 과거의 횡포에 맞서 그 힘을 무력화할 수 있다.\n7 # 30년이 넘는 세월이 흐른 후 존과 함께 다시 찾은 그곳은, 회청색 갈매나무와 가시금작화 수풀 사이로 새로 깔린 판잣길이 모래언덕까지 이어져 있었다. 마침내 깨끗한 모래사장에 파도가 부서지는 해변에 이르자, 나는 워시만의 바닷물에 발을 담갔다. 차갑지만 상쾌했다. 어찌 보면 모질고 변덕스러운 바다였지만 나는 이곳에 오면 늘 기분이 새로웠다. 아이 때도 10대 때도 여름날 저녁이면 아빠와 함께 자주 와서, 바다에서 수영하는 아빠를 지켜보았던 바로 그곳이었다. 그때의 장면들이 새록새록 떠올랐다. \u0026ldquo;아빠가 항상 저 모래언덕에 앉았어.\u0026rdquo; 내가 존에게 외쳤다. \u0026ldquo;아빠가 여기를 정말 좋아했어. 수영을 워낙 잘했거든.\u0026rdquo; 힘차게 바다로 헤엄치던 아빠의 검게 탄 어깨가 떠올랐다. 그때는 아빠와 함께 있으면 무척 안전하게 느껴졌다. 아빠가 너무 좋았다. 잠시 아빠의 모습이 보였다. 아빠는 바다 저쪽, 아빠가 좋아했던 그 자리에 앉아 있었다. 힘찬 모습으로 살아서, 검게 탄 긴 팔을 석양에 번들거리며 나를 향해 흔들고 있었다. 그러고는 다시 물에 들어가더니 거센 물살을 헤치며 나를 향해 헤엄쳐왔다.\n나는 아버지가 돌아가신 후 오랫동안 아버지를 잃었다는 사실을 받아들이지 못했다. 그리고 언제까지나 아버지를 그리워할 것이다. 애통해한다는 것은, 놓아주고 앞으로 나아가는 것이다. 애통해할 수 있게 되면 잃어버린 사람을 그 사람 그대로 기억할 수 있게 된다. 이상화된 성자도, 분노와 실망을 쏟아부을 표적도 아닌, 복잡하고 현실적이면서도 매우 인간적인 존재로. 내가 가진 아빠 사진은 한 장 뿐이다. 내가 집을 떠나 대학에 가기 얼마 전에 찍은 사진이다. 아빠는 구겨진 셔츠 차림으로 서서 한 팔을 엄마 어깨에 두르고 있고, 엄마는 아빠 손을 꼭 잡아 허리에 붙인 모습이다. 나는 아빠 왼쪽으로 살짝 뒤에 서서 해를 쏘아보고 있고, 동생 이언은 우리 앞에 서 있다. 앨런은 아마 카메라를 들고 있었을 것이다. 아빠는 마치 우리가 모르고 있는 비밀을 알고 있기라도 한듯 묘한 미소를 엷게 짓고 있다. 엄마는 방금 전까지 다들 싸우기라도 한 듯 억지스러운 미소를 활짝 짓고 있다. 세월이 흐르면서 사진도 점점 빛이 바래 흑백에 가까워져가고, 내 애통한 마음도 흐릿해져간다. 지금은 알 수 있다. 나라는 사람은 결국 아빠가 아니면 아무것도 아니었다는 것을. 아빠는 말로는 표현하지 않았지만 행동으로 내게 변치 않는 사랑의 힘을 가르쳐주었고, 내가 지금 모습이 될 수 있게 도와주었다.\n8 # 중요한 건 애통한 마음의 변화라고 생각한다. 예컨대 상실의 기억을 떠올릴 때 15년 전이나 지금이나 똑같이 괴롭고 아픔이 생생하다면 진전이 없는 것이다. 감정이 잦아들지 않고 점점 커진다면 그 역시 심각한 신호다. 애도가 제대로 이루어지지 못하면 우울증이 된다. 애통한 마음의 크기를 1에서 10까지의 숫자로 생각해볼 때 그날그날 아주 미미하게라도 줄어들고 있따면, 앞으로 나아가고 있다는 신호다. 조금씩 다시 일상을 마주하고 앞날을 바라보고 있는 것이다. 지나간 일을 조금씩 손에서 놓아가는 것이다.\n불행한 것과 우울한 것. # 2024-12-31 # 1 # \u0026ldquo;기분이 최고로 좋았을 때를 10이라고 하면, 지금 기분은 1에서 10 중 몇 정도인가요?\u0026rdquo; 그녀는 조용히 내 답을 기다렸다.\n\u0026ldquo;6에서 7 정도요.\u0026rdquo;\n정말 답하기 어려운 질문이다. 나는 환자들에게 생각하지 말고 직감적으로 답하라고 요구한다. 하지만 \u0026lsquo;7\u0026rsquo;이란 건 내 솔직한 느낌이었을까, 아니면 일반 환자 대신 상담 시간을 차지한 내 행동을 합리화하려는 의도였을까?\n난 내 우울증의 원인을 오랫동안 탐구했다. 어떤 힘든 일이 닥치면 며칠도 안 되어 극심한 절망에 빠지는 이유가 뭘까. 정신역동치료는 과거의 인간관계가 현재에 미치는 영향을 통찰해보려는 쪽이다. 반면 인지행동치료는 현실을 자신에게 해로운 관점으로 보기 때문에 \u0026lsquo;지금 이곳에서\u0026rsquo; 우울해진다고 보고 그런 관점을 개선하려는 쪽이다.\n모든 역사가 그렇듯, 개인의 역사도 불변의 존재가 아니다. 남에게 이야기하고 반복해 서술하는 과정에서 유기체처럼 변한다. 어느 시점에서건, 내가 \u0026lsquo;진짜\u0026rsquo; 아는 건 그때그때 느끼는 감정뿐이다. 1년 전 느꼈던 감정, 품었던 고민이 아무리 해도 기억나지 않을 때가 있다. 어쩌면 일부러 잊는 건지도 모르겠지만, 지금부터 할 이야기는 지금의 나에 대해 내가 아는 이야기다. 그리고 나와 비슷한 문제를 겪는 사람들에게 도움이 되리라고 생각되는 이야기다. 이 일을 하면서 배웠지만, 의사는 환자가 안고 있는 문제의 \u0026lsquo;이력을 알아내는\u0026rsquo; 데 그치지 말고 환자의 이야기에 귀를 기울여야 한다.\n그는 아버지의 폭력에 몸만 다친 게 아니었다. 10대 시절 우울증을 앓았던 것도, 20대 중반인 지금 기분이 심하게 침체되어 있는 것도 이해가 된다. 그는 성장기의 어려움을 극복하고 좋은 회사에 취직했지만, 어릴 때부터 앓았던 당뇨병이 합병증을 일으키면서 그간 노력해 얻은 것들을 다 잃게 되었다고 느꼈다. 어머니도 당뇨병이 있었다. 리처드는 최근 시력이 나빠졌고, 어린 시절 경험 때문에 우울증에도 대단히 취약해진 상태였다. 물론 충분히 이해는 된다. 그럴 수 있다. 당뇨병처럼 큰 병을 앓는 게 얼마나 힘들지도 짐작이 된다. 하지만 그런 상황이라고 해서 모든 사람들이 다 심각할 정도로 기분이 침체되지는 않는다. 알아서 살 길을 찾아나간다. 리처드는 그러지 못하고 있다.\n의사들이 가끔 하는 실수는, 환자가 현재 처한 상황에 비추어볼 때 기분이 가라앉는 것을 \u0026lsquo;이해할 만하다\u0026rsquo;고 넘겨짚어 버리는 것이다. \u0026ldquo;그런 일이 있으면 누구든 기분이 처지는 게 당연하죠. 저라도 그러겠어요!\u0026rdquo; 이런 식으로 말이다.\n하지만 문제는 그리 간단치 않다. 환자는 우울한 것일 수도 있다. 우울은 불행한 감정과는 다르다. 우울은 불행보다 훨씬 더 깊고 큰 절망감으로, 세상을 보는 눈에 색을 덧입히고 일상생활을 해나가기 어렵게 만든다.\n2 # 출발점으로 돌아왔을 때 나는 엉엉 울고 있었다. 아빠는 먼저 훌쩍 내렸다. 나와 일행이 아닌 척 하는 것 같았다. \u0026lsquo;이 울보 여자애 내 딸 아니야\u0026rsquo; 하고 말하는 듯했다. 어린 나이에도 나는 아빠의 기질을 파악했다. 우리 둘은 여러모로 많이 닮았으면서도 또 달랐다. 나는 쉽게 불안해하고 겁이 많았지만, 아빠는 위험한 상황에서도 힘이 세고 용감했다.\n\u0026ldquo;뭐가 문제야?\u0026rdquo; 아침마다 학교 가기 전에 티셔츠를 몇 번이나 입었다 벗었다 하는 앨런에게 나는 묻곤 했다. 엄마 아빠 둘 다 7시 30분까지 출근해야 해서, 내가 두 남동생을 아침마다 준비시켜야 했다. 나보다 열한 살 어린 막내 이언은 골치를 썩이지 않았다. 알아서 시리얼을 우걱우걱 맛있게 먹었다. 하지만 나의 일곱 살 터울인 앨런은 알 수 없는 무언가로 늘 괴로워했다.\n\u0026ldquo;저리 가! 나 좀 가만 놔둬.\u0026rdquo; 앨런이 소리쳤다.\n\u0026ldquo;왜 그러는 건데.\u0026rdquo; 나는 이유를 말해달라고 구슬렸다.\n\u0026ldquo;주름이 너무 많아.\u0026rdquo; 앨런은 중얼거리거나 울면서 외치곤 했다.\n\u0026ldquo;우리 늦었어.\u0026rdquo;\n\u0026ldquo;상관없어! 나 좀 놔둬.\u0026rdquo;\n동생은 그렇게 옷과 씨름하다가 화를 못 이겨 옷을 갈가리 찢기도 했다. 밤에도 쉽지 않았다. 깜깜한 방에서 침대에 눕지도 않고 몇 시간을 서 있었다. 자기 전에 치러야 하는, 자신도 설명하지 못하는 어떤 복잡한 절차에 문제가 생겼기 때문이었다.\n아빠는 절망감에 빠졌다. \u0026ldquo;앨런, 제발 잠옷 좀 입어, 응?\u0026rdquo;\n\u0026ldquo;싫어.\u0026rdquo;\n\u0026ldquo;여보, 이제 자정이야.\u0026rdquo; 엄마가 문간에 서서 애걸했다.\n\u0026ldquo;그냥 놔둬. 서 있다가 알아서 불 끄고 자라고 해.\u0026rdquo;\n어슴푸레한 어둠 속에서, 동생은 자기 침대 옆에 돌처럼 꼼짝 않고 서 있었다. 그러다 문이 꽝 닫혔고, 방 안에서는 흐느끼는 울음소리만 흘러나왔다. 결국 아빠도 포기하고, 실망과 분노로 피폐해진 채 방에 들어가 잠이 들었다. 앨런은 여러 해가 지나서야 비로소 강박 장애 진단을 받았다.\n그때는 병명을 몰랐지만, 아빠는 사회공포증이 점점 심해졌다. 구체적으로는 공공장소에서 남들과 대화하는 것을 두려워했다. 그래서 엄마는 아빠가 살 만한 옷이나 신발 따위를 집에 가져가서 먼저 좀 입혀보겠다고 가게 주인에게 사정해야 했다. 심지어 아빠는 도서관에 가서 책을 빌려오지도 못할 정도로 불안이 심했다. 술을 마시면 불안이 좀 가라앉긴 했지만 아빠는 술을 잘 마시지 않았다. 대신 담배를 하루에 40개비까지 피웠다.\n부모님은 앨런과 함께 가족 치료를 받으러 다녔다. 아빠는 의사가 자기를 빤히 쳐다보기만 하고 아무 설명도 해주지 않는다며 질색했다. \u0026ldquo;뭘 하겠다는 건지 도무지 알 수가 없어. 죄책감만 잔뜩 주고.\u0026rdquo; 의사가 나도 함께 오라고 했지만 나는 거부했다. 나와는 관계없는 일이라고 생각하려 했다.. 난 학교 공부에 너무 바빴다.\n당시엔 정신질환의 생물학적 근거라는 것이 거의 알려져 있지 않았다. 뇌의 배선 결함이 아닌 양육의 문제로 보는 것이 보통이었다. 지금은 유전과 양육 어느 한 쪽의 문제라기보다 둘이 복잡하게 얽힌 경우가 많다고 알려져 있다. 나는 동생 앨런이 불안 장애 성향을 부모 양쪽에게서 물려받았을 것으로 짐작한다. 동생은 난산 끝에 태어났다. 생사의 갈림길을 걷던 몇 분 동안 심장박동이 잡히지 않았는데, 그때 경미한 저산소성 뇌 손상이 일어났을 가능성도 있다. 크면서는 엄마 아빠를 애먹여 두 사람 사이에 긴장을 조성했고, 그로 인해 자신도 더 불안해졌다. 이는 옷 입기나 취침과 관련된 이상행동과 분노와 반항, 또다시 이상행동의 증가로 이어지는 악순환을 낳았다.\n나는 유전적으로 신경증적 성향을 타고나기도 했지만, 안전하고 정서적으로 안정된 성장 터전을 가족에게서 제공받지 못했다는 사실이 늘 괴로웠다. 아이가 자신 있게 세상에 부딪칠 줄 아는 사람으로 커나가기 어려운 환경이었다. 엄마는 불안이 있음에도 천성적으로 매사에 태도가 당당한 사람이었지만, 나는 아빠의 과묵한 내향성을 더 많이 물려받은 것 같다. 어릴 때 엄마보다 아빠와 훨씬 친하기도 했다. 그러나 그 애착은 10대 시절 점점 불안과 두려움으로 바뀌어갔다. 그러한 변화는 인생의 시련을 버티는 내 능력의 한계를 더욱 낮추는 구실을 했다.\n3 # 나는 모종의 이유로 인해 점점 취약성이 높아졌다. 마음에 안드는 옷을 입고 외출하는 것, 책상에서 볼펜을 떨어뜨려서 허리를 숙여야 하는 것, 침대에 누워서 과자를 먹고 봉지를 휴지통에 버리기 위해 팔을 뻗는 것, 문 밖의 누군가의 발소리를 듣는 것. 생각하기에 따라 큰 불행이 아닐 수도 있는 것들이 나에겐 견디기 힘든 큰 불행처럼 느껴졌다.\n어제는 밤에 불행해서 죽고싶어서 울었다. 그 이유는 엄마 아빠와 평생 함께 있고 싶은데 미래의 어느 날은 죽을 것임을 떠올렸기 때문이다. 한참 울은 뒤에 나는 한 가지 처방을 내리고 마음이 편안해져서 잠이 들었다. 내가 내린 처방은 엄마 아빠가 죽을 때 같이 죽겠다는 계획을 세우는 것이었다. 다음 날 아침. 언제 어린애처럼 울었냐는듯이 나는 짐을 챙겨 할일을 하러 집을 나섰다. 출근 전 카페에 와서 읽고 싶던 책도 읽고 맛있는 커피도 마셨다. 기분이 최고로 좋았을 때를 10이라고 하면, 지금 기분은 1에서 10 중 몇 정도인가요? 같은 질문에 7 같다고 답변했다. 그리고 사실 알고있다. 나는 엄마 아빠가 죽는다고 해서 죽지 못할 것이다. 그리고 어제 죽고싶어 울었던 것은 엄마 아빠가 나보다 일찍 죽기 때문이 아니었다. 물론 큰 불행이지만 그 사건이 갖는 \u0026lsquo;시간\u0026rsquo;이라는 특성 때문에 지금의 나에겐 불행의 본질적 크기에 비해 그만한 영향을 주지 못한다. 사실 어제 불행해서 죽고싶어서 울었던 이유는 미팅에서 부정적인 피드백을 받았기 때문이다. 의아한 점은 그 피드백을 온전히 이해했으며 더 안좋은 결과가 나타날 수도 있던 상황을 성공적으로 회피하기까지 했다는 것이다. 피드백 자체는 아무런 문제가 없었지만, 작은 불행 하나가 내 안의 기폭제를 밀었고 벼랑을 구르며 점점 커졌으며 우울한 감정이 발생했다. 만약 덧입혀질 불행이 없다면 그대로 축적되어 다음 발생할 우울을 조금 당길 예정이었으나, 어제는 먼 미래의 불행이 떠오름에 따라 감정이 덧입혀져 발현될 수 있었으며 그렇기에 나는 죽을 듯이 울었던 것이다.\n결핍과 그에 대한 애도의 기간(라디오스타 김영철) # 2024-12-31 # 1 # https://youtu.be/Qa8zJkZlDF0 은 참 생각지도 못한 순간에, 생각지 못한 계기로 끝나네\n2 # 겨울 아침의 어스름 속에, 아빠 옆에 있는 빛바랜 파란색 소파에 놓인 무언가가 보인다. 엄마가 출근하기 전에 꺼내놓고 간 아빠 웃옷과 바지다. 아빠는 이상한 고집이 있다. 아무리 몸이 아파도 의사를 만나려면 꼭 옷을 제대로 챙겨 입고 가야 한다. 엄마가 출근하러 나갈 때까지만 해도 아빠는 침대에 누워 있었다. 지난주 내내 거의 누워 있었다. 어깨 뒤쪽에 통증이 워낙 심해 대로 숨 쉬기가 어려웠다. 하지만 의사에게는 그런 말을 하지 않았다. 의사는 여기저기 눌러보더니 심장병 이력이 있는 걸 알면서도 디스크일 거라고 했다. 의사가 쉬라고 해서 아빠는 일주일간 쉬었다. 그러다가 오늘은 겨우 일어나 병원에 진단서를 떼러 갈 참이다. 옷을 다 입고 나니, 마지막 차 한 잔을 탈 주전자 물이 끓고 있다.\n벽난로 앞 바닥에 쓰러져 있는 아빠를 사람들이 발견했을 때, 주전자 물은 이미 다 졸아 없이진 지 오래였다.\n아버지가 돌아가신 후 나는 처음엔 끔찍한 죄책감에 휩싸였다. 아버지에게 가봤어야 했다. 그랬다면 아버지를 살릴 수 있었다. 아버지는 옷을 입고 병원에 갈 준비를 하다가 심장마비로 쓰러졌다. 나는 의사가 되려고 5년을 공부했지만 결국 내 아버지도 살리지 못했다. 지금까지 공부한 게 다 무슨 소용인가? 나라는 인간은 무슨 쓸모가 있나? 그러나 끔찍한 죄책감도 가슴 찢어지는 애통함도, 그리 오래가지 않았다. 내가 떨쳐버렸다. 가슴 깊숙이 어딘가서 꾹꾹 눌러 담고 묻어버렸다. 나는 제대로 애통해하지 못했다. 그것도 아주 오랫동안.\n나는 아버지가 돌아가신 후 오랫동안 아버지를 잃었다는 사실을 받아들이지 못했다. 그리고 언제까지나 아버지를 그리워할 것이다. 애통해한다는 것은, 놓아주고 앞으로 나아가는 것이다. 애통해할 수 있게 되면 잃어버린 사람을 그 사람 그대로 기억할 수 있게 된다. 이상화된 성자도, 분노와 실망을 쏟아부을 표적도 아닌, 복잡하고 현실적이면서 매우 인간적인 존재로.\n내가 가진 아빠 사진은 한 장뿐이다. 내가 집을 떠나 대학에 가기 얼마 전에 찍은 사진이다. 아빠는 구겨진 셔츠 차림으로 서서 한 팔을 엄마 어깨에 두르고 있고, 엄마는 아빠 손을 꼭 잡아 허리에 붙인 모습니다. 나는 아빠 왼쪽으로 살짝 뒤에 서서 해를 쏘아보고 있고, 동생 이언은 우리 앞에 서 있다. 앨런은 아마 카메라를 들고 있었을 것이다. 아빠는 마치 우리가 모르고 있는 비밀을 알고 있기라도 한 듯 묘한 미소를 엷게 짓고 있다. 엄마는 방금 전까지 다들 싸우기라도 한 듯 억지스러운 미소를 활짝 짓고 있다. 세월이 흐르면서 사진도 점점 빛이 바래 흑백에 가까워져가고, 내 애통한 마음도 흐릿해져간다. 지금은 알 수 있다. 나라는 사람은 결국 아빠가 아니면 아무것도 아니었다는 것을. 아빠는 말로 표현하지 않았지만 행동으로 내게 변치 않는 사랑의 힘을 가르쳐주었고, 내가 지금 모습이 될 수 있게 도와주었다.\n중요한 건 애통한 마음의 변화라고 생각한다. 예컨대 상실의 기억을 떠올릴 때 15년 전이나 지금이나 똑같이 괴롭고 아픔이 생생하다면 진전이 없는 것이다. 감정이 잦아들지 않고 점점 커진다면 그 역시 심각한 신호다. 애도가 제대로 이루어지지 못하면 우울증이 된다. 애통한 마음의 크기를 1에서 10까지의 숫자로 생각해볼 때 그날그날 아주 미미하게라도 줄어들고 있다면, 앞으로 나아가고 있다는 신호다. 조금씩 다시 일상을 마주하고 앞날을 바라보고 있는 것이다. 지나간 일을 조금씩 손에서 놓아가는 것이다.\n3 # 내가 가장 좋아하는 장이 15장 \u0026lt;애도\u0026gt; 였는데 그래서인지 김영철 토크 영상을 보고 눈물이 많이 났다\n"},{"id":26,"href":"/docs/hobby/book/book3/","title":"책","section":"책","content":" 지적 생활의 즐거움 | P.G.해머튼 # 목록 # [북마크] 결혼과 행복\n결혼과 행복 # 2024-12-31 # 1 # 결혼은 안해도 되는데 한 사람들이 더 행복함.\n사랑이 있든 없든 간에 정신적, 육체적으로 한 명의 남편 혹은 부인에게 초점을 맞추고 가족, 친구, 이웃, 나아가 잠깐 만나는 캐주얼한 섹스 파트너와 전남편 혹은 전 부인까지 양파 껍질처럼 차곡차곡 쌓인 울타리를 만듦으로써 우리 삶은 안정되고 행복해질 수 있다.\n2 # https://youtu.be/vFN_DoqWAL4 우리는 종종 너무나 단순한 걸 놓치고 허우적대곤 하지만요.\n행복한 인생을 살고 싶다면, 성공한 인생을 살고 싶다면, 공략법은 정말로 \u0026lsquo;유일\u0026rsquo;합니다.\n정말 열심히 운동하고 정말 열심히 일하고 정말 열심히 배워서..\n연인과, 친구와, 가족과, 동료를 정말 열심히..\n사랑하는 거죠.\n3 # 내적인 건강만이 열풍처럼 불어 닥친 신경쇠약의 유행으로부터 나를 지켜줄 것입니다. 이 질환은 처음 시작되었던 때와 마찬가지로 사라질 때도 순식간일 것입니다.\n먼저 세 가지 육체적 수단은 충분한 수면과 신선한 공기, 적절한 운동, 그리고 알콜과 육식의 섭취를 줄이라는 것입니다. 두 가지 정신적 수단은 보다 지적인 향상을 바라는 나에 대한 믿음과 지성에 대한 사랑입니다. 이 다섯 가지 외엔 신경쇠약증을 치료할 만한 다른 수단은 없습니다.\n출처\nSKEPTIC Korea Vol.28 책- 지적 생활의 즐거움 "},{"id":27,"href":"/docs/hobby/book/book4/","title":"책","section":"책","content":" 자신의 존재에 대해 사과하지 말 것 | 카밀라 팡 # 최정문 북클럽 2023년 07월 도서여서 읽어봤다! 저자가 생물정보학 과학자이다.\n목록 # [북마크] 깔끔한 상자 모서리는 든든하지만 환상일 뿐이다.\n[북마크] 모든 것을 가질 수는 없을까? 현재에도 행복하고 미래도 이상적으로 계획할 수 있을까?\n깔끔한 상자 모서리는 든든하지만 환상일 뿐이다. # 2024-12-31 # 1 # 더 나은 의사 결정을 하기 위해, 정보에 접근하고 해석하는 방식을 더 체계화할 필요는 없다. 머신러닝이 우리를 그런 방향으로 이끌 것이라고 예상하게 되지만 사실 그 반대다. 알고리즘은 복잡성과 무작위성 속에서 역할을 수행하며, 환경의 변화에 효율적으로 반응하는 능력이 탁월하다. 단순한 패턴을 추구하는 경향은 아이러니하게도 인간의 사고방식에서 나타난다.\n기계는 복잡한 현실을 전체적인 데이터 집합의 또 다른 일부로 여겨 단순하게 접근하는 데 반해, 정작 그로부터 도피하는 것은 우리 인간이다. 단순하거나 직접적이지 않은 대상을 더 복잡한 방식으로 사고하는 통찰력과 자발성이 인간에게 필요한 것이다.\n2 # 비지도 학습 머신러닝 중 클러스터링은 데이터를 A, B, C로 분류하려는 선입견 없이 \u0026ldquo;공통점\u0026quot;을 기준으로 분류한다. 미리 정한 결론에 꿰맞추기보다 데이터 자체가 말해주기를 바랄 때 특히 유용하다.\n3 # 상자는 유용한 증거와 대안을 모아 정돈된 형태로 만든 것이다. 상자 속 사고방식은 깔끔하기 때문에 선택을 분명하게 인지할 수 있다. 이에 반해 나무는 유기적으로 자란다. 나무는 우리를 사방으로 이끌 수 있고, 그중 상당수는 의사 결정의 막다른 길이나 완벽한 미궁으로 밝혀진다. 그러면 어느 쪽이 나을까? 상자, 아니면 나무? 정답은 \u0026lsquo;둘 다 필요하다\u0026rsquo;이다.\n4 # 상자 속에서 생각하는 사람이었던 나는 내 주변 세상과 사람들에 관해 모든 것을 알고 싶었고, 내가 더 많은 데이터를 모을수록 더 나은 결정을 내릴 수 있다고 스스로를 안심시켰다. 하지만 모은 정보를 효과적으로 처리할 방법이 없었기에 쓸모없는 잡동사니로 가득 찬 상자만 점점 늘어났다. 나는 이 과정 때문에 거의 움직일 수 없게 되었고, 때로는 몸을 어느 각도로 유지해야 하는지에 집중하느라 침대에서 벗어날 때조차 고군분투 해야했다.\n물론 분류는 강력한 도구이며 어떤 옷을 입을지, 무슨 영화를 볼지 같은 문제에서 즉각적으로 결정하는 데 유용하다. 그러나 정보를 처리하고 해석하며, 미래를 알기 위해 과거의 증거를 이용해서 까다로운 결정을 내리는 능력을 심각하게 억압한다.\n5 # 우리는 모두 모순과 불가측성, 무작위성을 헤쳐나간다. 이들은 삶을 현실로 만드는 요소다. 우리는 둘 이상의 선택지 중에서 골라야 하며, 고려해야 할 증거들은 파일로 정리되어있지 않다. 깔끔한 상자 모서리는 든든하지만 환상일 뿐이다. 현실의 그 무엇도 그렇게 딱 떨어지지 않기 때문이다. 상자는 고정되어 있고 휘어지지도 않지만, 우리의 삶은 역동적이며 계속 변한다.\n6 # 좋은 의사 결정은 보통 확실성을 가정하는 데서 나오지 않으며 혼돈, 다른 말로는 증거라는 것에서 나온다. 의사 결정을 둘러싼 데이터 집합을 충분히 깊이 탐색하지 않고 다양한 가능성과 결과를 고려하지 않는다면, 그리고 다양한 의사 결정으로 이어지는 나뭇가지가 일제히 닫히거나 열리지 않는다면 사실상 눈가리개를 한 채 선택하는 셈이다. 우리는 미래를 예측할 수 없지만, 데이터 포인트를 충분히 수집하고 가능성이 큰 계획을 구상하면 대부분 상황에서 제대로 된 지도를 손에 쥘 수 있다. 관행이나 미리 정해놓은 결과가 아니라 증거가 의사결정을 이끌 것이고, 다양한 결과와 각 결과가 미치는 영향을 스스로 고려할 수 있을 것이다.\n모든 것을 가질 수는 없을까? 현재에도 행복하고 미래도 이상적으로 계획할 수 있을까? # 2024-12-31 # 1 # 시간과 공간은 고정된 것도 아니고, 무한한 것도 아니며, 서로 독립적인 것도 아니다. 우주를 이해하려면 이들을 합쳐서 4차원, 즉 공간을 나타내는 세 축과 시간을 나타내는 한 축으로 시각화해야 한다.\n호킹 박사는 \u0026lsquo;시공(spacetime)\u0026rsquo; 이라는 개념을 시각화할 때 광원뿔(light cone) 이미지를 활용해 과거와 미래의 사건이 어떻게 연결되는지 보여주었다. 빛은 발산될 때 연못의 물결처럼 퍼져나가면서 원뿔 형태를 형성한다. 빛의 속도보다 빠른 것은 없으므로 (과거에) 기여하거나 (미래에서) 시작된 현재 순간의 모든 사건은 이 원뿔 안에서 빛의 속도나 그보다 느린 속도로 일어나야만 한다.\n호킹은 원뿔 밖에서 일어나는 사건은 다른 곳에 있다고 말한다. 따라서 그 사건들은 현재를 바꿀 수 없고 현재에 의해 바뀔 수도 없다. 이를 설명하기 위해 호킹은 어느 날 갑자기 태양이 죽는다는 시나리오를 얘기했다. 이 사건은 과거의 광원뿔에서 일어나지 않았고, 태양에서 지구까지 빛이 도착하려면 8분이 걸리기 때문에 현재에 영향을 미치지 않는다. 오직 이 지점에서만, 미래의 광원뿔까지의 어느 정도 거리에서만 이 사건이 우리의 현실과 교차하고 현실을 변화시킨다. 우리는 사건이 실제로 일어났을 때가 아니라 우리으 ㅣ의식을 가로지르기 시작한 순간에 그 사실을 인정한다.\n우리는 모두 우리에게 일어난 일을 통해 배우고 다음에 일어날 일을 바꿀 방법을 찾는다. 우리는 확실성을 원하지만 기회도 원한다. 미래가 안전하다고 느끼기를 바라지만 동시에 가능성에 고무되기를 바란다. 우리가 영향력을 행사하지 못하는 것이 있음을 인정하면서, 그럼에도 우리가 바꿀 수 있는 것이 무엇인지 알고 싶어 한다. 우리는 목표를 설정하고, 판단에 따른 결정을 내리고, 우선순위를 미세하게 조정하는 더 나은 방법을 바란다. 미래를 효율적으로 계획할 도구뿐만 아니라 현재를 살아가는 방법도 필요하다.\n다행히 이런 질문은 잠들지 못해 깨어있는 밤이나, 올해 목표와 다짐을 적는 새해 아침에만 고민하는 질문이 아니다. 이론물리학은 우리를 위해 어려운 부분을 상당히 많이 해결했다. 이론물리학은 삶의 사건을 시각화해서 앞으로 나아갈 길을 계획하고 원하는 결과를 얻는 가능성을 극대화하는 방법을 알려준다. 심지어 더 좋은 점은 내가 여덟 살의 나를 안심시켰듯이, 이론물리학이 알려주는 방법은 이진법 모델과 냉혹한 광원뿔의 경계선에 의존하지 않는다는 것이다. 이 장에서 소개할 개념인 네트워크이론, 토폴로지, 경사하강법을 활용하면 인간만큼이나 유연하고 변하기 쉬운 삶을 계획할 수 있다. 그리고 그에 따라 목표를 설정할 수 있다.\n아마도 삶의 계획과 목표를 세울 때 마주하는 가장 중요한 질문은 \u0026lsquo;무엇에 집중할까?\u0026lsquo;일 것이다. 현재와 미래, 어느 쪽에 집중해야 할까? 지금 느낄 만족감인가, 아니면 뒤로 미룰 기쁨인가? 끊임없이 장기 계획을 세우느라 현재의 삶을 즐기지 못하는가? 아니면 현재에 너무 집중한 나머지 다가올 미래를 제대로 준비하지 못하는가?\n모든 것을 가질 수는 없을까? 현재에도 행복하고 미래도 이상적으로 계획할 수 있을까?\n이 딜레마를 두고 너무 고심하느라 걱정한 적이 있다면, 양자역학이 당신을 안심시켜줄 것이다. 양자역학은 우리가 아는 한 가장 작은 입자인 아원자입자(원자보다 더 작은 입자)를 연구하는 이론물리학의 한 분야다. 하이젠베르크의 불확정성 원리는 아원자입자의 위치를 더 정확하게 측정할수록 입자의 운동량을 측정하기는 더 어려워진다고 우리에게 말한다. 역의 명제도 똑같이 적용된다. 다시 말하면 물리학은 우리에게 위치와 운동 속도를 동시에 정확하게 측정할 수 없다고 말해준다. 한쪽에 집중할수록 다른 쪽의 측정은 부정확해진다.\n어디서 들어본 것 같은가? 하이젠베르크는 양자입자에 관해 썼겠지만, 같은 원리가 거시 세계인 우리의 일상에도 적용되는 듯하다. 정밀 측정 장비에도 한계가 있듯이, 집중하고 우선순위를 매기는 우리의 능력도 마찬가지다. 훌륭한 파티를 주최하는 동시에 파티를 즐길 수는 없다. 파티에 대해 고민하든지 파티를 즐기든지, 재미있는 시간을 보내든지 다른 사람은 어떤지 걱정하든지 둘 중 하나다. 하나를 하면 다른 하나를 하는 능력이 억제된다. 특히 나처럼 \u0026lsquo;재미있게 노는 법\u0026rsquo;을 준비하려고 구글에 검색해야 한다몀ㄴ 말이다.\n이는 성인의 딜레마로, 우리는 끊임없이 모순되는 두 개의 욕구를 인식한다. 현재를 즐기거나, 미래를 계획하거나. 동시에 두 가지 모두 챙기려는 욕망은 둘 중 하나를 적절하게 성취할 능력을 조금씩 갉아먹는다. 우리는 앞으로 무엇이 다가올지 걱정하느라 현재를 즐기지 못하거나, 너무나 즐겁게 지내느라 미래를 대비할 여유를 갖지 못한다. 정보 중심의 연구에 기반을 둔 삶을 즐기는 나조차, 그저 배움을 멈추고 세계에 무지한 채 행복에 젖어 진실로 순간을 살아가는 아이로 되돌아가고 싶을 때가 있다.\n아빠와 부엌에서 생선을 요리하거나 정원에서 놀고, 마음 가는 대로 수많은 모래성을 만들고, 멋지고 다채로운 색상의 수영복을 입은 채 루 해변의 \u0026lsquo;밀리의 바위\u0026rsquo;에 앉아있기도 했다. 일곱 살에는 체크무늬를 좋아했고, 엄마의 푸른색 덴마크산 그릇으로 영화의 한 장면을 재현하거나 나를 두근거리게 하는 남성과의 미래를 상상하는 것도 좋아했다. 물론 그 남성은 스티븐 호킹이었다. 모든 기억의 색, 맛, 냄새가 20년이 지난 지금도 생생하게 내 마음에 남아있다. 타인이 어떻게 생각하든 개의치 않고 무엇이든 내가 원하는 것을 했던 시절, 즐거운 삶이었다.\n온갖 취미가 뒤섞인 이 주머니는 무작위였을 수도 있고 일정한 형태가 없어 보이기도 하지만, 모두 과거의 광원뿔을 형성하는 일부로서 지금 여기까지 나를 이끌어왔다. 내 흥미와 독자성, 개성을 강화하는 경험의 축적이다. 이 기억들은 대세에서 나만 소외되리라는 두려움이나 다음에 무슨 일이 일어날지에 대한 걱정이 없었던 때를 상기시킨다.\n균형을 잡으려 노력하던 나는 시간과 공간을 이동하는 파동을 연구하는 또 다른 양자역학 분야에서 영감을 받았다. 이는 전통적인 하이젠베르크 문제, 즉 특정 순간에는 파동의 운동량이나 파동의 위치 둘 중 하나만 정확하게 기술할 수 있다는 문제를 가리킨다. 양손 손가락을 동시에 마주 대려 해보라. 자꾸 어긋나서 쉽지 않을 것이다. 이 문제를 해결하기 위해 우리는 확률파동(wave packet)이라는 것을 만들었다. 확률파동은 수많은 다양한 파동을 합성해서 시각화한 것으로, 과학자들은 파동들이 나타내는 총체적 행동을 연구한다. 하나의 파동은 분명하게 정의하기 힘들지만, 여러 파동 \u0026lsquo;뭉치(packet)\u0026lsquo;은 더 효율적으로 연구할 수 있다. 목표를 설정하고 삶의 계획을 세우는 일도 크게 다르지 않다. 따로 떼어놓고 보면 하나하나의 결정이나 목표가 올바른지 알기 힘들다. 이럴 때는 큰 그림과 맥락, 즉 전체 \u0026lsquo;뭉치\u0026rsquo;를 살펴야 지금 이 순간뿐만 아니라 미래 전체의 최상의 결과와 비교해서 우리가 가능한 최고의 선택을 하는지 알 수 있다.\n가상의 확률파동을 만들면서 나는 삶을 숙고하는 두 가지 사고방식이 이루는 또 다른 균형에 부딪혀야 했다. 모멘텀 사고(momentom thinking)는 시간에 따라 살면서 한 시간에서 다른 시간으로 옮겨 가도록 하며, 이 사고에 따르면 행복은 우리가 성취하고 계획한 것으로 정의된다(즉, 책임이라는 어른의 세계다). 반면, 포지션 사고(position thinking)는 현재를 살면서 현재 순간과 현재가 주는 느낌에 사로잡혀 다른 모든 것을 차단하고 그저 존재하게 하는데, 여기에는 죄책감까지 따른다. 포지션 사고를 받아들이기는 매우 힘든데, 그것이 \u0026lsquo;제대로 된 어른\u0026rsquo;이 되려면 해야 한다고 들어왔던 것과 완전히 어긋나기 때문이다. 그러나 이 역시도 꼭 필요하다. 가만히 서 있다고 해서 멈춰 있다는 뜻은 아니다. 오히려 더 창의적이고, 현재 거치는 과정을 재평가하며, 감각의 힘을 통해 살아가고, 미래를 위해 더 많은 가능성을 탐색한다.\n다음에 무엇을 할지 집착하고 거의 모든 삶의 순간에 끼어들며 현재 이 순간의 즐거움을 부정하는 모멘텀 사고의 연결 고리를 끊을 방법이 필요했다. 나는 명확한 미래에 대하 ㄴ끊임없는 욕구를 희생하지 않으면서도 순간을 살아가는 능력을 회복하고 싶었다. 그래서 2013년, 변화가 사회적으로 수용되는 시기인 사순절(부활절 전 40일 동안의 기간. 단식을 하기도 한다) 직전에 특별한 팬케이크 한 접시를 먹으며 실험을 개시했다. 완벽하고 엄격하게 해야 할 일을 확인하고 모든 우선 사항을 처리했다. 나머지 절반은 포지션 사고를 하며 살았다. 모든 순간을 즐기고 미래에 관한 생각은 전혀 하지 않았다.\n이제 당신은 아마 이 계획이 잘되지 않았으리라고 짐작할 만큼은 나를 잘 알 것이다*. 지금의 나를 만든, 지극히 중요하지만 실패한 또 하나의 실험이었다. 실험하면서도 현재의 즐거움이든 미래의 명확성이든, 실험을 침식하는 무엇인가를 놓치고 있다는 생각을 멈출 수 없었다. 파티를 열고도 파티가 끝난 후 해야 할 설거지 생각을 멈출 수 없었다. 나는 과정을 관찰하는 것만으로도 관찰자가 근본적으로 결과에 영향을 미치고 결과를 바꿀 수 있다는 또 다른 양자역학 교리, 즉 관찰자 효과의 희생자가 되었던 것이다. 이를 설명할 때 가장 많이 드는 예시로는 현미경으로 전자를 관찰하는 사례가 있다. 관찰자가 광자를 투사하는 데 의존하면 이 행위가 광자의 운동 방향을 바꿀 것이다. 이처럼 내가 내 실험을 관찰하는 행위는 당연히 결과를 왜곡했다. 나는 무엇을 빠뜨렸는지 생각하느라 너무 바빠서 그 순간의 나를 즐길 수 없었다.\n실패한 실험 덕분에 나는 포지션 사고와 모멘텀 사고, 현재와 미래 사이의 어디쯤에서 타협할 수 있었다. 평범한 날의 각기 다른 순간에, 나는 바로 그 특정 순간에 내게 가장 필요한 사고로 전환되기를 바라면서 두 사고 사이를 반복해서 왔다 갔다 할 것이다. 나는 지금 당장 모든 것을 원하며 시간이라는 개념 자체가 없는 ADHD와 싸우면서, 현재를 사는 것과 미래를 계획하는 것 사이에서 적당히 춤출 것이다. 불확정성의 원리를 알기만 해도 올바른 균형을 이루는 데 도움이 된다. 내가 발견했듯이 이 둘을 완벽하게 구분하기란 불가능하지만, 그저 이 둘이 양립할 수 없다는 사실을 수용하는 것만으로도 자유로워질 수 있다. 지금 하지 않는 일을 할 시간이 나중에 있을 것이며, 오후에 햇볕을 쬐면서, 혹은 모두가 밖에서 즐기는 동안 안에서 계획을 세우면서 죄책감을 느끼지 않아야 한다는 점을 깨달으면, 우리가 하지 않는 일에 대한 걱정을 덜 수 있다.\n그러나 현재를 사는 것과 미래를 계획하는 것이 다르다는 사실을 인식하고 두 사고방식이 정확히 맞물리게 노력하는 것만으로는 충분하지 않다. 현재와 미래가 어떻게 연결되는지 시각화할 방법도 필요하다. 그러면 목표를 설정하는 방법을 명확하게 선택하고 우리의 여행 속도에 안심할 수 있을 것이다. 바로 여기서, 내 삶에서 가장 신뢰하는 동맹인 네트워크이론이 진가를 발휘한다.\n*사실 저자를 이해한 것이 아님. 내게도 계획은 항상 어그러지는 쪽이었다. a와 b중 a 로 방향을 틀자마자 세상은 b 방향으로 휘어진다. 왜일까? a를 선택하자마자 갑자기 세상에서 a에 대한 반례가 속출하고 다시 양 갈래 길로 돌아오게 된다. 관찰자 효과였을수도 있겠다는 생각이 드네..\n​\n2 # \u0026lt;짧고 쉽게 쓴 \u0026lsquo;시간의 역사\u0026rsquo;\u0026gt;를 읽은 후, 나는 광원뿔의 고정된 경계선보다 내 요구를 더 잘 충족해줄 예측 모델을 찾아 헤맸다. 나는 전통적인 인간의 모순, 즉 확실성에 대한 욕구와 정해진 한계에 대한 좌절감의 모순에 사로잡혔다. 다음에 무슨 일이 일어날지 모르는 것을 제외하면 내게 주어진 계획의 한계만큼 나를 놀라게 하는 것은 없다. 이런 두꺼운 직선을 필요에 따라 구부리고 주변을 탐색할 구불구불한 선으로 바꾸려면 유연성이 필요하다.\n나는 집을 나서는 데만 다섯 시간이 걸리는 끝없는 준비의 필요성과, 오랜 시간 신중하게 생각해 온 것을 극심한 조바심이 폭발하는 순간 모두 파기해버리는 성향, 두 가지 픅면 모두를 고려한 계획법이 필요했다. 이런 성향은 일종의 심리적인 뇌 정지 상태로, 오늘 하루가 레몬 셔벗과 비슷할 것으로 생각하는 순간, 바닐라 아이스크림과 더 비슷해지는 것과 같다. 현재와 미래를 조화시키려는 나의 하이젠베르크식 전투는, ADHD의 시간 왜곡과 나를 계속 바닥으로 짓누르는 정신 가속기 덕분에 더 치열해진다.\n이 모든 것을 처리하는 데 네트워크이론이 나의 구원자가 되었다. 이 이론은 상당히 단순한 개념이다. 연결된 대상을 그래프로 나타내고, 총체적으로 형성되는 네트워크를 시각화하며, 이런 연결성이 우리에게 알려주는 것이 무엇인지 연구한다. 네트워크이론과 그래프 이로닝라는 연관된 기술을 이용해서, 우리는 복잡하고 밀접하며 동적인 계를 분석할 수 있다.\n네트워크는 대상이나 사람들이 연결된 연속체다. 당신과 친구, 이웃은 여러 사회적 네트워크로 연결되어 있다. 런던 지하철은 서로 다른 노선으로 연결된 정거장 네트워크다. 토스터 플러그 속에 든 전기회로도 네트워크다. 와이파이와 무선 근거리통신망 일부에 연결된 채 여러분 옆에 놓여 있을 스마트폰은 아마 현재 네트워크의 일부일 것이다. 인터넷은 그 자체가 물리적으로나 무선으로 연결된 컴퓨터들의 메가 네트워크로, 그를 통해 방대한 양의 자료가 움직인다.\n물질세계에서 디지털 세계까지, 사회에서 과학까지, 네트워크는 어디에나 있다. 네트워크는 무형이지만 분명히 실재하는 구조이며, 우리가 수십 년에 걸쳐 경력을 쌓는 과정부터 지금 우리가 인터넷에 연결되는 방법까지, 모든 것에 영향을 미친다.\n네트워크는 장기간 및 단기간의 삶을 계획하고 시각화하는 이상적인 방법을 제공하기도 한다. 우리는 너무나 많은 것에 영향받으며 사방으로 밀고 밀리므로, 미리 계획을 세우는 투두 리스트보다 더 복잡하고 반복적이며 적용하기 쉬운 모델이 필요하다. 네트워크이론이 바로 이것을 제공하며, 특히 토폴로지는 네트워크 구성 요소인 노드(node, 컴퓨터과학의 기초 단위. 보통 네트워크에 연결된 하나의 기기를 뜻한다)가 연결되는 방식과 형성되는 구조를 알려준다. 토폴로지(네트워크의 요소들을 물리적으로 연결하는 방식)는 경직된 직선을 유동성 있는 가능성의 네트워크로 바꿔준다. 어둠 속에 감춰진 것을 밝은 곳으로 끌어내고, 정점에 이른 내 불안을 느슨하게 풀어준다. 한때는 유용했던 원리가 더는 쓸모없을 때나, 싹트는 생각이 이제 번성할 준비가 되었을 때를 알아차리게 돕기도 한다.\n토폴로지의 본질은 매우 중요하다. 여섯 개의 단추로 패턴을 만들 때, 당신은 선이나 원, V자를 만들 수 있다. 토폴로지는 네트워크의 기능, 즉 역량과 한계를 결정한다. 우리가 살면서 의사 결정을 하고 우선순위를 설정할 때도 똑같은 일을 한다. 즉, 단기간 및 장기간의 결과를 결정할 유용한 증거와 선택을 패턴으로 배열한다.\n미래의 삶을 하나의 거대한 네트워크로 생각해보면 이 네트워크의 노드는 사람부터 희망, 두려움, 목표까지, 무엇이든 될 수 있다. 이것은 내가 발견한 계획법 중에서 너무 단순하지도, 불편할 정도로 제한적이지도 않은 최고의 방법이다. 역동적으로 당신의 환경이 그렇듯 적응력이 있어서 유용하다. 게다가 무엇이 정말 중요하고 중요하지 않은지 알 수 있도록 도와주므로 명확하다. 또 연결성에 초점을 맞추므로, 연결된 노드를 확인하여 어떤 노드가 영향을 주고받는지 살피며 특정 경로가 어디로 이어질지 알려준다.\n네트워크는 호킹이 알려준 대로 시간과 공간의 맥락에서 광원뿔의 궤도에 한정되지 않고 생각하게 해준다. 또 우리가 시간과 공간이라는 이중 캔버스에서 사람, 특정 목표, 삶의 단계 사이의 근접성과 거리를 탐색하게 돕는다. 어떤 사건이 일어나야 하는지, 그 사건이 일어나게 하려면 언제 어디에 있어야 하는지 알려준다. 시간이 지나면서 나는 호킹의 다이어그램에 선이 존재하는 이유를 깨달았다. 소음에서 신호를 찾아내고, 길이나 자기 삶을 잃을 것 같은 불안을 극복하려면 우리에게 방향성이 필요하기 때문이다*. 그러나 네트워크는 이런 직선을 구불구불한 선으로 부드럽게 바꾸며, 시간이 흐르면서 고정된 광원뿔을 다른 면이 빛에 노출되도록 스스로 접히고 돌돌 말리는 잎사귀 모양으로 바꾼다. 우리에게 구조를, 따라갈 길을, 유연성 있는 움직임을 준다**.\n시간과 공간에 걸쳐서 네트워크를 만들 때 필요한 능력, 즉 다음에 무슨 일이 일어나야 하는지 명확하게 인식하는 능력이 있어야만 현재에 대한 과도한 불안을 피하고 미래에 대한 두려움을 없앨 수 있다. 목표 목록 자체는 도움이 되지 않는다. 목록에는 맥락이 없고, 서로 연결되어 있다는 감각도 없으며, 선호도를 설정할 방법도 없기 때문이다. 그것은 삶의 선형성에는 적절할 수 있지만 의사 결정에는 목표와 함께 사람과 장소를 계획하는 네트워크가 필요하며, 이 네트워크는 특정 형태를 고수할 필요 없이 오직 당신의 의도에만 맞으면 된다. 그러나 이 중 어느 것도 우리가 자신의 토폴로지를 친구나 동료의 것과 비교하면서 불안해하거나 부러워하지 않을 거라고, 갖고 싶은 것과 가질 수 있는 모든 것을 궁금해하지 않을 거라고, 대열의 끝으로 밀려날 것을 걱정하지 않을 거라고 보장해주지는 않는다. 네트워크이론은 당신을 자신만 뒤쳐지거나 소외될까봐 두려워하는 마음에서 구원할 수는 없지만, 최소한 당신이 유연하게 형태를 만들어나가면 시간이 흐르면서 진화할 방향과 목적은 알려줄 수 있다.\n일단 네트워크를 만들었다면 탐색을 시작해서, 대량의 정보와 구성 요소 중에서 어떤 것이 성공을 향해 나아가는 길을 보여주는지 알아내야 한다. 어떻게 해야 최적의 경로를 발견하고 발전시켜서, 상황이 바뀔 때마다 움직일 수 있는 부분을 계속 뒤섞을 수 있을까?\n​*삶에서 중요한 것들은 기준이 필요하다. 중요하고 필요한 요소들은 선으로 정해두기. 중요하고 소중한 것은 규정하지 않고 존재하는 그대로 건드리지 말고 두기. 그 상태 그대로도 선명하게 드러나게 하려면 중요하고 필요한 요소들이 선명하게 배경을 형성해줘야한다.\n**열심히 생각해서 가장 적절한 해를 내놓는 식을 통해 결과를 내야 하는 일이 있고, \u0026ldquo;결정\u0026rdquo; 방법을 \u0026ldquo;식\u0026rdquo; 같은게 아니라 그 사안만의 결정하는 방법대로 두고 어느순간 결정할만큼 선명해졌을때, 그 시점이 정답이라고 믿고 그 시점에서의 위치를 결과로 내야하는일도 있고. 그런것같네\n​\n3 # 경사하강법은 머신러닝에서 가장 기본적인 기술의 하나이며, 삶의 네트워크를 탐색하는 우리 모두에게 여러 가지 교훈을 주는 개념이다. 첫 번째 교훈은 우리는 경로 전체를 미리 볼 수 없으며, 심지어 대부분을 볼 수도 없다는 것이다. 노드를 연결하고 군집을 확인할 수는 있지만 결국 길을 따라 아래로, 즉 미래로 갈수록 우리의 시야는 흐릿해진다. 하지만 그래도 괜찮다. 경사하강법의 두 번째 교훈은 현재의 전후 사정이 당신이 지금 당장 알아야 할 모든 것을 말해준다는 것이기 때문이다. 알고리즘이 결정 과정에서 경사도를 시험하듯이, 우리도 우리만의 기준에 따라 특정 경로의 가치를 판단해야 한다. 이 길이 우리를 더 행복하게 하는가, 성취감이 더 큰가, 더 의미 있는가? 우리는 미래에 어떤 일이 어떻게 진행될지 예측할 수 없지만, 여행의 방향을 시험해보고 삶의 비용함수를 최소화하는 방향으로 나아갈 수는 있다. 여기서 가치와 목적에 대한 감각을 개발하고, 매슬로의 욕구 단계의 상층을 충족하는 일이 가능해진다. 매슬로의 욕구 단계는 일단 음식과 쉼터처럼 가장 기본적인 인간 욕구를 충족하면 우리의 관심은 더 덧없는 문제, 즉 성취감을 느끼고 존경받고 문제를 해결하고 창의적으로 생각하는 능력 같은 것으로 이동한다고 말한다.\n만약 그 방향에 대한 선호도가 떨어지기 시작하면, 즉 경사도가 차츰 감소하면 당신의 모멘텀도 줄어들면서 침체되거나 멍해지거나 그저 뭔가 잘못된 것 같은 기분이 들면서 변화하게 된다.* 경사하강법 알고리즘은 선택에 한해서는 감상적이지 않다. 만약 가장 가파른 하강 경로로 되돌아갈 수 있다면 기꺼이 두 단계 뒤로 물러난다. 우리도 그렇게 해야 한다. 우리도 경로를 선택하고 적응하는 과정을 반복해야 하며, 언제든 목표와 행복에 가까워지는 것이 아니라 멀어지고 있다고 느끼면 경로를 바꿔야 한다.** 또한 곧고 완벽하고 유일한 길은 없으며, 다만 발견해서 따라가기까지 기꺼움, 흥미, 인내심을 가져야 하는 길만 있다는 걸 받아들여야 한다. 당신이 선택하는 최고의 경로는 항상 객관적인 안정성 보다는 여러 요인에 좌우될 것이다. 이는 선택 사항을 탐색할 시간이 얼마나 있는가, 그리고 당신이 어느 정도의 완벽주의자인가에 달렸다.***\n목표를 설정하고 추구하는 일은 두려울 수 있지만, 내가 사랑하는 스포츠인 암벽 등반처럼 이것도 그저 적절한 장비와 개인의 노력 문제다. 하이젠베르크는 우리에게 빌레이(암벽 등반에서 등반자의 추락을 방지하기 위한 로프 조작 기술)를, 네트워크이론은 밧줄을, 경사하강법은 경로를 제공한다.\n*학습에서 멈춰야할 지점은 어디일까? 학습의 목표가 되는 적용 분야에의 적합성보다는 학습 자체가 목적이 되어버리는 어느 지점에서 멈춰야 할 것이다. 그 말은? 너무 정확해지면. 또는 너무 어디서 본것같아지면. 그럼 학습을 멈추고 남은 역량은 어디에 써야하는가? 목표에 안전하게 도착하는데 써야한다. 역량은 조금 남아야 제대로 분배한거다.\n**그리디 알고리즘의 반대 발명하면 좋을듯. 대인배 알고리즘 aka 상남자 알고리즘. 너무 멀어질때만 수정하면됨. (ㅋㅋ)\n***\u0026ldquo;동전 던지기 결과\u0026quot;를 예측하기 위한 학습을 수행한다고 하자. 1/2 라는 답보다 아주 적절한 양의 적은 오차를 넣는게 정답에 더 가까울 때도 있을 것이다. 아닐 때도 있ㅇ르 것이다. 고장난 시계가 하루에 두번 맞듯이. 그렇다고 해서 \u0026ldquo;동전\u0026quot;이 앞면과 뒷면 말고 다른 면을 갖고있는 것은 아니다. 동전은 정확히 앞면과 뒷면만 존재하며 1을 둘에 할당하면 (미묘한 무게차이 같은걸 신경쓰지 않으면) 1/2 를 할당하는 것 말고 다른 방법은 (상식적으로) 억지이다. 하지만 10번 던졌을때 정확히 5번이 나오는가 하면, 10번 던지기를 10번 해보면 5번이 나오는 게 더 적을 것이다. 목적을 확실히 해야한다. \u0026ldquo;동전\u0026quot;의 특성을 알아내는 것인가? 아니면 \u0026ldquo;동전 던지기 결과\u0026quot;를 정확히 예측하는 것인가? \u0026ldquo;동전\u0026quot;의 특성을 알아내는게 목적이라면 10번을 10번 한 뒤 smoothing을 해서 1/2 로 결정하면 된다. \u0026ldquo;동전 던지기 결과\u0026quot;를 정확히 예측하는 것이라면, 그리고 더 정확히는 \u0026ldquo;동전 던지기 결과를 누구보다 가장 정확히 맞히는것\u0026rdquo; 이 목적이며 다른 결과는 무의미하다면, 1/2에 난수를 더하는게 목적에는 더 부합할지 모른다. 예측이란 그런것이다\u0026hellip;\n"},{"id":28,"href":"/docs/hobby/book/book5/","title":"책","section":"책","content":" 세이노의 가르침 # 원래 같으면 조금 읽고 덮었을 것 같은데 취준시즌에 읽어서 꽤 많이 읽음. \u0026lsquo;나\u0026rsquo;에게 도움이 되는 책인지는 모르겠는데 \u0026lsquo;취준하는 나\u0026rsquo;에게는 매우 유용한 책이었다! ㅋㅋ\n목록 # [북마크] 공부를 안해서 오는 스트레스는 사실 공부를 해야 없어진다.\n[북마크] 잘할 수 있는 일을 찾기 vs 일을 잘하기\n[북마크] 인테그리티\n공부를 안해서 오는 스트레스는 사실 공부를 해야 없어진다. # 2024-12-31 # 1 # 카드 다섯 장을 쥐고 하는 포커판에서 나올 수 있는 카드패에는 2,598,960개 종류가 있다고 한다. 즉, 최고의 카드패를 쥘 사람은 약 260만명 중의 한 명이다. 하지만 포커에서 그런 카드패를 갖고 있지 않아도 당신은 이길 수 있다. 그저 포커 게임에 참석한 사람들보다 조금 더 좋은 패를 갖고 있으면 된다. 그러므로 최고의 카드를 받은 잘난 사람들은 무시해라. 그들의 포커판에는 비슷한 사람들이 몰려 있다.\n현재의 위치에서 미래를 미리 계산하여 보고 미리 포기하는 사람들이 당신 주변 사람들이며 그들은 그저 일확천금을 꿈꾸면서 연예인이나 정치인, 스포츠 선수들, 컴퓨터 게임, 채팅, 명품 브랜드, 경마 등에 무지 관심이 많다. 당신이 하는 게임은 바로 그런 사람들과 하는 것이다. 기억하라. 이것 역시 당신에게는 춤을 추고 싶을 정도로 너무나도 기쁘고 다행한 사실이라는 것을.\n\u0026lt;미래의 결단\u0026gt;, \u0026lt;자본주의 이후의 사회\u0026gt; 등으로 우리에게 잘 알려진 미국 미래학의 거두 피터 드러커 역시 높은 성과를 올리는 생산적인 사람, 끊임없이 혁신을 꾀하면서 계속 발전하는 사람, 다른 사람에게 영향을 미치는 비중 있는 사람, 그런 사람이 되는 길은 오직 지속적인 관리와 노력밖에 없다고 말한다. 나도 그의 말에 동의한다.\n부자가 되는 데 있어서 경쟁자는 결국 천재가 아니라 자기 자신이다. 이 지극히 간단한 사실이 독자들 마음 속에 각인되기를 바란다.\n2 # \u0026ldquo;실패를 심각하게 생각하지 말라. 주말에는 교외로 나가 신선한 자연을 벗하라. 일에 쫓기지 말라. 오늘 못한다고 내일 세상이 무너지는 일이란 없다. 긴장을 풀고 살아라. 경쟁심을 버려라. 그들은 그들이고 당신은 당신이다. 실력과 능력이 다가 아니다. 인생은 결과가 아니라 과정이 중요하다. 건강을 생각하며 운동을 하라. 운동은 당신이 생각하는 그 어떤 일보다 중요한 것이다. 자주 친구들과 만나 웃고 떠들며 놀아라. 그것이 정신 건강에 좋다. 느긋하게 천천히 살아라. 그것이 스트레스를 피하는 길이다.\u0026rdquo; 이런 조언에 충실히 따르며 살아간다면 장담하건데 몇년 후에 건강한 신체를 갖게 될는지는 모르겠지만 아마도 하고 있는 일은 망한지 오래이거나, 아니면 직장에서 이미 해고되어 구직 이력서를 서너 통 언제나 준비하여 갖고 다니는 몸 튼튼한 실업자가 되어 있을 것이다. 그래도 건강이 최고라고? 건강을 잃으면 모든 것을 다 잃는다고? 맞는 말이기는 하지만 그렇다고 해서 건강을 지키면 모든 것을 다 갖게 된다는 말은 아니지 않는가.\n왜 스트레스가 생기는가? 어떤 문제가 발생하기 때문이다. 그 문제는 어디서 발생하는 것인가? 일이나 인간관계에서 발생한다. 스트레스는 일이나 인간관계에서 발생한 문제가 풀리지 않아서 생기는 것이다. 왜 문제가 안 풀리는 것일까? 푸는 방법을 모르기 때문이다. 왜 모르는가? 책도 안 읽고 공부도 안 하기 때문이다.\n왜 공부를 스스로 안 하는가? 게으르기 때문이며 스스로의 판단과 생각을 우물 안 개구리처럼 최고로 여기기 때문이다. 한 달에 책 한 권도 안 보고 공부는 학원이나 학교에 가야만 하는 걸로 믿는다. 그러면서도 놀 것은 다 찾아다니며 논다. 그런 주제에 자기는 성실하게 열심히 살아가는데 주변 상황 때문에 스트레스를 받는다고 생각하며 그러면서도 수입이 적다고 투덜투덜댄다.\n문제가 있으면 문제를 해결하려고 덤벼드는 것이 올바른 태도이다. 문제는 그대로 남겨둔 채 그 문제로 인하여 생긴 스트레스만을 풀어 버리려고 한다면 원인은 여전히 남아있는 셈 아닌가. 휴식을 충분히 갖고 쉬라고? 웃으로고? 한 달을 바닷가 해변에서 뒹굴어 보아라. 백날을 하하 호호 웃어 보아라. 문제가 해결되는가? 웃기는 소리들 그만해라.\n기억하라. 제초제를 뿌리는 이유는 뿌리를 죽이기 위함이다. 뿌리를 살려 두는 한 잡초는 다시 살아난다. 스트레스를 없애는 가장 정확한 방법 역시 스트레스를 주는 문제의 원인을 파악하고 그 원인을 뿌리채 뽑아 버리는 것이다. 장담하건대 그 모든 원인은 일이나 인간관계에서 발생한 문제를 어떻게 해결하여야 하는지 모르는 당신의 무지 그 자체이다. 즉, 외부적 상황 때문에 스트레스가 생기는 것이 아니라 그 외부 상황을 어떻게 해야 헤쳐나가는지를 모르고 있는 당신의 두뇌 속 무지 대문에 생긴다는 말이다.\n그리고 그 무지함의 뿌리는 바로 게으름이다. 스트레스를 해소한답시고 빈 맥주병을 쌓아가지 말고 문제를 정면으로 돌파하라. 절대 회피하지 말라. 책을 읽고 방법론을 찾아내라. 그게 바로 스트레스를 없애는 제초제이다.\n3 # 결국 스트레스는 문제를 해결하면 없어지는데 해결책을 찾는 법은?\n아인슈타인은 \u0026ldquo;많은 문제가 무의식중에 해결된다\u0026quot;고 하고, \u0026ldquo;말이 아닌 이미지로 대부분 문제를 해결해 냈다\u0026rdquo;, \u0026ldquo;쓰거나 말하는 단어나 언어는 내 생각의 메커니즘에서 아무 역할도 하지 않는 것 같다. 생각의 요소를 받쳐 주는 듯 보이는 어떤 영적 존재들은 어떤 신호이거나 정도의 차이가 있기는 하나 분명한 이미지들인데 그것들은 스스로 반복되어 나타나기도 하고 결합되어 나타날 수도 있다\u0026rdquo;\n내가 문제 해결을 위해 꽤 오랫동안 사용하여 온 것은 인식 상태에서 미인식 영역을 건드리는 방식이다. 첫째, 샤워장 앞에서 옷을 벗을 때부터 두 눈을 감고 움직이며 샤워를 마칠 때까지 계속 눈을 감고 진행한다. 그렇게 함으로써 평상시에 사용되지 않았던 신경과 감각이 일어나 마인드브레인의 전선들이 재배치되도록 한다. 둘째, 인식 상태에서 들어 본 적 없는 음악 소리를 듣는 것이다. 비록 파리넬리의 노래나 파가니니의 연주를 들으면서 의식을 잃고 졸도한 사람들이 있었다고는 하지만 클래식으로는 안 된다. 최초로 시도했던 것은 아이언 버터플라이Iron Butterfly의 In-A-Gadda-Da-Vida(라이브가 아닌 1968년 스튜디오 녹음)였고 핑크 플로이드Pink Floyd의 Echoes(1971년)가 그 뒤를 이었다가 탠저린 드림Tangerine Dream의 Phaedra(1974년), Rubycon과 Ricochet(1975년), Stratosfear(1976년), Force Majeure(1979년), Tangram(1980년), Logos(1982년) 등을 들었는데 각각 그 음반들이 발표되고 나서 몇 년 후에야 비로소 입수할 수 있었다. 유행가도 아니고 상당히 긴 그런 음악 소리(들어 보면 내가 왜 음악이라고 하지 않고 소리라고 하는지 알게 될 것이고 In-A-Gadda-Da-Vida는 중간 부분만 그렇다)를 듣다가 번쩍 힌트가 스쳐 가는 경험을 나는 아주 많이 했었기에, 적어도 나에게는 그 음악 소리들이 앞에서 설명한 만트라가 되어 전선 재배치를 도와주었다고 믿는다. 시도하여 보아라. 눈을 감고 편안한 자세로 크게 들어야 하며 운전 중에는 절대 듣지 말아라(예전에 지인이 운전 중에 듣다가 사고를 낼 뻔했다고 들었다. 탠저린 드림의 80년대 초반 이후 음반들은 대체로 별로였다). 아, 물론 나에게는 이 방법이 효과가 있었지만 당신에게는 아무런 효과가 없을 가능성도 높다.\n요약 # 게으름 피우지 말고 스트레스를 제거해라. 천재는 쳐다보지 마라.\n잘할 수 있는 일을 찾기 vs 일을 잘하기. # 2024-12-31 # 1 # 많은 부자들은 일하는 것이 취미라고 말한다. 재미있게 즐긴다는 뜻이다. 토마스 J. 스탠리는 〈백만장자 마인드〉에서 미국의 백만장자 733명을 표본 조사하여 얻은 자료들을 보여 주는데 미국의 백만장자들 중 86%는 “나의 성공은 내 일과 직업을 사랑한 결과이다”라고 공통적으로 말한다(투자를 잘해야 부자가 된다는 말에 현혹되지 말라! 일이 우선이고 투자는 나중이다, 이 바보들아). 그리고 81%는 “나의 일은 내 능력과 적성을 한껏 발휘할 수 있도록 해 준다”고 말한다.\n하지만 사람들이 자기 능력과 적성에 맞는 일만을 찾아 나서는 것은 내가 볼 때는 정말 어리석은 일이다. 게다가 대다수의 사람들은 ‘자기가 머릿속에서 꿈꾸고 원하여 온 일’을 그 일을 위한 구체적인 준비도 없이 ‘자신이 해야 하는 일’과 동일시하거나 ‘자기가 능력을 갖고 있는 일’, ‘자기 적성에 맞는 일’, ‘자기가 잘할 수 있는 일’로 믿는다. 그러나 능력이니 적성이니 하는 것들은 관련 분야의 지식을 갖춘 뒤 실제로 일을 경험하여 보기 전까지는 뚜렷하게 나타나는 것이 아니다. 적성 검사 결과를 너무 믿지는 말라는 말이다(나는 학교에서 적성 검사를 받을 때마다 뭐 하나 유달리 적성이 뛰어난 것으로 나온 분야가 전혀 없었다).\n정말 그러냐고? 미국 백만장자들의 경우를 좀 더 살펴보자. 그들이 어느 날 아침 갑자기 일어나 자기 능력과 적성에 맞는 일을 하기 시작한 것은 절대 아니다. 그런 일은 천재들에게나 일어난다. 백만장자들이 일을 택하게 된 동기는 그저 우연한 기회(29%), 시행착오(27%), 예전 직업과의 관련성(12%), 이전 고용주가 놓친 기회(7%) 때문이다. 이 수치는 중고등학교 시절부터 공부를 잘해서 의사나 변호사 같은 전문직업인이 되어 부자가 된 사람들도 포함시킨 것이므로 그들을 제외한다면 거의 대다수의 백만장자들은 어떻게 하다 보니까 그렇게 되었다는 말이며, 어쩌다 하게 된 일이 시발점이 되어 돈을 벌었다는 뜻이다.\n진실은 이것이다. 백만장자들은 ‘어떻게 하다 보니까 하게 된 일’에서 기회를 포착하고 그 일을 사랑하고 즐김으로써 ‘능력과 적성을 한껏 발휘할 수 있는 일’로 바꾸어 버렸던 것이다. 내 말을 믿어라. 마크 피셔Mark Fisher와 마크 앨런Marc Allen의 공저 〈백만장자처럼 생각하라〉에서도 ‘성공하는 사람들은 그들의 일을 사랑한다’고 단언한다.\n2 # 명심해라. 내가 믿고 있는 원칙은 단 하나, 모르면 괴롭고 알면 즐겁다는 것이다.\n학창 시절을 돌이켜 생각하여 보아라. 누구나 자기가 잘하는 과목은 공부에 재미를 느끼지만 잘 못하는 과목은 정말 지겨워한다. 무엇인가를 잘하면 재미를 느끼기 마련이고 잘 못하면 재미고 뭐고 없지 않겠는가. 즉, 재미를 느끼느냐는 것과 잘하느냐 못하느냐 하는 데에는 비례 관계가 있는 것이다. 무엇인가를 잘한다는 것은 그것에 대하여 많이 알고 있기에 가능하며, 잘하니까 재미도 생기는 것이다. 학창 시절에 어떤 과목을 지겨워하였는데 그 과목을 가르치는 선생님이 미남 총각이어서(혹은 예쁜 여선생님이어서) 관심을 쏟아 가며 열심히 하게 되었고 하다 보니 많이 알게 되어 잘하게 되고 잘하게 되니 성적도 잘 나오고 칭찬도 받으니 재미도 많이 느끼고… 이런 경험을 가진 사람들이 실제로 주변에 널려 있지 않은가.\n결국 어떤 일에 대한 재미는 그 일에 대하여 얼마나 관심을 쏟고 관련된 지식을 얼마나 많이 갖고서 경험하는가에 따라 좌우되는 문제이다. 부자들은 초기에 무슨 일을 하든 우선은 그 일의 구조 전체를 파악하는 데 필요한 지식을 흡수하고 경험을 하다 보니, 점점 더 많이 알아 가게 되고 더 많이 알기에 재미도 느끼고 돈도 벌게 되니 즐거움도 배가 된다. 하기 싫은 일이란 것이 적어도 부자가 되는 과정에서는 있을 수 없다는 말이다.\n반면에 대개의 사람들은 일을 사랑하지도 않으며 즐기지도 못한다. 그저 목구멍이 포도청이라서 억지로 한다는 생각을 한다.\n3 # 애당초부터 가까이 가서는 안 될 우물도 있다. 하지만 처음부터 가까이 가서는 안 될 우물이 아니라면 어느 우물이건 그 우물 주인처럼 생각하고 행동하라. 즉, 하고 있는 일이 아무리 엿같이 생각되어도 그 구조체와 흐름을 완전히 파악하여야 하며 거기에 필요한 모든 지식을 스펀지처럼 흡수해 나가야 한다.\n부자가 되려면 이 원칙을 평생 잊지 말라. 사람들은 자기가 잘할 수 있는 일이 따로 있을 것이라고 생각하지만 성격상의 문제나 기술적 분야가 아닌 이상 어느 한 분야의 일에서 새는 바가지는 다른 분야의 일터에서도 새기 마련이며, 어느 한 분야에서 귀신이 되는 사람은 다른 일을 해도 중복되는 부분이 반드시 있기 때문에 남들보다 빠른 시간 안에 귀신이 된다.\n이런 말을 들은 적이 있다. \u0026ldquo;세 번은 질리고 다섯 번은 하기 싫고 일곱 번은 짜증이 나는데 아홉 번째는 재가 잡힌다.\u0026rdquo; 재가 잡힌다는 말은 일에 리듬이 생겨 묘미가 생긴다는 말이다. 즉 피곤을 가져오는 \u0026lsquo;노동\u0026rsquo;이 더 이상 아니고 재미를 느끼게 되는 단계인 \u0026lsquo;일\u0026rsquo;이 된다는 말이다.\n4 # 허드렛일을 싫어하는 사람들은 자존심을 내세운다. 내가 이런 일 하려고 취직한 건 아니라고 하면서 말이다.\n정말 자존심이 세다면 낮은 곳으로 내려가라. 성경에도 낮은 곳으로 내려가라는 말이 나온다. 낮은 곳에서 걸레를 누구보다 먼저 잡고 하찮아 보이는 일들을 즐겁고 기쁜 마음으로 하면서 실수 없이 완벽하게 해치울 때 비로소 사람들은 당신을 인정할 것이다.\n당신의 자존심은 그렇게 주변 사람들이 당신을 스스로 낮출 줄 아는 사람으로 인정할 때 저절로 지켜지게 되는 것이다.\n5 # 주 5일제 근무 좋아하지 마라.\n만약에 말이다. 당신은 다른 사람들 역시 이틀이나 되는 주말을 당신처럼 \u0026lsquo;재충전 내지는 삶의 질 향상\u0026rsquo;이라는 명목으로 쉬면서 보낸다고 생각하지만 사실 그들 중 일부는 자기 계발을 위하여 그 주말의 황금시간을 거의 모두 바치면서 일과 관련된 능력과 지식을 \u0026lsquo;독하게\u0026rsquo; 향상시키고 있다면, 그리고 그런 노력이 2년 정도 지속되면 어떻게 되는지 아는가?\n6 # 내가 말하고자 하는 것은 자기계발은 일찍 하면 일찍 할수록 유리하다는 것이다. 결국 부자가 되는 게임은 먼저 실전 지식을 축적한 사람이 이기게 되어 있기 때문이다.\n한줄 요약 # 성공하려면 자기 일을 알고, 재미를 느끼고, 사랑하면 된다. 허드렛일도 해라. 주 5일제 좋아하지 마라.\n인테그리티 # 2024-12-31 # 1998년 워런 버핏은 플로리다대학교에서 MBA 학생들에게 사람을 고용할 때 살펴보는 3가지를 언급하였다. 지능이 좋은지(머리가 잘 돌아가는지, 똑똑한지, 어리바리하지는 않은지), 일을 선도적으로 열정을 갖고 이끌어 나갈 수 있는지(시키는 것만 하는지, 해야 할 것들을 알아서 챙기는지), 그리고 integrity가 있는지 살펴봐야 한다. 머리도 좋고 일을 주도적으로 이끌어 나갈 열정도 있으나 integrity가 없는 자는 회사를 망칠 사람이다. integrity가 없는 사람을 고용하면 직원들을 게으름뱅이, 멍청이로 만들려는 것이기 때문이다.\n인테그리티란 자신이 옳다고 믿거나 생각하는 것을 말과 행동을 통해 일관성 있게 실천하는 것이다. 인테그리티를 완벽하게 실천하며 살아가기란 쉽지 않을 수 있다. 하지만 살아가면서 꾸준히 추구해야 할 가치이다.\n"},{"id":29,"href":"/docs/hobby/book/book6/","title":"책","section":"책","content":" 물고기는 존재하지 않는다 | 룰루 밀러 # https://blog.naver.com/afx1979/222154049972?trackingCode=blog_bloghome_searchlist\n이 블로그 글에는 이런 말이 나온다.\n미(학)적으로는 우울이나 자살이 아름다워 보일지 몰라도 진선미가 다 우울의 편을 든다고 해도 나는 분노가 더 낫다고 본다. 분노는 삶에 도움이 되고 삶을 더 좋게 변화시키는 원동력이 되기 때문이다.\n미학적으로는 진실만 받아들이는 것이 온전해보인다. 그런데 진실은 조금 밀어놓고 일단 달리기 시작하는 사람도 있다. 하이젠베르크의 불확정성 원리처럼 둘 다를 챙기는 것은 불가능하고 둘 중 하나는 어쩔 수 없이 포기해야 한다.\n목록 # [북마크] 자연은 인간의 사정을 봐주지 않는다 vs 운명의 형태를 만드는 것은 사람의 의지다.\n[북마크] 그릿을 획득하기 vs 진실로의 창을 열어놓기.\n[북마크] 좋은 것들이 기다리고 있다는 약속\n플레이리스트 | 물고기는 존재하지 않는다 by 룰루 밀러\n자연은 인간의 사정을 봐주지 않는다 vs 운명의 형태를 만드는 것은 사람의 의지다. # 2024-12-31 # 1 # “넌 중요하지 않아”라는 말은 아버지의 모든 걸음, 베어 무는 모든 것에 연료를 공급하는 것 같았다. “그러니 너 좋은 대로 살아.” 아버지는 수년 동안 오토바이를 몰고, 엄청난 양의 맥주를 마시고, 물에 들어가는 게 가능할 때마다 큰 배로 풍덩 수면을 치며 물속으로 뛰어들었다. 아버지는 언제나 게걸스러운 자신의 쾌락주의에 한계를 설정하는 자기만의 도덕률을 세우고 또 지키고자 자신에게 단 하나의 거짓말만을 허용했다. 그 도덕률은 “다른 사람들도 중요하지 않기는 매한가지지만, 그들에게는 그들이 중요한 것처럼 행동하며 살아가라”는 것이었다.\n아버지는 반세기 동안 거의 매일 아침 어머니에게 커피를 만들어주었고, 자기 학생들에게 헌신적이었다. 그들은 명절 때 우리 집에 식사하러 오고, 때로는 우리 집에서 살기도 했다. 우리 집 식탁에는 아버지가 떨리는 손으로 새긴 수천 개의 작은 숫자들이 새겨져 있는데, 이는 우리 세 자매에게 수학의 논리를 이해시키려 노력하며 보낸 무수한 밤들의 물리적 기록이다.\n암울한 현실일 수도 있는 것들이 아버지에게는 오히려 인생에 활력을 가득 불어넣고, 아버지가 크고 대범하게 살도록 만들었다. 나는 평생 광대 신발을 신은 허무주의자 같은 아버지의 발자국을 따라 걸으려 노력해왔다. 우리의 무의미함을 직시하고, 그런 무의미함 때문에 오히려 행복을 향해 뒤뚱뒤뚱 나아가려고 말이다.\n2 # 그것이, 바로 그것이 데이비드 스타 조던이 내 주의를 끌었던 이유다. 결코 승리하지 못할 거라는 그 모든 경고에도 불구하고, 그로 하여금 혼돈을 향해 계속 바늘을 찔러 넣도록 한 것이 무엇인지 알고 싶었다. 그가 우연히 어떤 비법을, 무정한 세상에서 희망을 찾을 수 있는 어떤 처방을 발견한 게 아닐까 궁금했다. 게다가 그는 과학자였으므로, 나는 무엇이든 끈질기게 지속하는 일에 대한 그의 정당화가 내 아버지가 심어준 세계관에도 들어맞을 수 있을 거라는 작은 가능성을 꽉 붙잡고 놓지 않았다. 어쩌면 그는 무언가 핵심적인 비결을 찾아냈을지도 몰랐다. 아무 약속도 존재하지 않는 세계에서 희망을 품는 비결, 가장 암울한 날에도 계속 앞으로 나아가는 비결, 신앙 없이도 믿음을 갖는 비결 말이다.\n3 # “낮이나 밤이나 호스로 물을 뿌려. 낮이나 밤이나.”\n해는 뜨고 지고, 뜨고 지고, 데이비드의 동료 두 사람은 고무 덧신을 신고서 물고기들의 살덩이를 향해 호스로 물을 뿌렸다. 이것이야말로 진정한 불굴의 기개가 무엇인지 보여주는 장면이 아닐까? 창밖에는 그들의 선지자가 머리를 거꾸로 처박고 있고, 공기 중에는 먼지가 희부옇게 드리워 있으며, 이 난장판을 어떻게 다시 수습할 수 있을지 알 수 없는 상황에서, 차가운 물과 불확실성을 정면으로 고스란히 받아내며 적어도 당장은 이것들을 마르지 않게 하겠다는 단호한 의지.\n4 # 그래서 그는 자신에게 어떤 말을 속삭였을까? 자기가 평생 해온 작업의 파편들을 쓸어 담을 때, 정체를 밝혀내지 못한 물고기들을 던져버릴 때, 이튿날 밤 작은아들 에릭을 침대에 뉘일 때, (영원히 끝나지 않을, 엄청난 양의) 번개와 세균과 지각변동이 잠복한 채 기다리고 있음을 알면서 이 모든 일을 하고 있을 때, 자신에게 계속 박차를 가하기 위해, 그 모든 일의 허망함에 짓눌려 으스러지지 않기 위해 그는 정확히 어떤 말을 자신에게 들려주었을까?\n5 # 나는 시카고로 옮겨 갔다. 친구 헤더가 몇 주 동안은 자기 집 남는 방에서 지내도 되니 거기서 앞으로 뭘 할지 생각해보라고 했다. 믿을 수 없을 만큼 친절한 제안이었다. 나는 시카고가 좋았다. 시카고의 추위가, 시카고의 익명성이. 나는 누구든 될 수 있었다. 컨버스 스니커즈를 신고, 탄산화 생성물이 약간 포함되어 있는 듯한 까끌까끌한 보도를 따라 걸었다. 나는 폴짝 뛰었다. 내가 되고 싶은 사람이 될 수 있을 것 같은 기분이었다. 바람둥이가 아니라, 우울증 환자가 아니라, 우주적 정의가 실행되는 대상이 아니라, 고향에 행복한 가정이 있는 사람이.\n그러나 헤더가 남자친구와 시내로 외출한 밤, 도시의 자주색 불빛이 창으로 쏟아져 들어올 때면 나는 그 모든 것의 현실성을 무시할 수 없다는 사실을 깨닫곤 했다. 내 인생에 생긴 공백을, 내가 품은 희망의 빛이 나를 더 따뜻이 데워줄수록 점점 더 넓어지고 차가워지기만 하는 그 공백을 말이다.\n그래서였다. 나는 절박했다. 단순하게 말하자. 데이비드 스타 조던의 책에서, 망해버린 사명을 계속 밀고 나아가는 일을 정당화하는 그 정확한 문장을 찾아내는 것이 내게는 절박했다.\n6 # 그는 갈수록 더욱더 내 아버지와 비슷한 소리를 했다. 인간이 살아가는 방법은 매번 숨 쉴 때마다 자신의 무의미성을 받아들이는 것이며, 거기서 자기만의 의미를 만들어내는 것이라고 말이다.\n심지어 절제에 관한 에세이에서도 그것을 찾을 수 있다. 그는 왜 그토록 약에 반대했을까? 그건 약이 사람을 실제보다 더 강력하다고 느끼게 하기 때문이다. 혹은 그의 표현을 빌리자면, 약이 “신경계가 거짓말을 하도록 강요”하기 때문이다.8 예를 들어 알코올은 사람들로 하여금 “실제로는 몸이 차가울 때도 따뜻하게 느끼도록 하고, 아무 근거 없이 기분 좋아지게 하며, 인격 수양의 핵심을 차지하는 제한과 자제에서 해방되었다고 느끼게 한다.” 달리 말하면, 자신에 대한 낙관적인 관점은 자기 발전에 대한 저주라는 것이다. 자신을 정체시키고 자기 발달을 저해하고 도덕적으로 미숙하게 만드는 길이자 멍청이가 되는 지름길이다.\n이런 게 정말 그의 세계관이라면, 그가 그렇게 자기 과신을 경계하는 사람이라면 도대체 어떻게 그런 집요함을 이끌어낼 수 있었을까? 모든 게 사라지고 부서지고 희망이라곤 없는 최악의 날에조차 어떻게 자신을 일으켜 세우고 밖으로 나가게 한 것일까?\n마침내 나는 가장 유의미한 단서가 될 만한 것을 손에 넣었다. 그것은 《절망의 철학》이라는 제목의 작고 검은 책이다.\n7 # 책에서 데이비드는 과학적 세계관이 골치 아픈 점은 삶의 의미를 찾고자 할 때 그 세계관이 보여주는 것은 허망함뿐이라는 사실을 고백한다. “우리가 붙인 불은 숯을 남기고 죽는다. 우리가 지은 성들은 우리 눈앞에서 사라진다. 강은 바닥을 드러내고 사막의 모래만 남긴다. (…) 어느 쪽으로 눈을 돌리든 생명의 과정을 묘사하려면 기운 빠지게 하는 은유를 사용할 수밖에 없다.”9\n그러면 어떻게 해야 한다는 말인가?\n데이비드는 청교도답게 손을 게으름에서 벗어나게 하라고 권한다. “활동적인 야외 생활과 그로 인해 얻게 되는 건강과 함께”10 “영혼의 고통은 사라진다.”11 그는 우리 몸이 일으키는 전기에 구원이 있다고 주장한다. 비슷한 시기에 쓴 한 강의 요강에서 그는 이렇게 말한다. “행복은 행하고, 돕고, 일하고, 사랑하고, 싸우고, 정복하고, 실제로 실행하고, 스스로 활동하는 데서 온다.”12 내 생각에는 너무 많이 생각하지 말라는 것이 그가 말하려는 요점 같다. 여정을 즐기고 작은 것들을 음미하라고 말이다. 복숭아의 “감미로운” 맛,13 열대어의 “호화로운” 색깔,14 “전사가 느끼는 준엄한 기쁨”15을 느끼게 해주는 운동 후 쇄도하는 쾌감 등.\n그러면 나쁜 나날을 보내고 있으면 어떻게 하라는 걸까? 데이비드는 나쁜 하루하루를 보내고 있는 사람에게는 동정심을 거의 느끼지 않는다. 《절망의 철학》의 최종 결론은 절망이 선택이라는 것이기 때문이다. 그는 절망이 청소년기에 자연스럽게 거쳐 가는 단계라고 생각하기는 해도 그런 감정을 떨쳐내지는 못하는 사람들은 경멸한다.\n8 # 나는 익숙한 수치심이 나를 덮치는 것을 느꼈다. 그것은 아버지가 엄청 차가운 호수에 풍덩 뛰어들었다가 개구쟁이 같은 미소를 만면에 띠고 큰 숨을 내쉬며 수면으로 치솟는 모습을 볼 때 느꼈던 바로 그 감정이었다. 나는 왜 아버지처럼 저렇게 살 수 없는 걸까? 내가 잘못하고 있는 게 뭘까? 그 답을 찾으려는 필사적인 마음에 나는 계속 책을 읽으며, 위생과 유머, 외교, 평화주의에 관한 그의 비판문과 시, 강의 노트, 알코올과 립스틱과 전쟁에 관한 논쟁을 뒤졌다. 그리고 마침내, 어느 오후 나는 발견했다. 공포에 대한 해독제, 희망에 대한 처방을 말이다.\n그것은 그가 ‘진화의 철학’이라 이름 붙인 강의 요강의 제일 밑에 묻혀 있었다. 알고 보니 그는 그날 하루의 강의를 내가 풀고자 했던 그 난제, 바로 과학적 세계관을 받아들이는 문제에 바쳤다. “이러한 인생관은 염세주의로 이어지는가?”20 강의가 끝나갈 무렵 그는 학생들에게 일종의 마술 같은 주문을 걸었다. 혼돈이 주는 냉기를 떨쳐버리는 한 가지 방법을 말이다. 특별한 활자체로 된 여덟 개의 단어.\n생명에 대한 이런 시각에는 어떤 장엄함이 깃들어 있다.\n나는 경악했다. 이거였다. 내 아버지가 즐겨 쓰는 바로 그 비법. 오늘날까지도 아버지 책상 위 액자 속에 담겨 있는 바로 그 단어들. 다윈이 외친 투쟁의 권유. 내 아버지와는 다르게—반항적이고, 희망과 신념이 가득한 사람으로—보였던 데이비드지만, 결국 그에게도 내게 알려줄 새로운 건 하나도 없었던 것이다. 내가 늘 들어왔던 말을 또다시 상기시키는 것밖에는.\n장엄함은 존재해. 네가 그걸 보지 못한다면 부끄러운 줄 알아.\n9 # 나는 스탠지에게 데이비드 스타 조던과 그 지진과 바늘에 대한 나의 집착을 이야기했다. “그러니까 말하자면 그건 왜 그러는지에 관한 집착이야”라고 나는 말했다. “한 사람을 계속 나아가도록 몰아대는 건 뭘까?”\n그때 그 친구가 한 말은 “흠”이 다여서 나는 맥이 좀 빠졌지만, 다음 날 오후 이메일을 통해 좀 더 긴 답변을 들을 수 있었다.\n그리고 네가 말한 그 이야기 말이야. 너무나 소중하고, 너무나 정교한 뭔가를 쌓아 올렸다가… 그 모든 게 다 무너지는 걸 목격한 그 사람… 그 사람은 계속 나아갈 의지를 어디서 다시 찾았을까 하는 그 질문. 계속 가고 싶든 그렇지 않든 어쨌든 계속 가게 만드는, 모든 사람의 내면 가장 깊은 곳에 자리한 그것을 카프카는 ‘파괴되지 않는 것’이라고 불렀어. 파괴되지 않는 것은 낙관주의와는 전혀 무관해. 낙관주의에 비하면 훨씬 더 심오하고 자의식은 훨씬 덜하지. 우리는 그 파괴되지 않는 것을 온갖 종류의 다른 상징과 희망과 야심 등으로 가리고 있어. 이런 상징과 희망과 야심은 그 밑에 무엇이 있는지 인정하라고 강요하지 않으니까. 음… 만약 그 모든 잉여를 제거한다면(혹은 제거할 수밖에 없게 된다면), 파괴되지 않는 그것을 찾게 될 거야. 그리고 우리가 일단 그것의 존재를 인정하게 되면(카프카는 여기서 더 깊게 들어가. 그는 우리가 파괴되지 않는 것을 낙관적이거나 긍정적인 것으로 생각하게 해주지 않아), 그것은 실제로 우리를 찢어발기고 파괴할 수도 있어.\n그래도 어쩔 수 없는 거지….\n10 # 나는 파괴되지 않는 것이라는 말이 마음에 들었다. 경이로운 개념이었다. 왜냐하면 그건 내가 비현실적인 목표를 향해 밀고 나아가는 것이 미친 짓인가 아닌가 하는 질문에 답하지 않아도 된다고 허락해주는 개념이기 때문이다. 그 개념은 단지 내가 그것을 거역한다면 나를 부숴버리겠다고만 약속할 뿐이다.\n하지만 나는 그것이 데이비드 스타 조던에게 잘 들어맞는다고는 생각하지 않았다.\n11 # 하지만 나는 확인하고 싶었다. 그래서 다시 그의 회고록으로 돌아갔다. “파괴되지 않는 것”이라는, 아마도 그전까지는 내게 불활성 상태로 있었을 개념에 생기를 불어넣은 이 새로운 단어로 무장한 채, 나는 그 개념이 데이비드가 쓴 글들 속 어딘가에 잠복해 있을지도 모른다고 생각하고 그 증거를 찾아 나섰다.\n그 증거는 긴 발췌문 속에 묻혀 있었다. 지진이 있고 겨우 며칠밖에 지나지 않았을 때, 아직 상처가 아물지 않은 채 샌프란시스코가 입은 피해의 규모를 조사하려 애쓰고 있을 때 데이비드 본인이 쓴 개인적인 에세이○에서 발췌한 글이었다.\n사람이 계획을 세우고 창조하기 시작한 이래, 사람이 노력해서 이룬 결과가 그토록 처참하게 파괴된 일은 한 번도 없었다. 엄청난 규모의 재앙 앞에서 그렇게 푸념하지 않는 인간을 만난 일은 한 번도 없었다. 평범한 한 남자가 자기 자신에게 그토록 희망차고, 그토록 용감하며, 그토록 자신과 자신의 미래를 확신하는 모습을 보여준 일은 그전엔 결코 없었다. 왜냐하면 결국 살아남는 것은 사람이고, 운명의 형태를 만드는 것도 사람의 의지이기 때문이다.\n사람은 결코 흔들리지 않으며 불에 타지 않는다는 것, 그것이 그 지진과 화재가 준 교훈이다. 그가 지은 집은 무너지기 쉬운 카드로 지은 집이지만, 그는 집 밖에 서 있고 다시 집을 지을 수 있다. 위대한 도시를 건설하는 것은 경이로운 일이다. 그보다 더 경이로운 일은 도시가 되는 것이다. 도시란 사람들로 이루어지며, 사람은 영원히 자신이 창조한 것들보다 높이 올라가야 한다. 사람의 내면에 있는 것은 그가 할 수 있는 모든 일보다 더 위대하다.21이 얼마나 경이롭고 분발을 요구하는 투쟁의 권유인가. 이 얼마나 영광스러운 위로이자, 어깨를 움켜쥐는 손길인가. 그런데 작은 문제가 하나 있다. 그가 쓴 단어들을 자세히 들여다보면 당신도 그 문제를 발견할 것이다. 그 진주알을 만든 최초의 작은 모래알 하나가 거짓말이라는 것을.\n운명의 형태를 만드는 것은 사람의 의지다.\n이 말은 그가 자기 자신에게 결코 하지 않겠다고 약속했던 바로 그런 종류의 거짓말이다. 사악함으로 이끌어가는 것이라고 그가 경고했던 그런 종류의 거짓말. 자기 경력을 바쳐 맞서 싸워왔던 그런 종류의 거짓말이자, 그가 죽기를 각오하고 싸울 가치가 있다고 말했던 그런 종류의 거짓말이다. 자연은 인간의 사정을 봐주지 않으니까! 그조차도 절망에 완전히 집어삼켜지지 않으려면 그 거짓말이 진실이기를 믿어야만 했던 것이다.\n그릿을 획득하기 vs 진실로의 창을 열어놓기. # 2024-12-31 # 1 # 나는 전문가들은 이 문제에 관해 뭐라고 이야기하는지 알아보기로 했다. 자기기만이 데이비드와 내 아버지가 경고한 것만큼 그렇게 위험한 것인가 하는 문제 말이다.\n20세기에는 의학 전문가들이 일치된 의견을 내놓았다. 지그문트 프로이트, 에이브러햄 매슬로, 에릭 에릭슨 같은 영향력 있는 심리학자들은 자기기만을 정신적 결함이자 시각에 생긴 문제여서 치료로 교정해야 한다고 보았다. 반면 정확한 시각은 \u0026ldquo;정신의 건강을 보여주는 표지\u0026quot;라고 여겼다.\n그러나 20세기가 기운차게 달려가는 동안, 임상심리학자들은 이상한 일들을 목격하기 시작했다. 그들이 볼 때 더 건강한 환자들, 인생을 더 쉽게 살아가는 사람들, 좌절을 겪은 뒤에도 재빨리 회복하는 사람들, 직업과 친구, 연인을 얻고 인생이라는 회전목마에서 황금기를 가지고 있는 사람들은 장밋빛 자기기만이라는 특징을 지니고 있는 것처럼 보였다.\n반면 그토록 칭송받던 정확한 인식이라는 미덕을 가진 사람들은 어떨까? 짐작했겠지만 그들은 병적인 수준의 우울증에 걸렸다. 살아가는 일을 힘들어했고, 좌절을 겪은 뒤에는 회복이 더 어려웠으며, 일과 사람들의 관계에서도 종종 더 많은 문제를 일으켰다.*\n*내가 느꼈던 바랑 어느정도 일치하는 듯하다. 갖고 싶어 노력했던 것들은 얻지 못하고, 우연찮게 얻게 된 것들은 후에 없어서는 안될 중요한 것들이 되었다. 이렇게나 내 의지와 무관하게 흘러가는게 내 삶이 맞나?라는 생각이 들었다.\n혼자서는 결론을 내리기가 어려운 일들이 많았다. 대다수는 내 존망과 직결되는 문제라서 좀 중요했다. 나는 답을 찾기 전까지는 아무것도 시작할 수 없다고 생각했다.\n많은 감정과 시간을 쏟았지만 해답은 엉뚱한 곳에서 찾았다. 사람은 다른 사람에 섞여 살아야 한다. 사람은 사람이랑 같이 살아야 한다. 혼자서는 답을 찾기 어려운 일들은 다른 머리로 생각했을 땐 의외로 쉬운 질문일 수 있다. 답은 더 엉뚱한 곳에서 나오기도 한다. 영원히 풀리지 않을 문제 같던 일을 어느 새 잊고 사는 것이다. 문제는 문제를 삼아서 문제인지도 모른다. 사실 그 질문은 답이 없었는지도 모른다.\n2 # “자신에게 거짓말을 하는 것이 괜찮을까요?” 내가 윌슨에게 물었다.\n“해로울 게 뭔가요? 두려움을 잠재워주고, 미래에 적응을 방해하는 행동으로 이어지지 않는다면 나는 아무 문제 될 게 없다고 봐요.”\n3 # 더크워스는 왜 어떤 학생은 다른 학생들보다 공부를 더 힘들어하는지 그 이유가 궁금했다.12 성취도가 높은 학생들에게는 무슨 비밀이 있는지 알아내고 싶었다. 몇 년 뒤 더크워스는 그 비밀의 요소라 여겨지는 한 가지 특징을 발견하고 그 특징에 ‘그릿Grit’(끈질긴 투지)이라는 이름을 붙였다. 그릿. 끈질김을 뜻하지만 그보다 귀에 착 붙는 단어, 그릿. “긍정적 피드백”이 없는데도 “매우 장기적인 목표”에 로봇처럼 뛰어들게 해주는 것,13 그릿. 머리로 벽을 반복적으로 들이받을 수 있는 능력. 더크워스는 웨스트포인트(미 육군사관학교) 사관생, 최고경영자, 뮤지션, 운동선수, 셰프 등 거의 모든 직업에서 정상에 선 사람들에게서 그릿을 발견했다.14 재능, 창의력, 친절함, IQ는 다 잊어라. 순수한 그릿이야말로 앞으로 나아가게 해주는 바로 그것인 것 같았다.\n그렇다면 어떤 인지적 결함이 그릿을 획득하는 데 도움이 될까? 바로 긍정적 착각이다.15 다른 연구들도 마찬가지로 긍정적 착각을 갖고 있는 사람이 좌절을 겪은 뒤에 낙담할 가능성이 적다는 것을 보여주었다.16 그릿이란 여러 특성들이 섞인 칵테일 같은 것이지만, 그중 가장 중요한 특징이 바로 이것이다. 좌절을 겪은 뒤에도 계속 나아갈 수 있는 능력, 자신이 추구하는 것이 이루어지리라는 증거가 전혀 없는데도 계속 해나갈 수 있는 능력, 또는 더크워스의 표현을 빌리면 “실패와 역경, 정체에도 불구하고 수년간 노력과 흥미를 유지하는 것”17 말이다.\n그릿의 가장 좋은 부분이자 가장 희망적인 속성이며, 아메리칸드림과도 가장 잘 들어맞는 지점은 이것이 생물학적 기반에서 나오지는 않았을 것이라는 생각이다. 꿈을 현실로 만들어주는 그릿이라는 이 마술적인 특성은 가르쳐서 기를 수 있다는 것이다.\n데이비드는 더크워스가 내린 그릿의 정의를 거의 그대로 복창하듯 자신을 이렇게 묘사했다. “나는 바라는 목표를 향해 끈질기게 일하고 그런 다음 결과를 차분히 받아들이는 데 익숙해졌다. 나아가 나는 일단 일어난 불운에 대해서는 절대 마음 졸이지 않았다.”18\n4 # 그런데 장밋빛 렌즈를 끼고 살아가는 일이 불리하게 작용하기도 할까?\n로빈스와 비어는 스스로 실망을 자초하는 것이라고, 즉 “단기적으로 혜택을 얻는 대신 장기적으로 비용을 치르는” 것이라고 설명했다.29 다시 말해서 기만은 나중에라도 대가를 치르게 된다는 것이다. 장밋빛 렌즈의 힘에는 한계가 수반된다. 그리고 그 힘이 떨어지면 자신이 무력하다는 사실을 정말로 따끔하게 받아들여야 한다.\n5 # 바우마이스터와 부시먼은 높은 자존감이 모두 나쁜 건 아니라는 점도 재빨리 덧붙였다. 그들은 높은 자존감도 아주 좋은 것일 수 있다며, 활짝 편 손바닥을 높이 들어 보이면서 해명해야 하는 상황을 자주 겪었다. 자존감이 높은 사람은 자기 자신을 아주 편안하게 받아들이며, 비판을 받아도 자기 가치가 위협받는다고 느끼지 않으므로 높은 자존감은 당사자를 기이할 정도로 평화롭게(그들의 표현으로는 “이례적으로 비공격적으로”) 만들 수도 있다고 했다. 그들은 자존감이 높기는 하지만 자존감에 대한 위협을 쉽게 느끼는 극히 소수의 사람만이 위험한 이들이라고 생각했다.\n바우마이스터와 부시먼은 이렇게 썼다. “쉽게 말해서 가장 위험한 사람은 자신을 우월한 존재라고 보는 사람들이라기보다 자신을 우월한 존재로 보고 싶다는 욕망이 강한 사람들이다. (…) 거창한 자기상을 확인받는 일에 집착하는 사람들은 비판당하는 것을 몹시 괴로워하며 자기를 비판한 사람을 사납게 공격하는 것으로 보인다.”38\n나는 스탠퍼드에서 보았던 그 오싹한 물고기, 데이비드 스타 조던이 직접 자신의 이름을 붙인 유일한 바닷물고기를 다시 떠올렸다. 서로 반대쪽에 위치한 두 면이 돌돌 말리듯 어디서 만나는지도 모르게 하나로 합쳐지는 뫼비우스 띠 모양의 그 가시 박힌 용 말이다. “모서리가 없는 조던.” 그가 선택한 이 물고기에 어떤 메시지가 숨어 있는 걸까? 그의 매력 아래 도사린 어두운 면에 대한 인정일까?\n루서 스피어는 이렇게 썼다. “조던의 재능 중 특히 양날을 지닌 재능은 자기가 옳은 일을 하고 있다고 자신을 설득하고, 그런 다음 무한해 보이는 에너지로 목표를 추구하는 능력이다. (…) 그는 자신의 관용과 관대함을 자랑스러워했다. (…) 하지만 조던은 파리 한 마리를 잡는 데 대포알을 쓰는 것도 마다하지 않았다.”39\n6 # 다윈은 《종의 기원》의 거의 모든 장에서 “변이”48의 힘을 칭송한다. 동질성은 사형선고와 같다. 한 종에서 돌연변이와 특이한 존재들을 모두 제거하는 것은 그 종이 자연의 힘에 취약하게 노출되도록 만들어 위험을 초래한다.\n이를 달리 표현하자면 “당신의 유전자 포트폴리오를 다양화하라”가 될 것이다.52 상황이 바뀌면 그 상황에 어떤 특징이 더 유용하게 적용될지는 아무도 모르는 법이다. 다윈은 간섭하지 말라고 특별히 강력하게 경고한다.53 그가 보기에 위험한 것은 인간의 눈에서 비롯된 오류 가능성, 복잡성을 이해하지 못하는 우리의 무능력이다. “적합성에 대한 우리의 관점에서는 불쾌하게”54 보일 수 있는 특징들이 사실 종 전체나 생태계에는 이로울 수도 있고, 혹은 시간이 지나고 상황이 바뀌면 이로운 것이 될 수도 있다는 것이다.\n인간의 지력으로 도저히 다 이해할 수 없는 생태의 복잡성에 대한 이러한 조심스러움과 겸손함, 공경하는 마음은 사실 대단히 오래된 것이다. 이는 때로 “민들레 원칙”58이라고도 불리는 철학적 개념이다. 우생학자들은 이런 단순한 상대성의 원칙을 고려하지 못한 것이다. 유전자 풀에서 “필수 불가결한”59 다양성을 제거하려고 노력함으로써 그들은 사실상 지배자 인종을 구축할 최선의 기회를 망쳐버리고 있었던 셈이다.\n7 # 데이비드 스타 조던은 죽는 날까지 열광적인 우생학자로 남았다. 데이비드의 정서적 해부도를 쫙 펼쳐놓고 볼 때 가장 눈에 띄는 원흉은 그 스스로 상당히 자랑스러워했던 두툼한 “낙천성의 방패”가 아닌가 싶다. 특히 시련의 시기에는 더욱더 자기기만에 의존했던 듯하다. 운명의 형태를 만드는 것은 사람의 의지다. “긍정적 착각은 견제하지 않고 내버려둘 경우 그 착각을 방해하는 것은 무엇이든 공격할 수 있는 사악한 힘으로 변질될 수 있다”고 경고한 그 심리학자들의 말이 옳았던 것 같다.\n나는 거꾸로 거슬러 올라가면서 그가 경로를 이탈한 지점을, 그의 방향타를 슬쩍 밀어 그가 그토록 파멸적으로 경로를 벗어나게 만든 사건 혹은 개념을 찾기 시작했다. 그러다 마침내 나는 제비들이 원을 그리며 날아다니는 페니키스 섬의 헛간에서 루이 아가시가 젊은 데이비드의 정신에 관념의 씨앗 하나를 심어놓는 순간에 다다랐다. 그것은 자연 속에 사다리가 내재해 있다는 믿음이었다. 자연의 사다리. 박테리아에서 시작해 인간에까지 이르는, 객관적으로 더 나은 방향으로 향하는 신성한 계층구조. 이 관념이 데이비드의 세계를 다시 건축했다. 그것은 꽃을 수집하던 그의 부끄러운 습관을 “가장 높은 수준의 선교 활동”으로 바꿔놓았다.\n그는 지느러미나 두개골의 형태 속에 도덕적 안내도가 담겨 있다는 믿음을 품고서, 나침반처럼 자연을 읽으며 앞으로 나아갔다. 그는 충분히 꼼꼼하게 살펴보면 누구를 모방해야 할지, 누구를 비난해야 할지 알아낼 수 있을 거라 확신했다. 한마디로 깨달음으로, 평화로, 그 무엇이든 사다리의 꼭대기에 놓여 있을 열매를 향해 나아가는 진실한 경로를 알게 될 거라고. 그리고 인류가 쇠퇴해가는 모습을 목격했다고 생각했을 때, 필요하다면 어떤 수단을 동원해서라도 인류를 구출해야 한다는 소명을 느꼈다. 그는 자연의 질서에 관한 믿음을 칼날처럼 휘두르며, 인류를 구원할 가장 건전한, 아니 유일한 방법은 불임화라고 사람들을 설득했다.\n**이 부분은 의사 결정에서 \u0026lsquo;상자\u0026rsquo;를 선택하는 대신에 \u0026lsquo;나무\u0026rsquo;처럼 생각해야 한다는 카밀라 팡의 의견과 일맥상통한다. \u0026lsquo;상자 속에서 \b생각하는 방식은 대개 감정의 조합이나 배짱으로 의사를 결정한다. 감정이나 배짱은 둘다 신뢰할 수 없다.\u0026rsquo;\n8 # 동물은 인간이 스스로 우월하다고 가정하는 거의 모든 기준에서 인간보다 더 우수할 수 있다. 까마귀는 우리보다 기억력이 좋고,6 침팬지는 우리보다 패턴 인식 능력이 뛰어나며,7 개미는 부상당한 동료를 구출하고,8 주혈흡충은 우리보다 일부일처제 비율이 더 높다.9 지구에 사는 모든 생물을 실제로 검토해볼 때, 인간을 꼭대기에 두는 단 하나의 계층구조를 그려내기 위해서는 상당히 무리해서 곡예를 해야 한다. 우리는 가장 큰 뇌를 갖고 있지도 않고 기억력이 가장 좋은 것도 아니다. 우리는 가장 빠르지도, 가장 힘이 세지도, 번식력이 가장 좋지도 않다. 같은 배우자와 평생을 함께하고, 도구나 언어를 사용하는 것은 인간만이 아니다. 심지어 우리는 지구에 가장 새롭게 나타난 생물도 아니다.\n이것이 바로 다윈이 독자들에게 알려주려고 그토록 노력했던 점이다. 사다리는 없다. 나투라 논 파싯 살툼Natura non facit saltum, “자연은 비약하지 않는다”고10 다윈은 과학자의 입으로 외쳤다. 우리가 보는 사다리의 층들은 우리 상상의 산물이며, 진리보다는 “편리함”을 위한 것이다. 다윈에게 기생충은 혐오스러운 것이 아니라 경이였고,11 비범한 적응성을 보여주는 사례였다. 크건 작건, 깃털이 있건 빛을 발하건, 혹이 있건 미끈하건 세상에 존재하는 생물의 그 어마어마한 범위 자체가 이 세상에서 생존하고 번성하는 데는 무한히 많은 방식이 존재한다는 증거였다.12\n9 # 데이비드는 왜 그걸 보지 못한 걸까? 사다리에 대한 그의 믿음을 반증하는 증거들이 이렇게 산더미처럼 쌓여 있는데. 식물과 동물이 배열되는 방식에 관한 이 자의적인 믿음을 왜 그토록 보호하려 한 걸까? 그 믿음에 도전이 제기되면 왜 더욱 강하게 그 믿음을 고수하고 폭력적인 조치를 합리화하는 데 그 믿음을 사용했을까? 아마도 그 믿음이 그에게 진실보다 더 중요한 무언가를 주었기 때문일 것이다. 그것은 바다와 별들과 현기증 나는 그의 인생을 휘몰아가는, 소용돌이치는 늪을 깔끔하고 빛나는 질서로 바꾸는 방법이었다. 처음 다윈을 읽을 때부터 마지막으로 우생학을 밀어붙일 때까지 어느 시점에서든 그 믿음을 놓아버리는 것은 현기증을 다시 불러일으키는 일이었을 것이다. 그것은 지독히도 방향감각을 앗아가는 일이었을 것이고 혼돈이었을 것이다. 너는 중요하지 않아라는 진실을 흘낏 엿본 바로 그 느낌일 것이다. 그 사다리가 데이비드에게 준 것은 바로 이것이다. 하나의 해독제. 하나의 거점. 중요성이라는 사랑스럽고 따뜻한 느낌. 그런 관점에서 보면 나는 그가 자연의 질서라는 비전을 그토록 단단하게 붙잡고 늘어졌던 이유를 이해할 수 있을 것 같다. 도덕과 이성과 진실에 맞서면서까지 그가 그렇게 맹렬하게 그 비전을 수호한 이유를.\n10 # 나는 살면서 내 인생의 많은 좋은 것들을 망쳐버렸다. 그리고 이제는 더 이상 나 자신을 속이지 않으려 한다. 그 곱슬머리 남자는 결코 돌아오지 않을 것이다. 데이비드 스타 조던은 나를 아름답고 새로운 경험으로 인도해주지 않을 것이다. 혼돈을 이길 방법은 없고, 결국 모든 게 다 괜찮아질 거라고 보장해주는 안내자도, 지름길도, 마법의 주문 따위도 없다. 희망을 놓아버린 다음에는 무슨 일을 해야 하지? 어디로 가야 할까?\n요약 # 자기가 옳은 일을 하고 있다고 자신을 설득하는데 성공하면 무한해 보이는 에너지로 목표를 추구할 수 있다. 하지만 믿음을 반증하는 증거가 나타났을 때도 맹목적으로 그 믿음을 보호하게 될수 있다. 그리고 근거가 *\u0026lsquo;실제로 옳은 일이기 때문\u0026rsquo;*이 아니라 *\u0026lsquo;깔끔한 질서를 잃고 이전의 혼돈으로 되돌아가기 때문\u0026rsquo;*일 수 있다. 결국\n긍정적 착각은 그릿을 획득하는 데 도움이 되지만 \u0026lsquo;궁극적인 진실을 받아들이는 능력\u0026rsquo;을 대가로 치러야 한다.\n좋은 것들이 기다리고 있다는 약속 # 2024-12-31 # 1 # 나는 그에게 통쾌하게 반박해줄 말이 있었으면 싶었다. 우리는 중요하다고, 우리는 사실 아주 중요하다고 말해줄 방법. 그러나 주먹이 올라가는 게 느껴지자마자 내 뇌가 주먹을 다시 잡아당겼다. 왜냐하면 당연히, 우리는 중요하지 않기 때문이다. 이것이 우주의 냉엄한 진실이다. 정말 이상한 일이지만, 이 진실을 무시하는 것은 정확히 데이비드 스타 조던과 똑같이 행동하는 것이다.\n2 # 천천히 그것이 초점 속으로 들어왔다. 서로서로 가라앉지 않도록 띄워주는 이 사람들의 작은 그물망이, 이 모든 작은 주고받음-다정하게 흔들어주는 손, 연필로 그린 스케치, 나일론 실에 꿴 플라스틱 구슬들-이 밖에서 보는 사람들에게는 그리 대단치 않은 것일지도 모른다. 하지만 그 그물망이 받쳐주는 사람들에게는 어떨까? 그들에게 그것은 모든 것일 수 있고, 그들을 지구라는 이 행성에 단단히 붙잡아두는 힘 자체일 수도 있다.\n바로 이런 점이 내가 우생학자들에 대해 그토록 격노하는 이유다. 그들은 이런 그물망의 가능성을 상상조차 하지 못한다.\n3 # 별이나 무한의 관점, 완벽함에 대한 우생학적 비전의 관점에서는 한 사람의 생명이 중요하지 않아 보일지도 모른다. 그러나 그것은 무한히 많은 관점 중 단 하나의 관점일 뿐이다. 이것이 바로 다윈이 독자들에게 그토록 열심히 인식시키고자 애썼던 관점이다. 자연에서 생물의 지위를 매기는 단 하나의 방법이란 결코 존재하지 않는다는 것. 하나의 계층구조에 매달리는 것은 더 큰 그림을, 자연의, \u0026ldquo;생명의 전체 조직\u0026quot;의 복잡다단한 진실을 놓치는 일이다. 좋은 과학이 할 일은 우리가 자연에 \u0026ldquo;편리하게\u0026rdquo; 그어 놓은 선들 너머를 보려고 노력하는 것, 당신이 응시하는 모든 생물에게는 당신이 결코 이해하지 못할 복잡성이 있다는 사실을 아는 것이다.\n4 # 분기학자들이 등장하던 시기에 \u0026ldquo;수리분류학\u0026quot;이라는 방법이 유행하고 있었다. 이는 컴퓨터가 그 무지막지한 계산 능력으로 진화적 친연성을 판단해줄 거라는 희망에 기초한 방법이다. 종들을 비교할 때 생각해낼 수 있는 특징들(예를 들어 새들을 비교한다면 부리의 유형, 알의 크기, 깃털 색깔, 척추골의 수, 내장의 길이 등)을 그냥 최대한 많이 입력하면, 컴퓨터가 개연성 있는 관계의 패턴을 뽑아내주는 것이다. 이는 두 종 사이에 비슷한 점이 많을수록 둘이 가까운 관계일 거라는 생각에 기초한 방법이다. 그러나 컴퓨터는 전혀 말이 안되는 관계를 제안할 때도 많았다. 인간의 직관을 완전히 제거했더니\u0026hellip; 혼돈만 남은 것이다.\n그러나 분기학자들은 어떤 특징들이 다른 특징보다 더 유용하다는 사실을 깨달았다. 종들이 거쳐 간 시간의 흐름을 가장 신빙성 있게 보여줄 수 있는 것은 그들이 \u0026ldquo;공통의 진화적 참신함\u0026quot;이라고 부른 특징들, 그러니까 새롭게 추가된 특징들이었다. 이를테면 완전히 새로운 더듬이라든가 반짝이는 노란 지느러미 같은 것들 말이다. 모델에 추가된 참신한 업그레이드가 무엇인지 알아낼 수 있다면, 그 새로운 특징을 따라 생물들이 거쳐 간 다양한 버전을 추적할 수 있고, 시간의 화살이 어느 길을 가리키고 있는지 (좀 더 자신 있게) 추측할 수 있고, 더 큰 확신을 갖고 누가 누구를 낳았는지 단언할 수 있다는 것이다.\n그 발견은 단순했고, 미묘했고, 특출났다. 그리고 시간이 지나며 아주 놀라운 관계들을 드러내기 시작했다. 예를 들어 박쥐는 날개가 달린 설치류처럼 보일지 모르지만 사실은 낙타와 훨씬 더 가깝고, 고래는 실제로 유제류(발굽이 있는 동물로, 사슴이 속한 과)라는 사실이 그렇다.\n5 # \u0026ldquo;어류\u0026quot;라는 범주가 모든 차이를 가리고 있다. 그 범주는 가까운 사촌들을 우리에게서 멀리 떼어놓음으로써 잘못된 거리 감각을 만들어낸다.\n어류는 존재하지 않는다. \u0026ldquo;어류\u0026quot;라는 범주는 존재하지 않는다. 데이비드에게 너무나도 소중했던 그 생물의 범주, 그가 역경의 시간이 닥쳐올 때마다 의지했던 범주, 그가 명료히 보기 위해 평생을 바쳤던 그 범주는 결코, 단 한 번도 존재한 적이 없었다.\n6 # 반세기 동안 분류학자로 일해온 데이브 스미스는 애매하게 얼버무리는 몇 마디를 뱉어내다가 결국 \u0026ldquo;아마 존재하지 않을 겁니다\u0026quot;라고 인정했다. 시간이 지나면서 자기의 일, 생명의 진정한 상호 연관을 밝혀내는 일을 정말로 할 마음이 있다면, 그들이 하는 말을 부인할 수 없다는 것을 깨달았다. \u0026ldquo;어류\u0026quot;라는 것은 그것을 제대로 직시한다면 사실 틀린 범주라는 것을 말이다. 명료하지 않고 날림으로 만든 이 범주-분류학자들의 용어로는 측계통군-에는 그 구성원들의 일부가 빠져 있다. 나중에 나는 미국자연사박물관의 어류분과 수석 큐레이터인 멜라니 스티아스니에게 전화해 긍게서도 어류라는 범주가 사라졌는지 물었다. 멜라니는 \u0026ldquo;어이쿠\u0026rdquo; 하고 운을 떼더니 \u0026ldquo;널리 그렇게 받아들여지죠\u0026quot;라고 말했다. 당신도 상상할 수 있듯이 무덤덤하게.\n\u0026ldquo;맞아요. 직관에 어긋납니다!\u0026rdquo; 자칭 \u0026ldquo;횡설수설하는 분기학자\u0026quot;인 릭 윈터바텀이 내게 한 말이다. 그는 30년 넘게 학생들에게 실제 자연 세계가 우리가 설정한 범주대로 분류되는 것은 아니라는 사실을 확인시키려 노력해왔다. 그리고 그 관념이 학계 밖으로는 도저히 퍼져나가지 않는 것을 보면서 크게 실망했다. 그는 자기가 대적하기에 너무 센 적수를 상대하고 있는 것 같다고 걱정스러워했다. 그 센 적수는 바로 직관이다. 그는 사람들이 결코 편안함을 진실과 맞바꾸지 않을 것이라고 했다.\n7 # 우주가 데이비드 스타 조던에게서 그가 사랑하는 물고기를 빼앗는 모습을 지켜보면서 느낀 약간의 병적인 만족감을 제외하면, 내게 그것이 중요한 일인가? 조금만 넓은 의미에서 보면, 표본들을 유리단지에 정리하는 것이 직업이 아닌 모든 사람에게, 하나의 범주로서 어류가 존재하지 않는다는 사실이 중요한 일일까?\n헤더는 코페르니쿠스를 예로 들었다. 그 시대 사람들이 하늘을 올려다보면서 움직이고 있는 게 별이 아니라는 걸 받아들이기가 얼마나 어려웠을지 이야기했다. 그럼에도 그에 관해 이야기하고, 그에 관해 생각하고, 별들이 매일 밤 그들 머리 위에서 빙빙 돌고 있는 천구의 천정이라는 생각을 사람들이 서서히 놓아버릴 수 있도록 수고스럽게 복잡한 사고를 하는 것은 중요한 일이라고 말이다. \u0026ldquo;왜냐하면 별들을 포기하면 우주를 얻게 되니까\u0026quot;라고 헤더는 말했다.\n물고기를 포기하면 무슨 일이 일어날까? 나는 전혀 알 수 없었다. 하지만 그순간 하나는 알 수 있었다. 물고기의 반대편에 다른 뭔가가 기다리고 있다는 것. 물고기를 놓아주는 일은 그 결과로 또 다른 어떤 실존적 변화를 불러온다는 것. 그리고 그 결과는 사람에 따라 다 다를 거라는 생각이 들었다.\n8 # 나의 아버지는 \u0026ldquo;어류\u0026quot;라는 단어를 포기하고 싶어 하지 않았다. 과학적으로 정확하지 않다는 건 이해하지만 유용한 단어라고 생각했다. 그 단어를 사용함으로써 세계를 경험하는 제한된 방식에 자신을 가두게 되는 것이 걱정되지 않으냐고 내가 묻자, 아버지는 불만스럽게 끙끙거리는 소리를 내더니 이렇게 말했다. \u0026ldquo;아이고, 그게 뭐든, 아직 내가 해방되기에는 너무 늙었어.\u0026rdquo; 큰언니는 물고기를 놓아버리는 데 아무런 문제도 없었다. 언니는 어류라는 범주 전체를 바로 손에서 놓아버렸다. 왜 언니한테는 그게 그렇게 쉬운 거냐고 묻자 이렇게 말했다. \u0026ldquo;왜냐하면 그게 피할 수 없는 사실이니까. 인간은 원래 곧잘 틀리잖아.\u0026rdquo; 언니는 평생 사람들이 자신에 대해 늘 반복적으로 오해해왔다고 말했다. 의사들에게는 오진을 받고, 급우들과 이웃들, 부모, 나에게서는 오해를 받았다고 말이다. \u0026ldquo;성장한다는 건, 자신에 대한 다른 사람들의 말을 더 이상 믿지 않는 법을 배우는 거야.\u0026rdquo;\n정말로 이 물음은 모든 사람마다 다 다르다.\n9 # 나는 시카고를 떠날 때가 되었다는 것을 알았다. 더이상 나의 연옥에 숨어 있을 수만은 없다는 사실을. 나는 내 인생을 계속 살아가야 했고 혼돈 속으로 다시 들어가 무슨 일이 벌어지는지 지켜봐야 했다.\n10 # \u0026lsquo;나는 이 사람이 없는 인생은 결코 원하지 않아.\u0026rsquo; 이건 내가 그려왔던 인생이 아니었다. 체격이 아주 작고, 나보다 일곱 살이 어리며, 자전거 경주에서 나를 이기고, 툭하면 나를 향해 어이없다는 듯 눈동자를 굴리는 여자를 쫓아다니는 것은. 그러나 이건 내가 원하는 인생이다. 나는 범주를 부수고 나왔다. 자연이 프린트된 커튼 뒤를 들춰보았다. 있는 그대로의 세상을, 무한한 가능성의 장소를 보았다. 모든 범주는 상상의 산물이다. 그건 세상에서 가장 근사한 느낌이었다.\n11 # 마침내 내가 줄곧 찾고 있었던 것을 얻었다. 하나의 주문과 하나의 속임수, 바로 희망에 대한 처방이다. 나는 좋은 것들이 기다리고 있다는 약속을 얻었다. 내가 그 좋은 것들을 누릴 자격이 있어서가 아니다. 내가 얻으려 노력했기 때문이 아니다. 파괴와 상실과 마찬가지로 좋은 것들 역시 혼돈의 일부이기 때문이다. 죽음의 이면인 삶. 부패의 이면인 성장.\n그 좋은 것들, 그 선물들, 내가 눈을 가늘게 뜨고 황량함을 노려보게 해주고, 그것을 더 명료히 보게 해준 요령을 절대 놓치지 않을 가장 좋은 방법은 자신이 보고 있는 것이 무엇인지 전혀 모른다는 사실을, 매 순간, 인정하는 것이다. 산사태처럼 닥쳐오는 혼돈 속에서 모든 대상을 호기심과 의심으로 검토하는 것이다.\n요약 # 우리가 지어낸 질서를 무너뜨리고 그 짜임을 풀어내는 것이 우리가 해야할 일이다.\n라고 하는데, \u0026lsquo;진실이 아닌 모든 것을 믿지 않기\u0026rsquo; 또한 맹목적으로 느껴짐. 유용하다면 취하기 vs 진실이 아닌 모든 것을 믿지 않기. 이 둘 사이를 왔다갔다\u0026hellip; 물고기를 놓아주는 일이 사람에 따라 다 다르듯이 \u0026lsquo;사실\u0026rsquo;의 중요도는 내게 엄연히 다르다. 어떤 사실에 대한 태도를 둘 사이의 어느 지점에 할당할지는 나만의 기준으로 정하면 되는 것이다.\n플레이리스트 # 2024-12-31 # 읽으면서 듣기에 딱은 아니지만(집중력 흐려짐) 좋았던 부분 타이핑하면서 듣기엔 딱이다!\n"},{"id":30,"href":"/docs/hobby/book/book7/","title":"책","section":"책","content":" 일론 머스크 | 월터 아이작슨 # 똑똑하면서 적당히 착한 마음이 있는 사람은 다 좋다.\n머스크는 태풍이 몰려올 때 가장 강력한 생기를 느끼는 그런 사람 중 한 명이다. “나는 폭풍을 위해 태어났어요. 그러니 고요함은 나에게 적합하지 않지요.” 미국의 7대 대통령 앤드류 잭슨이 한 말이다. 일론 머스크도 마찬가지다. 그는 위기나 데드라인, 할 일의 폭증과 같은 상황에서 번성했다. 복잡하고 난해한 도전에 직면하면, 그로 인한 긴장으로 종종 잠을 이루지 못하거나 심지어 토하기도 했다. 그러나 그런 상황은 그에게 활력도 불어넣었다. “형은 드라마를 끄는 자석과 같아요.” 킴벌이 말한다. “드라마가 그의 강박이자 삶의 주제입니다.”\n목록 # 화성 북마크 구매!!\n[관련 영상][일론 머스크] 제1원리 사고법: 추정이 아닌 근본적인 문제로의 접근\n[북마크] X1\n그러나 저스틴은 항상 자녀에게 감정적으로 관심을 기울이는 일론이 아버지와는 근본적으로 다르다고 말한다. “에롤을 보면 정말로 주변에서 나쁜 일이 일어날 것 같은 분위기를 느낄 수 있어요. 반면에 좀비가 창궐하는 대재앙이 발생한다면 일론의 팀에 속하고 싶을 거예요. 일론이라면 좀비를 줄 세우는 방법을 알아낼 것이기 때문이죠. 그는 매우 냉혹할 수 있지만, 결국에는 승리할 방법을 찾아낼 것이라는 믿음을 주는 사람이에요.”\n[북마크] X2\n머스크는 또한 1994년에 접어들며 급격히 확산되기 시작한 태양광 발전이 지속 가능한 에너지로 나아가는 최선의 길이라고 확신하게 되었다. 그의 졸업논문 제목은 〈태양광의 중요성〉이었다. 기후변화의 위험성뿐만 아니라 화석연료 매장량이 줄어들기 시작할 것이라는 사실도 그에게 동기를 부여했다. 그는 “사회는 곧 재생 가능한 동력원에 집중할 수밖에 없게 될 것이다”라고 썼다. 논문의 마지막 페이지에서는 ‘미래의 발전소’에 대해 설명하고 있는데, 거기에는 태양 전지판에 햇빛을 집중시켜 생성한 전기를 마이크로파 빔을 통해 지구로 다시 보내는, 거울들이 달린 위성이 포함되었다. 교수는 “느닷없이 제시한 마지막 수치만 제외하면 매우 잘 쓴 흥미로운 논문”이라는 평가와 함께 98점을 주었다.\n[북마크] X3\n충동적으로 자신의 욕구를 분출한 이후, 그는 새롭게 발견한 자신의 부에 대한 취향을 경솔하게 과시하는 것이 꼴사나운 짓임을 깨달았다. “어떤 사람들은 이 차를 구입한 것을 보고 건방진 제국주의자의 전형적인 행동방식으로 해석할 수도 있습니다. 제 가치관이 변했을지 모르지만, 저는 제 가치관이 변했다는 것을 의식적으로 자각하지 못하고 있습니다.”\n과연 그가 변한 걸까? 새롭게 얻은 부로 그는 자신의 욕망과 충동에 거의 제약을 받지 않게 되었지만, 그런 상황은 항상 보기 좋은 것은 아니었다. 하지만 그의 진지하고 사명감 넘치는 강렬함은 조금도 변함이 없었다.\n[북마크] X4\n틸은 머스크에게 잠재적 합병조건을 어떻게 구상하고 있는지 물었다. 머스크는 “합병된 회사의 90퍼센트는 우리가 소유하고 10퍼센트는 당신들이 소유하는 것”이라고 대답했다. 레브친은 머스크의 말을 어떻게 받아들여야 할지 알 수 없었다. 진담인가? 두 회사의 고객 기반은 거의 비슷했다. 레브친은 말한다. “머스크는 농담하는 게 아니라는 듯 매우 진지한 표정을 짓고 있었지만, 그 이면에 무언가 아이러니한 구석이 있는 것 같았어요.” 머스크는 나중에 레브친의 말을 인정하며 말했다. “사실 우리는 게임을 하고 있었던 거예요.”\n점심을 먹고 나오며 레브친은 틸에게 이렇게 말했다. “이 거래는 절대 성사될 수 없을 것 같네요. 그냥 우리끼리 다음 행보를 밟기로 하죠.” 하지만 틸은 사람을 읽는 데 더 능숙했다. 그래서 레브친에게 말했다. “이제 막 시작했을 뿐이에요. 머스크 같은 친구는 인내심을 갖고 상대해야 해요.”\n[북마크] X5\n레브친은 머스크를 어떻게 이해하면 좋을지 고민이 됐다. 그의 팔씨름 제안은 진담이었을까? 바보 같은 유머와 게임 플레이로 간간이 중단되곤 하는 일련의 광적인 격렬함은 계산된 것일까, 아니면 그저 발광일 뿐인가? 레브친은 말한다. “그가 하는 모든 일에는 아이러니가 있어요. 그는 11까지 올라가지만 4 이하로는 내려가지 않는 아이러니 설정 상태에서 움직입니다.” 머스크의 힘 중 하나는 다른 사람들을 자신의 아이러니 서클로 끌어들여 자기들만 아는 농담을 공유할 수 있게 하는 것이다. “그는 자신의 아이러니 화염방사기를 켜고 일론 클럽의 회원이라는 배타적인 의식을 만들어내죠.”\n칩을 테이블에서 거두지 않고 계속 리스크를 감수하는 것, 그것은 그의 인생의 주제가 되었다. 그리고 그것은 그에게 좋은 전략인 것으로 드러났다. 틸은 말한다. “그가 이어서 설립한 두 회사, 스페이스X와 테슬라를 보세요. 실리콘밸리의 통념에 따르면 이 두 회사는 모두 엄청나게 미친 도박이었지요. 하지만 모두가 불가능하다고 생각하던 두 개의 미친 회사가 성공한다면, 사람들은 무슨 생각이 들까요? ‘일론은 리스크와 관련해 다른 사람들이 알지 못하는 무언가를 이해하고 있는 게 틀림없어.’ 이렇게 생각하지 않을까요?”\n[북마크] ♥️X6\n일론이 도저히 집으로 돌아가지 못하겠다고 해서 킴벌은 부부가 베벌리윌셔 호텔에 머물도록 조처했다. 호텔 지배인은 그들에게 프레지덴셜 스위트를 내주었다. 일론은 그에게 호텔로 가져왔던 네바다의 옷과 장난감을 치워달라고 부탁했다. 일론이 가까스로 집에 가서 한때 아들의 방이었던 곳을 보기까지 3주가 걸렸다.\n일론은 슬픔을 조용히 감내했다. 퀸스대학교에서 사귄 친구 나베이드 패룩은 그가 집에 돌아오자마자 로스앤젤레스로 날아와 곁을 지켰다. 패룩은 말한다. “저스틴과 나는 그간의 일에 대한 대화에 일론을 끌어들이려 했지만, 그는 그 일에 대해 이야기하고 싶어 하지 않았지요.” 그래서 그들은 대신 영화를 보고 비디오 게임을 하며 시간을 보냈다. 오랜 침묵의 시간이 흐른 후 패룩이 물었다. “기분은 어때? 잘 견디고 있는 거지?” 하지만 일론은 그런 대화 자체를 완전히 차단했다. “그의 표정을 읽을 수 있을 정도로 오랫동안 그를 알고 지내온 사이였기에 그가 그 일에 대해 이야기하지 않기로 결심했다는 것을 알 수 있었어요.” 패룩의 말이다. 저스틴은 그가 그렇게 감정을 억압하는 것이 어린 시절에 발달된 방어기제 때문이라고 생각한다. “그는 어두운 상황에 처하면 감정을 차단해버려요. 그에게는 그것이 생존을 위한 방법인 것 같아요.”\n[북마크] ♥️X7\n뮬러는 스페이스X의 첫 번째 주요 영입자가 되었다. 뮬러가 고집한 한 가지 조건은 머스크가 그의 2년 치 보수를 조건부 날인 증서로 보장해주는 것이었다. 머스크는 동의했다. 하지만 이 일로 머스크는 뮬러를 스페이스X의 공동창업자가 아닌 직원으로 여기게 되었다. 이것은 머스크가 페이팔 시절에도 중요하게 여겼고, 테슬라를 창업하면서도 마찬가지로 중시할 투자와 관련된 문제였다. 그는 회사에 투자할 의사가 없다면 창업자 자격이 없다고 생각했다. \u0026ldquo;2년치 월급을 조건부 날인 증서로 예치해달라면서 자신을 공동창업자라고 생각해서는 안되는 거지요.\u0026rdquo; 머스크는 말한다. \u0026ldquo;공동창업자가 되려면 영감과 땀, 리스크가 어느 정도 조합이 되어야 하는 겁니다.\u0026rdquo;\n화성 # 2024-12-31 # 알라딘 중고서점 갔다가 화성 북마크 보여서 ㅎㅎ 이책 생각나서 구매함.\n관련 영상 # 2024-12-31 # [일론 머스크] 제1원리 사고법: 추정이 아닌 근본적인 문제로의 접근\nhttps://youtu.be/BWxYWnwi08o?si=dC6veL5s0JWogbbz\nI do think there’s a good framework for thinking. It is physics. You know, the sort of first principles reasoning. Generally I think there are.. what I mean by that is boil things down to their fundamental truths and reason up from there, as opposed to reasoning by analogy. Through most of our life, we get through life by reasoning by analogy, which essentially means copying what other people do with slight variations. And you have to do that. Otherwise, mentally you wouldn’t be able to get through the day. But when you want to do something new, you have to apply the physics approach. Physics is really figuring out how to discover new things that are counterintuitive, like quantum mechanics. It’s really counterintuitive. So I think that’s an important thing to do, and then also to really pay attention to negative feedback, and solicit it, particularly from friends. This may sound like simple advice, but hardly anyone does that, and it’s incredibly helpful.\n글쎄요.. 저는 생각을 할 때 써먹기 좋은 어떠한 틀이 있다고 보는데 바로 물리입니다. 일종의 제1원리 사고법 이라고 할까요. 일반적으로 저는.. 그러니까 이게 무슨 말이냐면, 물질의 근본적인 것까지 파고들어 그로부터 다시 생각해 나가는 것인데요, 유추해 나가는 방식과는 반대되는 개념입니다. 우리 대부분은 인생을 살아가면서 유추한 것을 기반으로 살아가죠. 이는 달리 말해 다른 사람들이 하는 것을 약간의 변화만을 주어 따라 한다는 건데요. 평소에는 그렇게 하는게 맞아요. 그렇지 않으면 정신적으로 하루하루를 버텨내기 힘드실테니까요. 그러나 무언가 새로운 걸 하고자 하신다면 물리학적으로 접근하셔야 합니다. 물리학은 직관에서 벗어나 어떻게 하면 새로운 것을 발견할 수 있을지 생각해 나가는 것인데 양자역학을 예로 들 수 있겠네요. 직관에 전혀 의존하지 않습니다. 그래서 저는 이런 사고방식이 중요하다고 생각하고 또한 부정적인 평가에도 귀를 기울일 줄 아셔야 합니다. 특히 친구들로부터 그런 평가를 해달라고 부탁하세요. 이게 정말 평범한 조언같이 들리시겠죠, 거의 대부분은 무시하시니까요. 정말 도움이 되는데도 말입니다.\nI think it’s also important to reason from first principles, rather than by analogy. So the normal way that we conduct our lives is we reason by analogy. It’s… we’re doing this because it’s like something else that was done, or it’s like what other people are doing. Cause it’s kind of mentally easier to reason by analogy, rather than from first principles. But first principle is kind of a physics way of looking at the world. And what that really means is you kind of boil things down to the most fundamental truths, and say, OK, what are we sure is true? Or sure as possible is true? and then reason up from there. That takes a lot more mental energy. Somebody could say, in fact, people do that battery packs are really expensive and that’s just the way the’ll always be because that’s the way they’ve been in the past. I’m like. Well, No. that’s pretty dumb, you know, because if you apply that reasoning to anything new, then you wouldn’t be able to ever get to that new thing. So, you know, it’s.. like, you can’t say. Oh, you know horses.. nobody wants a car because horses are great, and we’re used to them and they can eat grass, there’s lots of grass all over the place and you know, there’s not like, there’s no gasoline that people can buy. So people will never going to get cars. People did say that. And for batteries, they would say, oh, it’s gonna cost.. You know, historically it’s cost 600 dollars per kilowatt hour, and so.. it’s gonna be much better than that in the future. I would say, no, okay, what are the batteries made of? So with the first principles, we say, ok. What are the material constituents of the batteries? What is the stock-market value of the mateiral constituents? So you can say, ok, it’s got cobalt, nickel, aluminum, carbon, and some polymers for separation, and a seal can. So break that down on a material basis and say, if we bought that on the London Metal Exchange, what would each of those things cost? Oh geez, it’s like $80 per kilowatt hour. So clearlly you just need to think of clever ways to take those materials and combine them into the shape of a better call, and you can have batteries that are much, much cheaper than anyone realizes.\n저는 유추를 하는 것보다는 제1원리에서부터 추론을 시작하는 것이 중요하다고 생각하는데요. 우리는 인생의 계획을 세울 때도 보통 유추를 바탕으로 계획을 수립하곤 하는데요. 그렇게 하는 이유는 지금껏 다른 것들도 다른 방식으로 행해져 왔기 때문이겠죠. 아니면 다른 누군가도 그렇게 해왔으니까요. 유추로부터 추론해 나가는 것은 그게 정신적으로 덜 힘들기 때문이겠죠, 제1원리를 따르는 것보다 말이에요. 제1원리는 물리학적 방식으로 세상을 바라보는 것이거든요. 이게 무슨 말이냐면, 가장 근본적인 논거에 이르기까지 어떠한 문제를 압축해 나가는 건데요, 예를 들어, 우리가 정말 참이라고 확신할 수 있는 것에는 무엇이 있을까? 라는 질문으로부터 추론을 시작해 나가는 겁니다. 이렇게 하면 정신적으로는 더 힘이 들겠지만요. 어떤 분들은.. 사실 정말로 이렇게 말씀들을 많이 하시는데 배터리 팩의 가격은 너무 비싸고 앞으로도 계속 비싸겠지. 과거에도 그래왔으니까. 그럼 저는, 아닌데! 그거 참 멍청한 소리 같은데? 무언가 새로운 것을 만드는 데 그런 식의 추론을 적용한다면 절대로 새로운 무언가를 만들어내지 못할 테니까. 그래서.. 뭐 이런 소리를 하면 곤란하겠죠, 말의 경우에는.. 말이 워낙 훌륭해서 차를 원하는 사람은 없을거야. 우리는 말을 타는 게 익숙하다고, 말은 풀도 뜯어 먹고, 여기 온 사방이 풀로 뒤덮여 있잖아. 지금 이곳을 봐, 사람들이 기름을 어디서 사냐고. 그러니 사람들은 절대로 차를 안 살거야. 진짜로 사람들이 이런 말을 했어요. 그래서 배터리 같은 경우에도 사람들이, 비용이 너무 많이 들어..역사적으로 보면 1킬로와트시(kWh) 당 600 달러가 드는데 미래에 이보다 가격이 더 떨어질 것 같지 않아.. 라고 말하면, 저는 이런 질문을 합니다. 그래? 배터리팩은 뭘로 만들어지지? 그러니까 제1원리로 접근하면 이런거죠. 배터리를 구성하는 물질 성분들은 어떤 것들이 있지? 거래소에서 이 물질들의 가치는 어떻게 형성되어 있지? 그러고 나서 이제, 배터리 팩은 코발트, 니켈, 알루미늄, 카본, 가체 분리용 중합체 그리고 밀봉된 캔으로 구성되는구나. 그럼 이러한 성분의 기저로부터 세부적으로 쪼개 들어가, 이 금속들을 런던금속거래소에서 구매한다면, 각각의 금속들은 얼마 정도 할까? 질문하는 겁니다. 그랬더니 뭐야! 1킬로와트시당 80달러 정도밖에 안 드네! 이와 같이 각각의 물질들을 보다 영리하게 접근해서 이를 배터리의 형태로 결합할 수 있는지 생각해 보는 겁니다. 그러면 그 누구도 생각지 못할 만큼 훨씬 저렴한 배터리도 만들 수 있게 되는 거죠.\nX1 # 2024-12-31 # 1 # 일론 머스크가 물려받은 유산과 혈통은 그의 뇌 배선과 어우러져 때때로 그를 냉담하게도, 충동적이게도 만들었다. 그리고 그것은 또한 리스크에 대한 극도로 높은 수준의 내성으로 이어졌다. 그는 리스크를 냉정하게 계산할 수도 있었고, 열정적으로 수용할 수도 있었다. “일론은 리스크 그 자체를 원합니다.” 페이팔PayPal 초창기에 머스크의 파트너로 일했던 피터 틸은 말한다. “그는 리스크를 즐기는 듯합니다. 때로는 정말 리스크에 중독된 것처럼 보이기도 하고요.”\n머스크는 태풍이 몰려올 때 가장 강력한 생기를 느끼는 그런 사람 중 한 명이다. “나는 폭풍을 위해 태어났어요. 그러니 고요함은 나에게 적합하지 않지요.” 미국의 7대 대통령 앤드류 잭슨이 한 말이다. 일론 머스크도 마찬가지다. 그는 일과 연애 양 측면에서 폭풍과 드라마를 끌어당기는 힘, 때로는 갈망을 발달시켰다(그래서 그가 그렇게 부부 또는 연인관계를 유지하는 데 어려움을 겪은 것이리라). 그는 위기나 데드라인, 할 일의 폭증과 같은 상황에서 번성했다. 복잡하고 난해한 도전에 직면하면, 그로 인한 긴장으로 종종 잠을 이루지 못하거나 심지어 토하기도 했다. 그러나 그런 상황은 그에게 활력도 불어넣었다. “형은 드라마를 끄는 자석과 같아요.” 킴벌이 말한다. “드라마가 그의 강박이자 삶의 주제입니다.”\n2 # 예전에 내가 스티브 잡스에 관해 취재하던 당시, 그의 파트너였던 스티브 워즈니악은 다음과 같은 질문을 제기하는 것이 중요하다고 말했다. “그가 꼭 그렇게 비열하게, 꼭 그렇게 거칠고 잔인하게, 꼭 그렇게 매번 드라마틱하게 굴었어야 했을까?” 인터뷰 말미에 해당 질문과 관련해 본인은 어떻게 다른지를 묻자, 워즈니악은 만약 자신이 애플을 경영했더라면 그보다는 좀 더 온화하게 처신했을 것이라고 답했다. 직원 모두를 가족처럼 대했을 것이고, 즉결로 해고하거나 그러지도 않았을 것이라고 했다. 그런 후 잠시 멈추었다가 이렇게 덧붙였다. “하지만 만약 내가 애플을 경영했더라면, 매킨토시 같은 것은 결코 만들어내지 못했을 겁니다.” 우리는 일론 머스크에 대해서도 유사한 질문을 떠올릴 수 있을 것이다. “만약 그가 괴팍하지 않았다면 과연 우리를 전기차의 미래로, 그리고 화성으로 인도하는 사람이 될 수 있었을까?”\n2022년 초, 스페이스X에서 31차례나 로켓을 성공적으로 발사했고, 테슬라의 자동차가 100만 대 가까이 팔렸으며, 머스크가 지구상에서 가장 부유한 사람으로 등극한 기념비적인 한 해를 보내고 새로운 해를 맞으며 머스크는 극적인 상황을 만들어내는 자신의 충동에 대해 유감스럽다는 듯이 말했다. “아무래도 사고방식을 위기 모드에서 다른 것으로 전환해야 할 필요가 있는 것 같아요.” 그가 나에게 한 말이다. “대략 지난 14년 동안 위기 모드로 살아왔거든요. 아니 거의 평생을 그랬다고 하는 게 맞겠네요.”\n그것은 새해 결심이라기보다는 아쉬움을 담은 말이었다. 그런 맹세를 했음에도 그는 세계 최상의 놀이터라 할 수 있는 트위터의 주식을 비밀리에 사들이고 있었다.\n3 # 머스크는 나중에 자신이 아스퍼거증후군을 앓고 있다고 밝히고 심지어 농담까지 하곤 했다. 아스퍼거증후군은 자폐 스펙트럼 장애의 한 형태에 대한 일반적인 명칭으로, 사회성과 인간관계, 정서적 연결, 자기 조절 능력 등에 영향을 미칠 수 있다. “어렸을 때 실제로 그런 진단을 받은 적은 한 번도 없거든요.” 어머니의 말이다. “하지만 본인이 그렇다고 하니 그 말이 맞겠지요.” 그의 그런 상태는 어린 시절의 트라우마로 악화되었다. 그의 절친한 친구 안토니오 그라시아스에 따르면, 성인이 된 이후에도 그는 괴롭힘을 당하거나 위협을 받는다고 느낄 때면 어린 시절에 얻은 외상후 스트레스장애가 뇌에서 감정을 조절하는 부분인 변연계를 완전히 장악해버렸다.\n그 결과 그는 사회적 신호를 잘 포착하지 못했다. “나는 사람들이 무언가를 말하면 액면 그대로 받아들이곤 했어요.” 그의 말이다. “사람들이 말하는 내용이 항상 진심은 아니라는 것을 오로지 독서를 통해 배웠어요.” 그는 공학, 물리학, 코딩과 같은 보다 정확한 주제를 선호했다.\n모든 심리적 특성이 그렇듯이 머스크의 특성 역시 복합적이고 개별화되어 있었다. 그는 특히 자녀와 관련해서는 매우 따뜻해질 수 있었고, 혼자 있게 되면 불안감을 심하게 느꼈다. 그러나 그에게는 일상적인 친절이나 따뜻함, 사랑받고 싶은 욕구를 만들어내는 감정 수용기가 없었다. 그는 공감 능력을 타고나지 못했다. 덜 전문적인 용어로 표현하자면, 그는 개자식처럼 굴 수도 있었다.\n4 # 하느님에 대한 경외심이 더 돈독했던 아버지는 일론에게 우리의 제한된 감각과 머리로는 알 수 없는 것들이 있다고 설명했다. “조종사 중에는 무신론자가 없는 법이지요.” 그의 말이다. 일론은 나중에 이렇게 덧붙였다. “시험 시간에는 무신론자가 없는 법이지요.” 하지만 일론은 일찍부터 과학이 모든 상황을 설명할 수 있으므로 창조주나 신성을 불러내 삶에 개입시킬 필요가 없다고 믿게 되었다.\n청소년기에 접어든 일론은 무언가 빠졌다는 생각에 시달리기 시작했다. 존재에 대한 종교적 설명과 과학적 설명 모두 ‘우주는 어디에서 왔으며 왜 존재하는가?’와 같은 정말 중요한 질문을 다루지 않았다고 그는 말한다. 물리학은 우주에 대한 모든 것을 가르칠 수 있었지만, 그 존재의 이유는 설명하지 못했다. 그것은 그가 스스로 ‘청소년기의 실존적 위기’라고 부르는 것으로 이어졌다. “나는 삶과 우주의 의미가 무엇인지 알아내려고 노력하기 시작했어요.” 그는 말한다. “그리고 인간의 삶이란 것이 아무런 의미가 없을지도 모른다는 생각에 정말 우울해졌지요.”\n훌륭한 책벌레들이 그러하듯이, 그는 독서를 통해 이런 의문을 해결했다. 처음에 그는 불안한 청소년의 전형적인 실수를 저질렀다. 니체나 하이데거, 쇼펜하우어와 같은 실존주의 철학자들의 책을 읽은 것이다. 이것은 일론의 혼란을 절망으로 바꾸어놓았다. “십대들에게는 니체를 읽으라고 권하면 안 된다고 생각합니다.” 일론은 말한다.\n5 # 머스크의 그런 청소년기에 가장 큰 영향을 미친 공상과학 소설은 더글러스 애덤스의 《은하수를 여행하는 히치하이커를 위한 안내서》였다. 유쾌함과 풍자가 넘치는 이 이야기는 머스크가 나름의 철학을 형성하는 데 도움이 되었고, 그의 진지한 표정에 익살스러운 유머를 더해주었다. “그 책은 내가 실존적 우울증에서 벗어나는 데 실제로 도움이 되었어요. 그 책을 읽는 순간 모든 부분에서 미묘한 방식으로 놀랄 만큼 재미있다고 생각했어요”라고 그는 말한다.\n이 소설에는 초공간 고속도로를 건설하는 외계 문명에 의해 지구가 파괴되기 몇 초 전에 지나가는 우주선에 의해 구조되는 아서 덴트라는 인간이 등장한다. 덴트는 자신을 구해준 외계인과 함께 “불가해성을 예술로 바꾼” 머리 두 개 달린 대통령이 통치하는 은하계의 다양한 구석구석을 탐험한다. 은하계의 주민들은 “생명과 우주, 그리고 모든 것에 대한 궁극적인 의문에 대한 답”을 알아내려고 노력하며 슈퍼컴퓨터를 만들지만, 그 컴퓨터는 700만 년 이상이 지난 후 그 질문에 대해 ‘42’라는 답을 내놓는다. 당황한 외계인들이 어리둥절해하며 법석을 떨자 컴퓨터는 응답한다. “확실히 답이 그렇게 나왔습니다. 솔직히 말해서 문제는 여러분이 질문이 무엇인지 제대로 알지 못한다는 것입니다.” 이 교훈은 머스크에게 그대로 각인되었다. “나는 그 책을 통해 의식의 범위를 확장해야 답을 얻을 수 있는 질문을 더 잘 던질 수 있다는 것을 깨달았어요. 우리 의식의 범위를 우주로 확장해야 하는 거지요.”\n6 # 아버지에 대한 이야기를 나눌 때 일론은 때때로 다소 거칠고 쓴 웃음을 터뜨렸다. 아버지와 비슷한 웃음이었다. 일론이 사용하는 일부 단어와 그가 응시하는 방식, 빛에서 어둠으로 그리고 다시 빛으로 갑작스럽게 변하는 모습은 그의 가족들에게 그의 내부에서 부글부글 끓고 있는 에롤을 떠올리게 한다. “일론이 나에게 들려준 끔찍한 이야기의 그림자가 자신의 행동방식에서 드러나는 것을 보곤 했어요.” 일론의 첫 번째 부인인 저스틴의 말이다. “그것은 우리가 원하든 원치 않든 자신이 성장한 환경의 영향을 받지 않는 것이 얼마나 어려운 일인지를 깨닫게 해주었지요.” 이따금 그녀는 감히 “당신이 아버지로 변하고 있어요”와 같은 말을 입에 올렸다. “사실 그것은 그가 어둠 속으로 들어가고 있음을 경고하는 우리의 암호였어요”라고 그녀는 설명한다.\n그러나 저스틴은 항상 자녀에게 감정적으로 관심을 기울이는 일론이 아버지와는 근본적으로 다르다고 말한다. “에롤을 보면 정말로 주변에서 나쁜 일이 일어날 것 같은 분위기를 느낄 수 있어요. 반면에 좀비가 창궐하는 대재앙이 발생한다면 일론의 팀에 속하고 싶을 거예요. 일론이라면 좀비를 줄 세우는 방법을 알아낼 것이기 때문이죠. 그는 매우 냉혹할 수 있지만, 결국에는 승리할 방법을 찾아낼 것이라는 믿음을 주는 사람이에요.”\n그러기 위해서 그는 앞으로 나아가야 했다. 남아공을 떠날 시간이었다.\nX2 # 2024-12-31 # 1 # 그는 아버지처럼 공학에 끌렸기에 물리학을 전공하기로 결정했다. 그가 느낀 엔지니어의 본질은 어떤 문제든 물리학의 가장 근본적인 원리를 파고들어 해결책을 찾는 것이었다. 그는 또한 공동 학위 과정을 밟아 경영학도 전공하기로 했다. “경영학을 공부하지 않으면 경영학을 공부한 누군가의 밑에서 일하게 될까 봐 걱정이 되었지요.” 그는 말한다. “내 목표는 물리학의 감각으로 제품을 설계 및 제작하는 것, 그리고 경영학을 전공한 보스를 위해 일할 필요가 없게 되는 것이었어요.”\n그는 정치적이지도 사교적이지도 않았지만 학생회 임원 선거에 출마했다. 그의 선거 공약 중 하나는 이력서를 화려하게 채우기 위해 학생회 활동을 하려는 학생들을 조롱하는 내용이었다. 그의 선거 공약 중 마지막 약속은 다음과 같았다. “만약 내가 이력서에 이 경력을 써 넣는다면, 공공장소에서 물구나무를 서서 이 공약서 50부를 씹어 먹겠습니다.”\n다행히도 그는 낙선했고, 덕분에 기질적으로 맞지 않는 학생자치회 유형의 학생들과는 어울릴 필요가 없었다. 대신 그는 과학적 힘과 관련된 영리한 농담을 하고 ‘던전앤드래곤’ 게임 및 비디오 게임에 탐닉하며 컴퓨터 코드 작성을 좋아하는 일단의 컴퓨터광 무리에 편안히 섞여들었다.\n2 # 렌은 머스크가 훗날의 경력 형성과 관계된 세 가지 분야에 집중했다고 회상한다. 중력을 측정하든 중력의 속성을 분석하든 그는 늘 렌과 로켓 제작에 적용되는 물리 법칙에 대해 논의했다. “그는 화성에 갈 수 있는 로켓을 만드는 것에 대해 계속 이야기했습니다.” 렌의 말이다. “물론 나는 그가 환상을 품고 있다고 생각했기에 별로 주의를 기울이지 않았지요.”\n머스크는 전기차에도 집중했다. 그와 렌은 종종 푸드 트럭 중 하나에서 점심을 급히 해결하고 캠퍼스 잔디밭에 앉아 쉬곤 했는데, 그때마다 머스크는 배터리에 관한 학술 논문을 읽곤 했다. 마침 캘리포니아 주에서 2003년까지 차량의 10퍼센트를 전기자동차로 전환할 것을 요구하는 법령이 막 통과된 시점이었다. 머스크는 “내가 그렇게 되도록 만드는 주역이 되고 싶어”라고 말했다.\n머스크는 또한 1994년에 접어들며 급격히 확산되기 시작한 태양광 발전이 지속 가능한 에너지로 나아가는 최선의 길이라고 확신하게 되었다. 그의 졸업논문 제목은 〈태양광의 중요성〉이었다. 기후변화의 위험성뿐만 아니라 화석연료 매장량이 줄어들기 시작할 것이라는 사실도 그에게 동기를 부여했다. 그는 “사회는 곧 재생 가능한 동력원에 집중할 수밖에 없게 될 것이다”라고 썼다. 논문의 마지막 페이지에서는 ‘미래의 발전소’에 대해 설명하고 있는데, 거기에는 태양 전지판에 햇빛을 집중시켜 생성한 전기를 마이크로파 빔을 통해 지구로 다시 보내는, 거울들이 달린 위성이 포함되었다. 교수는 “느닷없이 제시한 마지막 수치만 제외하면 매우 잘 쓴 흥미로운 논문”이라는 평가와 함께 98점을 주었다.\n3 # 레시는 나중에 일론이 약간 무심한 것처럼 보인다는 사실에 놀랐다. “그는 파티에 참석하는 것을 즐겼지만, 완전히 파티에 빠지지는 않았어요. 그가 진정으로 탐닉한 것은 오로지 비디오 게임이었지요.” 레시가 보기에, 일론은 그 많은 파티에 참석하면서도 인간의 사교적인 행동을 배우려는 다른 행성의 관찰자처럼 근본적으로 소외감을 느끼며 물러나 있었다. “일론이 조금 더 행복해지는 방법을 알았으면 좋겠어요”라고 레시는 말했다.\nX3 # 2024-12-31 # 1 # 머스크는 여름이 끝날 무렵 스탠퍼드대학원에 진학하여 재료과학을 공부할 계획을 세웠다. 여전히 커패시터에 매료된 그는 그것으로 전기자동차에 전력을 공급할 수 있는 방법을 연구하고 싶었다. “첨단 칩 제조 장비를 활용하여 자동차의 주행거리를 늘리기에 충분한 에너지 밀도를 가진 고체 소자 울트라 커패시터를 만들어볼 생각이었어요.” 그는 말한다. 하지만 등록기간이 가까워지면서 걱정이 들기 시작했다. “스탠퍼드에서 몇 년을 보내고 박사학위까지 받았는데 그 커패시터가 실현 불가능한 것으로 밝혀지면 어떻게 해야 할 것인가, 하는 걱정이 들었어요. 사실 대부분의 박사학위는 무의미해요. 실제로 그 부류 가운데 세상에 진정한 변화를 가져오는 사람은 거의 없잖아요.” 머스크의 말이다.\n그 무렵 그는 마치 ‘만트라’처럼 되새기고 되새길 인생의 비전을 마음속에 품고 있었다. “인류에게 진정으로 영향을 미칠 수 있는 것이 무엇인지 생각했어요. 그리고 세 가지를 떠올렸지요. 인터넷, 지속 가능한 에너지, 우주여행.” 1995년 여름, 머스크는 그중 첫 번째인 인터넷이 그가 대학원을 마칠 때까지 기다려주지 않을 거라는 사실을 깨달았다. 얼마 전 웹이 상업용으로 개방되었으며, 8월 초에 브라우저 스타트업 넷스케이프Netscape가 IPO를 단행해 하루 만에 시가총액 29억 달러의 기업으로 날아오른 상황이었다.\n머스크는 사실 펜실베이니아대학교 졸업반 시절에 구상한 인터넷 기업에 대한 아이디어를 하나 갖고 있었다. 뉴욕 및 뉴잉글랜드 지역 전신전화 회사인 나이넥스NYNEX의 한 임원이 학교 강연회에 와서 옐로페이지(미국의 업종별 전화번호부-옮긴이)의 온라인 버전 출시 계획에 대해 밝혔을 때 떠올린 아이디어였다. ‘빅옐로Big Yellow’라는 이름의 그 온라인 버전은 인터랙티브 기능을 갖추어 사용자들이 자신의 필요에 따라 정보를 맞춤화할 수 있다는 것이 그 임원의 설명이었다. 하지만 머스크는 나이넥스가 진정한 인터랙티브의 구현 방법을 전혀 모른다고 생각했다(결과적으로 그것은 올바른 판단이었다). 그는 킴벌에게 “우리가 직접 만드는 게 어떨까?”라고 제안했다. 킴벌은 사업체 목록과 지도 데이터를 결합할 수 있는 코드를 작성하기 시작했고, 거기에 ‘버추얼 시티내비게이터Virtual City Navigator’라는 이름을 붙였다.\n스탠퍼드대학원 등록 마감일 직전, 머스크는 노바스코샤 은행의 피터 니콜슨에게 조언을 구하기 위해 토론토로 갔다. 버추얼 시티내비게이터에 대한 아이디어를 계속 추구해야 할까요, 아니면 박사과정을 시작하는 게 나을까요? 스탠퍼드에서 박사학위를 받은 니콜슨은 애매하게 둘러말하지 않았다. “인터넷 혁명 같은 것은 일생에 단 한 번 올까 말까 한 기회라네. 물 들어올 때 노 저으라는 말이 있지 않은가.” 니콜슨은 머스크와 함께 온타리오 호숫가를 따라 걸으며 말했다. “대학원은 나중에라도 뜻만 있으면 얼마든지 갈 수 있지.” 머스크는 팰로앨토로 돌아와 렌에게 결심을 굳혔다고 말했다. “다른 모든 것은 보류하기로 했어. 지금은 인터넷의 물결에 올라탈 때야.”\n하지만 그는 사실 자신의 베팅에 보험을 들었다. 스탠퍼드에 정식 등록하고 즉시 휴학을 신청한 것이다. “실은 제가 최초로 인터넷 지도와 전화번호부를 갖춘 소프트웨어를 개발했습니다.” 머스크는 재료과학과 담당교수인 빌 닉스에게 이렇게 말했다. “아마 실패할 겁니다. 실패하는 경우 다시 돌아오고 싶습니다.” 닉스는 머스크가 학업을 연기하는 것은 문제 될 게 없다고 말했다. 그러면서 그는, 그렇지만 머스크가 다시 돌아오지 않을 것이라고 예측했다.\n2 # 머스크 형제는 수익금 가운데서 아버지에게 30만 달러를, 어머니에게 100만 달러를 드렸다. 일론은 50평짜리 콘도를 구입하고 당시 가장 빠른 양산차인 맥라렌 F1 스포츠카를 100만 달러에 구입하는 등 나름대로 궁극의 사치를 부렸다. 그는 그의 집에서 차가 배달되는 모습을 촬영하게 해달라는 CNN의 요청을 받아들였다. “불과 3년 전만 해도 YMCA에서 샤워를 하고 사무실 바닥에서 잠을 자던 제가 이제 100만 달러짜리 차를 갖게 되었습니다.” 머스크는 트럭에서 차가 내려지는 동안 이렇게 말한 후 거리를 이리저리 껑충껑충 뛰어다녔다.\n충동적으로 자신의 욕구를 분출한 이후, 그는 새롭게 발견한 자신의 부에 대한 취향을 경솔하게 과시하는 것이 꼴사나운 짓임을 깨달았다. “어떤 사람들은 이 차를 구입한 것을 보고 건방진 제국주의자의 전형적인 행동방식으로 해석할 수도 있습니다. 제 가치관이 변했을지 모르지만, 저는 제 가치관이 변했다는 것을 의식적으로 자각하지 못하고 있습니다.”\n과연 그가 변한 걸까? 새롭게 얻은 부로 그는 자신의 욕망과 충동에 거의 제약을 받지 않게 되었지만, 그런 상황은 항상 보기 좋은 것은 아니었다. 하지만 그의 진지하고 사명감 넘치는 강렬함은 조금도 변함이 없었다.\n작가 마이클 그로스는 실리콘벨리에서 티나 브라운의 번지르르한 잡지인 \u0026lt;토크\u0026gt;에 새로 부자가 된 테크노브랏techno-brat, 즉 기술 열풍을 타고 벼락부자가 된 젊은 리더들에 대한 기사를 쓰고 있었다. “날카롭게 비판해도 될 만한 허세 가득 찬 주인공을 찾고 있었습니다.” 그로스는 몇 년 후 이렇게 회상했다. “하지만 2000년에 만난 머스크는 삶의 환희가 넘치는, 너무 호감 가는 인물이라 비판할 수가 없었지요. 그는 지금과 마찬가지로 주변의 기대에 대해 무관심하고 무심했지만, 편하고 개방적이며 매력적이고 재미난 인물이었어요.”\nX4 # 2024-12-31 # 1 # 신규 가입 고객의 이름을 모니터링하던 중, 머스크는 이름 하나에 시선이 머물렀다. 바로 피터 틸이었다. 그는 엑스닷컴과 같은 건물에 있다가 지금은 거리 아래쪽으로 사무실을 옮긴 컨피니티Confinity라는 회사의 창업자 중 한 명이었다. 틸과 그의 주요 공동창업자 맥스 레브친은 모두 머스크만큼이나 열정적이었지만, 비교적 절제된 태도를 견지하는 사람들이었다. 엑스닷컴과 마찬가지로 컨피니티도 개인 간 결제 서비스를 제공했는데, 컨피니티의 시스템은 페이팔PayPal이라고 불렸다.\n2000년 초 인터넷 거품이 꺼질 조짐이 보이기 시작하던 무렵, 엑스닷컴과 페이팔은 신규 고객을 유치하기 위해 치열한 경쟁을 벌이고 있었다. “고객이 가입하고 친구를 추천하도록 유도하기 위해 양사 모두 엄청난 보너스를 지급하는 미친 경쟁을 벌이고 있었지요.” 틸의 설명이다. 나중에 머스크는 이렇게 표현했다. “어느 쪽이 먼저 돈이 바닥나는지 끝까지 가보자는 경쟁이었어요.” 머스크는 비디오 게임에 쏟던 열정으로 경쟁에 임했다. 반면에 틸은 냉정하게 계산하고 리스크를 완화하는 편을 좋아했다. 두 사람 모두 네트워크 효과(먼저 규모를 키우는 회사가 더욱 빠르게 성장하는 현상)로 인해 어느 한 회사만 살아남는다는 사실을 곧 깨달았다. 따라서 ‘모탈 컴뱃’ 게임식의 경쟁으로 치닫는 것보다는 합병하는 것이 합리적이라고 생각하게 되었다.\n머스크와 신임 CEO 빌 해리스는 팰로앨토에 있는 그리스 레스토랑 에비아의 별실에서 틸과 레브친을 만났다. 양측은 각자의 고객 보유 현황을 적은 메모를 교환했는데, 머스크는 거기에 평소처럼 나름의 과장을 섞어 넣었다. 틸은 머스크에게 잠재적 합병조건을 어떻게 구상하고 있는지 물었다. 머스크는 “합병된 회사의 90퍼센트는 우리가 소유하고 10퍼센트는 당신들이 소유하는 것”이라고 대답했다. 레브친은 머스크의 말을 어떻게 받아들여야 할지 알 수 없었다. 진담인가? 두 회사의 고객 기반은 거의 비슷했다. 레브친은 말한다. “머스크는 농담하는 게 아니라는 듯 매우 진지한 표정을 짓고 있었지만, 그 이면에 무언가 아이러니한 구석이 있는 것 같았어요.” 머스크는 나중에 레브친의 말을 인정하며 말했다. “사실 우리는 게임을 하고 있었던 거예요.”\n점심을 먹고 나오며 레브친은 틸에게 이렇게 말했다. “이 거래는 절대 성사될 수 없을 것 같네요. 그냥 우리끼리 다음 행보를 밟기로 하죠.” 하지만 틸은 사람을 읽는 데 더 능숙했다. 그래서 레브친에게 말했다. “이제 막 시작했을 뿐이에요. 머스크 같은 친구는 인내심을 갖고 상대해야 해요.”\n밀고당기는 협상 과정은 2000년 1월 내내 계속되었고, 머스크는 저스틴과의 신혼여행을 연기해야 했다. 엑스닷컴의 주요 투자자였던 마이클 모리츠는 샌드힐로드에 있는 자신의 사무실에서 양측이 만나도록 주선했다. 틸은 머스크의 맥라렌을 함께 타고 샌드힐로드로 향했다. “그래서, 이 차의 특별한 장점은 무엇인가요?” 틸이 물었다. “한번 보시죠.” 머스크는 그렇게 답하곤 추월차선으로 들어가 가속페달을 있는 힘껏 밟았다. 갑자기 뒷차축이 부러졌고 차가 빙글빙글 돌다가 갓길 경사면에 부딪힌 후 비행접시처럼 공중을 날았다. 차체 일부가 찢어졌다. 평소 자유주의를 실천하던 틸은 안전벨트를 매고 있지 않았지만, 다친 데 없이 빠져나왔다. 그는 지나가던 차를 얻어 타고 샌드힐로드의 세쿼이아 사무실까지 갈 수 있었다. 머스크도 다치지 않았고, 차를 견인시키기 위해 30분 정도 그 자리에 머물렀다가 세쿼이아로 왔다. 그는 해리스에게 무슨 일이 있었는지 말하지 않고 회의에 참석했다. 나중에 머스크는 웃으며 말했다. “적어도 내가 위험을 두려워하지 않는 사람이라는 것을 틸에게 보여준 거죠.” 틸은 동의한다. “맞아요, 그가 좀 미친 사람이라는 걸 깨달았죠.”\n2 # 머스크는 여전히 합병에 반대했다. 두 회사 모두 이베이의 전자결제를 위해 등록한 약 20만 명의 고객을 보유하고 있었지만, 그는 좀 더 광범위한 은행 서비스를 제공하는 엑스닷컴이 더 가치 있는 회사라고 믿었다. 그래서 그는 해리스와 갈등을 빚었고, 해리스는 만약 머스크가 합병 협상을 무산시키려 들면 사임하겠다고 위협하기에 이르렀다. “해리스가 그만두면 재앙이 닥칠 수 있는 상황이었어요. 인터넷 시장이 위축되고 있던 터라 더 많은 자금을 조달하기 위해 애쓰고 있었거든요.” 머스크의 말이다.\n머스크가 틸과 레브친과 다시 한번 점심식사를 하며 유대감을 형성하는 시간을 가지면서 상황은 달라졌다. 이번에 그들은 팰로앨토에 있는, 하얀 식탁보가 인상적인 이탈리아 레스토랑 일포르나이오에서 만났다. 음식을 기다리는 시간이 길어지자 해리스가 주방으로 뛰어들어가 어떤 요리부터 나올 수 있는지 살폈다. 머스크와 틸, 레브친은 서로를 바라보며 의미심장한 눈빛을 나누었다. 레브친은 말한다. “해리스는 극도로 외향적인 사업개발자 유형이었어요. 마치 가슴에 S자를 새긴 슈퍼맨처럼 행동했지요. 반면에 우리 셋은 뭐랄까, 비사교적인 괴짜들 같았다고나 할까요. 우리는 절대로 해리스처럼 나서서 설치진 않을 사람들이라는 점에서 유대감을 느꼈습니다.”\n양측은 엑스닷컴이 합병회사의 지분 55퍼센트를 갖는 조건에 합의했지만, 머스크가 곧이어 레브친에게 도둑질을 하고 있다고 비난하는 바람에 상황이 크게 꼬여버렸다. 격분한 레브친은 없던 일로 하자고 위협했다. 해리스는 레브친의 집으로 차를 몰고 가 빨래 개는 것을 도와주며 그를 진정시켰다. 계약 조건은 다시 한번 수정되어 기본적으로 50대 50으로 합병하되, 엑스닷컴이 존속법인으로 남는 것으로 합의되었다. 2000년 3월, 거래가 성사되었고 최대 주주였던 머스크가 의장으로 취임했다. 몇 주 후, 그는 레브친과 함께 해리스를 몰아내고(ㅋㅋ) CEO 자리도 되찾았다. 어른들의 지휘는 더 이상 환영받지 못했다.\nX5 # 2024-12-31 # 1 # 레브친은 머스크를 어떻게 이해하면 좋을지 고민이 됐다. 그의 팔씨름 제안은 진담이었을까? 바보 같은 유머와 게임 플레이로 간간이 중단되곤 하는 일련의 광적인 격렬함은 계산된 것일까, 아니면 그저 발광일 뿐인가? 레브친은 말한다. “그가 하는 모든 일에는 아이러니가 있어요. 그는 11까지 올라가지만 4 이하로는 내려가지 않는 아이러니 설정 상태에서 움직입니다.” 머스크의 힘 중 하나는 다른 사람들을 자신의 아이러니 서클로 끌어들여 자기들만 아는 농담을 공유할 수 있게 하는 것이다. “그는 자신의 아이러니 화염방사기를 켜고 일론 클럽의 회원이라는 배타적인 의식을 만들어내죠.”\n하지만 레브친에게는 그런 방식이 잘 먹히지 않았다. 그는 진지함이라는 자신의 방패로 머스크의 아이러니 화염방사기를 막아내고 있었다. 그는 머스크의 과장을 탐지하는 데 탁월한 레이더를 보유했다. 합병 과정에서 머스크는 엑스닷컴의 사용자가 2배 가까이 많다고 계속 주장했고, 레브친은 엔지니어들에게 확인하여 실제 사용자 수를 알아내곤 했다. “머스크는 단순히 과장하는 데서 그치는 게 아니라 없는 얘기를 지어내기도 했어요.” 레브친의 말이다. 그의 아버지가 종종 보여주던 행태였다.\n하지만 레브친은 그에 반하는 사례를 접하면서 경탄하기도 했다. 머스크가 박학다식으로 그를 놀라게 했을 때가 대표적인 경우다. 어느 날 레브친과 그의 엔지니어들은 사용 중인 오라클 데이터베이스와 관련한 어려운 문제로 씨름하고 있었다. 다른 일로 그 방에 들어선 머스크는 자신의 전문 분야는 오라클이 아닌 윈도였지만, 대화의 맥락을 즉시 파악하고 정확한 기술적인 답변을 내놓은 후 확인을 기다리지도 않고 방을 나갔다. 레브친과 그의 팀은 오라클 매뉴얼로 돌아가 머스크가 설명한 내용을 찾아보았다. “하나씩 하나씩 들여다보며 우리 모두 ‘젠장, 머스크 말이 맞네’라고 했지요.” 레브친의 회상이다. “머스크는 말도 안 되는 소리를 지껄이기도 하지만, 때로는 다른 사람의 전문 분야에 대해 그보다 훨씬 더 많이 알고 있어 사람들을 놀라게 하곤 하죠. 나는 그가 사람들에게 동기를 부여하는 방법 중 상당 부분이 바로 때때로 드러내는 그런 예리함에 있다고 생각합니다. 그를 헛소리꾼이나 바보로 잘못 알고 있던 사람들이 전혀 기대하지 않고 있다가 그런 면모에 세게 한 방 맞은 기분이 드는 거지요.”\n2 # 이사회에서 투표를 통해 머스크의 해임을 결정했을 때, 머스크는 지금까지 그의 격렬한 투쟁을 지켜본 사람들을 놀라게 할 만큼 차분하고 품위 있게 대응했다. 그는 직원들에게 보낸 이메일에 이렇게 썼다. “엑스닷컴을 다음 단계로 끌어올릴 경험 많은 CEO를 영입할 때가 되었다고 결정했습니다. 그 작업이 완료되면 3~4개월 정도 안식 기간을 갖고 몇 가지 아이디어를 검토해본 다음 새로운 회사를 설립할 계획입니다.”\n머스크는 길거리 싸움꾼이었음에도 의외로 패배에 현실적으로 대처할 수 있는 능력이 있었다. 나중에 옐프Yelp를 창업하는 머스크의 추종자 제러미 스토플먼이 이사회 결정에 대한 항의의 표시로 자신과 다른 몇몇이 사직해야 하는 거 아니냐고 물었을 때, 머스크는 아니라고 답했다. “회사는 나의 아기였고, 솔로몬 이야기에 나오는 어머니처럼 나는 회사가 살아남을 수 있도록 기꺼이 포기할 수 있었어요.” 머스크는 말한다. “나는 틸 및 레브친과의 관계를 회복하기 위해 열심히 노력하기로 결심했어요.”\n3 # 머스크는 3년 만에 두 번째로 회사에서 쫓겨났다. 그는 사람들과 잘 어울리지 못하는 선지자였다. 페이팔의 동료들이 머스크의 가차 없고 거친 스타일에 더하여 놀랐던 것은 리스크를 감수하려는 그의 의지, 심지어 욕망이었다. “기업가는 사실 리스크를 감수하는 사람이 아니지요.” 로로프 보타는 말한다. “기업가는 리스크를 완화하는 사람이에요. 리스크를 감수하면서 번창하려 하지도 않고 리스크를 증폭시키려 하지도 않죠. 대신 통제 가능한 변수를 파악해서 리스크를 최소화하려고 노력하지요.” 하지만 머스크는 그렇지 않았다. “그는 리스크를 증폭시키고 우리가 물러설 수도 없게 배를 불태워버리는 데 몰두했어요.” 보타가 보기에 머스크의 맥라렌 사고는 그런 성향을 상징적으로 보여주는 것이었다. 가속페달을 있는 대로 밟고 얼마나 빨리 달리는지 보려다 난 사고였기 때문이다.\n이것이 항상 리스크를 제한하는 데 집중하던 틸과 머스크가 근본적으로 다른 점이었다. 한번은 틸과 호프먼이 페이팔에서의 경험을 담은 책을 집필할 계획을 세웠다. 그들은 머스크에 관한 장의 제목을 “‘리스크’라는 단어의 의미를 이해하지 못한 남자”로 잡기로 했다. 하지만 그의 리스크 중독은 불가능해 보이는 일을 하도록 사람들을 이끈다는 면에서는 유용할 수도 있었다. 호프먼은 말한다. “머스크는 놀랍도록 성공적으로 사람들이 사막을 가로질러 행진하게 만들곤 하지요. 그는 모든 칩을 테이블 위에 올려놓을 수 있을 정도의 확신을 가지고 움직입니다.”\n이는 단순한 비유가 아니었다. 수년 후 레브친은 한 독신 친구의 아파트에서 머스크 등과 함께 어울렸다. 몇몇 사람들은 판돈을 크게 걸고 텍사스 홀덤이라는 포커 게임을 하고 있었다. 머스크는 카드 플레이어가 아니었음에도 테이블로 다가갔다. “카드를 외우고 확률을 계산하는 데 능한 컴퓨터광들과 타짜 수준의 꾼들이 모여 있었지요.” 레브친의 설명이다. “일론은 모든 판에서 올인을 걸었고, 당연히 졌지요. 그러자 칩을 더 사서 더블 다운을 하고, 계속 그런 식으로 플레이했어요. 그렇게 여러 판에서 돈을 잃은 후에 마침내 올인을 걸고 이겼지요. 그랬더니 ‘좋아, 여기까지’라고 하면서 일어서더군요.” 칩을 테이블에서 거두지 않고 계속 리스크를 감수하는 것, 그것은 그의 인생의 주제가 되었다.\n그리고 그것은 그에게 좋은 전략인 것으로 드러났다. 틸은 말한다. “그가 이어서 설립한 두 회사, 스페이스X와 테슬라를 보세요. 실리콘밸리의 통념에 따르면 이 두 회사는 모두 엄청나게 미친 도박이었지요. 하지만 모두가 불가능하다고 생각하던 두 개의 미친 회사가 성공한다면, 사람들은 무슨 생각이 들까요? ‘일론은 리스크와 관련해 다른 사람들이 알지 못하는 무언가를 이해하고 있는 게 틀림없어.’ 이렇게 생각하지 않을까요?”\n♥️X6 # 2024-12-31 # 1 # 머스크는 러시아인들이 받아내려 했던 터무니없는 가격을 곱씹으면서 제 1원리First Principles(다른 경험적 데이터를 필요로 하지 않는 \u0026lsquo;자명한 진리\u0026rsquo;)에 입각한 사고를 동원해 그 상황에 대한 기본 물리학을 파고들었고 거기서부터 차근차근 쌓아 올려나갔다. 그리고 이를 통해 완제품이 기본 재료비보다 얼마나 더 비싼지 계산하는 \u0026lsquo;바보 지수idiot index\u0026rsquo;를 개발했다. 제품의 \u0026lsquo;바보 지수\u0026rsquo;가 높으면 보다 효율적인 제조기술을 고안하여 비용을 크게 줄일 수 있다는 것을 의미했다.\n로켓은 \u0026lsquo;바보 지수\u0026rsquo;가 극도로 높았다. 머스크는 로켓에 들어가는 탄소섬유와 금속, 연료 및 기타 재료의 원가를 계산하기 시작했다. 기존의 방법을 사용한 완제품의 제작비용은 머스크가 계산한 원가보다 최소 50배 이상 비쌌다.\n인류가 화성에 가려면 로켓 기술이 획기적으로 개선되어야 했다. 중고 로켓, 특히 러시아의 오래된 로켓에 의존해서는 기술을 발전시킬 수 없었다.\n그래서 집으로 돌아오는 비행기에서 그는 노트북을 꺼내 중형 로켓을 만드는 데 들어가는 모든 재료와 비용을 세세히 나열하며 스프레드시트를 만들기 시작했다. 뒷자리에 앉은 캔트렐과 그리핀은 술을 주문하며 웃었다. “우리의 저 천재백치께서는 대체 지금 뭘 하고 있는 걸까요?” 그리핀이 캔트렐에게 물었다. 머스크가 몸을 돌려 “이것 좀 봐요, 여러분”이라고 말하며 자신이 만든 스프레드시트를 보여주었다. “이런 로켓을 우리가 직접 만들 수 있을 것 같아요.” 캔트렐은 숫자를 살피며 혼잣말로 중얼거렸다. “헐, 내 책을 다 빌려가더니만 결국 이러려고 그랬군.” 그러고는 승무원에게 술을 한 잔 더 달라고 했다.\n2 # 킴벌은 일론과 저스틴, 아기와 함께 병원으로 향했다. 네바다는 뇌사 판정을 받은 상태로 3일 동안 생명유지장치를 달고 생을 유지했다. 마침내 호흡기를 끄기로 결정했을 때, 일론은 아기의 마지막 심장 박동을 느꼈고 저스틴은 아기를 품에 안고 죽음의 떨림을 느꼈다. 일론은 주체할 수 없이 흐느꼈다. “마치 늑대처럼 울었어요.” 그의 어머니는 말한다. “늑대처럼….”\n일론이 도저히 집으로 돌아가지 못하겠다고 해서 킴벌은 부부가 베벌리윌셔 호텔에 머물도록 조처했다. 호텔 지배인은 그들에게 프레지덴셜 스위트를 내주었다. 일론은 그에게 호텔로 가져왔던 네바다의 옷과 장난감을 치워달라고 부탁했다. 일론이 가까스로 집에 가서 한때 아들의 방이었던 곳을 보기까지 3주가 걸렸다.\n일론은 슬픔을 조용히 감내했다. 퀸스대학교에서 사귄 친구 나베이드 패룩은 그가 집에 돌아오자마자 로스앤젤레스로 날아와 곁을 지켰다. 패룩은 말한다. “저스틴과 나는 그간의 일에 대한 대화에 일론을 끌어들이려 했지만, 그는 그 일에 대해 이야기하고 싶어 하지 않았지요.” 그래서 그들은 대신 영화를 보고 비디오 게임을 하며 시간을 보냈다. 오랜 침묵의 시간이 흐른 후 패룩이 물었다. “기분은 어때? 잘 견디고 있는 거지?” 하지만 일론은 그런 대화 자체를 완전히 차단했다. “그의 표정을 읽을 수 있을 정도로 오랫동안 그를 알고 지내온 사이였기에 그가 그 일에 대해 이야기하지 않기로 결심했다는 것을 알 수 있었어요.” 패룩의 말이다.\n반대로 저스틴은 자신의 감정에 매우 솔직했다. “남편은 내가 네바다의 죽음에 대한 감정을 표출하는 것을 달가워하지 않았어요.” 그녀는 말한다. “그는 내가 감정을 숨김없이 털어놓으면서 감정적으로 자기를 조종하려 한다고 말하기도 했어요.” 저스틴은 그가 그렇게 감정을 억압하는 것이 어린 시절에 발달된 방어기제 때문이라고 생각한다. “그는 어두운 상황에 처하면 감정을 차단해버려요. 그에게는 그것이 생존을 위한 방법인 것 같아요.”\n3 # 요하네스버그에서 출발한 비행의 첫 번째 구간을 마치고 노스캐롤라이나 주 랠리에 도착했을 때, 에롤은 델타항공 담당자로부터 호출을 받았다. \u0026ldquo;나쁜 소식이 있습니다.\u0026rdquo; 담당자가 말했다. \u0026ldquo;아드님께서 손자 네바다가 사망했다는 소식을 전해달라고 하셨습니다.\u0026rdquo; 일론은 그 내용을 직접 말할 자신이 없었기에 항공사 담당자에게 대신 전해달라고 부탁한 것이다.\n에롤이 전화를 받자 킴벌은 상황을 설명하며 말했다. \u0026ldquo;아버지, 오시면 안돼요.\u0026rdquo; 킴벌은 아버지에게 발길을 돌려 남아공으로 돌아가라고 설득했지만, 에롤은 거부했다. \u0026ldquo;아니다, 이미 미국에 도착했으니 로스앤젤레스에 가봐야 되겠다.\u0026rdquo;\n에롤은 베벌리윌셔 호텔 펜트하우스의 규모를 보고 놀랐던 기억을 떠올렸다. \u0026ldquo;아마도 그때까지 내가 본 호텔 방 중 가장 놀랍지 않았나 싶어요.\u0026rdquo; 일론은 넋이 나간 듯 보였지만, 복잡한 심정으로 애정에 목말라 있기도 했다. 그는 거칠고 거만한 성격의 아버지가 그런 나약한 모습의 자신을 보는 것이 불편했지만, 아버지가 떠나기를 원하지도 않았다. 결국 그는 아버지와 그의 새 가족이 로스앤젤레스에 머물 것을 종용하기에 이르렀다. \u0026ldquo;남아공으로 돌아가지 않으셨으면 좋겠어요.\u0026rdquo; 그가 말했다. \u0026ldquo;제가 여기에 집을 사드릴게요.\u0026rdquo;\n킴벌은 깜짝 놀랐다. \u0026ldquo;아냐, 아냐, 좋은 생각이 아니야.\u0026rdquo; 그가 일론에게 말했다. \u0026ldquo;형은 아버지가 얼마나 음흉한 인간인지 벌써 잊었어? 그러지 마, 형. 이건 자학이나 마찬가지라고.\u0026rdquo; 하지만 동생이 설득하려고 애쓸수록 일론은 더욱 슬퍼졌다. 수년 후, 킴벌은 어떤 갈망이 형에게 그런 동기를 부여했는지 다시 한 번 되짚었다. \u0026ldquo;아들이 죽는 것을 지켜본 일이 아버지가 곁에 있기를 원하도록 이끈 게 분명해요.\u0026rdquo; 그가 내게 말했다.\n4 # 어느 날 에롤이 보트에 올라 있을 때 일론으로부터 메시지 한 통이 날아왔다. “상황이 좋아지기는커녕 엉망이 되고 있으니” 에롤에게 남아공으로 돌아가라는 내용이었다. 에롤은 그렇게 했다. 몇 달 후, 그의 아내와 아이들도 남아공으로 돌아갔다. “아버지를 더 나은 방향으로 바꾸기 위해서 협박도 하고 보상도 하고 논쟁도 벌이고 별의별 시도를 다 했지요.” 일론이 나중에 한 말이다. “그런데 그는…” 머스크는 오랜 시간 말을 잇지 못했다. “말도 안 되게도, 더 나빠졌어요.” 인적 네트워크는 디지털 네트워크보다 복잡하기 마련이다.\n♥️X7 # 2024-12-31 # 1 # 2002년 1월의 어느 일요일, 창고를 빌려 그 아마추어 엔진의 제작에 열중하던 중 가비가 뮬러에게 일론 머스크라는 인터넷 백만장자가 그를 만나고 싶어 한다고 말했다. 머스크가 저스틴과 함께 도착했을 때, 뮬러는 줄에 매단 80파운드짜리 엔진을 어깨로 떠받친 채 프레임에 고정하기 위해 볼트를 조이고 있었다. 머스크는 다짜고짜 그에게 질문을 퍼붓기 시작했다. \u0026ldquo;그게 추력은 얼마나 되나요?\u0026rdquo; 뮬러는 1만 3,000파운드라고 답했다. \u0026ldquo;더 큰 것도 만들어본 적이 있나요?\u0026rdquo; 뮬러는 얼마 전부터 TRW에서 65만 파운드의 추력을 가진 TR-106의 제작에 참여하고 있다고 설명했다. \u0026ldquo;추진 연료로는 무엇을 쓰나요?\u0026rdquo; 머스크가 또 물었다. 뮬러는 머스크의 속사포 질문에 집중하기 위해 마침내 볼트 결합 작업을 일시 중단했다.\n머스크는 뮬러에게 TRW의 TR-106만큼 큰 엔진을 혼자서 만들 수 있는지 물었다. 뮬러는 자신이 인젝터와 점화기를 직접 설계했고, 펌프 시스템을 잘 알고 있으며, 나머지는 팀과 함께 해결할 수 있다고 답했다. 머스크는 물었다. \u0026ldquo;비용이 얼마나 들까요?\u0026rdquo; 뮬러는 TRW가 1,200만 달러를 들여 그것을 제작하고 있다고 답했다. 머스크는 방금 전에 던진 질문을 재차 반복했다. \u0026ldquo;비용이 얼마나 들까요?\u0026rdquo; \u0026ldquo;오, 이런, 그거 참 답하기 어려운 문제이긴 합니다.\u0026rdquo; 대화가 너무 빨리 구체적인 사안으로 진행되어서 속으로 놀라고 있던 뮬러 역시 그 부분은 재고해볼 필요가 있다고 판단했다.\n그때 긴 가죽 코트를 걸치고 있던 저스틴이 머스크를 쿡 찌르며 이제 갈 시간이 되었다고 말을 건넸다. 머스크는 뮬러에게 다음 일요일에 만날 수 있는지 물었다. 뮬러는 주저했다. \u0026ldquo;마침 슈퍼볼 일요일이었고, 나는 와이드스크린 TV를 막 구입했기에 친구들과 함께 경기를 보고 싶었어요.\u0026rdquo; 하지만 그는 거부해봤자 소용이 없을 것 같은 느낌이 들었고, 그래서 찾아오겠다는 머스크의 제안을 받아들였다.\n\u0026ldquo;우리가 발사체 제작에 대해 얼마나 몰두해서 이야기를 나누었던지 마치 한 편의 연극을 보는 것 같았지요.\u0026rdquo; 뮬러의 기억이다. 그들은 그 자리에서 다른 엔지니어 몇 명과 함께 최초의 스페이스X 로켓에 대한 계획을 계략적으로 세우기까지 했다. 발사체의 1단은 액체산소와 등유를 사용하는 엔진으로 추진하기로 결정했다. \u0026ldquo;제가 그 작업을 쉽게 할 수 있는 방법을 알고 있습니다.\u0026rdquo; 뮬러가 말했다. 머스크는 상단에는 과산화수소를 사용하자고 제안했지만, 뮬러는 그것을 다루기 어려울 것이라고 생각했다. 그래서 사산화질소를 제안했지만, 머스크는 그것이 너무 비싸다고 생각했다. 결국 두 사람은 2단에도 액체산소와 등유를 사용하기로 합의했다. 슈퍼볼은 잊혔다. 로켓이 더 흥미로웠다.\n2 # 뮬러는 스페이스X의 첫 번째 주요 영입자가 되었다. 뮬러가 고집한 한 가지 조건은 머스크가 그의 2년 치 보수를 조건부 날인 증서로 보장해주는 것이었다. 그는 인터넷 백만장자가 아니었기에 벤처가 실패할 경우 보수를 받지 못하게 될 가능성을 감수하고 싶지 않았다. 머스크는 동의했다. 하지만 이 일로 머스크는 뮬러를 스페이스X의 공동창업자가 아닌 직원으로 여기게 되었다. 이것은 머스크가 페이팔 시절에도 중요하게 여겼고, 테슬라를 창업하면서도 마찬가지로 중시할 투자와 관련된 문제였다. 그는 회사에 투자할 의사가 없다면 창업자 자격이 없다고 생각했다. \u0026ldquo;2년치 월급을 조건부 날인 증서로 예치해달라면서 자신을 공동창업자라고 생각해서는 안되는 거지요.\u0026rdquo; 머스크는 말한다. \u0026ldquo;공동창업자가 되려면 영감과 땀, 리스크가 어느 정도 조합이 되어야 하는 겁니다.\u0026rdquo;\n3 # 공장을 설계할 때 머스크는 디자인과 엔지니어링, 제조 팀이 모두 함께 모여 있어야 한다는 자신의 철학을 따랐다. \u0026ldquo;조립라인에 있는 사람들이 즉각적으로 디자이너나 엔지니어를 붙잡아 세우고 \u0026lsquo;대체 왜 이런 식으로 만든 거요?\u0026lsquo;라고 따질 수 있어야 하는 거예요.\u0026rdquo; 머스크가 뮬러에게 설명했다. \u0026ldquo;가스레인지 위에 자기 손을 올려 놓으면 뜨거워지자마자 바로 떼어내지만, 다른 사람의 손이 올라가 있으면 무언가 조치를 하는 데 시간이 더 오래 걸리기 마련이지요.\u0026rdquo;\n팀이 성장함에 따라 머스크는 자신의 리스크에 대한 내성과 의도적인 현실 왜곡 논리를 자신의 팀에도 불어넣었다. \u0026ldquo;부정적으로 생각하거나 무언가를 할 수 없다는 태도를 보이면 다음 회의에 초대받지 못했지요.\u0026rdquo; 뮬러의 회상이다. \u0026ldquo;그는 그저 어떻게든 일을 해낼 사람들을 원했어요.\u0026rdquo; 이는 사람들이 불가능하다고 생각하는 일을 해내도록 유도하는 좋은 방법이었다. 하지만 그것은 나쁜 소식을 전하거나 결정에 의문을 제기하길 두려워하는 사람들에게 둘러싸이기에도 좋은 방법이었다.\n4 (광적인 긴박감을 유지하라) # 멀린 엔진을 개발할 때, 뮬러는 버전 중 하나를 완성하기 위해 공격적인 일정을 제시했다. 하지만 머스크가 보기엔 충분히 공격적이지 않았다. \u0026ldquo;도대체 왜 이렇게 오래 걸리는 거요? 이건 말도 안 돼. 반으로 줄이세요.\u0026rdquo;\n뮬러는 난색을 표했다. \u0026ldquo;이미 반으로 줄인 일정을 그렇게 다시 반으로 줄일 수는 없습니다.\u0026rdquo; 머스크는 그를 차갑게 쳐다보며 회의가 끝난 뒤에 남으라고 말했다. 둘만 남았을 때 그는 뮬러에게 계쏙 엔진 책임자로 남고 싶은지 물었다. 뮬러가 그렇다고 대답하자 머스크는 \u0026ldquo;그럼 내가 뭔가를 요구하면, 염병할, 그냥 그렇게 해주시오\u0026quot;라고 했다.\n뮬러는 이에 동의하고 임의로 일정을 반으로 줄였다. \u0026ldquo;그리고 어떻게 됐을까요?\u0026rdquo; 뮬러가 물었다. \u0026ldquo;결국 원래 일정에 잡혀 있던 시간을 거의 다 들인 후에야 완성이 되었지요.\u0026rdquo; 머스크의 미친 스케쥴은 때대로 불가능을 가능으로 만들기도 했지만, 매번 그러지는 못했다. 뮬러는 말한다. \u0026ldquo;머스크에게는 절대 안 된다고 말하면 안 된다는 것을 배웠지요. 그냥 해보겠다고 말하고 나중에 잘 안 되면 그 이유를 설명하면 되는 겁니다.\u0026rdquo; (이거 우리 교수님이자나..)\n5 (실패를 통해 배워라) # 머스크는 설계에 반복적 접근방식을 취했다. 로켓과 엔진의 프로토타입을 빠르게 만들어 테스트하고, 날려버리고, 수정하고, 다시 시도하는 식으로 마침내 제대로 된 게 나올 때까지 반복했다. 빠르게 움직이고, 날려버리고, 반복하라! 뮬러는 말한다. “중요한 것은 문제를 얼마나 잘 피하느냐가 아니거든요. 어떤 문제가 있는지 얼마나 빨리 파악해서 해결하느냐가 진정으로 중요한 겁니다.”\n예를 들면, 새로운 버전의 엔진을 여러 다양한 조건에서 몇 시간 동안 시험 발사해야 하는지에 대한 일련의 국방규격 표준이 있었다. “지루하기 짝이 없는데다가 비용도 많이 드는 접근방식이었지요.” 팀 부자의 설명이다. “일론은 그저 엔진 하나를 만들어서 테스트 스탠드에서 불을 붙여보라고 했어요. 그래서 작동하면 로켓에 장착해 날려보자는 거였지요.” 스페이스X는 민간기업이었고, 머스크는 기꺼이 규칙을 어기는 성향이었기에 그렇게 원하는 대로 리스크를 감수할 수 있었다. 부자와 뮬러는 엔진이 고장 날 때까지 밀어붙여 한계가 어디까지인지 파악하곤 했다. 반복적 설계에 대한 이러한 신념은 곧 스페이스X에 언제든 이용할 수 있는 자유로운 테스트 장소가 필요하다는 것을 의미했다.\n물론 항상 성공하는 것은 아니었다. 머스크는 2003년 말 엔진 연소실 내부의 열 확산 소재에 균열이 발생했을 때도 마찬가지로 색다른 접근방식을 시도했다. “처음에 하나, 이어서 또 하나, 또 하나, 그렇게 우리가 만든 최초의 연소실 세 개에 균열이 생겼어요.” 뮬러의 회상이다. “말 그대로 재앙이었지요.”\n나쁜 소식을 듣자 머스크는 뮬러에게 고칠 방법을 찾으라고 지시했다. “그냥 버릴 수는 없어요.” 뮬러는 “고칠 방법이 없습니다”라고 대답했다.\n머스크를 격분하게 만드는 종류의 발언이었다. 그는 뮬러에게 비행기를 보낼 테니 그 세 개의 연소실을 싣고 로스앤젤레스의 스페이스X 공장으로 날아오라고 지시했다. 그의 아이디어는 에폭시 접착제를 균열에 스며들도록 도포해 문제를 해결하자는 것이었다. 뮬러가 말도 안 되는 미친 아이디어라고 말했고, 둘 사이에는 고성이 오갔다. 그러다 마침내 뮬러가 물러섰다. 그는 팀원들에게 말했다. “그가 결정권자니까.”\n연소실이 공장에 도착했을 때 머스크는 마침 크리스마스 파티에 참석하기로 되어 있던 터라 고급 가죽 부츠를 신고 있었다. 그는 파티에 가지 못했다. 대신 그는 밤새 에폭시 도포 작업을 도왔다. 멋진 부츠가 엉망이 되도록.\n도박은 실패로 돌아갔다. 압력을 가하자마자 에폭시가 떨어져나갔다. 연소실을 다시 설계해야 했고 발사 일정은 4개월 뒤로 미뤄졌다. 하지만 혁신적인 아이디어를 추구하며 기꺼이 공장에서 밤을 새는 머스크를 보면서 엔지니어들은 두려움 없이 색다른 해결책을 시도해볼 수 있다는 생각에 고무되었다.\n그렇게 패턴이 형성되었다. 새로운 아이디어를 시도하고 기꺼이 날려버려라.\n"},{"id":31,"href":"/docs/hobby/book/book8/","title":"책","section":"책","content":" 콜 미 바이 유어 네임 | 안드레 애치먼 # 북마크 # bookmark1\nbookmark2\nbookmark1 # 2024-12-31 # 1 # 그는 뭘 하면서 지내느냐고 물었다. 테니스. 수영. 밤에 시내로 놀러 나가기. 조깅. 편곡. 독서.\n2 # 모든 것이 올리버가 우리 집에 온 그 여름에 시작되었다. 그것들은 그해 여름에 유행한 곡과 그가 머무는 동안 그리고 떠난 후에 읽은 책들, 뜨거운 날의 로즈메리 냄새부터 오후의 요란한 매미 소리까지 모든 것에 새겨졌다. 여름마다 접해서 익숙해진 냄새와 소리들이 갑자기 나에게 달려들었고, 그 여름의 사건들로 영원히 다른 색조를 띠게 되었다.\n3 # 그는 유대인이라는 사실에 만족했다. 자기 자신에게도 만족했다. 자신의 몸, 얼굴, 특이한 테니스 백핸드, 책과 음악, 영화, 친구를 고르는 취향에도 만족했다. 아끼는 몽블랑 만년필을 잃어버렸을 때도 대수롭지 않게 여겼다. \u0026ldquo;다시 사면 돼.\u0026rdquo; 비판을 받아도 아무렇지 않았다. 언젠가 그 스스로 자랑스럽게 생각하는 원고 몇 장을 우리 아버지에게 보여준 적이 있었다. 아버지는 헤라클레이토스에 대한 통찰은 훌륭하지만 강화할 필요가 있다고 지적했다. 헤라클레이토스라는 철학자의 사상을 그냥 설명하려 하지 말고 모순된 특징이 있음을 받아들여야 한다고. 그는 강화할 필요가 있다는 것도, 모순도 아무렇지 않아 했다. 방향을 처음부터 다시 잡아야 한다는 사실도 괜찮았다.\n그가 우리 집에 온 지 며칠 되지 않았을 때 딱 한번, 의지가 강하지만 호의적이고 느긋하고 흔들림 없으며 당황할 줄 모르는 데다 삶의 많은 것을 대수롭지 않게 여기는 이 스물 넷의 남자가 사실은 사람과 상황을 판단할 때는 철저하게 경계하고 냉정하며 현명하다고 느낀 일이 있었다. 그의 말과 행동은 미리 계획되지 않은 게 하나도 없었다. 그는 모두를 꿰뚫어 보았다. 그가 사람을 정확하게 꿰뚫어 볼 수 있는 것은 타인을 바라볼 때 자신의 내면에서 남들이 보지 말았으면 하는 부분을 가장 먼저 보기 때문이었다.\n4 # 올리버는 어울릴 사람을 원했다. 처음에는 내 테이블을 함께 쓰더니 나중에는 잔디밭에 커다란 담요를 깔고 누워 있는 걸 좋아했다. 옆에는 아무렇게나 펼쳐진 원고와 그가 \u0026lsquo;잡동사니\u0026rsquo;라고 부르는 것들이 놓여 있었다. 레모네이드, 선크림, 책, 에스파듀, 선글라스, 색연필. 그리고 헤드폰을 쓰고 음악을 들었기에 그가 먼저 말을 걸지 않는 이상 말을 걸 수가 없었다. 아침에 작곡 노트나 책을 들고 아래층으로 내려가면 빨간색이나 노란색 수영복 차리므이 그가 벌써 태양 아래 땀을 흘리며 누워 있기도 했다. 함께 조깅이나 수영을 하고 돌아오면 아침 식사가 기다렸다.\n그는 \u0026lsquo;집동사니\u0026rsquo;를 잔디밭에 그대로 둔 채 수영장 바로 옆에 누워 있는 버릇이 생겼다. 그가 \u0026lsquo;여긴 천국이야\u0026rsquo;를 줄여서 \u0026lsquo;천국\u0026rsquo;이라고 부르는 자리였다. 점심을 먹고 나서 라틴어 학자들만의 농담으로 \u0026ldquo;전 이제 천국에 갑니다. 일광욕하러.\u0026ldquo;라고 덧붙이곤 했다. 우리는 그가 수영장가 똑같은 자리에서 선탠오일을 듬뿍 바른 채 몇 시간이고 누워 있다며 놀렸다. 어미니는 \u0026ldquo;오늘 아침에는 천국에 얼마나 있었어요?\u0026ldquo;라고 물었다. \u0026ldquo;두 시간 연속이요. 오늘은 일찍 돌아와서 더 오랫동안 일광욕을 하려고요.\u0026rdquo; 그에게 천국의 가장자리에 간다는 것은 수영장가에 누워서 한쪽 다리는 물에 담그고 헤드폰을 쓰고 얼굴은 밀짚모자로 가리고 있겠다는 뜻이기도 했다.\n무엇 하나 부족할 게 없는 사람이었다. 나는 그 느낌을 이해할 수가 없었다. 그가 부러웠다.\n5 # \u0026ldquo;마르지아랑 거의 할 뻔했어요.\u0026rdquo; 다음 날 아침을 먹으면서 아버지와 올리버에게 말했다. 아무튼 나는 과시하는 중이었다.\n\u0026ldquo;나중에 다시 해 봐.\u0026rdquo; 올리버가 말했다. 무심한 사람들이 하는 말이었다. 하지만 그가 속마음이 따로 있으며 드러내지 않을 거라는 느낌도 들었다. \u0026lsquo;나중에 다시 해 봐라는 바보 같지만 좋은 의도로 한 말 이면에서 약간의 동요가 느껴졌기 때문이다. 그는 나를 비난하고 있었다. 또는 놀리거나. 아니면 꿰뚫어 보거나.\n그가 마침내 속마음을 드러내자 나는 감정이 상해 버렸다. 나를 완전히 간파한 사람만 할 수 있는 말이었다. \u0026ldquo;나중이 아니면 언제?\u0026rdquo; 올리버는 말이 심했다고 생각했는지 곧바로 덧붙였다. \u0026ldquo;나라면 당연히 다시 해 볼거야. 그리고 또다시 해 볼 거고.\u0026rdquo; 좀 누그러진 표현이기는 했다. 하지만 그는 *\u0026lsquo;나중에 다시 해 봐\u0026rsquo;*라는 베일로 *\u0026lsquo;나중이 아니면 언제?\u0026rsquo;*를 가린 것 뿐이었다.\n6 # 나중에 다시 시도한다는 것은 당장은 용기가 없다는 뜻이었다. 아직 준비되지 않은 것 뿐이었다. 다시 시도해 볼 용기와 의지는 어디세서 찾아야 하는지 알 수 없었다. 하지만 가만히 앉아 있지 말고 뭔가 해야겠다고 결심하면 벌써부터 뭔가 하는 듯한 기분이었다. 있지도 않은 돈으로, 투자하지도 않은 돈으로 수익을 거두는 것처럼.\n하지만 *\u0026lsquo;나중에 다시 해 봐야지\u0026rsquo;*하는 방어적인 태도로 일관하며 살아왔다는 사실도 잘 알고 있었다. 매일 *\u0026lsquo;나중에 다시 해 봐야지\u0026rsquo;*하면서 한 달, 한 계절, 한 해 또는 평생을 보낼 수도 있었다. 나중에 다시 해 보는 것은 올리버 같은 사람에게나 맞았다. 나 같은 사람한테는 *\u0026lsquo;나중이 아니면 언제?\u0026rsquo;*가 더 어울렸다.\n나중이 아니면 언제? 그가 이 말로 나를 간파했고 내 비밀을 하나씩 벗겼다면? 그에게 전혀 관심이 없다는 사실을 알려 줄 필요가 있었다.\nbookmark2 # 2024-12-31 # 1 # \u0026ldquo;당신은 내가 뭘 좋아하는지 몰라요.\u0026rdquo; 나는 냉정하게 쏘아붙였다. \u0026ldquo;전혀요.\u0026rdquo;\n인간의 영혼을 읽는 능력이 조금 덜 예리한 사람이라면 나의 끊임없는 부정에서 키아라를 방어막으로 사용하고 있음을 허둥지둥 시인한다는 끔찍한 신호를 발견했을 것이다.\n하지만 그런 능력이 대단히 날카로운 사람은 내 행동에서 완전히 다른 진실로 이어지는 문을 발견했으리라. 그 문을 열러면 위험을 각오해요. 장담하건대 당신은 진실을 듣고 싶지 않을 거예요. 아직 시간이 있을 때 자리를 피하는 게 좋을 거예요.\n2 # 바다가 내려다보이는 작은 광장에 도착하자 올리버는 담배를 사기 위해 멈추었다. 그는 골루아즈를 피우기 시작한 터였다. 피워 본 적 없는 브랜드라 나도 한대 피워 봐도 되느냐고 물었다. 그가 성냥개비 하나를 꺼내 내 얼굴 가까이에서 양손을 동그랗게 모아 쥐고 담뱃불을 붙여 주었다.\n\u0026ldquo;나쁘지 않지?\u0026rdquo;\n\u0026ldquo;나쁘지 않네요.\u0026rdquo;\n그를, 오늘을 떠올리는 담배가 되리라고 생각했다. 앞으로 한 달도 되지 않아 그는 흔적도 없이 사라질 테니까. 그가 B에서 지낼 날이 얼마나 남았는지 세어 보기로 마음먹은 것은 그때가 처음이었다.\n3 # \u0026ldquo;이걸 좀 봐.\u0026rdquo; 아래로 완만하게 경사진 언덕이 내려다보이는 광장 끄트머리를 향해 아침 햇살 속에서 자전거를 끌고 천천히 걸으며 그가 말했다.\n저 아래 저 멀리 그림 같은 바다가 펼쳐저 있었다. 거대한 돌고래들이 파도를 부수는 듯 작은 만에 몇 가닥의 하얀 거품이 보였다. 작은 버스 한 대가 언덕길을 오르고 제복 차림의 남자 셋이 자전거를 타고 뒤따라 왔다. 분명히 버스에서 나오는 매연에 대해 불평하고 있으리라.\n“이 근처에서 누가 익사했는지 알겠지?” 그가 물었다. “시인 퍼시 셸리요.” “시신이 발견된 후 그의 아내 메리와 친구들이 어떻게 했는지도 알고?” “Cor cordium, 마음 중의 마음이요.” 부풀어 오른 시신을 해변에서 화장할 때, 불꽃이 시신을 완전히 집어삼키기 전에 친구가 셸리의 심장을 떼어 냈다는 이야기를 떠올리며 대답했다. 시험이라도 치듯 왜 저러는 걸까?\n“넌 모르는 게 없지?” 나는 그를 바라보았다. 지금이 바로 나를 위한 순간이었다. 그 순간을, 나는 잡을 수도 놓칠 수도 있지만 어느 쪽이건 평생 잊지 못할 당혹스러운 순간으로 남을 것이다. 아니면 칭찬에 흡족해할 수도, 나머지 전부를 후회하면서 살 수도 있었다. 내가 할 말을 미리 계획하지 않고 어른에게 말하기는 그때가 처음이었을 것이다. 너무 떨려서 계획할 수도 없었다. “난 아무것도 몰라요, 올리버. 아무것도. 아무것도요.” “넌 여기 그 누구보다 많이 아는데.” 어째서 그는 비극에 가까운 내 말투에 저렇듯 단조롭게 칭찬처럼 답하는 거지? “정말로 중요한 건 잘 모른다는 걸 당신이 몰라서 그래요.” 나는 물을 향해 걸어가고 있었다. 익사하려 하지도, 안전하게 헤엄치려 하지도 않고 그냥 머물기 위해. 진실을 말하거나 암시조차 못 한다고 해도 진실은 항상 우리 주변에 놓여 있을 테니까. 마치 수영하다가 잃어버린 목걸이 이야기를 하듯이. 나는 그것이 어딘가에 있음을 안다. 뻔히 드러나 보이는 사실을 종합해서 무한대보다 큰 숫자를 떠올리도록 내가 기회를 주는 거라는 사실을 그가 알 수만 있다면. 하지만 그가 이해했다면 눈치를 챘다는 뜻이고, 만약 눈치를 챘다면 그동안 결코 만나지 않는 평행선 너머에서 적대적으로 강철처럼 차갑고 무표정하게 다 안다는 듯 허를 찌르는 눈빛으로 나를 쳐다보고 있었으리라.\n그는 뭔가 떠오른 게 틀림없었다. 그게 뭔지는 아무도 알 수 없지만. 어쩌면 그는 놀라지 않은 척하는 건지도 모른다. “중요한 게 뭐지?” 그는 지금 솔직하지 못한 것일까? “뭔지 알잖아요. 지금쯤이면 다른 사람은 몰라도 당신은 알 거예요.” 침묵이 흘렀다. “왜 이런 말을 하는 거지?” “당신이 알아야 한다고 생각했어요.” “내가 알아야 한다고 생각했다…….” 그는 깊은 생각에 잠긴 듯 내 말을 그대로 읊었다. 그 말에 담긴 의미를 파악하고 정리할 시간을 벌려는 듯이. 강철이 뜨겁게 달아오르고 있었다. “당신이 알았으면 해요.” 나도 모르게 튀어나왔다. “당신 말고는 말할 사람이 아무도 없으니까요.” 말해 버렸다. 도대체 말이 되기나 하는 걸까? 나는 바다나 내일 날씨 혹은 아버지가 매년 이맘때면 꼭 약속하는 E 항해가 과연 좋은 생각인지에 대한 이야기로 화제를 돌리려고 했다. 하지만 역시나 그냥 넘길 그가 아니었다. “지금 무슨 말을 하는지 알고 하는 얘기야?” 나는 바다를 쳐다보면서 모호하고 지친 어조로 대답했다. 내 마지막 방향 전환이자 위장막이자 최후의 도피였다. “네. 내가 무슨 말을 하는지 알고 당신도 제대로 받아들이고 있어요. 난 말을 잘 못해요. 다시는 나랑 말하지 않겠다고 해도 괜찮아요.” “잠깐. 내가 생각하는 그런 말이 맞는 거야?” “네에.” 이왕 말을 꺼낸 마당이라 약간 느긋하고 짜증 난 것처럼 굴 수 있었다. 경찰에 항복한 뒤 범행 방법을 몇 번이나 반복해서 진술해야 하는 절도범처럼 말이다. “잠깐 여기서 기다려. 2층에 올라가서 원고를 받아 와야 하니까. 딴 데 가지 마.” 나는 그에게 믿음직한 미소를 보냈다. “내가 아무 데도 안 간다는 걸 당신도 잘 알잖아요.” 이거야말로 내 속마음을 확실하게 인정하는 게 아니고 뭐란 말인가?\n4 # “말하지 말걸 그랬어요.” 마침내 내가 말문을 열었다. 그렇게 말하는 순간 우리 사이의 미약한 마법의 주문이 깨지리라는 것을 알고 있었다. “못 들은 걸로 할게.” 전혀 예상하지 못한 대답이었다. 뭐든 괜찮다고 말하는 사람이니까. 우리 집에서는 단 한 번도 들어 본 적 없는 말이었다. “그럼 서로 말은 하고 지내는 거예요, 아니면 아닌 거예요?” 그가 생각에 잠겼다. “우린 그런 얘기를 해서는 안 돼. 정말로 안 돼.” 그가 가방을 둘러멨고 우리는 내리막길을 향해 출발했다.\n5 # “여기는 내 공간이에요. 나만의 공간. 책을 읽으러 와요. 여기서 몇 권이나 읽었는지는 나도 몰라요.” “넌 혼자 있는 게 좋아?” “아뇨. 혼자 있는 걸 좋아하는 사람은 없어요. 난 그걸 견디는 법을 배웠죠.” “넌 항상 그렇게 지혜로우니?” 그도 다른 사람들처럼 밖에 나가서 친구 좀 사귀라고, 사귄 친구들한테 이기적으로 굴지 말라고 거들먹거리는 말투로 설교를 시작하려는 것일까? 아니면 정신과 의사 겸 가족 친구의 역할을 수행하겠다는 신호일까? 아니면 내가 또 그를 완전히 잘못 읽은 걸까? “난 전혀 지혜롭지 않아요. 말했잖아요. 난 아무것도 몰라요. 책은 알죠. 말을 결합할 줄은 알지만 나한테 가장 중요한 얘기를 할 줄 안다는 뜻은 아니에요.” “하지만 지금 그러고 있는데. 어떤 면에서는 말이야.” “그래요. 어떤 면에서는 그렇죠. 난 항상 그런 식으로 말해요.”\n그를 바라보지 않으려고 앞바다로 시선을 향하면서 풀밭에 앉았다. 그가 몇 미터 떨어진 곳에 쭈그려 앉는 모습이 보였다. 언제든 자전거가 있는 곳으로 뛰어가려는 듯 발끝이 들려 있었다.\n그때는 몰랐다. 그를 이곳에 데려온 이유는 단지 그에게 내 작은 세상을 보여 주려는 게 아니라 내 작은 세상이 그를 받아들여 주길 바라서라는 것을. 내가 여름날 오후면 홀로 찾던 장소가 그를 보고 괜찮은 사람인지 판단하여 받아들일 수 있도록. 그래야 훗날 다시 왔을 때도 내가 기존의 세상을 피해 스스로 만든 세상을 찾으러 이곳에 온다는 사실을 기억할 테니 말이다. 그에게 다른 세상으로 출발하는 내 발사대를 소개해 준 셈이었다. 이곳에 서 읽은 책을 나열하면 그는 내가 어디를 여행했는지 알 터였다. “난 네가 말하는 방식이 마음에 드는데, 왜 넌 항상 너를 깎아내리지?” 나는 어깨를 으쓱했다. 지금 나를 비판하는 건가? “모르겠어요. 그러니까 당신도 알 수 없겠죠.” “남들이 어떻게 생각할지 두려워?” 고개를 저었다. 하지만 답을 알지 못했다. 어쩌면 너무 뻔해서 대답할 필요가 없는지도 모른다. 이럴 때면 벌거벗은 것처럼 한없이 연약해지는 기분이었다. 자신을 몰아세우고 초조하게 만들어서 상대방을 몰아세우지 않는 한 다 들켜 버린다. 아뇨. 뭐라고 답할 말이 없었다. 하지만 나는 움직이지도 않았다. 그더러 혼자 집으로 돌아가라 말하고 싶은 충동이 일었다. 나는 점심시간에 맞춰서 가겠다고.\n그는 내 입에서 무슨 말이 나오기를 기다리고 있었다. 나를 빤히 쳐다보았다.\n6 # “네 기분이 조금이라도 좋아질지 모르겠는데 이젠 나도 참아야 해. 넌 지금쯤이면 참는 법을 배웠겠지만.” “내가 할 수 있는 최선은 신경 쓰지 않는 척하는 거예요.” “그건 이미 서로 알고 있는 거잖아.” 그가 곧바로 쏘아붙였다.\n산산이 부서진 기분이었다. 내가 정원과 발코니, 해변에서 그를 얼마나 쉽게 무시할 수 있는지 보여 줄 때마다 그는 나를 다 꿰뚫어 보았고 짜증이 섞인 지극히 전형적인 수라고 생각한 것이다. 우리 사이의 수로를 다 열어 준 듯한 그의 고백은 오히려 새롭게 솟아나는 내 희망을 삼켜 버렸다. 이제 우리는 어떻게 하지? 여기서 더 할 게 뭐가 있는가? 서로 말하지 않는 척하지만 서로의 사이에 낀 서리가 가짜라는 것을 더 이상 확인할 수 없어지면 어떻게 되는 거지? 우리는 잠시 더 이야기를 나누었지만 대화는 점차 사라졌다. 서로의 마음을 털어놓은 후라 그냥 잡담을 나누는 것처럼 느껴졌다. “그래, 모네가 그림을 그린 곳이라고…….” “집에 가서 보여 줄게요. 여기 풍경을 그린 모네 그림이 실린 책이 있어요.” “그래, 꼭 보여 줘.” 그는 잔소리하기 좋아하는 대역 배우를 연기하고 있었다. 나는 그게 싫었다. 우리는 각자 한 팔로 기대고 누워서 멀리 보이는 경치를 감상했다.\n7 # 우리는 내 언덕에서 출발해 자전거를 타고 달리며 N을 향해 남쪽으로 가는 관광객용 밴 두 대를 보았다. 정오가 가까워진 게 틀림없었다.\n“우리 이제 말하지 말아요.” 내가 영원히 끝나지 않는 내리막길을 달리며 말했다. 그와 나의 머리카락이 바람에 날렸다. “그런 말 하지 마.” “난 알 수 있어요. 그냥 잡담이나 하겠죠. 시시콜콜한 잡담이나. 그게 전부겠죠. 웃긴 건 그래도 난 살 수 있겠죠.” “방금 운율이 딱딱 맞았어.”\n"},{"id":32,"href":"/docs/about/","title":" ","section":"Docs","content":" Build Information # Tool: Hugo(v0.131.0) Build Date: 2024-08-02 Theme \u0026amp; Deployment # Theme: Hugo-Book Hosting Platform: GitHub Pages Source Code \u0026amp; License # Source Code: GitHub Repository License: MIT Contact # Email: yshggid@gmail.com "},{"id":33,"href":"/docs/hobby/daily/blog39/","title":"일상","section":"일상","content":" Club Med Kiroro☃️ # 2025-02-28 # "}]