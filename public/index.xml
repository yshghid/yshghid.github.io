<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>윤소의 블로그 (๑˘ ᵕ˘๑) on  </title>
    <link>http://localhost:1313/</link>
    <description>Recent content in 윤소의 블로그 (๑˘ ᵕ˘๑) on  </description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 15 Jan 2026 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>클럽메드 ☃️</title>
      <link>http://localhost:1313/docs/hobby/daily/blog39/</link>
      <pubDate>Sat, 08 Feb 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/daily/blog39/</guid>
      <description>클럽메드 ☃️ # #2025-02-28</description>
    </item>
    <item>
      <title>블로그 시작 (부제: 제발열심히살자..)</title>
      <link>http://localhost:1313/docs/hobby/daily/daily1/</link>
      <pubDate>Tue, 31 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/daily/daily1/</guid>
      <description>블로그 시작 (부제: 제발열심히살자..) # #2024-12-31&#xA;최근에 무기력한 기분이 너무 오래가서&amp;hellip; 느슨해지다못해 일시정지해버린 일상에 긴장감을 주기 위해 블로그를 시작한다. 공부도 하기싫고 취준도 하기싫고 구냥 아무것도 하고싶지않다 ㅠㅠ&#xA;오늘도 사실 랩미팅 피피티만들어야되는데 하기싫어서, 전에 오류나서 엎었던 블로그 다시 만들었다. 정말이지 일하는것빼고 다 재밌는듯.&#xA;그리고 독감걸린동안 아무것도 안했는데 내일이면 휴가 끝나니까 그것도 너무 두렵다. 이제 몸은 안아픈데 정신이 아픈거같음.. ㅋㅋ&#xA;일단 지금 해야되는일은&#xA;SQL 공부 (시험일: 3.8) 빅분기 필기 공부 (시험일: 4.</description>
    </item>
    <item>
      <title>경주🍀</title>
      <link>http://localhost:1313/docs/hobby/daily/blog34/</link>
      <pubDate>Sun, 03 Nov 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/daily/blog34/</guid>
      <description>경주🍀 # #2024-11-03</description>
    </item>
    <item>
      <title>진도</title>
      <link>http://localhost:1313/docs/hobby/daily/blog33/</link>
      <pubDate>Mon, 26 Aug 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/daily/blog33/</guid>
      <description>진도 # #2024-08-26</description>
    </item>
    <item>
      <title>수원</title>
      <link>http://localhost:1313/docs/hobby/daily/blog32/</link>
      <pubDate>Fri, 21 Jun 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/daily/blog32/</guid>
      <description>수원 # #2024-06-21</description>
    </item>
    <item>
      <title>제주🏝️</title>
      <link>http://localhost:1313/docs/hobby/daily/blog31/</link>
      <pubDate>Wed, 01 May 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/daily/blog31/</guid>
      <description>제주🏝️ # #2024-05-01</description>
    </item>
    <item>
      <title>엄마랑 갑자기 서울!!</title>
      <link>http://localhost:1313/docs/hobby/daily/blog35/</link>
      <pubDate>Sat, 09 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/daily/blog35/</guid>
      <description>엄마랑 갑자기 서울!! # #2024-03-09</description>
    </item>
    <item>
      <title>졸업식 2023</title>
      <link>http://localhost:1313/docs/hobby/daily/blog36/</link>
      <pubDate>Fri, 18 Aug 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/daily/blog36/</guid>
      <description>졸업식 2023 # #2023-08-18</description>
    </item>
    <item>
      <title>데이터 분석 #8 확률밀도, t-검정</title>
      <link>http://localhost:1313/docs/study/ai/ai43/</link>
      <pubDate>Thu, 15 Jan 2026 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai43/</guid>
      <description>데이터 분석 #8 확률밀도, t-검정 # #2026-01-15&#xA;#1 이산과 연속변수&#xA;이산과 연속변수&#xA;암 유전체 데이터에서 1개 위치에 나타는 돌연변이 횟수 같은 정수 데이터 -&amp;gt; 이산(discrete) 변수 실수 값 데이터 -&amp;gt; 연속(continuous) 변수 확률적으로 이 데이터를 처리하기 위해서는 정규분포를 써야한다. # #2 확률밀도&#xA;연속확률분포&#xA;연속확률변수를 표현하기 위해서는 &amp;lsquo;범위&amp;rsquo;를 사용해야한다. 170cm인 사람은 실제로는 169.5~170.5cm 이므로 키를 재보니 170인 사람이 3%였다는 것은 P(키=170)=3% 라고 쓸수없고 P(169.5&amp;lt;키&amp;lt;170.5)=3% 와 같이 써야한다. 연속확률분포로 가장 유명한 것은 정규분포이고 파라미터는 평균과 표준편차.</description>
    </item>
    <item>
      <title>새해모임과 롱디데이트</title>
      <link>http://localhost:1313/docs/hobby/daily/daily29/</link>
      <pubDate>Thu, 15 Jan 2026 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/daily/daily29/</guid>
      <description>새해모임과 롱디데이트 # #2026-01-15&#xA;길이랑 지수랑 연말모임을 못해서 연말연초 모임 겸 내 생일겸으로 만났다!&#xA;집가자마자 옷맞춰놓은거 보고 ㅋㅋㅋ 머먹을지부터 정했는데 마라엽떡이랑 맘터치킨 먹기로해서 세븐일레븐가서 하이볼같은거 보이는대로 사서 왔다&#xA;지수가 와인 가져온거랑 먹기 ㅎㅎ 맘터 후라이드랑 칠리 마싯는건 원래 알고있었는데 에드워드리 콜라보 치킨이 겁나 마싯었다&#xA;다먹구 이미 배는 포화상태지만 케이크 꺼내기..ㅎㅎ&#xA;티셔츠랑 케이크 자랑!! 나만 글귀 다른게 뭔가 웃기다 ㅋㅋㅋ&#xA;요런거 보면서 엄청 열띤 토론을 했다 ㅋㅋ 지수는 말 골랐고 길은 시간이었던거같고 나도 말 골랐는데 사실 선물빼고 셋다 우열을 가리기 어렵다고 생각했다 ㅠㅠ</description>
    </item>
    <item>
      <title>데이터 분석 #7 확률분포, 카이제곱검정</title>
      <link>http://localhost:1313/docs/study/ai/ai41/</link>
      <pubDate>Tue, 13 Jan 2026 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai41/</guid>
      <description>데이터 분석 #7 확률분포, 카이제곱검정 # #2026-01-13&#xA;#1 통계적 유의성&#xA;통계적 유의성&#xA;실험 결과로 나온 수치가 우연인지, 주장을 뒷받침할만큼 확률(빈도)이 높은 것인지 그 의미를 검증할수만 있으면 된다. 어떤 실험 결과가 통계적으로 유의하다는 말은 그 결과가 우연히 일어난 것이 아니라는 것 통계 분석을 통해 어떤 암에서 특정 유전자가 빈번하게 발현되는것을 발견했다고 할때 이것이 우연히 관측된 결과인지 중복된 관찰을 통해 큰 의미가 있는 것으로 결론지을수 있는 것인지 정량적으로 밝힐 수 있다. p-value</description>
    </item>
    <item>
      <title>제목없음</title>
      <link>http://localhost:1313/docs/hobby/book/book57/</link>
      <pubDate>Tue, 13 Jan 2026 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/book/book57/</guid>
      <description>제목없음 # #2026-01-13&#xA;#1&#xA;피험자가 비디오 게임을 하는 동안 환하게 빛난 해마 영역은 피험자가 꿈을 꾸기 시작하면서 자극을 받는 영역과 일치했다. 이미 알고 있듯이 우리는 시각 경로에 의해 앞을 볼 수 있는 것이며 이 경로의 어느 한 부분이라도 방해를 받으면 앞을 볼 수 없다. 뇌에는 꿈의 경로도 있어서, 눈을 감고 바깥세상을 보지 못하는 상태일지라도 마치 눈이 보이는것처럼 이미지를 지각할 수 있다. 눈을 감고 있어도 이미지를 지각할 수 있다는 것은 꿈의 회로와 시각 회로가 분리되어 있음을 뜻한다.</description>
    </item>
    <item>
      <title>데이터 분석 #6 pandas numpy 데이터 처리</title>
      <link>http://localhost:1313/docs/study/ai/ai40/</link>
      <pubDate>Fri, 09 Jan 2026 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai40/</guid>
      <description>데이터 분석 #6 pandas numpy 데이터 처리 # #2026-01-09&#xA;#1 데이터 처리&#xA;pandas scipy sklearn&#xA;pandas로 데이터프레임으로 데이터를 확인하고 scipy와 sklearn에서 통계 패키지와 머신러닝 패키지를 사용한다 numpy&#xA;python이 제공하는 머신러닝 패키지는 sklearn인데 이를 사용하려면 numpy를 알아야 한다. tensorflow같은 딥러닝 패키지들이 입출력을 위해 numpy를 사용한다 numpy는 다차원 배열인데 포함된 모든 데이터는 같은 형식이어야한다 머신러닝을 하고싶으면 float 형식으로 만들어진 다차원 배열이 필요하다. pandas 쓰는 이유&#xA;데이터가 표 형식이라도 그 안에는 여러 type의 데이터가 혼재되어 있고 행과 열의 라벨 등이 문자열일것인데, 이를 읽어들이는 도구가 pandas.</description>
    </item>
    <item>
      <title>전전두피질과 생각능력</title>
      <link>http://localhost:1313/docs/hobby/book/book56/</link>
      <pubDate>Fri, 09 Jan 2026 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/book/book56/</guid>
      <description>전전두피질과 생각능력 # #2026-01-09&#xA;#1&#xA;교묘하게 왜곡된 문장을 읽을 때 오차를 가려낼 경우에는 앞대상겉질(전측대상피질) 영역이 활성화되었지만 가장 활성화된 영역은 이마앞옆겉질(전전두엽피질)이었다. 이 영역은 습관에 기대려는 성향을 이겨내려는 의지를 비롯해 고차원적인 인지 과제를 풀 때 가장 주된 역할을 한다.&#xA;뇌는 익숙한 패턴을 인식하고 그것을 예상함으로써 사고의 효율성을 극대화하려고 노력한다. 왜곡된 문장은 기대한 의미와 실제 의미가 서로 어긋나기 때문에 제대로 해석하려면 집중력을 최대한 발휘해야 한다. 왜곡 여부를 제대로 알아내는 유일한 방법은 예측하려는 성향을 이마앞옆겉질이 지닌 고차원적인 인지 능력으로 막고 사실에만 초점을 맞추는 것밖에 없다.</description>
    </item>
    <item>
      <title>데이터 분석 #5 bash python과 bioinformatics</title>
      <link>http://localhost:1313/docs/study/ai/ai42/</link>
      <pubDate>Tue, 06 Jan 2026 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai42/</guid>
      <description>데이터 분석 #5 bash python과 bioinformatics # #2026-01-06&#xA;#1 생물정보학의 데이터&#xA;정보학&#xA;서로다른 두 종류의 데이터를 연결해서 새로운 데이터를 만들수있다. 일일이 알고리즘을 설계하고 직접 구현하기가 어렵기 때문에 툴을 사용하면 된다. 다만, 툴을 쓰면서 정보학 지식에 대해서 필요성을 느끼고 지속적으로 갖춰가야한다. ex. 데이터 더미에서 불필요한 부분을 없애는것과 정렬 작업 중 무엇을 먼저 할까? 생물정보학&#xA;수학, 통계, 컴퓨터과학을 이용해서 방대한 양의 생물학 데이터를 분석하고 유전자의 발현과 같은 생명 현상을 이해하는 학문. 질병 관련 단백질 찾기 - 항원항체 반응</description>
    </item>
    <item>
      <title>연말과 생일</title>
      <link>http://localhost:1313/docs/hobby/daily/daily28/</link>
      <pubDate>Mon, 05 Jan 2026 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/daily/daily28/</guid>
      <description>연말과 생일 (부제: 행복이 손닿는 감각) # #2026-01-05&#xA;수많은 추억을 끌어안구,, 정리하고 나온집&#xA;엄마아빠동생이랑 밥먹고 근처카페에서 커피도마시구&#xA;엄마가 먹고싶다한 타코야끼집이 3시 오픈이어서 카페에서 기다렸는데 25일이어서 휴무였다 ㅠㅠ 그래서 3시에 다들 집으로 돌아갔당&#xA;10분 누워있다가 바로 자기보러가깅 강남신세계 스위트파크 내가 좋아할거같다구 거기 가자고 해줬다&#xA;쓱 구경하다가 아이스크림 먹구!! 사진은 없는데 엄청마싰는 에그타르트도먹었다. ㅎㅎ&#xA;저녁은 뭐먹지머먹지 엄청 하다가 쿄코코라는 스테이크집을 갔다 자기가 무조건 구워먹어야한대서 구워먹었는데 그냥보다 훨배 마싰었다!!&#xA;방앗간에 들어간 참새가댄게 넘 기여워서 찍을수밖에없었던 ㅋㅋㅎㅎ</description>
    </item>
    <item>
      <title>춥지만 포근했던 연말</title>
      <link>http://localhost:1313/docs/hobby/daily/daily27/</link>
      <pubDate>Tue, 23 Dec 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/daily/daily27/</guid>
      <description>춥지만 포근했던 연말 # #2025-12-23</description>
    </item>
    <item>
      <title>사랑과 자유주의</title>
      <link>http://localhost:1313/docs/hobby/book/book55/</link>
      <pubDate>Mon, 22 Dec 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/book/book55/</guid>
      <description>사랑과 자유주의 # #2025-12-22&#xA;#1&#xA;사랑과 자유주의를 등식으로 보는, 전자가 후자의 하녀라고 보는 낙관적 입장에서는 이런 선택을 간과하는 경우가 많다. 설사 두 항을 결합시킨다고 해도 그것은 강제로 이루어진 결론에 불가하다. 사랑에 대하여 이야기하면서 동시에 상대를 마음대로 살게 해주는 것은 불가능해 보이기 때문이다. 상대가 우리더러 마음대로 살라고 허락한다면 그것은 보통 우리를 사랑하지 않는다는 것이다. 따라서, 왜 두 연인 사이에서 목격되는 잔인함을 &amp;ldquo;증오와는 다른 문제로 인정하고 받아들이지 못하는가&amp;rdquo; 하고 물어볼 수밖에 없다.</description>
    </item>
    <item>
      <title>2026 다이어리 쇼핑</title>
      <link>http://localhost:1313/docs/hobby/daily/daily22/</link>
      <pubDate>Sun, 23 Nov 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/daily/daily22/</guid>
      <description>2026 다이어리 쇼핑 # #2025-11-23&#xA;사실 다이어리를 쓰겠다고 맘먹은이상 11월말이댈때까지 다이어리를 못고른건 굉장히 이례적인데 ㅠㅠ 그만큼 살게 너무 없었다. 그래두 나름의 충분한 고찰을 거치고 흡족한 결론에 도달해서 쓰는 다이어리 결정기록 !&#xA;일단 후보는 아래 3개였다.&#xA;# 몰스킨 2026 라이프스파이럴 다이어리 아몬드 하드커버 라지 사실 9월정도부터 요녀석을 발견하고 이미 2026 다이어리는 이거다!!라구 정해놨었는데 이 블로그 글을 보고 매우 많은 고민을 하게되었다&amp;hellip;&#xA;나는 다이어리 맨날맨날들고다니면서 시도때도없이 펼쳐보는걸 좋아하기때문에, 비록 표지의 감성/색감, 속지 디자인/폰트 등 모든게 100% 내 취향이었음에도 불구하고 보내주겠다는 선택을 할수밖에 없었다 ㅠㅠ</description>
    </item>
    <item>
      <title>가을의 서울숲🍁</title>
      <link>http://localhost:1313/docs/hobby/daily/daily26/</link>
      <pubDate>Sat, 01 Nov 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/daily/daily26/</guid>
      <description>가을의 서울숲🍁 # #2025-11-01&#xA;첫 데이트를 잘 남기고 싶어서 미루다가 이제야 남기는,, 11월 1일 서울숲 기록 ㅎㅎ&#xA;나름의 웨이팅을 해주고 먹은 카츠바이콘반 맛은 당연히 마싯었구 밝지않은 우드톤인 내부 감성이 특히 좋았당&#xA;자기가 데려가준 서울숲&#xA;다리 너머 탁트인 전경이 사진에 안담겨서 넘 아쉽다. 시야와 함께 마음이 탁 트이는 기분이었는데!!&#xA;이전의 사진및 기억이 있지만 2025년 11월의 모습을 남기는중 ㅎㅎ&#xA;자기의 작품&#xA;내사진보다 훨씬 이쁘지만 역시 사진으론 나무의 무게감이 담기지 않는다 ㅠㅠ</description>
    </item>
    <item>
      <title>몽글몽글 10월 일상</title>
      <link>http://localhost:1313/docs/hobby/daily/daily24/</link>
      <pubDate>Fri, 31 Oct 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/daily/daily24/</guid>
      <description> 몽글몽글 10월 일상 # #2025-10-31&#xA;# </description>
    </item>
    <item>
      <title>Langchain #3 LangGraph 기반 Multi-Agent &#43; Agentic RAG 시스템</title>
      <link>http://localhost:1313/docs/study/be/be9/</link>
      <pubDate>Mon, 13 Oct 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be9/</guid>
      <description>Langchain #3 LangGraph 기반 Multi-Agent + Agentic RAG 시스템 # #2025-10-13&#xA;1. 실습 개요 # 목적&#xA;AI 헬스케어 스타트업의 투자 가치를 평가하기 위해 입력된 스타트업 정보에서 &amp;lsquo;경쟁사 유무를 자동 판별&amp;rsquo;하고, 판별 결과에 따라 워크플로우를 동적으로 분기하여 &amp;lsquo;Multi-Agent 시스템(10개 전문 에이전트)&amp;lsquo;이 각자의 역할(정보 수집, 기술력 분석, 시장성 평가, 경쟁사 비교)을 순차적으로 수행하며, 외부 문서(시장 보고서, 기술 리뷰, 규제 정보)를 &amp;lsquo;RAG 시스템(FAISS + OpenAI Embeddings)&amp;lsquo;으로 검색하여 LLM 분석에 참조 컨텍스트를 제공하고, &amp;lsquo;Scorecard Method 가중치 평가 방식&amp;rsquo;으로 6개 항목(창업자/팀, 시장성, 제품/기술력, 경쟁 우위, 실적, 투자조건)을 정량화하여 10점 만점 투자 점수를 산출한 뒤, 전체 프로세스를 &amp;lsquo;LangGraph 기반 상태 관리 워크플로우&amp;rsquo;로 자동화하고, 최종적으로 분석 결과를 Executive Summary, 기술력/시장성 평가, 경쟁 분석, 투자 판단을 포함한 전문적인 &amp;lsquo;Word/PDF 형식의 투자 평가 보고서&amp;rsquo;로 생성 실습 설계</description>
    </item>
    <item>
      <title>9월 일상 이모저모</title>
      <link>http://localhost:1313/docs/hobby/daily/daily23/</link>
      <pubDate>Tue, 30 Sep 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/daily/daily23/</guid>
      <description>9월 일상 이모저모 # #2025-09-30</description>
    </item>
    <item>
      <title>Langchain #2 RAG 기반 LLM API 서버 구축</title>
      <link>http://localhost:1313/docs/study/be/be29/</link>
      <pubDate>Tue, 23 Sep 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be29/</guid>
      <description>Langchain #2 RAG 기반 LLM API 서버 구축 # #2025-09-23&#xA;1. 실습1 - LLM 질문-응답 Agent 구현 # #1 작업 위치 설정&#xA;# 1. 작업 위치 $ pwd /Users/yshmbid/Documents/home/github/MLops/template/#10.code # 2. 파일 확인 $ ls __pycache__ practice_LLM_App_main.py practice_LLM_App_front.vue # #2 백엔드 띄우기&#xA;# 3. 백엔드 띄우기 $ uvicorn practice_LLM_App_main:app --port 8005 --reload INFO: Will watch for changes in these directories: [&amp;#39;/Users/yshmbid/Documents/home/github/MLops/template/#10.code&amp;#39;] INFO: Uvicorn running on http://127.0.0.1:8005 (Press CTRL+C to quit) INFO: Started reloader process [7018] using StatReload 🖥 CPU 환경에서 로드합니다.</description>
    </item>
    <item>
      <title>AI #2 HPO, XAI 실습</title>
      <link>http://localhost:1313/docs/study/ai/ai38/</link>
      <pubDate>Mon, 22 Sep 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai38/</guid>
      <description>AI #2 HPO, XAI 실습 # #2025-09-22&#xA;1. 실습 개요 # 목적 UCI Breast Cancer 데이터를 로드하고 전처리 후 XGBoost 모델을 구축 및 평가 교차검증(StratifiedKFold, KFold)과 하이퍼파라미터 탐색 기법(RandomizedSearchCV, Optuna)을 비교하여 최적 성능을 도출 SHAP을 활용하여 전역적·집단적·개별적 수준에서 해석력을 확보하고 도메인 지식과 연결 구현 데이터 로드: UCI Breast Cancer 데이터셋 데이터 전처리: 타겟(Diagnosis)을 이진화(M=1, B=0), StandardScaler로 범위 스케일링, 상관계수 0.9 이상인 중복 변수 제거 모델 구축: xgboost.XGBClassifier 모델 평가: 정확도, AUC, 분류리포트, 혼동행렬, feature importance 교차검증: KFold, StratifiedKFold 하이퍼파라미터 최적화: Random Search, Optuna TPE 모델 해석 (SHAP) Bar Summary Plot: 전역적 중요도(평균 |SHAP|)를 통해 주요 변수 확인 Beeswarm Plot: 변수 값 크기(빨강/파랑)와 방향성(+/−)에 따른 분포 해석 Force / Waterfall Plot: 3가지 개별 환자 샘플(예측 확률 극단/불확실, SHAP 영향력 최대, 도메인 특이 케이스)을 선택하여 모델이 어떤 요인 때문에 해당 예측을 내렸는지 설명 # 2.</description>
    </item>
    <item>
      <title>AI #1 ML 방법론 기초</title>
      <link>http://localhost:1313/docs/study/ai/ai36/</link>
      <pubDate>Fri, 19 Sep 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai36/</guid>
      <description>AI #1 ML 방법론 기초 # #2025-09-19&#xA;#1 ML 방법론&#xA;통계기반 방법론은? linear regression이나 logistic regression 같은걸 말함 가설과 근거가 명확히 세워져 있고 데이터가 알고리즘에 맞게 정제돼있고 통계적 유의성으로 결과가 나오는 깔끔한 방식 ML 방법론은? 작은 경연을 열듯 시행착오를 거치며 가장 적합한 모델을 찾는다는 컨셉이다. # #2 지도 비지도 준지도&#xA;모두 입력 데이터에 존재하는 구조를 추론함 준지도 이상 탐지: 처럼 라벨링 비용이 클때 딥러닝: 은 파라미터 수가 많아 안정적인 학습을 위해 충분한 데이터가 필요한데 우선 라벨이 있는 데이터로 기본 학습을 진행하고 -&amp;gt; 라벨이 없는 데이터의 구조나 의사결정 경계를 활용해 모델을 보완함 # #3 regression, instance based algorithm</description>
    </item>
    <item>
      <title>FastAPI #1 MariaDB, DB Migration, Swagger UI</title>
      <link>http://localhost:1313/docs/study/be/be24/</link>
      <pubDate>Wed, 17 Sep 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be24/</guid>
      <description>FastAPI #1 MariaDB, DB Migration, Swagger UI # #2025-09-17&#xA;1. 실습 내용 # #1 maria db container 띄우기&#xA;# 1. conda 가상환경 생성 $ conda create -n demo-app python=3.11 $ conda activate demo-app # 2. 작업 위치 # mariadb_tmplt 디렉토리를 다운받고 압축 해제함 $ pwd /Users/yshmbid/Documents/home/github/MLops/mariadb_tmplt $ ls conf.d data env maria_db.yaml # 3. Docker Compose로 MariaDB 실행 $ docker compose -p maria_db -f maria_db.yaml up -d # 4. 컨테이너가 잘떴는지확인 $ docker ps | grep mariadb ae333f330cc4 mariadb:10.</description>
    </item>
    <item>
      <title>FastAPI #2 논문 업로드 및 벡터화 API</title>
      <link>http://localhost:1313/docs/study/be/be26/</link>
      <pubDate>Wed, 17 Sep 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be26/</guid>
      <description>FastAPI #2 논문 업로드 및 벡터화 API # #2025-09-17&#xA;1. 실행 # $ pwd /Users/yshmbid/Documents/home/github/MLops $ ls mariadb_tmplt pjt-main.py skala-fastapi-rpt.zip mariadb_tmplt.zip skala-fastapi-rpt template.zip $ uvicorn pjt-main:app --host 127.0.0.1 --port 8002 --reload INFO: Will watch for changes in these directories: [&amp;#39;/Users/yshmbid/Documents/home/github/MLops&amp;#39;] INFO: Uvicorn running on http://127.0.0.1:8002 (Press CTRL+C to quit) INFO: Started reloader process [75232] using WatchFiles INFO: Started server process [75234] INFO: Waiting for application startup. INFO: Application startup complete.</description>
    </item>
    <item>
      <title>FastAPI #3 비동기 데이터베이스</title>
      <link>http://localhost:1313/docs/study/be/be25/</link>
      <pubDate>Wed, 17 Sep 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be25/</guid>
      <description>FastAPI #3 비동기 데이터베이스 # #2025-09-17&#xA;#1 main.py&#xA;#main.py # FastAPI 엔드포인트 정의 이해 # FastAPI는 아래 두 가지 방식 중 하나로 엔드포인트를 정의 # ① 직접 app에 정의 # ② 모듈화한 라우터 파일을 include from fastapi import FastAPI from api.routers import task_a from api.routers import done_a from fastapi.staticfiles import StaticFiles from fastapi.responses import FileResponse from fastapi.openapi.docs import get_swagger_ui_html import os main.py fastapi app 서버를 구성. fastapi 프레임워크 웹 요청이 들어오면 특정 함수로 연결해준다.</description>
    </item>
    <item>
      <title>Ray #1 Batch Prediction with Ray Core</title>
      <link>http://localhost:1313/docs/study/be/be6/</link>
      <pubDate>Mon, 15 Sep 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be6/</guid>
      <description>Ray #1 Batch Prediction with Ray Core # #2025-09-15&#xA;스터디때 준비해갔던 Ray Core를 사용해서 batch prediction 수행하는 예제!!&#xA;batch prediction이 batch를 예측하는건줄알았는데(..) batch로 prediction하는것이었다. 순서는 1. Task 기반 batch prediction 2. Actor 기반 batch prediction 3. GPU 기반 수행 코드 출처는 Ray Document의 Batch Prediction with Ray Core이다. # 0. 개요 # 목적 Parquet 형식의 대규모 데이터셋을 Ray를 이용해 분산 처리하며, 더미 모델을 로딩하여 배치 예측(batch prediction) 을 수행한다. Task와 Actor 두 가지 실행 방식을 비교하고, CPU/GPU 자원 활용 차이를 이해한다.</description>
    </item>
    <item>
      <title>AI #1 ML 방법론 기초</title>
      <link>http://localhost:1313/docs/study/ai/ai33/</link>
      <pubDate>Sat, 13 Sep 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai33/</guid>
      <description>AI #1 ML 방법론 기초 # #2025-09-13&#xA;#1 ML type (p.31-33)&#xA;ML의 학습방법 3가지 지도학습(Supervised) 입력 데이터와 출력 데이터가 모두 제공되고 모델은 입력을 보면 어떤 출력이 나와야 하는지를 배움. 학습한 모델은 새로운 데이터가 들어오면 예측을 하고 -&amp;gt; 결과를 실제 정답과 비교해 정확도 계산. 비지도학습(Unsupervised) 문제는 있지만 정답 라벨이 없음. 비슷한 특징을 가진 학생들을 묶어서 그룹을 만들고 어떤 그룹이 우수한지 알 수 없지만 데이터 안에서 자연스럽게 나타나는 구조를 파악한다(클러스터링) 준지도학습(Semi-Supervised) 라벨이 붙은 소량의 데이터와, 라벨이 없는 대량의 데이터를 동시에 사용하면 더 나은 모델을 만들 수 있다 왜냐하면 100% 라벨링된 데이터가 있을 때만큼 정확하지는 않지만, 현실에서는 라벨링이 부족한 경우가 많고 라벨 없는 데이터가 양은 많아서 데이터 분포를 더 잘 보여주기 때문이다.</description>
    </item>
    <item>
      <title>ATMOSPHERE</title>
      <link>http://localhost:1313/docs/hobby/daily/daily20/</link>
      <pubDate>Fri, 12 Sep 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/daily/daily20/</guid>
      <description> ATMOSPHERE # #2025-09-12&#xA;# </description>
    </item>
    <item>
      <title>Langchain #1 노션 데이터로 나만의 RAG 시스템 구축하기 (스터디)</title>
      <link>http://localhost:1313/docs/study/be/be5/</link>
      <pubDate>Wed, 10 Sep 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be5/</guid>
      <description>Langchain #1 노션 데이터로 나만의 RAG 시스템 구축하기 (스터디) # #2025-09-10&#xA;스터디하는친구가 만들어준코드인데 내 노션으로 돌려봤다!&#xA;실습 목적&#xA;노션 데이터를 임베딩 생성하여 FAISS 벡터 스토어에 저장하고 이를 기반으로 유사 문서 검색을 수행하며, 청킹 기법을 통해 데이터 구조를 이해하고 LLM 프롬프트 제약을 적용한 뒤, RAG 구조를 접목해 자동 답변 구현 실습 설계&#xA;임베딩 생성: SentenceTransformer(&amp;ldquo;BAAI/bge-m3&amp;rdquo;) 유사 문서 검색: 코사인 유사도 + FAISS 벡터 스토어 기반 최근접 탐색 청킹 기법: Markdown 단위 분리 + 길이 기반 추가 분할 LLM 프롬프트 제약: 근거 기반 답변(추측 금지 규칙 포함) 자동 답변 구현: RAG 구조 + &amp;ldquo;meta-llama/llama-3.</description>
    </item>
    <item>
      <title>Kubernetes #2 ConfigMap, PVC, Liveness/Readiness, Blue/Green</title>
      <link>http://localhost:1313/docs/study/be/be33/</link>
      <pubDate>Tue, 09 Sep 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be33/</guid>
      <description>Kubernetes #2 ConfigMap, PVC, Liveness/Readiness, Blue/Green # #2025-09-09&#xA;1. kubectl 명령어 실습 # #1 배포된 컨테이너를 쿠버네티스에서 확인하기&#xA;# 배포 상태 확인 $ kubectl get pod -n skala-practice | grep sk019 sk019-myfirst-api-server-57fddcd6c8-l4jms 1/1 Running 0 108m # 서비스 확인 $ kubectl get svc -n skala-practice | grep sk019 sk019-myfirst-api-server ClusterIP 10.100.83.86 &amp;lt;none&amp;gt; 8080/TCP,8081/TCP 18h # #2 로컬 &amp;lt;-&amp;gt; Pod 간 파일/디렉토리 복사&#xA;# 수행 위치 $ pwd /Users/yshmbid/Documents/home/github/Cloud/workspace/kubernetes/02.deploy # Pod 이름 확인 $ kubectl get pod -n skala-practice | grep sk019 sk019-myfirst-api-server-57fddcd6c8-l4jms 1/1 Running 0 120m # 로컬의 data 디렉토리를 Pod 내부 /app/data 로 복사 $ kubectl cp $(pwd)/data skala-practice/sk019-myfirst-api-server-57fddcd6c8-l4jms:/app/data # Pod /app/data → 로컬 .</description>
    </item>
    <item>
      <title>Kubernetes #1 Pod, Port-forward</title>
      <link>http://localhost:1313/docs/study/be/be32/</link>
      <pubDate>Mon, 08 Sep 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be32/</guid>
      <description>Kubernetes #1 Pod, Port-forward # #2025-09-08&#xA;1. 실습환경설정 # 필요 패키지 kubectl, jq, curl, maven, Java brew install kubectl jq curl maven kubectl&#xA;Kubernetes 클러스터와 통신하는 CLI 도구 쿠버네티스는 여러 개의 프로그램이 동시에 돌아가는 큰 시스템이고 여기에 지시를 내리는 도구. Java 17&#xA;여러 프로그램을 실행하는 공통 실행 환경(JVM)을 제공 공통 실행 환경? 여러 프로그램을 공통 언어로 사용하게해준다. 프로그램들이 Java가 어디 있는지 알아야 하니까 JAVA_HOME이라는 환경 변수를 설정해준다. export JAVA_HOME=/opt/homebrew/opt/openjdk@17 # 클라우드 인증 정보, 커맨드 스크립트 다운로드 # 클라우드 인증 정보 wsl-install.</description>
    </item>
    <item>
      <title>DBMS 및 SQL 활용 #5 Vector DB 스키마 설계</title>
      <link>http://localhost:1313/docs/study/be/be34/</link>
      <pubDate>Tue, 02 Sep 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be34/</guid>
      <description>DBMS 및 SQL 활용 #5 Vector DB 스키마 설계 # #2025-09-02&#xA;1. 개념 # #1 KNN vs ANN&#xA;KNN과 ANN의 공통 목적&#xA;질문을 하고 그 질문과 비슷한 질문이나 답변을 데이터베이스에서 찾기 구현 차이&#xA;모든 데이터를 하나하나 다 비교해서 가장 가까운 것을 찾는다(KNN) 데이터 전체를 다 비교하지 않고 인덱스를 이용해서 후보군을좁혀서 그 안에서만 비교(ANN) 친구가 수십만 명 있으면 모든 친구에게 질문을 던져서 과거 답변을 확인하는 대신 비슷한 취향을 가진 대표 그룹 몇 개를 빠르게 찾고 그 안에서만 가장 가까운 답을 고르는 방식.</description>
    </item>
    <item>
      <title>Java #2 객체지향 설계 원칙 SOLID</title>
      <link>http://localhost:1313/docs/study/fe/fe19/</link>
      <pubDate>Tue, 02 Sep 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/fe/fe19/</guid>
      <description>Java #2 객체지향 설계 원칙 SOLID # #2025-09-02&#xA;목차 # 단일 책임 원칙 (Single Responsibility Principle, SRP) 개방-폐쇄 원칙 (Open-Closed Principle, OCP) 리스코프 치환 원칙 (Liskov Substitution Principle, LSP) 인터페이스 분리 원칙 (Interface Segregation Principle, ISP) 의존 역전 원칙 (Dependency Inversion Principle, DIP) 공통 특성: 응집도를 높이거나 결합도를 낮추는 설계 # 1. 단일 책임 원칙 (Single Responsibility Principle, SRP) # #1 정의&#xA;한 클래스는 하나의 책임만 가져야 하고 클래스가 변경되어야 할 이유는 오직 하나여야 한다.</description>
    </item>
    <item>
      <title>혼돈후의 고요</title>
      <link>http://localhost:1313/docs/hobby/book/book54/</link>
      <pubDate>Tue, 02 Sep 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/book/book54/</guid>
      <description>혼돈후의 고요 # #2025-09-02&#xA;#1&#xA;병이 어떻게 시작되었는지 알리스는 뚜렷이 기억한다. 당시의 통증은 뱃속에서 화산이 폭발하는 듯했다. 어머니에게 이렇게 고통스러운 게 정상이냐고 묻자, 어머니는 그렇다고 답했다. 어느 날 어머니가 아무래도 병원에 데려가야겠다고 결심했다. 의사의 입에서는 이런 말이 나왔다. &amp;ldquo;자궁 내막증입니다.&amp;rdquo; 의사는 그것이 염증성 여성 질환이며 전 세계 여성 10퍼센트에게 발생하는 만큼 비교적 흔한 병이라고 설명했다. 그중 다수가 사춘기부터 갱년기까지 질환을 안고 살지만 그리 어렵지 않게 증상을 다스린다고 덧붙였다. 위로하려는 양, 매릴린 먼로 역시 그 병을 앓았지만 그래도 온 세상이 찬사를 바치는 여자가 되지 않았냐고 하기까지 했다.</description>
    </item>
    <item>
      <title>Java #1 객체지향 프로그래밍: 캡슐화, 추상화, 다형성, 상속</title>
      <link>http://localhost:1313/docs/study/fe/fe20/</link>
      <pubDate>Mon, 01 Sep 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/fe/fe20/</guid>
      <description>Java #1 객체지향 프로그래밍: 캡슐화, 추상화, 다형성, 상속 # #2025-09-01&#xA;목차 # 캡슐화 추상화 다형성 상속 공통 특성: 인터페이스와 구현의 분리 # 1. 캡슐화 # #1 개념 및 목적&#xA;개념 객체지향 프로그래밍에서 객체의 속성(필드)을 외부로부터 숨기고, 공개된 메서드(getter/setter)를 통해서만 접근하도록 만드는 원칙 필드를 private으로 선언하고, 외부에서 직접 접근하지 못하게 제한하고, public 메서드인 getter와 setter를 제공해 값을 읽거나 수정할 수 있도록 한다. setter 내부에는 유효성 검사 로직을 넣어 잘못된 값이 들어오는 것을 막을 수도 있다.</description>
    </item>
    <item>
      <title>POINT of VIEW 포인트오브뷰 서울</title>
      <link>http://localhost:1313/docs/hobby/daily/daily19/</link>
      <pubDate>Sun, 31 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/daily/daily19/</guid>
      <description>POINT of VIEW 포인트오브뷰 서울 # #2025-08-31&#xA;사람 많은것만 빼면 다 좋은 곳 ㅎㅎ 몇번 가봤는데 갈때마다 점점 맘에 든당&#xA;# 그러고 그냥 서울 소품샵 방앗간이 되겠다~ 생각하고 말았었는데&#xA;찾고싶은 물건이 있어서 홈페이지를어쩌다가 들어갔는데 너무너무 내취향이어서 충격받았다.&#xA;여기를 대하는 마음가짐이 홈페이지를 보기 전이랑 후가 완전히 달라져서, 주중 오전쯤 사람 별로 없을때 가면 진짜 행복한 시간을 보낼수있을것같아서 벌써 설렌다 ㅎㅎ&#xA;물건이 너무 많아서 다보진 못했구 TOOLS 들어가서 한 22페이지까지만 봤다.</description>
    </item>
    <item>
      <title>DBMS 및 SQL 활용 #3 집계함수, 고급 객체기능, 고급 인덱스</title>
      <link>http://localhost:1313/docs/study/be/be37/</link>
      <pubDate>Thu, 28 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be37/</guid>
      <description>DBMS 및 SQL 활용 #3 집계함수, 고급 객체기능, 고급 인덱스 # #2025-08-28&#xA;1. GROUPBY # GROUP BY&#xA;테이블 안에 있는 데이터를 특정 기준으로 묶어서 요약.&#xA;테이블 embedding_store에서&#xA;id, user_id, cluster_id, similarity, tag 5개 컬럼이 있는데 있는 그대로보면 큰 그림을 보기 힘들다 즉 해석이 어렵다. GROUP BY를 쓰면 요약 정보를 만들수있는데 user_id로 묶으면 “사용자 A는 총 10건, 사용자 B는 총 5건” 같은 식으로 정리 / cluster_id로 묶으면 “클러스터 1은 평균 유사도가 0.</description>
    </item>
    <item>
      <title>DBMS 및 SQL 활용 #4 pgvector 기반 유사도 검색 &#43; FastAPI 연동</title>
      <link>http://localhost:1313/docs/study/be/be38/</link>
      <pubDate>Thu, 28 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be38/</guid>
      <description>DBMS 및 SQL 활용 #4 pgvector 기반 유사도 검색 + FastAPI 연동 # #2025-08-28&#xA;1. 실습 시나리오 # -- 1. 확장 설치 및 테이블 생성 -- 2. 예시 데이터 삽입 (10건만 임시) -- 3. 인덱스 생성 및 분석 -- 4. 성능 비교: LIMIT 5 vs LIMIT 50 -- 5. 인덱스 종류별 비교 (코사인 vs L2) -- 6. 사용자 입력 벡터를 Python에서 API로 전달하여 동적 쿼리 구성 예시 (FastAPI 측에서 처리) # 2.</description>
    </item>
    <item>
      <title>DBMS 및 SQL 활용 #1 설계안 데이터 적재 (postgresql, pgvector)</title>
      <link>http://localhost:1313/docs/study/be/be35/</link>
      <pubDate>Wed, 27 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be35/</guid>
      <description>DBMS 및 SQL 활용 #1 설계안 데이터 적재 (postgresql, pgvector) # #2025-08-27&#xA;1. 실습1 # 실습 시나리오&#xA;사용자가 설계안 텍스트(예: description)를 입력 해당 텍스트에 대해 Python에서 AI 임베딩을 수행 임베딩 결과가 유효할 경우 design 테이블에 등록 (COMMIT) 실패하면 아무 데이터도 등록하지 않음 (ROLLBACK) PostgreSQL + pgvector 확장 사용 Python에서 psycopg2 + 임베딩 처리 # 코드&#xA;#1 SQL&#xA;CREATE EXTENSION IF NOT EXISTS vector; CREATE TABLE IF NOT EXISTS design ( id SERIAL PRIMARY KEY, description TEXT, embedding VECTOR(1536) -- OpenAI 임베딩 차원 ); # #2 python</description>
    </item>
    <item>
      <title>DBMS 및 SQL 활용 #2 트랜젝션 격리수준, pgaudit, AI 시스템 운영</title>
      <link>http://localhost:1313/docs/study/be/be36/</link>
      <pubDate>Wed, 27 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be36/</guid>
      <description>DBMS 및 SQL 활용 #2 트랜젝션 격리수준, pgaudit, AI 시스템 운영 # #2025-08-27&#xA;1. 트랜젝션 격리수준 # 트랜젝션&#xA;데이터베이스에서 하나의 작업 단위. 여러 개의 쿼리나 연산이 묶여 하나로 실행되는데 그 결과는 전부 성공하거나 아니면 전부 실패해서 원래 상태로 되돌아가야 한다. 그렇지 않으면 데이터가 꼬인다. 문제는?&#xA;여러 사람이 동시에 같은 데이터베이스를 건드린다. 그래서 데이터가 뒤섞이지 않도록 격리 수준이라는 규칙을 둬야한다. 데이터가 뒤섞인다?&#xA;은행 계좌에서 A 트랜잭션이 “잔액 100만 원에서 10만 원 빼기” 작업을 하고 있고 동시에 B 트랜잭션이 “잔액 100만 원에서 20만 원 빼기” 작업을 한다고 하면 각각 따로 실행하면 당연히 최종 잔액은 70만 원이 되어야 한다.</description>
    </item>
    <item>
      <title>MLops #2 mlflow 파이프라인</title>
      <link>http://localhost:1313/docs/study/ai/ai25/</link>
      <pubDate>Fri, 22 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai25/</guid>
      <description>MLops #2 mlflow 파이프라인 # #2025-08-22&#xA;1. 코드 # #1 트래킹 서버 설정&#xA;import os import mlflow # 1. 로그를 저장할 서버/위치 지정 mlflow.set_tracking_uri(uri=os.getenv(&amp;#34;MLFLOW_TRACKING_URI&amp;#34;, &amp;#34;&amp;#34;)) # MLFLOW_TRACKING_URI로 MLflow 서버를 연결 current_uri = mlflow.get_tracking_uri() print(f&amp;#34;Current Tracking URI: {current_uri}&amp;#34;) # #2 Experiment 생성&#xA;# 2. Experiment 생성 experiment = mlflow.set_experiment(&amp;#34;new_experiment&amp;#34;) print(f&amp;#34;Experiment ID: {experiment.experiment_id}&amp;#34;) print(f&amp;#34;Experiment Name: {experiment.name}&amp;#34;) print(f&amp;#34;Artifact Location: {experiment.artifact_location}&amp;#34;) print(f&amp;#34;Lifecycle Stage: {experiment.lifecycle_stage}&amp;#34;) Experiment ID: 2 Experiment Name: new_experiment Artifact Location: /mlflow/mlruns/2 Lifecycle Stage: active # #3 information 확인, 로그 기록</description>
    </item>
    <item>
      <title>MLops #1 mlflow 설치 &amp; 실습</title>
      <link>http://localhost:1313/docs/study/ai/ai24/</link>
      <pubDate>Thu, 21 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai24/</guid>
      <description>MLops #1 mlflow 설치 &amp;amp; 실습 # #2025-08-21&#xA;1. mlflow 설치 및 docker 띄우기 # $ export CR_PAT=* # *: github token 블라인드 처리 $ echo $CR_PAT | docker login ghcr.io -u yshghid --password-stdin Login Succeeded 로그인햇으면 도커를 켠다음에 다음을 수행.&#xA;$ docker pull ghcr.io/mlflow/mlflow:v2.0.1 v2.0.1: Pulling from mlflow/mlflow 7a6db449b51b: Pull complete e238bceb2957: Pull complete ce77f44508b5: Pull complete 455a39ac3ab8: Pull complete f8c2fbfe5046: Pull complete 60e3c6e8536b: Pull complete Digest: sha256:1e1f28a6134e7e6c4b0d0a4f5f8647ff31c953ad53eb3bb5af4c51ae4e8dd14d Status: Downloaded newer image for ghcr.</description>
    </item>
    <item>
      <title>python #3 pgvector 유사 리뷰 검색</title>
      <link>http://localhost:1313/docs/study/be/be48/</link>
      <pubDate>Wed, 20 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be48/</guid>
      <description>python #3 pgvector 유사 리뷰 검색 # #2025-08-20&#xA;1. 목적 # 고객 리뷰 문장을 벡터로 임베딩하고 PostgreSQL의 pgvector 기능을 활용하여 비슷한 리뷰를 검색하는 기능을 구현&#xA;# 2. 코드 # import torch import transformers import sentence_transformers import sklearn import numpy import scipy print(f&amp;#34;torch: {torch.__version__}&amp;#34;) print(f&amp;#34;transformers: {transformers.__version__}&amp;#34;) print(f&amp;#34;sentence-transformers: {sentence_transformers.__version__}&amp;#34;) print(f&amp;#34;scikit-learn: {sklearn.__version__}&amp;#34;) print(f&amp;#34;numpy: {numpy.__version__}&amp;#34;) print(f&amp;#34;scipy: {scipy.__version__}&amp;#34;) from dotenv import load_dotenv import os load_dotenv() # 같은 폴더에 있는 .env 로드 torch: 2.2.2 transformers: 4.</description>
    </item>
    <item>
      <title>LLM #2 LLM과 AI 기술요소를 활용하여 비즈니스 서비스 기획안 작성</title>
      <link>http://localhost:1313/docs/study/be/be8/</link>
      <pubDate>Tue, 19 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be8/</guid>
      <description>LLM #2 LLM과 AI 기술요소를 활용하여 비즈니스 서비스 기획안 작성 # #2025-08-19&#xA;1. 목적 # 등기부등본/건축물대장 업로드 시 AI가 자동으로 문서를 분석하여 전세사기 위험 요소를 탐지하고 수치화한다. # 2. 모델 구성도 # #1 데이터 수집및 정규화&#xA;기술요소: PaddleOCR 선택 이유: 한국어 인식 정확도와 속도가 좋고, 오픈소스+온프레미스 운영 가능(비용·보안 유리), 표 레이아웃/좌표 추출 지원. 입력 파일: PDF/스캔 이미지(JPG/PNG) 매개변수: lang=&amp;ldquo;korean&amp;rdquo;, det+rec 사용, dpi(≥300) 출력 텍스트 블록: [{page, bbox, text}] 정규화 결과: 주소/금액/날짜/권리유형 표준화(JSON) #2 위험 특약/권리 분석</description>
    </item>
    <item>
      <title>데이터 분석 #4 리뷰 데이터 분석</title>
      <link>http://localhost:1313/docs/study/ai/ai22/</link>
      <pubDate>Tue, 19 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai22/</guid>
      <description>데이터 분석 #4 리뷰 데이터 분석 # #2025-08-19&#xA;1. 목적 # 리뷰 데이터를 보고&#xA;감성 점수와 평점의 관계 리뷰 길이와 감성 점수의 관계 카테고리별 감성 차이 Review_length가 AI 임베딩 유사도에 영향을 줄 수 있는지 인사이트 생성하기.&#xA;# 2. 코드 # import os import pandas as pd import numpy as np import seaborn as sns import matplotlib.pyplot as plt import matplotlib.pyplot as plt import matplotlib as mpl from sentence_transformers import SentenceTransformer, util # Mac 환경 한글 폰트 설정 plt.</description>
    </item>
    <item>
      <title>LLM #1 LLM 이해와 Transformer</title>
      <link>http://localhost:1313/docs/study/be/be7/</link>
      <pubDate>Mon, 18 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be7/</guid>
      <description>LLM #1 LLM 이해와 Transformer # #2025-08-11&#xA;1. LLM 기본이해 # #1 Word Embedding (p.27-28)&#xA;Word Embedding&#xA;핵심 아이디어는 단어가 어떤 맥락에서 자주 함께 등장하는지를 학습. “you say goodbye and I say hello”에서 ‘goodbye’주변에는 ‘you’, ‘say’, ‘and’, ‘I’ 같은 단어가 함께 등장하고 그 관계를 학습하도록 신경망을 훈련시킨다. 학습이 반복되면 각 단어는 벡터로 표현되고 의미가 비슷한 단어일수록 벡터 공간에서 가깝게 위치한다. Input이 ‘goodbye’이고 Target이 ‘you’, ‘say’, ‘and’, ‘I’여도 된다. Word Embedding - 신경망 구조 그림</description>
    </item>
    <item>
      <title>논문 어셉.. ㅠㅠ</title>
      <link>http://localhost:1313/docs/study/career/career7/</link>
      <pubDate>Sat, 16 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/career/career7/</guid>
      <description> 논문 어셉.. ㅠㅠ # #2025-08-16&#xA;학위논문이랑 skala 병행하면서 신체/정신적 체력이슬슬 고갈되던중이었는데&#xA;여느날처럼 새벽에 깼는데 어셉메일이 와있었다 ㅎㅎㅎ&#xA;# 리비전때 사실 잘못적은내용이있어서 계속걸렸었고 2차리비전 각오도 하고있었는데 돼버리니깐 안와닿는데 너무 좋다. ㅎㅎ 진짜 한시름 덜었따&#xA;어제오늘 좀쳐져서 잠도너무많이자고그랬는데 진짜이번주안에 학위논문이랑 피피티 마무리할수있을거같다 ㅎㅎㅎ&#xA;# # </description>
    </item>
    <item>
      <title>python #2 객체지향 프로그래밍, 병렬처리</title>
      <link>http://localhost:1313/docs/study/be/be47/</link>
      <pubDate>Wed, 13 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be47/</guid>
      <description>python #2 객체지향 프로그래밍, 병렬처리 # #2025-08-13&#xA;1. 객체지향 프로그래밍 # #1 property &amp;amp; dataclass (p.139-140)&#xA;@property&#xA;diameter 메서드는 사실 _radius * 2라는 계산을 수행하지만 외부에선 c.diameter라고 쓰면 바로 10이라는 결과를 얻을 수 있다. @diameter.setter를 사용하면 c.diameter = 20 형태로 diameter을 수정할수있고 내부에서는 diameter을 받아 _radius=10으로 변환 저장한다. fastapi에서 젤많이쓰는 기능이 속성화이다. @dataclass&#xA;보통 클래스를 만들면 __init__으로 생성자, __repr__으로 객체 출력 형식, __eq__로 동등성 비교 등을 직접 정의해야 하는데 @dataclass를 붙이면 이런 메서드들이 자동 생성된다.</description>
    </item>
    <item>
      <title>python #1 기본문법, 가상환경, 로깅</title>
      <link>http://localhost:1313/docs/study/be/be45/</link>
      <pubDate>Tue, 12 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be45/</guid>
      <description>python #1 기본문법, 가상환경, 로깅 # #2025-08-12&#xA;1. 기본문법 # #1 break와 continue의 차이 (p.29)&#xA;# break for i in range(10): if i==5: break print(i) # continue for i in range(5): if i==2: continue print(i) break 0부터 9까지 세는 반복문에서 i가 5가 되는 순간 break를 만나면 그 뒤의 숫자는 전혀 세지 않고 반복이 끝난다. continue 0부터 4까지 세는 반복문에서 i가 2인 경우 continue를 만나면 2를 출력하지 않고 바로 다음 숫자인 3으로 넘어가고 반복문 자체는 끝나지 않는다.</description>
    </item>
    <item>
      <title>python #2 리스트 vs 제너레이터 비교 실습</title>
      <link>http://localhost:1313/docs/study/be/be46/</link>
      <pubDate>Tue, 12 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be46/</guid>
      <description>python #2 리스트 vs 제너레이터 비교 실습 # #2025-08-12&#xA;1. 100만 개의 숫자 합 구하기 # 1) 리스트 방식&#xA;import sys # 1) 리스트 방식 numbers = list(range(1000000)) # 0부터 999,999 리스트 생성 list_sum = sum(numbers) # 합계 구하기 list_mem = sys.getsizeof(numbers) # 메모리 사용량 확인 (리스트 객체 크기) print(f&amp;#34;리스트 합: {list_sum:,}&amp;#34;) print(f&amp;#34;리스트 메모리 사용량: {list_mem} bytes&amp;#34;) 리스트 합: 499,999,500,000 리스트 메모리 사용량: 8000056 bytes numbers=list(range(1000000)) -&amp;gt; sum(numbers) 0~999,999를 리스트(numbers)로 만들어 합계를 구함 sys.</description>
    </item>
    <item>
      <title>Devops #1 Python 프로젝트 CI/CD &amp; 클라우드 빌드</title>
      <link>http://localhost:1313/docs/study/be/be10/</link>
      <pubDate>Mon, 11 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be10/</guid>
      <description>Devops #1 Python 프로젝트 CI/CD &amp;amp; 클라우드 빌드 # #2025-08-11&#xA;실습 # 메이크파일, 린팅, 테스트와 같이 파이썬 프로젝트 스캐폴딩에 필수적인 요소가 포함된 깃허브 저장소를 생성해보자. 그리고 간단하게 코드 포매팅을 수행하도록 메이크파일 스크립트를 작성해보자.&#xA;깃허브 액션을 사용하여 두개 이상의 파이썬 버전에 대해 깃허브 프로젝트 테스트를 수행해보자.&#xA;클라우드 네이티브 빌드 서버(AWS 코드빌드, GCP 클라우드 빌드, 애저 DevOps 파이프라인)를 사용하여 지속적 통합을 수행해보자.&#xA;깃허브 프로젝트를 도커 파일로 컨테이너화하고, 자동으로 컨테이너 레지스트리에 새로운 컨테이너가 등록되도록 만들어보자.</description>
    </item>
    <item>
      <title>생성형 AI #1 생성형 AI 기초 및 Prompt Engineering</title>
      <link>http://localhost:1313/docs/study/ai/ai18/</link>
      <pubDate>Sat, 09 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai18/</guid>
      <description>생성형 AI #1 생성형 AI 기초 및 Prompt Engineering # #2025-08-09&#xA;#1 RAG (p.27)&#xA;RAG의 역할?&#xA;질문을 LLM에 던지기 전에 knowledge corpus에 질문을 미리 검색한다(회사 데이터에 대한 지식 벡터 db). 질문과 연관된 문서를 찾고 적절하게 만들어서 retrieval 던지면 의도대로 답변이 잘 나온다. # #2 LLM 출력 구성 (p.42-45)&#xA;Output Length (Max Tockens)&#xA;500자로 제한을 걸면 500자로 맞춰주는게 아니라 500자 넘으면 출력을 멈춘다. Sampling Controls&#xA;LLM은 다음에 올 단어를 고를 때 미리 계산된 사전 확률분포를 가지고 거기서 하나를 뽑는다</description>
    </item>
    <item>
      <title>생성형 AI #2 Prompt Engineering 실습 미리돌려보기</title>
      <link>http://localhost:1313/docs/study/ai/ai19/</link>
      <pubDate>Sat, 09 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai19/</guid>
      <description>생성형 AI #2 Prompt Engineering 실습 미리돌려보기 # #2025-08-09&#xA;1. VOC 분석 # setting&#xA;https://openrouter.ai/ Model: GPT-5 Temperature: 0.2 (낮게: 일관성 있는 분류 결과) Top-k / Top-p: default Max tokens: 1024 system prompt&#xA;너는 IT 시스템의 평가전문가야. 이번에 개발한 AI를 적용한 회계세무 시스템을 테스트한 고객의 평가내용인 VOC를 분석하는 것이 너의 역할이야. 판단근거를 2가지로 함께 제시해줘. user prompt&#xA;아래에 제공하는 모든 VOC 문장을 긍정, 중립, 부정 중 하나로 분류하고, 특히 부정일 경우 그렇게 판단한 이유를 2가지로 요약해줘.</description>
    </item>
    <item>
      <title>데이터 분석 #3 회귀분석</title>
      <link>http://localhost:1313/docs/study/ai/ai17/</link>
      <pubDate>Thu, 07 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai17/</guid>
      <description>데이터 분석 #3 회귀분석 # #2025-08-07&#xA;#1 Oversampling Techinique (p.69-71)&#xA;SMOTE&#xA;소수 클래스 포인트 중 하나를 랜덤하게 고르고 이웃 포인트 k개를 찾고 이 이웃들과의 연결선을 따라 중간 어딘가에 새로운 샘플을 만든다. 즉 원본과 이웃 사이에 위치한 점들을 생성한다. 소수 클래스 포인트들 사이의 직선 위에서만 새로운 데이터를 만들기 때문에 실제로는 decision boundary 근처에서 중요한 데이터를 놓칠 수 있다 Borderline-SMOTE&#xA;소수 클래스의 포인트에 대해 kNN을 수행해서 이웃들을 찾는데 이때 이웃 중에서 과반수 이상이 다수 클래스인 경우 위험한 샘플(danger set)으로 간주된다 즉 이 샘플은 결정 경계에 가깝기 때문에 모델 입장에서 헷갈릴 가능성이 높다.</description>
    </item>
    <item>
      <title>데이터 분석 #2 Preprocessing</title>
      <link>http://localhost:1313/docs/study/ai/ai16/</link>
      <pubDate>Wed, 06 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai16/</guid>
      <description>데이터 분석 #2 Preprocessing # #2025-08-06&#xA;#1 머신러닝 프로세스 (p.25)&#xA;test data가 필요한 이유? hyperparameter tuning을 하면서 validation data는 모델이 이미 참고했다 즉 간접적으로 학습에 영향을 줬기 때문에 모델 학습 과정에서 한번도 보지않은 데이터가 필요함. # #2 Box plot (p.38)&#xA;그림이 7개 차종에서 연비 플롯이라고 가정&#xA;투입됏을때 예측에 긍정적영향을 줄수잇는건?&#xA;납작한애들. 두꺼우면 대표성이 떨어진다. 2번에서 이상치들이 많으니까 잘 처리해야하겠다.&#xA;만약 그림같지 않고 y축 높이가 다 비슷비슷했다면?&#xA;이 변수들이 연비를 결정하는데 큰 영향을 못줌.</description>
    </item>
    <item>
      <title>데이터 분석 #1 기초통계</title>
      <link>http://localhost:1313/docs/study/ai/ai14/</link>
      <pubDate>Tue, 05 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai14/</guid>
      <description>데이터 분석 #1 기초통계 # #2025-08-05&#xA;1. 기술 통계 # #1 IQR (p.34)&#xA;IQR은? 가운데 50%의 거리.&#xA;그림 설명&#xA;그림의 2,3: 각각 IQR의 1.5배 선, median 값 선. 그림의 B: ⚬ 가 많으면 특이값이 많은 것. 그림의 1,2,3: 1,2는 각각 IQR의 1.5배 선이라고 했는데 3과의 거리가 서로 다른 이유는? 1.5배 안쪽에 데이터들이 다 분포해서. 즉max가 1.5배보다 작아서. # #2 변이 계수(Coefficient of Variables)&#xA;평균치가 다른 집단 비교. 변이 계수 = 표준편차 / 평균.</description>
    </item>
    <item>
      <title>Docker #3 레지스트리 접속, 이미지 관리</title>
      <link>http://localhost:1313/docs/study/be/be42/</link>
      <pubDate>Mon, 04 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be42/</guid>
      <description>Docker #3 # #2025-08-04&#xA;1. 레지스트리에 접속하고 이미지를 pull/push하기 # # Docker 로그인 $ docker login https://{실습링크}.com # ID: * # Password: * $ Login Succeeded # 이미지 Pull (이미지 내려받기): 예를 들어 container-linux:1.1 이미지를 다운로드 $ docker pull {실습링크}.com/{실습id}/container-linux:1.1 # 이미지 Push (Image Push 정보 사용): Push 권한은 일반 계정이 아니라 로봇 계정(CI/CD 용)을 사용합니다. # 로봇 계정 로그인 $ docker login https://{실습링크}.com # ID: robot$skala25a # Password: 1qB9cyusbNComZPHAdjNIFWinf52xaBJ # 태깅 (Tag local image) $ docker tag container-linux:1.</description>
    </item>
    <item>
      <title>Docker #4 자신의 Frontend 개발 코드를 컨테이너로 만들고 이것을 실행시켜 보자</title>
      <link>http://localhost:1313/docs/study/be/be43/</link>
      <pubDate>Mon, 04 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be43/</guid>
      <description>Docker #4 자신의 Frontend 개발 코드를 컨테이너로 만들고 이것을 실행시켜 보자 # #2025-08-04&#xA;#조건&#xA;nginx:alpine 이미지를 사용 노출 Port는80 nginx를실행하는방식은 -nginx -g daemon off; nginx의 routing 설정은 default.conf에설정한다. #path&#xA;$ pwd /Users/yshmbid/rde/config/workspace/exec-template $ ls Dockerfile default.conf deploy deploy.yaml docker-build.sh docker-push.sh service.yaml src # 1. docker-build.sh와 docker-push.sh 복사 # $ pwd /Users/yshmbid/rde/config/workspace/container/05.webserver $ ls Dockerfile default.conf deploy docker-build.sh docker-push.sh src # docker-build.sh #!/bin/bash NAME=sk019 IMAGE_NAME=&amp;#34;healthcheck-server&amp;#34; #IMAGE_NAME=&amp;#34;webserver&amp;#34; VERSION=&amp;#34;1.0.0&amp;#34; CPU_PLATFORM=arm64 #amd64 # Docker 이미지 빌드 docker build \ --tag ${NAME}-${IMAGE_NAME}:${VERSION} \ --file Dockerfile \ --platform linux/${CPU_PLATFORM} \ ${IS_CACHE} .</description>
    </item>
    <item>
      <title>Docker #5 kubernetes 환경에 나의 앱을 배포해보자</title>
      <link>http://localhost:1313/docs/study/be/be44/</link>
      <pubDate>Mon, 04 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be44/</guid>
      <description>Docker #5 kubernetes 환경에 나의 앱을 배포해보자 # #2025-08-04&#xA;#path&#xA;$ pwd /Users/yshmbid/rde/config/workspace/exec-template #파일 구조&#xA;/workspace └── exec-template ├── Dockerfile ├── default.conf ├── docker-build.sh ├── docker-push.sh ├── cicd.sh ├── deploy/ │ ├── deploy.t │ ├── deploy.sh │ ├── service.t │ ├── service.sh │ └── env.properties └── src/ ├── index.html └── media/ #이전 실습과의 차이?&#xA;cicd.sh를 쓴다. deploy 디렉토리를 쓴다. docker-build.sh와 docker-push.sh에서 amd였던걸 arm으로 바꿔줬는데 이걸다시 amd로 바꿔준다. # 1. cicd.</description>
    </item>
    <item>
      <title>결단</title>
      <link>http://localhost:1313/docs/hobby/book/book52/</link>
      <pubDate>Mon, 04 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/book/book52/</guid>
      <description>결단 # #2025-08-04&#xA;#1&#xA;머스크는 로켓이 산소가 희박한 높이로 충분히 솟아올라 불꽃이 꺼지길 바랐다. 그러나 로켓은 추락하기 시작했다. 비디오 피드에서 오멜렉이 가까이 다가오더니 더 이상 화면에 아무것도 비치지 않았다. 그리고 불타는 파편들이 바다로 떨어졌다. “위장이 뒤틀렸지요.” 머스크의 말이다. 1시간 후, 머스크는 뮬러, 쾨니스만, 부자, 톰슨 등 수석 팀원들과 함께 잔해를 둘러보기 위해 육군 헬리콥터에 올랐다.&#xA;그날 밤 모두가 콰즈의 야외 바에 모여 조용히 맥주를 마셨다. 몇몇 엔지니어는 눈물을 흘렸다. 머스크는 돌처럼 굳은 얼굴과 먼 곳을 응시하는 눈빛으로 조용히 생각에 잠겼다.</description>
    </item>
    <item>
      <title>Docker #1 Python 실행 컨테이너 만들기</title>
      <link>http://localhost:1313/docs/study/be/be40/</link>
      <pubDate>Fri, 01 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be40/</guid>
      <description>Docker #1 Python 실행 컨테이너 만들기 # #2025-08-01&#xA;Background # RDE #1 Local PC에서 RDE 환경 구성에서 Harbor registry로부터 RdE Container download를 수행했음 아이콘을 클릭해서 RDE 런처를 실행한다. # 1. 웹 서비스 실행 컨테이너 만들기 # /config/workspace/cloud/container/00.container-linux 경로로 이동 cd /config/workspace/cloud/container/00.container-linux 디렉토리 구조는? 00.container-linux/ ├── Dockerfile // 컨테이너 환경 설정 ├── Dockerfile.pytho-slim ├── Dockerfile.ubuntu ├── docker-build.sh ├── docker-push.sh ├── mycode.py ├── fastserver.py ├── webserver.py └── mydata/ Dockerfile 내용 확인하기 FROM python:3.</description>
    </item>
    <item>
      <title>Docker #2 작년 작업 복기: netmhcpan image 불러와서 패키지 돌리기</title>
      <link>http://localhost:1313/docs/study/be/be41/</link>
      <pubDate>Fri, 01 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be41/</guid>
      <description>Docker #2 작년 작업 복기: netmhcpan image 불러와서 패키지 돌리기 # #2025-08-01&#xA;1 # 2024.11.24 MutClust 작업중에 netmhcpan을 돌려야되는 상황이 왓었는데&#xA;netmhcpan이 유료였나 그래서 패키지 다운은 안되고 담당 박사님은 그만두셧고.. 서버 뒤지다가 위 README 파일 발견해서 결과물 저장까진 했던 기억이있다.&#xA;# 이때먼가 의문이 들었던게 새로운 conda 환경에 접속한거같은 느낌이 아니라 완전 다른 제2의서버에 접속한 느낌이었는데 이상하게 연구실 디렉토리들은 그대로 접근이 가능해서 혼란스럽지만 그냥 절대경로 다 박고 수행했는데 결과들이 문제없이 저장됐었다.</description>
    </item>
    <item>
      <title>HTML #2 SKCT 공부용 메모장&#43;계산기 만들기</title>
      <link>http://localhost:1313/docs/study/fe/fe18/</link>
      <pubDate>Thu, 31 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/fe/fe18/</guid>
      <description>HTML #2 SKCT 공부용 메모장+계산기 만들기 # #2025-07-31&#xA;1. 문제 # SKCT는 응시화면이 아래와같이 돼잇는데&#xA;연습하기 불편한거같애서 html로 만들어봣다&#xA;# 2. SKCT 공부용 메모장+계산기 # #구조&#xA;/skct ├── index.html └── script.js #링크&#xA;https://github.com/yshghid/skct-tools/tree/main&#xA;#활용&#xA;요렇게 문제옆에 띄워놓고 쓰면됨 ㅎㅎㅎ&#xA;# 3. 수정사항 # #메모장&#xA;메모장 ↔ 그림판 전환 버튼 메모장일때는 &amp;lsquo;🎨 그림판&amp;rsquo;, 그림판일때는 &amp;lsquo;📝 메모장&amp;rsquo;이 뜨게 수정 # #그림판&#xA;선 굵기 조절하는 슬라이더 넣기 html: 슬라이더 UI 추가 javascript: 초기 선 굵기 1로 설정 / 그림판 상태일때만 보기로 설정 &amp;lt;!</description>
    </item>
    <item>
      <title>SQL #6 AI 서비스 리뷰 시스템</title>
      <link>http://localhost:1313/docs/study/be/be39/</link>
      <pubDate>Thu, 31 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be39/</guid>
      <description>SQL #6 AI 서비스 리뷰 시스템 # #2025-07-31&#xA;1. 문제 # AI 서비스 리뷰 시스템: 키워드 기반 텍스트 필터링과 AI 기반 방식의 비교를 통해 유사도 기반 검색에 대한 개념 이해&#xA;테이블 개요&#xA;Day 3 – ai_service_creator_ranking.sql 주제: AI 서비스 리뷰 (WITH (CTE) + 집계로 인기 기획자 추출) 목적: CTE(Common Table Expression)로 집계 테이블을 구성, AVG(평점)과 COUNT(리뷰)를 기준으로 인기 있는 기획자 선정, ROW_NUMBER()로 랭킹 부여, 향후 AI 추천(예: 유사도 기반 + 평점 기반 추천) 전단 필터링에 활용 실습 문제</description>
    </item>
    <item>
      <title>SQL #4 AI 피드백 분석 시스템의 테이블 정규화</title>
      <link>http://localhost:1313/docs/study/be/be22/</link>
      <pubDate>Wed, 30 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be22/</guid>
      <description>SQL #4 AI 피드백 분석 시스템의 테이블 정규화 # #2025-07-30&#xA;1. 문제 # AI 피드백 분석 시스템의 테이블 정규화&#xA;시나리오&#xA;여러분은 AI 피드백 분석 시스템을 위한 데이터 모델링을 맡았습니다. 현재는 여러 실험 데이터를 한 테이블에 모아두었지만, 벡터 임베딩 처리, 학습데이터 전처리, RAG 문서 기반 검색 등을 고려해 정규화 설계가 필요합니다. [비정규 테이블 예시: Day 2 – 정규화와 제약조건_실습1_예제_ai_feedback_raw.csv] 실습 목표&#xA;LLM Feedback 데이터 정규화 (3NF까지 고려) model, user, prompt-response, tags 분리 tags 필드는:TEXT[ ] 배열로 유지한 구조 (빠른 전처리, FAISS 등 용이) feedback_tag라는 별도 테이블로 정규화 (통계, RAG 전처리 유리) AI 분석 목적의 전처리 성능 관점에서 두 방식 비교 설명 # 2.</description>
    </item>
    <item>
      <title>SQL #5 소셜미디어 포스트 리뷰 시스템</title>
      <link>http://localhost:1313/docs/study/be/be23/</link>
      <pubDate>Wed, 30 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be23/</guid>
      <description>SQL #5 소셜미디어 포스트 리뷰 시스템 # #2025-07-30&#xA;1. 문제 # JSONB 기반의 메타정보 필드 설계 + 검색 + AI 분석 연계&#xA;테이블 개요&#xA;Day 2 – jsonb_metadata_sql_practice.sql 주제: 소셜미디어 포스트 리뷰 목적: 포스트에 대한 사용자 평가 + 해시태그/속성을 JSONB로 저장하여 AI 추천/필터 기반 만들기 실습 준비&#xA;특정 메타 속성 포함 검색(JSONB 검색 쿼리 실습) GIN 인덱스 생성 AI 필터링 활용 시나리오 (Hybrid Filtering 기반) 문제&#xA;sentiment가 negative인 리뷰만 출력 메타데이터에 &amp;ldquo;language&amp;rdquo; 키가 포함된 행 찾기 (?</description>
    </item>
    <item>
      <title>SQL #1 학사 관리 시스템 설계 - 엔터티 도출 및 ERD 작성</title>
      <link>http://localhost:1313/docs/study/be/be19/</link>
      <pubDate>Tue, 29 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be19/</guid>
      <description>SQL #1 학사 관리 시스템 설계 - 엔터티 도출 및 ERD 작성 # #2025-07-29&#xA;1. 문제 # AI 기반 학사 관리 시스템 (Learning Management System) 설계를 위한 엔터티 도출 및 ERD 작성 실습입니다.&#xA;요구사항 . 교육과정, 수강생, 과정운영자, 강사, 과정 설명 텍스트, Review 등으로 구성 . 과정 설명 텍스트는 향후 AI 임베딩 대상이므로 충분한 길이와 자유 텍스트로 정의&#xA;순서 . 학사관리시스템 엔티티 도출 및 검증 . ERD 변환 작업 .</description>
    </item>
    <item>
      <title>SQL #2 학사 관리 시스템 설계 - 스키마 분리 및 멀티 프로젝트 설계</title>
      <link>http://localhost:1313/docs/study/be/be20/</link>
      <pubDate>Tue, 29 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be20/</guid>
      <description>SQL #2 학사 관리 시스템 설계 - 스키마 분리 및 멀티 프로젝트 설계 # #2025-07-29&#xA;1. 문제 # 이전에 만든 ERD를 기반으로 PostgreSQL 로 스키마 분리 및 멀티 프로젝트 설계합니다.&#xA;주제 . 서울캠퍼스/제주캠퍼스별 학사 관리 시스템 (Learning Management System) 동일한 학사관리 시스템 구조를 기반으로, 캠퍼스에 따라 데이터를 스키마 단위로 분리 설계하고 향후 AI 분석 결과의 멀티 벡터 저장 구조로 확장 가능하도록 구조 설계 요구사항 . 교육과정, 수강생 과정운영자, 강사, 과정 설명 텍스트, Review 등으로 구성하되, 캠퍼스별 특성을 고려하여 스키마 분리 .</description>
    </item>
    <item>
      <title>SQL #3 스키마 분리와 AI 분석</title>
      <link>http://localhost:1313/docs/study/be/be21/</link>
      <pubDate>Tue, 29 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be21/</guid>
      <description>SQL #3 스키마 분리와 AI 분석 # #2025-07-29&#xA;생각 정리&#xA;AI 분석이 들어갈 때 왜 별도 스키마로 나누는 것이 유리할까요? 스키마 vs. 테이블 분리, 어떤 방식이 어떤 상황에 적합할까요? 향후 pgvector 또는 AI 모델 결과를 넣기 위해 어떻게 테이블을 확장할 수 있을까요? # AI 분석이 들어갈 때 왜 별도 스키마로 나누는 것이 유리할까요? AI 분석이 포함된 시스템에서 데이터를 다룰 때, 별도 스키마로 나누는 것이 유리한 이유는 (1) 데이터의 사용 목적이 다르기 때문이고, (2) 데이터의 구조와 속성이 근본적으로 다르기 때문입니다.</description>
    </item>
    <item>
      <title>DBSCAN #2 슈도코드</title>
      <link>http://localhost:1313/docs/study/ai/ai9/</link>
      <pubDate>Mon, 28 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai9/</guid>
      <description>DBSCAN #2 슈도코드 # #2025-07-28&#xA;1 # Input: - D: 데이터 포인트 집합 - eps: 이웃 거리 임계값 - minPts: 최소 이웃 수 (밀도 기준) Output: - cluster_labels: 각 데이터 포인트에 대한 클러스터 라벨 (노이즈는 -1) Initialize: - cluster_id ← 0 - label[x] ← UNVISITED for all x in D 데이터 집합 D, 파라미터 eps와 minPts가 들어간다.&#xA;2 # For each point x in D: If label[x] ≠ UNVISITED: continue N ← regionQuery(x, eps) // x 주변의 eps 이내 이웃 포인트 탐색 If |N| &amp;lt; minPts: label[x] ← NOISE // Else: // cluster_id ← cluster_id + 1 // expandCluster(x, N, cluster_id, eps, minPts, label) Function regionQuery(x, eps): return { all points y in D such that distance(x, y) ≤ eps } 주석 처리 안된 부분만 보기.</description>
    </item>
    <item>
      <title>DBSCAN: #1 1D 클러스터링의 성능 평가</title>
      <link>http://localhost:1313/docs/study/ai/ai8/</link>
      <pubDate>Mon, 28 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai8/</guid>
      <description>DBSCAN: #1 1D 클러스터링의 성능 평가 # #2025-07-28&#xA;1. Problem # 클러스터 응집도는 보통 클러스터 내 데이터 간의 평균 거리나 분산, 혹은 실루엣 계수처럼 군집 내 응집도와 군집 간 분리도를 동시에 평가한다.&#xA;하지만 1차원 데이터에서는 클러스터 응집도(Cluster Cohesion) 또는 실루엣 계수(Silhouette coefficient) 같은 지표가 잘 작동하지 않는다.&#xA;2. 클러스터 응집도 # 클러스터링 성능을 평가하는 지표 중 하나인 응집도(Cohesion)는 클러스터 내부의 데이터들이 얼마나 서로 가까운지를 측정하는 지표다. 대표적으로는 클러스터 내 모든 점 간의 평균 거리, 클러스터 중심과 각 점 사이의 평균 거리, 혹은 분산을 사용하는 방식 등이 있다.</description>
    </item>
    <item>
      <title>DMR 분석 (methylKit)</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi31/</link>
      <pubDate>Mon, 28 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi31/</guid>
      <description>DMR 분석 (methylKit) # #2025-07-28&#xA;# #1 Load packages&#xA;library(&amp;#34;methylKit&amp;#34;) library(&amp;#34;genomation&amp;#34;) library(&amp;#34;GenomicRanges&amp;#34;) # #2 Set path&#xA;setwd(&amp;#34;/data/home/ysh980101/2309_5-aza/Bismark/sorted_n&amp;#34;) getwd() &amp;#39;/data1/home/ysh980101/2309_5-aza/Bismark/sorted_n&amp;#39; # #3 Load data&#xA;# Define the list containing the bismark coverage files. covlist &amp;lt;- list( &amp;#34;KEB1/KEB01_1_bismark_bt2_pe.sorted_n.deduplicated.bismark.cov.gz&amp;#34;, &amp;#34;KEB2/KEB02_1_bismark_bt2_pe.sorted_n.deduplicated.bismark.cov.gz&amp;#34;, &amp;#34;KEB4/KEB04_1_bismark_bt2_pe.sorted_n.deduplicated.bismark.cov.gz&amp;#34;) myobj_lowCov &amp;lt;- methRead(covlist, sample.id=list(&amp;#34;KEB01&amp;#34;,&amp;#34;KEB02&amp;#34;,&amp;#34;KEB04&amp;#34;), pipeline = &amp;#34;bismarkCoverage&amp;#34;, assembly=&amp;#34;hg38&amp;#34;, treatment=c(0,1,2), mincov = 3 ) tiles &amp;lt;- tileMethylCounts(myobj_lowCov,win.size=1000,step.size=1000,cov.bases = 3 tiles.norm &amp;lt;- normalizeCoverage(tiles, method = &amp;#34;median&amp;#34;) meth.tiles &amp;lt;- unite(tiles.norm, destrand=FALSE) meth.tiles meth.tilesDf = getData(meth.</description>
    </item>
    <item>
      <title>Influenza 시퀀스 크롤링 (Selenium)</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi28/</link>
      <pubDate>Mon, 28 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi28/</guid>
      <description>Influenza 시퀀스 크롤링 (Selenium) # #2025-07-28&#xA;1. Load package # import pandas as pd import numpy as np import os # 2. Set path # os.chdir(&amp;#39;/Users/yshmbid/Desktop/workspace/gisaid&amp;#39;) os.getcwd() &amp;#39;/Users/yshmbid/Desktop/workspace/gisaid&amp;#39; # 3. Run crawling # # ChromeDriver 경로를 설치하고 Service 객체로 전달 chrome_service = Service(ChromeDriverManager().install()) try: # ChromeDriver 실행 crawler = webdriver.Chrome(service=chrome_service) except: # 크롬드라이버가 없을 때 autoinstaller로 설치 chromedriver_autoinstaller.install(True) crawler = webdriver.Chrome(service=chrome_service) crawler.implicitly_wait(6) # 크롤러 대기 시간 설정 crawler.get(&amp;#39;https://gisaid.org/&amp;#39;) # 웹사이트 열기 # login 선택 engine = WebDriverWait(crawler, 10).</description>
    </item>
    <item>
      <title>MAFFT 작업 #1 Fasta 파일 전처리</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi29/</link>
      <pubDate>Mon, 28 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi29/</guid>
      <description>MAFFT 작업 #1 Fasta 파일 전처리 # #2025-07-28&#xA;1. Load package # import pandas as pd import numpy as np import os import matplotlib.pyplot as plt import random os.sys.path.append(&amp;#34;/data/home/ysh980101/2410/Mutclust2&amp;#34;) from Bin.sc import * # 2. Objective # Influenza type A의 H1N1 strain의 fasta 파일을 확인해보면?&#xA;&amp;gt;로 시작하는 행에 해당 시퀀스의 메타데이터가 있고&#xA;다음 &amp;gt;로 시작하는 행 이전까지 해당 시퀀스 정보가 있다.&#xA;&amp;gt;로 시작하는 행을 |로 분리했을때 제일 마지막값에 유전자 정보가 있다.</description>
    </item>
    <item>
      <title>MAFFT 작업 #2 MAFFT 실행</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi30/</link>
      <pubDate>Mon, 28 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi30/</guid>
      <description>MAFFT 작업 #2 MAFFT 실행 # #2025-07-28&#xA;1. Objective # Influenza의 Reference squence는 길이가 fix되어있지만,&#xA;각 sequence는 삽입/탈락 mutation이 일어남에 따라 모두 길이가 같지 않다. 이 길이를 맞춰주는 padding을 하기 위해 MAFFT를 이용해 정렬(Multiple Sequence Alignment)한다. # 2. MAFFT 실행 bash script # #data&#xA;/Influenza └── Preprocessed/ ├── HA/ │ ├── A-H1N1.fasta │ ├── A-H1N1.fasta │ ├── ... │ └── B.fasta └── ... └── (HA와 동일 구조) └── MAFFT/ └── (empty) #!</description>
    </item>
    <item>
      <title>MutClust 슈도코드 작성하기</title>
      <link>http://localhost:1313/docs/study/ai/ai10/</link>
      <pubDate>Mon, 28 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai10/</guid>
      <description>MutClust 슈도코드 작성하기 # #2025-07-28&#xA;1 # Input: - D: 데이터 포인트 집합 - Efactor: 이웃 거리 조정값 - DiminFactor: 클러스터 경계 조정값 - minPts: 최소 이웃 수 (밀도 기준) Output: - cluster_labels: 각 데이터 포인트에 대한 클러스터 라벨 (노이즈는 -1) Initialize: - cluster_id ← 0 - Label[x] ← UNVISITED for all x in D 데이터 집합 D, 파라미터 eps와 minPts가 들어간다.&#xA;2. H-중요도 계산 # For each point x in D: x.</description>
    </item>
    <item>
      <title>Hugo #3 Markdown HTML 렌더링 문제</title>
      <link>http://localhost:1313/docs/study/fe/fe3/</link>
      <pubDate>Thu, 24 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/fe/fe3/</guid>
      <description>Hugo #1 Markdown HTML 렌더링 문제 # #2025-07-24&#xA;1. 문제 # &amp;lt;details&amp;gt; &amp;lt;summary&amp;gt; 토글 &amp;lt;/summary&amp;gt; 토글 내용 &amp;lt;/details&amp;gt; Hugo book Theme는 원래 위 코드를 작성하면 아래처럼 토글이 나온다.&#xA;토글 토글 내용 어느날부터 갑자기 토글이든 문단나누기든 다 안먹어서, 근데 원인을 몰라서 그냥 shortcode 기능 없는대로 쓰다가, 너무 불편해서 좀 찾아봤고 hugo.toml에 다음 내용 넣어준 뒤로는 잘 작동했다.&#xA;[markup] [markup.goldmark] [markup.goldmark.renderer] unsafe = true 근데 이후에 html 관련 포스팅을 작성했는데 넣어준 코드가 다 깨졌다.</description>
    </item>
    <item>
      <title>JavaScript #1 쇼핑몰 주문 처리</title>
      <link>http://localhost:1313/docs/study/fe/fe2/</link>
      <pubDate>Wed, 23 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/fe/fe2/</guid>
      <description>JavaScript #1 쇼핑몰 주문 처리 # #2025-07-23&#xA;1. 문제 # 당신은 온라인 쇼핑몰의 개발자로, 고객 주문을 처리하는 프로그램을 작성하고 있습니다. 주문 처리 과정에서는 여러 조건을 고려해야 합니다. 예를 들어, 상품의 재고 여부, 고객의 회원 등급, 주문 금액, 배송 옵션 등을 확인하여 적절한 메시지와 할인율을 적용해야 합니다. 아래의 세부 조건에 맞도록 JavaScript 함수를 구현하고, 최종 결과를 console.log 또는 alert로 출력해보세요.&#xA;#세부 조건&#xA;상품 재고 확인&#xA;재고가 1개 이상일 경우: 주문을 진행한다.</description>
    </item>
    <item>
      <title>netMHCpan 작업 #1 환자 시퀀스 생성</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi24/</link>
      <pubDate>Wed, 23 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi24/</guid>
      <description>netMHCpan 작업 #1 환자 시퀀스 생성 # #2025-07-23&#xA;path&#xA;data/ ├── clusters.tsv ├── meta.csv └── codon ├── reference_codon.csv └── *.codon.csv (*: patient id) # #1 Load package&#xA;import pandas as pd import numpy as np import os import sys import re sys.path.append(&amp;#39;/data/home/ysh980101/2409/bin&amp;#39;) from mhc_epitope import * # #2 Load data&#xA;import pandas as pd import os def make_sequence_df(): # 참조 시퀀스 파일 불러오기 및 컬럼 이름 변경 ref_sequence = pd.</description>
    </item>
    <item>
      <title>netMHCpan 작업 #2 HLA-I 펩타이드 추출</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi25/</link>
      <pubDate>Wed, 23 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi25/</guid>
      <description>netMHCpan 작업 #2 HLA-I 펩타이드 추출 # #2025-07-23&#xA;# #1 Patient id 추출&#xA;#data&#xA;data/ ├── c315 │ └── allprot.fasta └── c442 └── allprot.fasta #patients.bash&#xA;#!/bin/bash # FASTA에서 patient ID 추출하여 patient_id.txt로 저장 ALLPROT_PATH=&amp;#34;data/c315/allprot.fasta&amp;#34; OUT_FILE=&amp;#34;data/patient_id.txt&amp;#34; # 스크립트가 있는 디렉터리로 이동 cd &amp;#34;$(dirname &amp;#34;$0&amp;#34;)&amp;#34; # patient_id.txt 파일 초기화 &amp;gt; &amp;#34;$OUT_FILE&amp;#34; # FASTA 파일에서 ID 추출 grep &amp;#34;^&amp;gt;&amp;#34; &amp;#34;$ALLPROT_PATH&amp;#34; | cut -d&amp;#39;|&amp;#39; -f1 | sed &amp;#39;s/^&amp;gt;//&amp;#39; &amp;gt;&amp;gt; &amp;#34;$OUT_FILE&amp;#34; #result&#xA;data/ ├── c315 │ └── allprot.</description>
    </item>
    <item>
      <title>netMHCpan 작업 #3 HLA-peptide affinity 분석</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi26/</link>
      <pubDate>Wed, 23 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi26/</guid>
      <description>netMHCpan 작업 #3 HLA-peptide affinity 분석 # #2025-07-23&#xA;#data&#xA;data/ ├── c315 │ ├── allprot.fasta │ └── * (*: patient id) │ ├── proteome.fasta │ └── peptides_HLA-I.csv ├── c442 │ └── (c315와 동일한 구조로 생성됨) ├── patient_id.txt └── common_mhc.txt # #predict_affinity.bash&#xA;#!/bin/bash # 입력: # 1) 클러스터명 (예: c315) # 2) 병렬 프로세스 수 (NUM_PROC) # 출력: # 환자별 binding_affinities_HLA-I.csv CLUSTER=$1 NUM_PROC=$2 netMHCpan=&amp;#34;../netMHCpan-4.1/netMHCpan&amp;#34; OUT_DIR=&amp;#34;data/${CLUSTER}&amp;#34; PATIENT_TXT=&amp;#34;data/patient_id.txt&amp;#34; HLA_I_ALLELES_FILE=&amp;#34;data/common_mhc.txt&amp;#34; # 스크립트가 있는 디렉터리로 이동 cd &amp;#34;$(dirname &amp;#34;$0&amp;#34;)&amp;#34; # 환자별로 netMHCpan 예측 수행 while read -r PATIENT_ID; do PATIENT_DIR=&amp;#34;$OUT_DIR/$PATIENT_ID&amp;#34; RAW_DIR=&amp;#34;$PATIENT_DIR/raw_predictions&amp;#34; mkdir -p &amp;#34;$RAW_DIR&amp;#34; PEPTIDES_TABLE=&amp;#34;$PATIENT_DIR/peptides_HLA-I.</description>
    </item>
    <item>
      <title>netMHCpan 작업 #4 결과 확인 및 heatmap 시각화</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi27/</link>
      <pubDate>Wed, 23 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi27/</guid>
      <description>netMHCpan 작업 #4 결과 확인 및 heatmap 시각화 # #2025-07-23&#xA;# #1 netMHCpan 결과 확인&#xA;#data&#xA;data/ ├── c315 │ └── * (*: patient id) │ ├── peptides_HLA-I.csv │ └── binding_affinities_HLA-I.csv ├── c442 │ └── (c315와 동일한 구조로 생성됨) └── patient_id.txt result/ └── (empty) # Load package import pandas as pd import numpy as np import os # Load patient id f = open(&amp;#34;/data/patient_id.txt&amp;#34;, &amp;#34;r&amp;#34;) patients = f.read().split(&amp;#34;\n&amp;#34;) # Merge epitope table hotspots = [&amp;#34;c315&amp;#34;, &amp;#34;c442&amp;#34;] peptide_df_list = [] for hotspot in hotspots: for patient in patients: peptide_df = pd.</description>
    </item>
    <item>
      <title>TFT #0 연구 방향</title>
      <link>http://localhost:1313/docs/study/ai/ai4/</link>
      <pubDate>Wed, 23 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai4/</guid>
      <description>TFT #0 연구 방향 # #2025-07-23&#xA;(#2025-05-31 작성)&#xA;#1&#xA;사용하고자 하는 데이터는?&#xA;feature Clinical feature (17, float): Creatinine, Hemoglobin, LDH, Lymphocytes, Neutrophils, Platelet count, WBC count, hs-CRP, D-Dimer, BDTEMP, BREATH, DBP, SBP, PULSE, SPO2, O2_APPLY Antibiotics feature (2, str) Treatment (list, str): 투여한 항생제, 결측값일수도있고 2개 이상일수도 있음 Strain (str): 환자가 감염된 균주, 1개 NEWS (int): 중증도 Code (int/str): 환자 등록번호 time-series 10개 시점 (항생제 투여 기준 D-3 ~ D+6) TFT input 형식은?</description>
    </item>
    <item>
      <title>TFT #1 입력 시퀀스 생성</title>
      <link>http://localhost:1313/docs/study/ai/ai5/</link>
      <pubDate>Wed, 23 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai5/</guid>
      <description>TFT #1 입력 시퀀스 생성 # #2025-07-23&#xA;1. Load package # %load_ext autoreload %autoreload 2 import sys import pandas as pd import numpy as np import os import pickle import ast sys.path.append(&amp;#39;/data3/projects/2025_Antibiotics/YSH/bin&amp;#39;) from sc import * os.chdir(&amp;#39;/data3/projects/2025_Antibiotics/YSH/workspace&amp;#39;) 2. Load raw data # #data&#xA;/data ├── PreprocessedData/ │ └── TimecourseData/ │ └── * (*: patient id) │ ├── SeverityScore.csv │ ├── Laboratory_processed.csv │ └── Medication.csv ├── PreprocessedData_knuh/ │ └── (PreprocessedData와 동일) └── 병원체자원은행 균주현황(2014-2024.</description>
    </item>
    <item>
      <title>TFT #2 입력 feature 생성</title>
      <link>http://localhost:1313/docs/study/ai/ai6/</link>
      <pubDate>Wed, 23 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai6/</guid>
      <description>TFT #2 입력 feature 생성 # #2025-07-23&#xA;1. Load package # %load_ext autoreload %autoreload 2 import sys import pandas as pd import numpy as np import os import pickle import ast sys.path.append(&amp;#39;/data3/projects/2025_Antibiotics/YSH/bin&amp;#39;) from sc import * os.chdir(&amp;#39;/data3/projects/2025_Antibiotics/YSH/workspace&amp;#39;) 2. Make feature1 # #data&#xA;/data └── all_meds.txt /data_knuch └── sequence └── *.pkl (*: antibiotics) /data_knuh └── sequence └── *.pkl (*: antibiotics) medinfo = &amp;#39;/data/all_meds.txt&amp;#39; with open(medinfo, &amp;#39;r&amp;#39;) as f: meds = [line.</description>
    </item>
    <item>
      <title>TFT #3 모델 학습</title>
      <link>http://localhost:1313/docs/study/ai/ai7/</link>
      <pubDate>Wed, 23 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai7/</guid>
      <description>TFT #3 모델 학습 # #2025-07-23&#xA;1. Load package # import pytorch_lightning as pl from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor from pytorch_lightning.loggers import TensorBoardLogger from pytorch_forecasting import TimeSeriesDataSet from pytorch_forecasting.models import TemporalFusionTransformer from pytorch_forecasting.models.baseline import Baseline from pytorch_forecasting.metrics import QuantileLoss from pytorch_forecasting.metrics import MAE from pytorch_forecasting.data import GroupNormalizer, NaNLabelEncoder import numpy as np import pandas as pd import torch import pickle import matplotlib.pyplot as plt #data&#xA;/data └── Sequence.pkl 2. Load data # sequence = pd.</description>
    </item>
    <item>
      <title>HTML #1 프로필 웹페이지 작성</title>
      <link>http://localhost:1313/docs/study/fe/fe1/</link>
      <pubDate>Tue, 22 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/fe/fe1/</guid>
      <description>HTML #1 프로필 웹페이지 작성 # #2025-07-22&#xA;1 # #구조&#xA;/HTML ├── 자기소개1.html ├── 자기소개2.html └── media/ ├── 증명사진.jpg ├── blog.jpg ├── net1.jpg ├── net2.jpg ├── net3.jpg ├── net4.jpg └── playlist.jpg #코드&#xA;&amp;lt;!DOCTYPE html&amp;gt; &amp;lt;html lang=&amp;#34;ko&amp;#34;&amp;gt; &amp;lt;head&amp;gt; &amp;lt;meta charset=&amp;#34;UTF-8&amp;#34;&amp;gt; &amp;lt;title&amp;gt;윤소현의 프로필&amp;lt;/title&amp;gt; &amp;lt;/head&amp;gt; &amp;lt;body&amp;gt; &amp;lt;!-- 헤더 --&amp;gt; &amp;lt;header&amp;gt; &amp;lt;h1&amp;gt;윤소현의 프로필&amp;lt;/h1&amp;gt; &amp;lt;/header&amp;gt; &amp;lt;!-- 자기소개 섹션 --&amp;gt; &amp;lt;section&amp;gt; &amp;lt;h2&amp;gt;자기소개&amp;lt;/h2&amp;gt; &amp;lt;p&amp;gt;안녕하세요! 저는 윤소현입니다. 생명공학과 바이오인포메틱스를 전공하였습니다. 취미는 넷플릭스, 음악 감상 입니다.&amp;lt;/p&amp;gt; &amp;lt;/section&amp;gt; &amp;lt;!-- 정보 목록 섹션 --&amp;gt; &amp;lt;section&amp;gt; &amp;lt;h2&amp;gt;취미&amp;lt;/h2&amp;gt; &amp;lt;ul&amp;gt; &amp;lt;li&amp;gt;넷플릭스&amp;lt;/li&amp;gt; &amp;lt;li&amp;gt;음악 감상&amp;lt;/li&amp;gt; &amp;lt;li&amp;gt;산책&amp;lt;/li&amp;gt; &amp;lt;/ul&amp;gt; &amp;lt;/section&amp;gt; &amp;lt;!</description>
    </item>
    <item>
      <title>Linux #1 NPM 과 PIP 명령어 목록</title>
      <link>http://localhost:1313/docs/study/be/be1/</link>
      <pubDate>Tue, 22 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be1/</guid>
      <description>Linux #1 NPM 과 PIP 명령어 목록 # #2025-07-22&#xA;1. NPM (Node Package Manager) # 패키지 설치&#xA;npm install &amp;lt;패키지명&amp;gt; - 패키지 설치 npm install -g &amp;lt;패키지명&amp;gt; - 전역 설치 npm install --save-dev &amp;lt;패키지명&amp;gt; - 개발 의존성으로 설치 npm install - package.json의 모든 의존성 설치 패키지 관리&#xA;npm uninstall &amp;lt;패키지명&amp;gt; - 패키지 제거 npm update &amp;lt;패키지명&amp;gt; - 패키지 업데이트 npm list - 설치된 패키지 목록 보기 npm list -g - 전역 설치된 패키지 목록 프로젝트 관리</description>
    </item>
    <item>
      <title>RDE #1 Local PC에서 RDE 환경 구성</title>
      <link>http://localhost:1313/docs/study/be/be2/</link>
      <pubDate>Mon, 21 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be2/</guid>
      <description>RDE #1 Local PC에서 RDE 환경 구성 # #2025-07-22&#xA;1 # Docker Desktop 설치 링크 - https://www.docker.com/products/docker-desktop/&#xA;RdE Container download Harbor registry로부터 이미지 다운로드 (*에 이미지 경로)&#xA;docker pull * 다운로드 확인하면?&#xA;잘들어가있다!&#xA;# 2 # Local RDE 설치하기 https://mattermost..com 접속해서 다운로드. (: 링크 블라인드처리)&#xA;실행 아이콘 클릭해서 실행&#xA;============================================= RDE Launcher 시작 중... ============================================= 시작 시간: 2025-07-22 16:55:56 작업 디렉토리: /Users/yshmbid/rde 실행 파일: rde-launcher-macos-arm64 로그 파일: /Users/yshmbid/rde/rde-launcher.log 작업 디렉토리로 이동했습니다.</description>
    </item>
    <item>
      <title>개발환경 설정 (GIT, Docker, VScode, RDE 컨테이너)</title>
      <link>http://localhost:1313/docs/study/be/be4/</link>
      <pubDate>Mon, 21 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be4/</guid>
      <description>개발환경 설정 (GIT, Docker, VScode, RDE 컨테이너) # #2025-07-21&#xA;1. GIT 사용자 정보 설정 # [Git 설치 확인] git --version [사용자 이름 설정] git config --global user.name &amp;#34;윤소현&amp;#34; [이메일 주소 설정] GitHub에 등록된 이메일 주소와 일치하는지 확인 필요 git config --global user.email &amp;#34;yshggid@gmail.com&amp;#34; [설정 확인] git config --global --list 2. 로컬 GIT Repository 생성 # vscode에서 좌측 SOURCE CONTRIL 아이콘 &amp;gt; Initialize Repository &amp;gt; 로컬 폴더를 git repository로 생성</description>
    </item>
    <item>
      <title>RAG #2 출력 파서의 개념, Pydantic/Json 출력 파서</title>
      <link>http://localhost:1313/docs/study/ai/ai2/</link>
      <pubDate>Sat, 19 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai2/</guid>
      <description>RAG #2 출력 파서의 개념, Pydantic/Json 출력 파서 # #2025-07-19&#xA;1. 출력 파서의 개념과 종류 그리고 세가지 주요 메서드 # 출력 파서(output parser)는 LLM에서 생성된 응답을 받아서 우리가 원하는 형식으로 변환해주는 역할을 한다. 쉽게 말해, LLM은 텍스트만 생성하지만 우리는 그 텍스트를 리스트, 딕셔너리, JSON, 숫자 등 구조화된 데이터로 바꾸어서 프로그램에 넘기거나, 다음 단계 체인으로 활용하길 원할 때가 많다. 출력 파서는 이 연결고리 역할을 한다. 출력 파서는 LLM이라는 기계가 말한 인간 언어를 다시 기계가 이해할 수 있는 언어로 &amp;lsquo;번역&amp;rsquo;하는 통역사 같은 존재이다.</description>
    </item>
    <item>
      <title>RAG #3 자동 대화 이력 관리</title>
      <link>http://localhost:1313/docs/study/ai/ai3/</link>
      <pubDate>Sat, 19 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai3/</guid>
      <description>RAG #3 자동 대화 이력 관리 # #2025-07-19&#xA;1. 자동 대화 이력 관리 # ChatPromptTemplate을 통해 시스템 메시지를 포함하는 프롬프트를 만든다. 시스템 메시지는 모델에게 “너는 금융 상담사야”라고 역할을 부여하는 것이다. 이어지는 (&amp;quot;placeholder&amp;quot;, &amp;quot;{messages}&amp;quot;)는 실제 사용자의 질문과 AI의 답변이 이 자리에 채워질 것이라는 의미다. 이 프롬프트는 chat = ChatOpenAI(model=&amp;quot;gpt-4o-mini&amp;quot;)와 연결되는데, 이는 OpenAI의 gpt-4o-mini 모델을 사용하는 챗 인터페이스이다. 이 프롬프트와 모델을 prompt | chat이라는 LCEL 표현으로 묶으면, 하나의 체인이 만들어진다. 이 체인은 주어진 메시지 목록을 받아, GPT 모델에 전달하고 응답을 생성하는 구조다.</description>
    </item>
    <item>
      <title>RAG #1 랭체인, LCEL, 프롬프트</title>
      <link>http://localhost:1313/docs/study/ai/ai1/</link>
      <pubDate>Thu, 17 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai1/</guid>
      <description>RAG #1 랭체인, LCEL, 프롬프트 # #2025-07-17&#xA;1. 랭체인 생태계의 주요 패키지 # 랭체인(LangChain)은 LLM(Large Language Model)을 활용한 애플리케이션을 쉽게 만들 수 있도록 돕는 프레임워크이다. 이 생태계는 단일 라이브러리로 구성된 것이 아니라 여러 개의 하위 패키지로 나뉘어 있고, 각각의 역할이 명확하게 분리되어 있다. 랭체인의 주요 목적은 LLM을 단순한 텍스트 생성 도구가 아니라, 여러 시스템과 결합하여 유의미한 작업을 수행하는 &amp;ldquo;생각하고 행동하는&amp;rdquo; 에이전트로 만드는 것이다. 이 생태계의 핵심 구성 요소들을 쉽게 설명하자면, 마치 LLM이라는 뇌에 주변 감각기관과 기억장치, 도구들, 그리고 의사결정 능력을 붙여주는 것이라고 보면 된다.</description>
    </item>
    <item>
      <title>카페 코잔타</title>
      <link>http://localhost:1313/docs/hobby/daily/daily18/</link>
      <pubDate>Sat, 12 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/daily/daily18/</guid>
      <description>카페 코잔타 # #2025-07-12&#xA;여름 분위기 그자체였던 카페 코잔타 ㅎㅎ&#xA;브런치카페긴 한데 밥을 먹고가서 초코브라우니랑 당근케이크를 시켰다. 브라우니는 무난했구 당근케이크가 좀 맛있었는데 인스타 찾아보니까 실제로도 요게 제일 잘나가는듯 ㅎ&#xA;그리고 커피가 진짜 맛있었다!!! 나는 오트라떼 마셨는데 내기준 1위인 폴바셋 오트라떼에 준하는 엄청 맛있는 라떼였다 ㅎㅎㅎ 그리고 컵이 진짜 이뻤음&#xA;별채 소품샵도 구경했는데 ㅎ 카페랑 한몸인듯한 감성이었다 키링 그릇 이런거 판매중이었고 이쁘다고 생각한 컵도 팔고있었는데 5마넌이어서 그냥 나옴 ㅋㅋㅎ&#xA;카페메뉴 3마넌이상 구매해서 캘린더두 받았당</description>
    </item>
    <item>
      <title>2025 하반기 일정</title>
      <link>http://localhost:1313/docs/study/career/career6/</link>
      <pubDate>Sat, 05 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/career/career6/</guid>
      <description>2025 하반기 일정 # #2025-07-05&#xA;1. 졸업 일정 # 2025학년도 1학기 대학원 수료생 등록 안내 https://cse.knu.ac.kr/bbs/board.php?bo_table=sub5_1&amp;wr_id=28393&amp;sca=대학원&amp;amp;page=3&#xA;신청-2025. 2. 24.(월)~2. 26.(수) 등록-2025. 3. 10.(월)~3. 11.(화) 2025학년도 1학기 대학원생 연구윤리교육 시행 안내 https://cse.knu.ac.kr/bbs/board.php?bo_table=sub5_1&amp;wr_id=28426&amp;sca=대학원&amp;amp;page=3&#xA;수강신청-2025. 3. 5.(수)~3. 10.(월) 교육기간-2025. 3. 12.(수)~6. 23.(월) 2025학년도 1학기 재학생 등록금 수납 https://cse.knu.ac.kr/bbs/board.php?bo_table=sub5_1&amp;wr_id=28429&amp;sca=대학원&amp;amp;page=3&#xA;납부기간-2025. 2. 18.(화) 9:00 ~ 2. 21.(금) 16:00 고지서 출력-2025. 2. 15.(토) 14:00부터 조회 가능 2025.1학기 학위논문 제출 예정자 신청안내 https://cse.knu.ac.kr/bbs/board.php?bo_table=sub5_1&amp;wr_id=28447&amp;sca=대학원&amp;amp;page=2&#xA;신청기간-2025. 3. 17.(월)~3. 19.</description>
    </item>
    <item>
      <title>SKALA 2기 지원</title>
      <link>http://localhost:1313/docs/study/career/career4/</link>
      <pubDate>Sat, 05 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/career/career4/</guid>
      <description>SKALA 2기 지원 # #2025-07-05&#xA;서류 -&amp;gt; SKCT 심층검사 -&amp;gt; 인성/직무 면접 이렇게 3단계로만 진행했고&#xA;6.15 서류제출 -&amp;gt; 7.4 결과발표로 전형기간이 엄청 짧은 편이었는데도 첨이라 그런지 엄청 길게 느껴졌다.&#xA;# 가볍게 회고해보면&#xA;서류는 진짜 대충썼던거같고..&#xA;인성검사 처음쳐봐서 걱정했는데 잡플랫 프패 10마넌짜리 끊어서 한 7-8개정도 쳐보고 친게 도움된거같다.&#xA;그리고 &amp;lsquo;나&amp;rsquo;라고 생각하기보다는 &amp;lsquo;나와 비슷하면서 sk 인재상에 맞는 누군가&amp;rsquo;를 떠올리면서 쳤는데 그게 일관성 유지에 도움된것같다. 모의검사 쳐보면서 느낀게 나는 복잡한 나를 너무 잘 알다보니 비슷한 문항을 다르게 해석해서 답변하게돼서 오히려 일관성이 떨어지는 느낌을 받았다 그래서 sk 인재상에 맞으면서 바람직한 사람인 교수님을 떠올리면서 교수님이라면 뭘 체크하실까?</description>
    </item>
    <item>
      <title>파인만 공부법</title>
      <link>http://localhost:1313/docs/hobby/book/book48/</link>
      <pubDate>Sat, 05 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/book/book48/</guid>
      <description>파인만 공부법 # #2025-07-05&#xA;#1&#xA;정전기학에 관한 내용처럼 어려운 부분을 만나면 저만의 요령이 하나 있었습니다.&#xA;뭐냐면 처음 두세 문단이 이해가 안 되더라도 내용 전체를 읽어요. 처음에는 전체를 흐릿하게 이해하지만 다시 읽으면 조금 나아지고 계속 그러다 보면 전부 이해가 되지요(예외도 있는데 그건 나중에 설명하겠습니다). 그다음 책에다 요점을 적어놓으면 완성됩니다. 가령 타원형 축전기의 정전용량 계산 같은 건 건너뛰는데, 내용 전체를 읽어보면 그런 기능이나 복잡한 계산은 뒤에 다시 나오지 않는 지엽적인 사안임을 이미 알기 때문이지요.</description>
    </item>
    <item>
      <title>나눔과 버팀</title>
      <link>http://localhost:1313/docs/hobby/book/book46/</link>
      <pubDate>Fri, 04 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/book/book46/</guid>
      <description>나눔과 버팀 # #2025-07-04&#xA;#1&#xA;짧고 평범한 인생이지만 그래도 살면서 한 가지 명확해진 사실이 있다. 인생은 그야말로 운의 상승과 하락의 반복이라는 점이다. 언뜻 보면, 모든 것은 자신의 노력이나 선택에 달려 있을 것 같지만, 실상은 그렇지 않다. 어떤 때는 아무리 노력해도 모든 것이 뜻대로 풀리지 않고, 반대로 마치 모든 일이 잘될 운명인 듯 일이 술술 풀리기도 한다.&#xA;가장 먼저 깨달은 것은, 모든 것이 잘 풀리는 운의 상승기에 있을 때야말로 주위 사람들에게 아낌없이 베풀어야 한다는 사실이다.</description>
    </item>
    <item>
      <title>비정상성, 궤도의 이탈과 행복</title>
      <link>http://localhost:1313/docs/hobby/book/book45/</link>
      <pubDate>Thu, 03 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/book/book45/</guid>
      <description>비정상성, 궤도의 이탈과 행복 # #2025-07-03&#xA;#1&#xA;‘행복이란 무엇인가?’라는 질문을 보면 어떠한 생각이 드는가? 너무 닳고 닳은 질문이면서 질문 자체가 명확할 수 없는 난제다. 사실 행복한 순간에는 이 질문이 떠오르지 않는다. 그럴 필요가 없기 때문이다. 지금 불만 없고 행복한데 저런 쓰잘머리 없는 질문이 떠오를 이유가 없다. 저 질문이 떠올랐다는 건 애초에 지금 행복하지 않고 불만이 많은 것이다.&#xA;사실 이 답도 없는 질문은 평생 죽을 때까지 내 곁에 있을 것 같다.</description>
    </item>
    <item>
      <title>가치</title>
      <link>http://localhost:1313/docs/hobby/daily/blog1/</link>
      <pubDate>Wed, 02 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/daily/blog1/</guid>
      <description>가치 # #2025-07-02&#xA;#1&#xA;나는왜케 커리어욕심을 내는지?&#xA;내가 중요하게 생각하는것은 사람과 성취감이다. 살면서 주변으로 접하는사람들이랑 좋은시간을 보내는게 행복하고 무언가를 노력해서 얻었을때 행복하다 그리고 그 성취라는게 대단한게 아니라 이쁜쿠키를 구웠을때도 마싯는커피를 내렷을때도 성취감은 든다. 꼭 NLP 모델링이어야하는 이유가 있나?&#xA;면접이 애매했던 이유도 그건거같다 지원동기가 애매했다. 면접관들도 의아했을것이다 지원동기가 명확하지 않은데 어떻게이렇게 의지가명확한지? 사실 이번&amp;rsquo;면접&amp;rsquo;에 붙고싶던 이유는 명확했다 &amp;lsquo;나도 대기업 갈수있는 사람인걸 인정받고 싶어&amp;rsquo; &amp;lsquo;이 연구실에 남아있는것 말고는 할수있는게 없는 사람이 아닌걸 증명하고싶어&amp;rsquo; &amp;lsquo;내가 이정도라는걸 보여주고싶어&amp;rsquo; 하지만 그게 해당 교육과정과 기업에 대한 동기였냐 하면 아니었다 그냥 석사와 취준을하면서 조금내려간 자존감을 이번지원을 통해서 해소하고싶었던거같다.</description>
    </item>
    <item>
      <title>기술적으로 완벽하지 않다는 두려움</title>
      <link>http://localhost:1313/docs/hobby/book/book44/</link>
      <pubDate>Wed, 02 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/book/book44/</guid>
      <description>기술적으로 완벽하지 않다는 두려움 # #2025-07-02&#xA;#1&#xA;이직을 고민할 때마다 내 머릿속을 짓눌렀던 의문이 하나 있었다. “내가 이 일을 그만두고 아예 새로운 다른 일을 할 수 있을까?” 이 의문은 나만의 것이 아니라, 비슷한 길을 걸어온 사람들에게 공통적으로 다가오는 두려움이기도 했다&#xA;그러나 이직을 생각하며 내가 겪어 본 다양한 경험과 그로부터 얻은 깨달음은 나의 두려움을 조금씩 덜어 주었다. 나는 여러 분야에서 다양한 사람들과 일을 하면서 조금씩 알아차렸다. 세상에서 완벽하게 돌아가는 일은 거의 없다는 것을, 그리고 그 속에서 중요한 것은 완벽한 준비보다는 오히려 부딪히며 배우고 적응하는 과정이라는 것을 말이다.</description>
    </item>
    <item>
      <title>지키기 위해서는 변해야 한다</title>
      <link>http://localhost:1313/docs/hobby/book/book42/</link>
      <pubDate>Tue, 01 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/book/book42/</guid>
      <description>지키기 위해서는 변해야 한다 # #2025-07-01&#xA;#1&#xA;난 그냥 나에게 맞는 직업을 찾아 이동했을 뿐이다. 내 주관적인 적성 그 외에는 어떠한 의미 부여도 가치 판단도 하고 싶지 않다.&#xA;#2&#xA;이직을 고민하면서 가장 핵심으로 생각한 질문은 이것이다. ‘내 인생에서 직장과 관련하여 단 하나를 잡는다면 무엇을 잡을 것이냐?’ 돈인가, 명예인가, 여유인가, 전문성인가, 꿈인가.&#xA;난 신이 아니기에 일을 하면서 모든 것을 얻을 수 없다. 돈도 명예도 여유도 전문성도 꿈도 모든 것을 갖고 싶지만 불완전한 인간이기에 당연히 무엇인가는 놓칠 수밖에 없다.</description>
    </item>
    <item>
      <title>첫면접</title>
      <link>http://localhost:1313/docs/study/career/career5/</link>
      <pubDate>Tue, 01 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/career/career5/</guid>
      <description>첫면접 # #2025-07-01&#xA;새로산기여운케이스랑 마고플레인이랑 저속노화좌 없었으면 멘탈 부셔졌을거같은데 다행히 마무리까지끝냈다&#xA;준비하는동안 24기광수책이랑 정희원의저속노화 너무 읽고싶었는데 이제읽을수있으니까 좋다.</description>
    </item>
    <item>
      <title>변이 클러스터링 연구 #6 HLA 결합력 변화 비교</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi39/</link>
      <pubDate>Fri, 27 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi39/</guid>
      <description>변이 클러스터링 연구 #6 HLA 결합력 변화 비교 # #2025-06-27&#xA;1. Load package # import pandas as pd import numpy as np 2. Load affinity data # with open(&amp;#39;/data/home/ysh980101/2411/data-mhc/patient_id.txt&amp;#39;, &amp;#39;r&amp;#39;) as file: patients = [line.strip() for line in file] len(patients) 388 #387+reference 3. Merge affinity tables # hotspot = &amp;#34;c315&amp;#34; dfs = [] for pid in patients: file_path = f&amp;#34;/data/home/ysh980101/2411/data-mhc/{hotspot}/{pid}/binding_affinities_HLA-I.csv&amp;#34; df = pd.read_csv(file_path) df.rename(columns={&amp;#39;Affinity&amp;#39;: f&amp;#39;{pid}&amp;#39;}, inplace=True) df.rename(columns={&amp;#39;Peptide&amp;#39;: f&amp;#39;Peptide_{pid}&amp;#39;}, inplace=True) if pid == &amp;#39;reference&amp;#39;: dfs.</description>
    </item>
    <item>
      <title>*</title>
      <link>http://localhost:1313/docs/hobby/memo/blog2/</link>
      <pubDate>Thu, 26 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/memo/blog2/</guid>
      <description>* # #2025-06-26&#xA;갑자기 튀어나온 나의 솔직한 마음.&#xA;연구실 와서 많이 느낀건데 나는 얼마나 성격이 이상한거지? 싶다. 내딴에는 남들을 불쾌하게 하지 않고 어떻게 생각할까를 엄청 고민해서 말하고 말조심하려고 노력하는데도 평판이 딱히 좋은 편이 아닌거같아서 &amp;hellip; 성격이 얼마나 안좋길래 이렇게 신경을 써도 남들이 불편하게 느끼는 부분이 많은걸까 ㅠㅠ&#xA;어느정도나면 남을 대하는 행위가 검열해야할것이 너무 많은 일이라 피로도가 높아서, 할일이 많거나 기분이 안좋거나 하는 이유로 1) 기분을 좋게하거나 할일을 하기 2) 사람을 대하기 이 두가지를 동시에 하는게 버거운 날이 있고</description>
    </item>
    <item>
      <title>변이 클러스터링 연구 #4 알고리즘 성능 평가 - k dist plot</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi37/</link>
      <pubDate>Tue, 24 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi37/</guid>
      <description>변이 클러스터링 연구 #4 알고리즘 성능 평가 - k dist plot # #2025-06-24&#xA;1. Load package # import pandas as pd import numpy as np import os os.sys.path.append(&amp;#34;/data/home/ysh980101/2407/Mutclust&amp;#34;) from pathlib import Path from Bin.Utils.utils import * from Bin.arg_parser import * from Bin.mlib import * os.sys.path.append(&amp;#34;/data/home/ysh980101/2506/mutclust&amp;#34;) from Bin.sc import * os.chdir(&amp;#34;/data/home/ysh980101/2506/mutclust&amp;#34;) 2. Load data # indir = &amp;#39;result/&amp;#39; resdir = &amp;#39;result/GISAID_test1/&amp;#39; with open(f&amp;#34;{indir}GISAID_total.pickle&amp;#34;, &amp;#34;rb&amp;#34;) as f: Input_df = pickle.load(f) hotspots = pd.</description>
    </item>
    <item>
      <title>변이 클러스터링 연구 #5 결과 검증: 계통 결정 돌연변이와 연관성</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi38/</link>
      <pubDate>Tue, 24 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi38/</guid>
      <description>변이 클러스터링 연구 #5 결과 검증: 계통 결정 돌연변이와 연관성 # #2025-06-24&#xA;1. Load package # import pandas as pd import numpy as np import os os.sys.path.append(&amp;#34;/data/home/ysh980101/2407/Mutclust&amp;#34;) from pathlib import Path from Bin.Utils.utils import * from Bin.arg_parser import * from Bin.mlib import * os.sys.path.append(&amp;#34;/data/home/ysh980101/2506/mutclust&amp;#34;) from Bin.sc import * os.chdir(&amp;#34;/data/home/ysh980101/2506/mutclust&amp;#34;) 2. Load data # lineage_info_dir = &amp;#39;/data/home/ysh980101/2411/data/mutation_info&amp;#39; covid_annotation = &amp;#34;/data/home/ysh980101/2404/Data/covid_annotation.tsv&amp;#34; sig_hotspots = &amp;#34;result/sig_hotspots.csv&amp;#34; lineage_info = make_lineage_info(lineage_info_dir) hotspot_lineage = make_hotspot_lineage(lineage_info, sig_hotspots_path, covid_annotation) hotspot_lineage plot_hotspot_lineage(hotspot_lineage) outdir = &amp;#34;result/&amp;#34; hotspot_lineage.</description>
    </item>
    <item>
      <title>비오는날의 카페 페이스포포</title>
      <link>http://localhost:1313/docs/hobby/daily/daily16/</link>
      <pubDate>Sat, 21 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/daily/daily16/</guid>
      <description>비오는날의 카페 페이스포포 # #2025-06-21&#xA;팍팍한 일상이지만 오랜만에 브런치먹으러 왔다..!&#xA;오늘 시킨 메뉴는 루꼴라 잠봉뵈르 / 루꼴라 쉬림프 타르틴 / 페스츄리소세지 푀이테 / 플레인 사워도우!!&#xA;여기는 모든메뉴가 맛이 중~상이어서 역시 맛있었다 ㅎㅎ 그래두 젤 마싯었던건 루꼴라 잠봉뵈르(이유: 원래 조아하는 스타일이라서..)였구 엄마아빠는 페스츄리소세지 마싯다고했는데 난그냥 무난했음&#xA;루꼴라 쉬림프 타르틴은 저번에도 시켰던건데 이메뉴는 실패가 없다. ㅎㅎ&#xA;비오니깐 뭔가 더 이쁜것같은 내부&#xA;요 케이크 넘 기엽다 ㅋㅋ</description>
    </item>
    <item>
      <title>6월 18-20일</title>
      <link>http://localhost:1313/docs/hobby/memo/memo9/</link>
      <pubDate>Fri, 20 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/memo/memo9/</guid>
      <description>6월 18-20일 # #2025-06-20&#xA;오늘은먼가또!!!!! 불안이 몰려오는데 그럼 할일을했냐?하면 리비전작업은 가시화된 결과물이 없고 인적성공부를 안했고 코테는 오전에좀공부했지만 많이는못했다. 인성검사공부는 오늘시작했는데 막막하고어렵다. 운동도안갔다. 그럼 할일을안해놨으니 우울한게 당연함!! 심지어 이번주는 잠도 좀 부족했다.&#xA;우울하지 않으려면 아무리 바빠도 인적성/코테 공부를 11시-12시에는 꼭 하자. (오전 집중시간애 리비전을 안하는게 불안하니깐 무리해서 오전에 할필요는없음) 그리고 8시-9시 운동은 꼭 가자.&#xA;생각을넘많이하지말구 주변에 건강하게 의지하면서 할일을 하자</description>
    </item>
    <item>
      <title>변이 클러스터링 연구 #1 알고리즘 실행</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi34/</link>
      <pubDate>Fri, 20 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi34/</guid>
      <description>변이 클러스터링 연구 #1 알고리즘 실행 # #2025-06-20&#xA;1. Load package # import pandas as pd import numpy as np import os os.sys.path.append(&amp;#34;/data/home/ysh980101/2407/Mutclust&amp;#34;) from pathlib import Path from Bin.Utils.utils import * from Bin.arg_parser import * from Bin.mlib import * 2. Find CCMs # i = 1 tag = f&amp;#34;test{i}&amp;#34; input_path = &amp;#34;/data/home/ysh980101/2407/Mutclust/Testdata/Input/GISAID_total.pickle&amp;#34; outdir = f&amp;#34;/data/home/ysh980101/2407/Mutclust/Testdata/Output/GISAID_{tag}/&amp;#34; Path(outdir).mkdir(parents=True, exist_ok=True) info = set_env(input = input_path, output = outdir) Input_df = readPickle(input_path) init(Input_df, info) mutInfo, ccms = get_candidate_core_mutations(Input_df, info, tag, i) --- Configurations --- Input data: &amp;#39;/data/home/ysh980101/2407/Mutclust/Testdata/Input/GISAID_total.</description>
    </item>
    <item>
      <title>변이 클러스터링 연구 #2 변이 중요도 계산</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi35/</link>
      <pubDate>Fri, 20 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi35/</guid>
      <description>변이 클러스터링 연구 #2 변이 중요도 계산 # #2025-06-20&#xA;1. Load package # import pandas as pd import numpy as np import os os.sys.path.append(&amp;#34;/data/home/ysh980101/2407/Mutclust&amp;#34;) from pathlib import Path from Bin.Utils.utils import * from Bin.arg_parser import * from Bin.mlib import * 2. Load GISAID data # indir = &amp;#34;/data/home/ysh980101/2407/Mutclust/Testdata/Input/&amp;#34; Refseq = getNucleotideRefSeq() GISAID_Freq = pd.read_csv(f&amp;#39;{indir}gisaid_freq_all.csv&amp;#39;, index_col=0) GISAID_meta = get_GISAID_meta() print(GISAID_Freq) A C G T R Y S W K M B D H V N 1 10612 390 415 785 11 1 3 4 24 2 1 2 0 0 219995 2 287 502 218 12942 3 31 14 4 61 0 1 2 1 0 218179 3 166 461 348 18168 1 12 29 10 15 1 0 1 1 0 213032 4 19398 267 502 972 12 5 1 33 37 6 1 1 0 1 211009 5 24962 281 334 699 6 21 6 17 15 10 5 1 1 1 205886 .</description>
    </item>
    <item>
      <title>변이 클러스터링 연구 #3 결과 검증: 임상 결과와의 연관성</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi36/</link>
      <pubDate>Fri, 20 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi36/</guid>
      <description>변이 클러스터링 연구 #3 결과 검증: 임상 결과와의 연관성 # #2025-06-20&#xA;1. Load package # import pandas as pd import numpy as np import os os.sys.path.append(&amp;#34;/data/home/ysh980101/2407/Mutclust&amp;#34;) from pathlib import Path from Bin.Utils.utils import * from Bin.arg_parser import * from Bin.mlib import * 2. Load COVID19 data # i = 1 tag = f&amp;#34;test{i}&amp;#34; resdir = f&amp;#34;/data/home/ysh980101/2407/Mutclust/Testdata/Output/GISAID_{tag}/&amp;#34; covid19_dir = &amp;#34;/data3/projects/2020_MUTCLUST/Data/Projects/COVID19/Sequence/Preprocessed/Nucleotide/Mutationinfo&amp;#34; meta_path = &amp;#34;/data/home/ysh980101/2506/data/meta.csv&amp;#34; hotspots = pd.read_csv(f&amp;#34;{resdir}clusters_{tag}.txt&amp;#34;,sep=&amp;#34;\t&amp;#34;) metaData = pd.read_csv(meta_path, index_col=0) mutInfo = make_mutInfo_covid19(covid19_dir) mutSignature = make_mutSignature(mutInfo, hotspots, metaData) print(mutSignature) COV-CCO-001 COV-CCO-002 COV-CCO-003 COV-CCO-004 COV-CCO-006 \ c0 0 0 0 0 0 c1 0 0 0 0 0 c2 0 0 0 0 0 c3 0 0 0 0 0 c4 0 0 0 0 0 .</description>
    </item>
    <item>
      <title>항생제 TFT 연구 #1 입력 데이터 생성</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi32/</link>
      <pubDate>Tue, 17 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi32/</guid>
      <description>항생제 TFT 연구 #1 입력 데이터 생성 # #2025-06-17&#xA;Load package # %load_ext autoreload %autoreload 2 import sys import os sys.path.append(&amp;#39;/data3/projects/2025_Antibiotics/YSH/bin&amp;#39;) from sc import * os.chdir(&amp;#39;/data3/projects/2025_Antibiotics/YSH&amp;#39;) Check data # raw_path = &amp;#39;/data3/projects/2025_Antibiotics/YSH/res/sev_dict_filtered.pkl&amp;#39; with open(raw_path, &amp;#39;rb&amp;#39;) as f: raw_data = pickle.load(f) keys = list(raw_data.keys()) print(len(keys)) print(keys[0], &amp;#39;\n&amp;#39;, raw_data[keys[0]]) 4515 74374 Date NEWS med_cnt med_list \ 0 2020-10-30 4 2 Trizele;Cefotaxime 1 2020-10-31 4 2 Trizele;Cefotaxime 2 2020-11-01 12 2 Pospenem;Pospenem_2 3 2020-11-02 9 3 Pospenem;Meropen;Vanco Kit 4 2020-11-03 12 2 Vanco Kit;Meropen 5 2020-11-04 8 2 Vanco Kit;Meropen 6 2020-11-05 9 0 strain 0 [] 1 [] 2 [] 3 [Enterobacter cloacae ssp cloacae] 4 [Enterobacter cloacae ssp cloacae] 5 [Enterobacter cloacae ssp cloacae] 6 [Enterobacter cloacae ssp cloacae] 4515명 환자 데이터이고</description>
    </item>
    <item>
      <title>항생제 TFT 연구 #2 입력 feature 생성</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi33/</link>
      <pubDate>Tue, 17 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi33/</guid>
      <description>항생제 TFT 연구 #2 입력 feature 생성 # #2025-06-17&#xA;1. Load package # %load_ext autoreload %autoreload 2 import sys import os import pickle import matplotlib.pyplot as plt from matplotlib.backends.backend_pdf import PdfPages import pandas as pd sys.path.append(&amp;#39;/data3/projects/2025_Antibiotics/YSH/bin&amp;#39;) from sc import * os.chdir(&amp;#39;/data3/projects/2025_Antibiotics/YSH&amp;#39;) 2. Previous # seqdir = &amp;#39;data/res_dict&amp;#39; seq_list = os.listdir(seqdir) print(len(seq_list)) 169 항생제 169종에 대해서 size 10 sequence를 생성했었는데&#xA;모델 입력 feature로 다음을 제외하는대신 antibiotics 리스트 strain 리스트 저 2개 feature를 반영하는 새로운 feature를 2개 생성하려고 한다: 현재 antibiotics가 현재 strain 환자의 NEWS를 감소시킨 이력이 있는지?</description>
    </item>
    <item>
      <title>6월 16일</title>
      <link>http://localhost:1313/docs/hobby/memo/memo8/</link>
      <pubDate>Mon, 16 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/memo/memo8/</guid>
      <description>6월 16일 # #2025-06-16&#xA;오늘할일&#xA;인적성 1회 코테 1문제 리비전작업 #인적성&#xA;##풀이문항&#xA;언어 - 14/15, 12/14 수리 - 11/15, 5/11 추리 - 14/15, 10/14 공간지각 - 6/10, 3/6&#xA;##총평&#xA;첫날보단 익숙해진듯.. 수리 넘급하게풀지말자&#xA;#코테&#xA;문제: 지게차와 크레인 https://school.programmers.co.kr/learn/courses/30/lessons/388353&#xA;##입출력 예&#xA;storage = [&amp;#34;AZWQY&amp;#34;, &amp;#34;CAABX&amp;#34;, &amp;#34;BBDDA&amp;#34;, &amp;#34;ACACA&amp;#34;]&#x9;requests = [&amp;#34;A&amp;#34;, &amp;#34;BB&amp;#34;, &amp;#34;A&amp;#34;] result = 11 ##풀이&#xA;myarray = [[False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False], [False, False, False, False, False]] myarray = [[True, True, True, True, True], [True, False, False, False, True], [True, False, False, False, True], [True, True, True, True, True]] storage_array = [A Z W Q Y C A A B X B B D D A A C A C A] rows = 4 columns = 5 left = rows*columns = 20 오늘한일</description>
    </item>
    <item>
      <title>6월 15일</title>
      <link>http://localhost:1313/docs/hobby/memo/memo6/</link>
      <pubDate>Sun, 15 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/memo/memo6/</guid>
      <description>6월 15일 # #2025-06-15&#xA;오늘할일&#xA;인적성 1회 - 언어: p.66-80 / 수리: p.153-166 / 추리: p.234-241 / 공간지각: p.322-329 코테 1문제 리비전작업 #인적성&#xA;##풀이문항&#xA;언어 - 15/15, 12/15&#xA;수리 - 7/15, 3/7&#xA;추리 - 12/15, 8/12&#xA;공간지각 - 6/10, 3/6&#xA;##간단리뷰&#xA;언어 - 11번: 기반식 고인돌이랑 개석식 고인돌 비교해야대는데 탁자식이랑 기반식을 비교하는 실수를함 / 16번: 근거를 안찾고 느낌으로 배열했는데 다시읽어보니까 &amp;ldquo;여러 학자&amp;quot;를 받는단어가없으니 (가)가 1번이 안됨 근데 빨리읽어서 그거까지 안봣다 / 20번: (나)랑 (라)는좀 헷갈릴만한듯 다시풀기</description>
    </item>
    <item>
      <title>원서정리</title>
      <link>http://localhost:1313/docs/hobby/memo/memo7/</link>
      <pubDate>Sun, 15 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/memo/memo7/</guid>
      <description>원서정리 # 4.20 삼양라운드스퀘어&#xA;﹂직무: OMICS AI Engineer (연구원)&#xA;# 4.21 한국산업기술기획평가원&#xA;﹂직무: 일반직 &amp;gt; R&amp;amp;D 기획평가 &amp;gt; 바이오생명&#xA;# 5.20 네이버클라우드&#xA;﹂직무: 환자향 진료기록 생성 모델 개발 (체험형 인턴)&#xA;﹂원서확인 https://recruit.navercorp.com/my/aplcnt.do#none&#xA;# 6.11 SK AX&#xA;﹂직무: 채용연계형 AI 서비스 개발 과정 (채용연계형 인턴)&#xA;﹂정보 http://linkareer.com/activity/245743&#xA;﹂전형: 지원접수 &amp;gt; 서류 검토 &amp;gt; SKCT(인성검사) 응시 및 AI 면접 &amp;gt; 면접 &amp;gt; 결과 안내&#xA;﹂SKALA 1기 후기 / SK 그룹 인적성 SKCT TIP</description>
    </item>
    <item>
      <title>6월 14일</title>
      <link>http://localhost:1313/docs/hobby/memo/memo5/</link>
      <pubDate>Sat, 14 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/memo/memo5/</guid>
      <description>6월 14일 # #2025-06-14&#xA;오늘한일&#xA;코테 공책 정리 SK AX 원서 운동 코테 3개 #코테&#xA;문제: 같은 숫자는 싫어 https://school.programmers.co.kr/learn/courses/30/lessons/12906&#xA;##입출력 예&#xA;arr = [1,1,3,3,0,1,1] answer = [1,3,0,1] ##정답&#xA;def solution(arr): answer = [arr[0]] for i in arr: if i != answer[-1]: answer.append(i) return answer 문제: 기능개발 https://school.programmers.co.kr/learn/courses/30/lessons/42586&#xA;##입출력 예&#xA;progresses = [95, 90, 99, 99, 80, 99]&#x9;speeds = [1, 1, 1, 1, 1, 1]&#x9;return = [1, 3, 2] ##정답</description>
    </item>
    <item>
      <title>6월 8일 (&#43;스트레스 받을 이유가 없는이유)</title>
      <link>http://localhost:1313/docs/hobby/memo/memo3/</link>
      <pubDate>Sun, 08 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/memo/memo3/</guid>
      <description>6월 8일 (+스트레스 받을 이유가 없는이유) # #2025-06-08&#xA;10:10-10:40 코테&#xA;10:40-11:00 공기업 서칭&#xA;#코테&#xA;문제: 베스트앨범 https://school.programmers.co.kr/learn/courses/30/lessons/42579&#xA;##입출력 예&#xA;genres = [&amp;#34;classic&amp;#34;, &amp;#34;pop&amp;#34;, &amp;#34;classic&amp;#34;, &amp;#34;classic&amp;#34;, &amp;#34;pop&amp;#34;] plays = [500, 600, 150, 800, 2500] return = [4, 1, 3, 0] ##정답&#xA;def solution(genres, plays): genre_total = {} # 장르별 총 재생 수 genre_songs = {} # 장르별 (고유 번호, 재생 수) 리스트 for i in range(len(genres)): genre = genres[i] play = plays[i] # 1.</description>
    </item>
    <item>
      <title>여름경주🍡🌿</title>
      <link>http://localhost:1313/docs/hobby/daily/daily15/</link>
      <pubDate>Sun, 08 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/daily/daily15/</guid>
      <description>여름경주🍡🌿 # #2025-06-08&#xA;주말이순삭됐지만 재밌었다 ㅎㅎ&#xA;행운/대박/합격 이런것만 보면 저항없이 사는 사람 ㅠ</description>
    </item>
    <item>
      <title>6월 7일</title>
      <link>http://localhost:1313/docs/hobby/memo/memo2/</link>
      <pubDate>Sat, 07 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/memo/memo2/</guid>
      <description>6월 7일 # #2025-06-07&#xA;#백신연구 진행상황&#xA;##1&#xA;목적이 개인의 면역 환경을 대표하고 면역 반응을 예측하는 feature를 찾는 것이라고 할때.&#xA;개인의 면역 환경을 대표하는 feature를 찾는 것은 쉽다. 단일 시점 clustering을 하고 군집의 feature를 찾으면 됨. 다만 이중에 &amp;lsquo;면역 반응&amp;rsquo;을 예측하는데 유용한 feature를 골라내는게 어렵다. &amp;lsquo;면역 반응&amp;rsquo;을 type1 2 3등으로 정의하는게 필요하고 그 반응을 대표하는 feature를 찾는게 필요하다. 목적이 &amp;lsquo;면역 반응&amp;rsquo;이 비슷한 환자를 군집화하는것일때.&#xA;&amp;lsquo;면역 반응&amp;rsquo;을 유전자 발현량 패턴이라고 정의하면 (단일 시점 clustering과) spherical kmeans는 편향이 최소화된 비지도학습 방법이지만 feature 선택이 어렵다.</description>
    </item>
    <item>
      <title>6월 5일 (특이점:외부에쫌많이 흔들림)</title>
      <link>http://localhost:1313/docs/hobby/memo/daily9/</link>
      <pubDate>Thu, 05 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/memo/daily9/</guid>
      <description>6월 5일 (특이점:외부에쫌많이 흔들림) # #2025-06-05&#xA;#코딩테스트&#xA;문제: 완주하지 못한 선수 https://school.programmers.co.kr/learn/courses/30/lessons/42576?language=python3&#xA;##입출력 예&#xA;participant = [&amp;#34;leo&amp;#34;, &amp;#34;kiki&amp;#34;, &amp;#34;eden&amp;#34;]&#x9;completion = [&amp;#34;eden&amp;#34;, &amp;#34;kiki&amp;#34;]&#x9;return = &amp;#34;leo&amp;#34; ##개념&#xA;Counter([&amp;#34;leo&amp;#34;, &amp;#34;kiki&amp;#34;, &amp;#34;eden&amp;#34;]) -&amp;gt; {&amp;#39;leo&amp;#39;:1, &amp;#39;kiki&amp;#39;:1, &amp;#39;eden&amp;#39;:1} Counter([&amp;#34;leo&amp;#34;, &amp;#34;kiki&amp;#34;, &amp;#34;eden&amp;#34;]) - Counter([&amp;#34;kiki&amp;#34;, &amp;#34;eden&amp;#34;]) -&amp;gt; {&amp;#39;leo&amp;#39;:1} (key별로 value를 빼서 0이나 음수되면 제거) ##정답&#xA;i) Counter(participant) -&amp;gt; {&amp;#39;leo&amp;#39;:1, &amp;#39;kiki&amp;#39;:1, &amp;#39;eden&amp;#39;:1} ii) Counter(participant) - Counter(completion) -&amp;gt; {&amp;#39;leo&amp;#39;:1} iii) 답은? 위를 X로 봣을때 list(X.keys())[0] from collections import Counter def solution(participant, completion): answer = Counter(participant) - Counter(completion) return list(answer.</description>
    </item>
    <item>
      <title>6월 5일 (특이점:외부에쫌많이 흔들림)</title>
      <link>http://localhost:1313/docs/hobby/memo/memo1/</link>
      <pubDate>Thu, 05 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/memo/memo1/</guid>
      <description>6월 5일 (특이점:외부에쫌많이 흔들림) # #2025-06-05&#xA;#코딩테스트&#xA;문제: 완주하지 못한 선수 https://school.programmers.co.kr/learn/courses/30/lessons/42576?language=python3&#xA;##입출력 예&#xA;participant = [&amp;#34;leo&amp;#34;, &amp;#34;kiki&amp;#34;, &amp;#34;eden&amp;#34;]&#x9;completion = [&amp;#34;eden&amp;#34;, &amp;#34;kiki&amp;#34;]&#x9;return = &amp;#34;leo&amp;#34; ##개념&#xA;Counter([&amp;#34;leo&amp;#34;, &amp;#34;kiki&amp;#34;, &amp;#34;eden&amp;#34;]) -&amp;gt; {&amp;#39;leo&amp;#39;:1, &amp;#39;kiki&amp;#39;:1, &amp;#39;eden&amp;#39;:1} Counter([&amp;#34;leo&amp;#34;, &amp;#34;kiki&amp;#34;, &amp;#34;eden&amp;#34;]) - Counter([&amp;#34;kiki&amp;#34;, &amp;#34;eden&amp;#34;]) -&amp;gt; {&amp;#39;leo&amp;#39;:1} (key별로 value를 빼서 0이나 음수되면 제거) ##정답&#xA;i) Counter(participant) -&amp;gt; {&amp;#39;leo&amp;#39;:1, &amp;#39;kiki&amp;#39;:1, &amp;#39;eden&amp;#39;:1} ii) Counter(participant) - Counter(completion) -&amp;gt; {&amp;#39;leo&amp;#39;:1} iii) 답은? 위를 X로 봣을때 list(X.keys())[0] from collections import Counter def solution(participant, completion): answer = Counter(participant) - Counter(completion) return list(answer.</description>
    </item>
    <item>
      <title>ADsP 45회 응시결과</title>
      <link>http://localhost:1313/docs/study/career/career1/</link>
      <pubDate>Thu, 05 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/career/career1/</guid>
      <description>ADsP 45회 응시결과 # #2025-06-05&#xA;ㅎㅎ 붙었다!!</description>
    </item>
    <item>
      <title>불행 속 우아함</title>
      <link>http://localhost:1313/docs/hobby/book/book39/</link>
      <pubDate>Mon, 02 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/book/book39/</guid>
      <description>불행 속 우아함 # #2025-06-02&#xA;#1&#xA;해소되지 않은 기분은 성격이 된다.&#xA;작은 짜증으로 시작된 기분은 일상에 대한 분노로 이어지고 속속들이 헤쳐 모여 결국 더러운 성격으로 완성된다. 어떤 성격으로 살고 싶은지는 빼곡히 적은 새해 다짐이 아니라 일상을 어떻게 다루는지에 달려 있었다.&#xA;#2&#xA;사람의 진짜 우아함은 무너졌을 때 드러난다고 한다.&#xA;윗사람에게 깨진 날 후배를 대하는 태도나 안 좋은 일이 넘친 날 웃응며 인사할 줄 아는 여유에서 우린 그 사람의 깊이를 느낄 수 있다.</description>
    </item>
    <item>
      <title>bashrc 스크립트 (연구실)</title>
      <link>http://localhost:1313/docs/study/be/be51/</link>
      <pubDate>Wed, 28 May 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be51/</guid>
      <description>bashrc 스크립트 (연구실) # #2025-05-28&#xA;#1 local&#xA;1 #alias cobi2=&amp;#39;ssh -p 5290 ysh980101@155.230.28.211&amp;#39; 2 alias cobi2=&amp;#34;ssh -p 3160 ysh980101@155.230.110.91&amp;#34; 3 alias cobi3=&amp;#34;ssh -p 7777 ysh980101@155.230.110.92&amp;#34; 4 alias cobi4=&amp;#34;ssh -p 4712 ysh980101@155.230.110.93&amp;#34; 5 # &amp;gt;&amp;gt;&amp;gt; conda initialize &amp;gt;&amp;gt;&amp;gt; 6 # !! Contents within this block are managed by &amp;#39;conda init&amp;#39; !! 7 __conda_setup=&amp;#34;$(&amp;#39;/opt/anaconda3/bin/conda&amp;#39; &amp;#39;shell.bash&amp;#39; &amp;#39;hook&amp;#39; 2&amp;gt; /dev/null )&amp;#34; 8 if [ $? -eq 0 ]; then 9 eval &amp;#34;$__conda_setup&amp;#34; 10 else 11 if [ -f &amp;#34;/opt/anaconda3/etc/profile.</description>
    </item>
    <item>
      <title>초여름 부산˚‧｡🐋</title>
      <link>http://localhost:1313/docs/hobby/daily/daily11/</link>
      <pubDate>Tue, 20 May 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/daily/daily11/</guid>
      <description>초여름 부산˚‧｡🐋 # #2025-05-20&#xA;간단하게 일상으로만 쓸려다가,,, 넘좋앗어서 그냥 따로 뺐다 ㅎㅎㅎ&#xA;다대포 할매집!! 문어삼합 / 냄비라면 / 올빚베리막걸리 시켯는데 다맛있었당 특히 딸기막걸리는 집에오니깐 또생각나서 사올걸 후회해따&#xA;넘이뻤던바닷가&#xA;길이사왓는데 넘맛있어서 막퍼먹은 케이크 ㅋㅋ 멜트인멜로우 검색해보니까 다른디저트도 다마싯을거같아서 또사먹을듯&#xA;생레몬하이볼 첨먹어봣는데 주점에서파는하이볼 같음&#xA;다음날&amp;hellip; 지수집엔 마싯는게 많다 일리커피가 네스프레소보다 훨배 맛있는거같음 다크원두인데 쓴맛이없고 향이 엄청 좋다&#xA;부산현대미술관 구경가서 소화시켜줌 전시란 어렵다 .. 저 망원경안엔 무려 구슬 4-5개가 들어있었는데 뭘전하고싶은건지모르겟어서 혼란스러웟음 ㅋㅋ</description>
    </item>
    <item>
      <title>열시미충전하는 연휴</title>
      <link>http://localhost:1313/docs/hobby/daily/daily8/</link>
      <pubDate>Tue, 06 May 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/daily/daily8/</guid>
      <description>열시미충전하는 연휴 # #2025-05-06</description>
    </item>
    <item>
      <title>카페 스페이스임원</title>
      <link>http://localhost:1313/docs/hobby/daily/daily7/</link>
      <pubDate>Mon, 28 Apr 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/daily/daily7/</guid>
      <description>카페 스페이스임원 # #2025-04-28&#xA;전체적으로 초록초록한 분위기가 넘 예뻤던 스페이스임원!!&#xA;브런치 종류가 많았는데 쉬림프 감자 타르틴 / 샥슈카 / 스페이스 치아바타 샌드위치를 시켰다.&#xA;셋다 마싰었지만 치아바타 샌드위치가 내스탈이었다 ㅎㅎㅎ 쉬림프 감자 타르틴은 엄마가 맛있다고 했는데 평소에 감자 사라다 st 그렇게 좋아하지 않는데두 내 입에도 괜찮았당&#xA;샥슈카는 일반적인 라구소스맛 브런치들에 비해 고기맛이랑 짠맛이 적게 나고 토마토맛이 많이 나서 맛있게 먹었다!&#xA;두명이서 오면 2층 테라스 자리에 앉아도 좋을것같음. 나오면서 트러플 에그 갈레트랑 라구 오픈 샌드위치를 다음에 먹을 메뉴로 찜해뒀다 ㅎㅎ</description>
    </item>
    <item>
      <title>ChIP-seq 전처리 (trimmomatic, samtools)</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi5/</link>
      <pubDate>Mon, 21 Apr 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi5/</guid>
      <description>ChIP-seq 전처리 (trimmomatic, samtools) # #2025-04-21&#xA;1. Trimming # chipseq_trimming.sh&#xA;#!/bin/bash # setting envs export bdir=&amp;#34;/data3/projects/2022_KNU_EBV&amp;#34; export hg38_bowtieidx=&amp;#34;/data3/PUBLIC_DATA/ref_genomes/homo_sapiens/hg38/hg38_bowtie_idx/hg38.fa&amp;#34; export hg38_bwaidx=&amp;#34;/data3/PUBLIC_DATA/ref_genomes/homo_sapiens/hg38/hg38_bwa_index/hg38.fa&amp;#34; export ebv_bowtie2idx=&amp;#34;/data3/PUBLIC_DATA/ref_genomes/Human_gammaherpesvirus_4_EBV/EBV_bowtie2_idx/NC_007605.1.fa&amp;#34; export ebv_bwaidx=&amp;#34;/data3/PUBLIC_DATA/ref_genomes/Human_gammaherpesvirus_4_EBV/EBV_bwa_index/NC_007605.1.fa&amp;#34; ### SET Path ### cd /data3/RAW_DATA/2023_KNU_EBV/ChIP-seq ### TRIMMING data ### mkdir -p trimmed sampdir=&amp;#34;/data3/RAW_DATA/2023_KNU_EBV/ChIP-seq&amp;#34; samplist=(&amp;#34;Input&amp;#34; &amp;#34;p65&amp;#34; &amp;#34;RIgG&amp;#34;) TRIMMOMATIC= &amp;#34;/data/packages/trimmomatic/Trimmomatic-0.39/trimmomatic-0.39.jar&amp;#34; for sampname in &amp;#34;${samplist[@]}&amp;#34;; do mkdir -p &amp;#34;trimmed/${sampname}&amp;#34; java -jar $TRIMMOMATIC PE -threads 40 -trimlog log1.txt $sampdir/${sampname}_1.fastq/${sampname}_1.fastq $sampdir/${sampname}_2.fastq/${sampname}_2.fastq $sampdir/trimmed/${sampname}/${sampname}_1.trimmed.fastq $sampdir/trimmed/${sampname}/${sampname}_1.up.trimmed.fastq $sampdir/trimmed/${sampname}/${sampname}_2.trimmed.fastq $sampdir/trimmed/${sampname}/${sampname}_2.up.trimmed.fastq ILLUMINACLIP:/data1/packages/trimmomatic/Trimmomatic-0.39/adapters/TruSeq3-PE.fa:2:30:10:2:True LEADING:3 TRAILING:3 MINLEN:36 done # 2.</description>
    </item>
    <item>
      <title>Enrichment 분석 및 시각화 (gProfiler/ggplot2)</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi3/</link>
      <pubDate>Mon, 21 Apr 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi3/</guid>
      <description>Enrichment 분석 및 시각화 (gProfiler/ggplot2) # #2025-04-21&#xA;# #1 Load Package&#xA;library(ggplot2) # #2 Set Path&#xA;setwd(&amp;#34;/data-blog/bi3&amp;#34;) getwd() &amp;#39;/data-blog/bi3&amp;#39; # #3 Functional Enrichment Bubble Plot&#xA;condition &amp;lt;- &amp;#39;150_con&amp;#39; gpsource &amp;lt;- &amp;#39;GO:BP&amp;#39; #gpsource &amp;lt;- &amp;#39;REAC&amp;#39; df_c1 &amp;lt;- read.csv(paste0(&amp;#34;./sleuth_ward/gprofiler/gProfiler_&amp;#34;,condition,&amp;#34;_termsize.csv&amp;#34;)) df_c2 &amp;lt;- read.csv(paste0(&amp;#34;gProfiler_&amp;#34;,condition,&amp;#34;_c2_padj0.1.csv&amp;#34;)) df_c1 &amp;lt;- df_c1[df_c1$source == gpsource, ] df_c2 &amp;lt;- df_c2[df_c2$source == gpsource, ] df_c1$reg_type &amp;lt;- &amp;#39;down&amp;#39; df_c2$reg_type &amp;lt;- &amp;#39;up&amp;#39; df_c1$nlog &amp;lt;- -abs(df_c1$negative_log10_of_adjusted_p_value) df_c2$nlog &amp;lt;- abs(df_c2$negative_log10_of_adjusted_p_value) df_c1 &amp;lt;- df_c1[order(df_c1$negative_log10_of_adjusted_p_value), ] df_c2 &amp;lt;- df_c2[order(-df_c2$negative_log10_of_adjusted_p_value), ] df &amp;lt;- rbind(df_c1, df_c2) ggplot(df, aes(x = reorder(term_name, nlog), y = negative_log10_of_adjusted_p_value, size = intersection_size, color = nlog)) + geom_point(alpha = 0.</description>
    </item>
    <item>
      <title>Kallisto Pseudoalignment 작업</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi4/</link>
      <pubDate>Mon, 21 Apr 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi4/</guid>
      <description>Kallisto Pseudoalignment 작업 # #2025-04-21&#xA;1. Build Index # $ kallisto index -i transcripts_cDNA.idx Homo_sapiens.GRCh38.cdna.all.fa.gz # 2. Pseudoalign # $ kallisto quant -i transcripts_cDNA.idx -o output_150-1 -t 40 ../2306_tophat/data/Bowtie2Index/5-AZA_150-1_1_edited.fastq ../2306_tophat/data/Bowtie2Index/5-AZA_150-1_2_edited.fastq 3개 파일 생성 abundance.h5 - HDF5 binary file containing run info, abundance esimates, bootstrap estimates, and transcript length information length. This file can be read in by sleuth abundance.tsv - plaintext file of the abundance estimates. It does not contains bootstrap estimates.</description>
    </item>
    <item>
      <title>RNA-seq 전처리 (Rsubread, edgeR)</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi8/</link>
      <pubDate>Mon, 21 Apr 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi8/</guid>
      <description>RNA-seq 전처리 (Rsubread, edgeR) # #2025-04-21&#xA;가장 오류 적게나는 조합!&#xA;1. Align RNA-seq # Load Packages&#xA;library(Rsubread) library(org.Mm.eg.db) library(gridExtra) library(reshape2) Set Path&#xA;indir = &amp;#34;/data/home/ysh980101/2504/mirna/data&amp;#34; outdir = &amp;#34;/data/home/ysh980101/2504/mirna/data&amp;#34; refpath = &amp;#34;/data/home/ysh980101/2406/data-gne/mm39.fa&amp;#34; setwd(indir) getwd() &amp;#39;/data/home/ysh980101/2504/mirna/data&amp;#39; Build Index&#xA;buildindex(basename = &amp;#34;mm39&amp;#34;, reference = refpath) Read Alignment&#xA;files &amp;lt;- list.files(pattern=&amp;#34;\\.fastq\\.gz$&amp;#34;, full.names=TRUE) bams &amp;lt;- sub(&amp;#34;\\.fastq\\.gz$&amp;#34;, &amp;#34;.bam&amp;#34;, files) samples &amp;lt;- gsub(&amp;#34;^\\.\\/|\\.fastq\\.gz$&amp;#34;, &amp;#34;&amp;#34;, files) targets &amp;lt;- read.delim(&amp;#34;target.txt&amp;#34;, header=TRUE) align(index=&amp;#34;mm39&amp;#34;, readfile1=files, input_format=&amp;#34;gzFASTQ&amp;#34;, output_file=bams, nthreads=50) Quantification&#xA;fc = featureCounts(bams, isGTFAnnotationFile=TRUE, GTF.</description>
    </item>
    <item>
      <title>RNA-seq 전처리 (TopHat, SAMtools, HTSeq)</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi7/</link>
      <pubDate>Mon, 21 Apr 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi7/</guid>
      <description>RNA-seq 전처리 (TopHat, SAMtools, HTSeq) # #2025-04-21&#xA;# #1 TopHat 실행&#xA;$ tophatpy -o tophat_out_33-1 --no-mixed -p 40 \ $ /data3/PUBLIC_DATA/ref_genomes/homo_sapiens/GRCh38/Homo_sapiens.GRCh38.dna.toplevel \ $ /data/home/ysh980101/2306_tophat/data/Bowtie2Index/5-AZA_33-1_1.fastq \ $ /data/home/ysh980101/2306_tophat/data/Bowtie2Index/5-AZA_33-1_2.fastq tophatpy: tophat2 안먹어서 커스텀한 명령어 (정식 명령어는 tophat2) -o tophat_out_33-1: 출력 디렉토리 설정 --no-mixed: 페어 중 하나만 매핑되면 제외 -p 40: 멀티스레딩, 40개 스레드 사용 /data3/PUBLIC_DATA/...dna.toplevel: reference genome FASTA (Bowtie2 인덱스가 이와 동일한 경로로 있어야 함) 2개의 paired-end read 입력 cf) tophat alias 확인</description>
    </item>
    <item>
      <title>RNA-seq 전처리 파이프라인 비교</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi9/</link>
      <pubDate>Mon, 21 Apr 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi9/</guid>
      <description>RNA-seq 전처리 파이프라인 비교 # #2025-04-21&#xA;# #1 Methods&#xA;비교 의의&#xA;Traditional 방법은 TopHat2+HTseq 조합이지만 오류도 넘 많이나고 Rsubread를 쓰면 빠르고 깔끔한데 왜 써야하지..? 싶어서 동일한 데이터(pair-end fastq)로 돌려봄. HTseq에서 아래 코드를 수행할때 파라미터가 많은데 뭐가 다르게나오는지 모르겠어서 실험해봄. Cases&#xA;Rsubread 사용 HTSeq 사용, -i gene_id --additional-attr=gene_name (exon 기준 count) HTSeq 사용, -i transcript_id --additional-attr=gene_id --additional-attr=gene_name (transcript 기준 count) HTSeq 사용, -i transcript_id --additional-attr=gene_id --additional-attr=gene_name --nonunique=all (여러 transcript에 매핑된 read는 모두 count) # #2 Result</description>
    </item>
    <item>
      <title>Sleuth 작업</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi2/</link>
      <pubDate>Mon, 21 Apr 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi2/</guid>
      <description>Sleuth 작업 # #2025-04-21&#xA;1. Load Package, Run Sleuth # require(&amp;#34;sleuth&amp;#34;) packageVersion(&amp;#34;sleuth&amp;#34;) library(&amp;#34;gridExtra&amp;#34;) library(&amp;#34;cowplot&amp;#34;) library(&amp;#34;biomaRt&amp;#34;) library(readr) setwd(&amp;#34;/data/home/ysh980101/2307_kallisto&amp;#34;) getwd() sample_id &amp;lt;- dir(file.path(&amp;#34;./&amp;#34;)) sample_id &amp;lt;- grep(&amp;#34;^output_(150|con)&amp;#34;, sample_id, value = TRUE) sample_id &amp;lt;- substring(sample_id, 8) sample_id kal_dirs &amp;lt;- file.path(paste0(&amp;#34;./output_&amp;#34;, sample_id)) s2c &amp;lt;- read.table(file.path(&amp;#34;./kallisto_demo_150_con.tsv&amp;#34;), header = TRUE, stringsAsFactors = FALSE, sep = &amp;#34;\t&amp;#34;) s2c &amp;lt;- dplyr::mutate(s2c, path = kal_dirs) s2c marts &amp;lt;- listMarts() ensembl &amp;lt;- useMart(&amp;#34;ensembl&amp;#34;) datasets &amp;lt;- listDatasets(ensembl) filtered_datasets &amp;lt;- datasets[grepl(&amp;#34;hsapiens&amp;#34;, datasets$dataset), ] hsapiens_mart &amp;lt;- useMart(&amp;#34;ensembl&amp;#34;,dataset=&amp;#34;hsapiens_gene_ensembl&amp;#34;) datasets &amp;lt;- listDatasets(hsapiens_mart) filtered_datasets &amp;lt;- datasets[grepl(&amp;#34;hsapiens&amp;#34;, datasets$dataset), ] hsapiens_mart &amp;lt;- useMart(&amp;#34;ensembl&amp;#34;,dataset=&amp;#34;hsapiens_gene_ensembl&amp;#34;,host=&amp;#34;ensembl.</description>
    </item>
    <item>
      <title>WGBS 전처리 (Bismark)</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi6/</link>
      <pubDate>Mon, 21 Apr 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi6/</guid>
      <description> WGBS 전처리 (Bismark) # #2025-04-21&#xA;1. Build Index # $ bowtie2-build Homo_sapiens.GRCh38.dna.toplevel.fa GRCh38 -p 40 2. Bam Sorting &amp;amp; Indexing # $ samtools sort KEB01_1_bismark_bt2_pe.bam -o KEB01_1_bismark_bt2_pe.sorted.bam $ samtools index KEB01_1_bismark_bt2_pe.sorted.bam 3. Methylation Extraction # $ bismark_methylation_extractor --gzip --bedGraph --buffer_size 10G --cytosine_report --genome_folder /data3/PUBLIC_DATA/ref_genomes/homo_sapiens/GRCh37_hg19/Homo_sapiens/Ensembl/GRCh37/Sequence/WholeGenomeFasta KEB01_1_bismark_bt2_pe.sorted.bam </description>
    </item>
    <item>
      <title>목표를 이루는 확실한 방법</title>
      <link>http://localhost:1313/docs/hobby/book/book15/</link>
      <pubDate>Mon, 21 Apr 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/book/book15/</guid>
      <description>목표를 이루는 확실한 방법 # #2025-04-21&#xA;#1&#xA;오늘의 세상 모습이 어떻든, 무엇이 당연해 보이든,&#xA;내일이 되면 그 누구도 생각하지 못한 작은 우연 때문에 모든 게 달라질 수 있다. 돈과 마찬가지로 사건도 복리 효과를 낸다. 그리고 복리 효과의 가장 주요한 특징은 미약하게 시작된 뭔가가 나중에 얼마나 거대해질 수 있는지를 처음에는 직관적으로 느낄 수가 없다는 사실이다.&#xA;#2&#xA;세상은 정보로 넘쳐난다.&#xA;사람들은 그 모든 정보를 꼼꼼하고 차분하게 살펴보면서 가장 합리적의고 옳은 답을 찾기 어렵다.</description>
    </item>
    <item>
      <title>사회생활은 너모어렵다</title>
      <link>http://localhost:1313/docs/hobby/daily/daily6/</link>
      <pubDate>Thu, 17 Apr 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/daily/daily6/</guid>
      <description>사회생활은 너모어렵다 # #2025-04-17&#xA;제일 어려운부분은 솔직한 느낌을 주면서 매우 솔직하면 안된다는것이다 나의 모든것을 함께한다는 느낌을 주면서도 남들이 듣고싶지 않아하거나 뒤에서 욕할만할 일들은 필터링하고 솔직해야 하는것이다.&#xA;근데 내입장에서만 쓰니까 괴랄한것처럼 느껴지는데 남들입장에서 쓰자면 그냥 &amp;lsquo;일원으로서 잘 지내는것&amp;rsquo;을 바라는것뿐이다. 이게 숨쉬듯이 안되는 사람은 하나하나 통제해야하는데, 처음에는 통제후 사람들이 살가워지고 반응이 바뀌는걸 보는게 즐거워서, 이런저런 방식으로 내보일 모습을 바꿔보고 &amp;lsquo;이정도는 괜찮다!&amp;rsquo; &amp;lsquo;이런건 싫어하구나!&amp;lsquo;하고 나만의 커스텀을 거치는 것에 열심히 임했다. 나중에 회사가거나 다른 집단에 속할때두 훈련돼있으면 크게 힘안들이고 살수있을거같아서 충분히 공들일 가치가 있는것 같아서 더 열심히 했던거같다.</description>
    </item>
    <item>
      <title>하찮은감정</title>
      <link>http://localhost:1313/docs/hobby/daily/daily5/</link>
      <pubDate>Tue, 15 Apr 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/daily/daily5/</guid>
      <description>하찮은감정 # #2025-04-15&#xA;취준시작하고 첫분기는 혼란그자체였다. 잡코리아에 생물정보학 쳐서 나오는곳 아무데나 내고 가면 되는줄알았는데 대기업들은 훨씬 덜 세부적인(?) 직무를 뽑고있었고 분야별 큰그림을 봣을땐 내가 햇던 연구가 어디에도 속하지 않는 느낌을 받았다. 보다보니까 내가 뭘 한건지도 잘 모르겠었다 바이오 공정기술도 내고 반도체 양산관리도 내고 AI도 내고 사업개발도 내고 dx 직무도 냈는데 전부 서탈했다. 공기업은 건축 토목이 메인같기도 하고 공기업/사기업 둘중에 하나 고정해서 하는게 좋다고 하길래 일치감치 포기했다.&#xA;1월 중순부터 3월 중순까지 두달정도 미친듯이 취준생각만 했는데, 마냥 달리다보니까 방향성도 못잡겠고 낼곳도 하나도없는것같고 관심없는 기업에대해서 관심을 글로 적고 미래를 생각하는게 너무 어려워서 초단기 번아웃으로 몸도 마음도 드러누워버렸다.</description>
    </item>
    <item>
      <title>Hugo #4 블로그 scss 커스텀하기 (visited 링크 글자색 수정)</title>
      <link>http://localhost:1313/docs/study/fe/fe6/</link>
      <pubDate>Sun, 13 Apr 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/fe/fe6/</guid>
      <description>Hugo #4 Hugo 블로그 scss 커스텀하기 (visited 링크 글자색 수정) # 기존 화면에서 방문하지않은 하이퍼링크는 파란색, 방문한 링크는 보라색으로 표시됐는데, 뭔가 링크를 누르는 느낌보다는 글을 누르는 느낌이 났으면 좋겠어서 + 근데 링크인건 인지돼야해서 적절한 색깔로 바꿔주고 싶었다.&#xA;Hugo Book Theme 깃히브를 확인해보면 assets 디렉토리에 _variables.scss 파일을 생성해주면 되는듯해서 아래와 같이 넣어줬다.&#xA;// Themes @mixin theme-light { --gray-100: #f8f9fa; --gray-200: #e9ecef; --gray-500: #adb5bd; --color-link: #0f5294;//#2619c1;//#0055bb; --color-visited-link: #0f5294;//#2619c1;//#0055bb;//#8440f1; --body-background: white; --body-font-color: black; --icon-filter: none; --hint-color-info: #6bf; --hint-color-warning: #fd6; --hint-color-danger: #f66; } 여러 색깔을 시도한 흔적.</description>
    </item>
    <item>
      <title>사실내가 하고싶은것</title>
      <link>http://localhost:1313/docs/hobby/daily/daily4/</link>
      <pubDate>Sun, 13 Apr 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/daily/daily4/</guid>
      <description>사실내가 하고싶은것 # #2025-04-13&#xA;컴학에서 3년동안 인턴+석사를 하면서 즐겁고 몰입되고 재밌는 순간도 꽤 많았는데 진로를 정하자니까 고민된다.&#xA;공부 나는 공부를 좋아함 나보다 공부를 좋아하거나 공부를 잘하는 사람은 대학원에 많음 좋아하는것 읽고 이해하는거 영화보거나 책보거나 영상보고 생각정리하는거 일기쓰기 쇼핑하기 좋아하는 사람들이랑 이야기하기 맛있는거 먹으러가기 했을때 즐거웠던것 카페알바 했을때 연구 (방법론을 찾고 수행해서 결과물 내기) 베이킹 남들 눈 신경쓰지 않고 이기적인 선택을 하자면, 내가 하고싶은일은 프랜차이즈 카페에서 알바하고 여가시간에는 책읽고 영화보고 좋아하는사람 만나고, 트레이딩 알고리즘 공부하면서 재태크도 하고.</description>
    </item>
    <item>
      <title>카페 오퐁드부아 이터리</title>
      <link>http://localhost:1313/docs/hobby/daily/daily3/</link>
      <pubDate>Sat, 12 Apr 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/daily/daily3/</guid>
      <description>카페 오퐁드부아 이터리 # #2025-04-12&#xA;오퐁드부아 카페는 2번인가 가봤었는데 이터리는 처음이었다!&#xA;내부는 테이블이 크고 간격이 넓어서 좁은느낌은 아니었지만 그래두 카페가 더 초록초록(?)하고 넓고 이쁜거같긴하다&#xA;감자베이컨스프와 빵 / 사워도우와 3가지버터 / 구운로메인샐러드 시켰는데 셋다 엄청 맛있었다..♥&#xA;버터는 트러플/레몬딜/다시마인데 레몬딜이 젤 좋았고 커피는 산미없는데 쓴맛도없는 다크원두여서 딱 좋아하는 맛이었다.&#xA;추가로 치아바타와 올리브오일브레드딥도 시켰는데 요녀석이 찐이었음 식빵을 강화한맛!!&#xA;담에 오면 1. 치아바타와 올리브오일브레드딥 2. 구운로메인샐러드 일케 두개 먹을듯.&#xA;근데사실 카페가 빵종류 더 많고 넓고 이뻐서 카페를 갈거같긴하다.</description>
    </item>
    <item>
      <title>가혹한 현실과 확고한 믿음</title>
      <link>http://localhost:1313/docs/hobby/book/book16/</link>
      <pubDate>Thu, 10 Apr 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/book/book16/</guid>
      <description>가혹한 현실과 확고한 믿음 # #2025-04-10&#xA;#1&#xA;&amp;ldquo;크리스마스에는 집에 돌아갈 거야&amp;quot;라고 입버릇처럼 말하는 사람은,&#xA;크리스마스가 왔다 지나가면 정신적으로 완전히 무너지곤 했다. 스톡데일의 말에 따르면 &amp;ldquo;그들은 죽을 만큼 괴로워했다&amp;quot;고 한다.&#xA;스톡데일은 상황이 나아지고 성공할 것이라는 확고한 믿음을 지니는 동시에 가혹한 현실을 받아들여아 한다고 말했다. &amp;lsquo;결국 상황은 나아질 것이다. 그러나 우리는 크리스마스 때까지 나가지는 못할 것이다.&amp;rsquo;&#xA;#2&#xA;심리학자 로런 앨로이와 린 이본 에이브럼슨은 &amp;lsquo;우울한 현실주의&amp;rsquo;라는 인상적인 개념을 소개했다.&#xA;이는 우울한 사람이 삶이 얼마나 위험하고 위태로운지에 관해 더 현실적인 감각을 지니기 때문에 세상을 더 정확하게 바라본다는 것을 의미한다.</description>
    </item>
    <item>
      <title>너무많은일</title>
      <link>http://localhost:1313/docs/hobby/daily/daily2/</link>
      <pubDate>Thu, 10 Apr 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/daily/daily2/</guid>
      <description>너무많은일 # #2025-04-10&#xA;사람때문에 힘들어진일을 사람한테 치유받고 정신차려서 일상에다시 올라탄 다음에 책을 읽어서 완전한 치유를 받고 +1 성장하고 다음 사이클로 들어가기&#xA;를 마냥 반복중인데 .. 매번 조금씩 베리에이션이 있기때문에 기록은 항상 하는게 좋은거같음</description>
    </item>
    <item>
      <title>Github #2 Ubuntu 20.04 brownout 오류</title>
      <link>http://localhost:1313/docs/study/be/be50/</link>
      <pubDate>Wed, 09 Apr 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be50/</guid>
      <description> Github #2 Ubuntu 20.04 brownout 오류 # #2025-04-09&#xA;블로그 수정하는데 갑자기 처음보는 오류가 발생,,&#xA;찾아보니 ubuntu-20.04 GitHub Actions runner가 2025년 4월 15일에 지원 종료함에 따라 workflow에서 runs-on: ubuntu-20.04를 사용중이라면 runs-on: ubuntu-22.04로 수정하라는 내용이었다.&#xA;jobs: deploy: runs-on: ubuntu-22.04 gh-pages.yml에 들어가서 runs-on: ubuntu-20.04를 runs-on: ubuntu-22.04로 바꿔주니까 다시 돌아간다!&#xA;# </description>
    </item>
    <item>
      <title>취약성</title>
      <link>http://localhost:1313/docs/hobby/book/book20/</link>
      <pubDate>Sat, 29 Mar 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/book/book20/</guid>
      <description>취약성 # #2025-03-29&#xA;#1&#xA;&amp;ldquo;기분이 최고로 좋았을 때를 10이라고 하면, 지금 기분은 1에서 10 중 몇 정도인가요?&amp;rdquo; 그녀는 조용히 내 답을 기다렸다.&#xA;&amp;ldquo;6에서 7 정도요.&amp;rdquo;&#xA;정말 답하기 어려운 질문이다. 나는 환자들에게 생각하지 말고 직감적으로 답하라고 요구한다. 하지만 &amp;lsquo;7&amp;rsquo;이란 건 내 솔직한 느낌이었을까, 아니면 일반 환자 대신 상담 시간을 차지한 내 행동을 합리화하려는 의도였을까?&#xA;난 내 우울증의 원인을 오랫동안 탐구했다. 어떤 힘든 일이 닥치면 며칠도 안 되어 극심한 절망에 빠지는 이유가 뭘까.</description>
    </item>
    <item>
      <title>카페 오딘</title>
      <link>http://localhost:1313/docs/hobby/daily/daily12/</link>
      <pubDate>Sat, 29 Mar 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/daily/daily12/</guid>
      <description>카페 오딘 # #2025-03-29&#xA;바다뷰가 넘 예뻤던 카페&#xA;저 크림들어간 크로와상이 완전 짱맛..! 샐러드두 맛있었당&#xA;바깥뷰도 이뻐서 나가서 걸어주기에좋다&#xA;이날 기분이별로였어서 아쉽다 담에가면 더마싯게먹고 잘구경하고다닐텐데!!!! 아쉬움이남아서 다시가고싶다 ㅎ</description>
    </item>
    <item>
      <title>수용</title>
      <link>http://localhost:1313/docs/hobby/book/book19/</link>
      <pubDate>Thu, 20 Mar 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/book/book19/</guid>
      <description>수용 # #2025-03-20&#xA;#1&#xA;지금까지 의사로 일하면서, 인생 계획을 완벽하게 할 수 있다고 생각하는 사람들을 많이 보았다. 그런 사람은 자녀들 인생까지도 그런 식으로 계획하려고 한다. 그리 생각하는 게 무리가 아닐지도 모른다. 살면서 정말 나쁜 일을 당해본 적이 한 번도 없고 모든 일이 기대한 대로 풀린 사람이라면 그럴 수 있다. 그러다가 상실을 경험하게 되면 그것이 본인의 자아정체감이나 인생의 이정표와 관련이 클수록 받아들이기가 더 힘들어진다. 나는 시험에 떨어지면서 계획이 일시적으로 틀어졌다. 주도면밀하게 그려놓았던 인생 계획이 어그러졌다.</description>
    </item>
    <item>
      <title>예측</title>
      <link>http://localhost:1313/docs/hobby/book/book22/</link>
      <pubDate>Fri, 21 Feb 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/book/book22/</guid>
      <description>예측 # #2025-02-21&#xA;#1&#xA;시간과 공간은 고정된 것도 아니고, 무한한 것도 아니며, 서로 독립적인 것도 아니다. 우주를 이해하려면 이들을 합쳐서 4차원, 즉 공간을 나타내는 세 축과 시간을 나타내는 한 축으로 시각화해야 한다.&#xA;호킹 박사는 &amp;lsquo;시공(spacetime)&amp;rsquo; 이라는 개념을 시각화할 때 광원뿔(light cone) 이미지를 활용해 과거와 미래의 사건이 어떻게 연결되는지 보여주었다. 빛은 발산될 때 연못의 물결처럼 퍼져나가면서 원뿔 형태를 형성한다. 빛의 속도보다 빠른 것은 없으므로 (과거에) 기여하거나 (미래에서) 시작된 현재 순간의 모든 사건은 이 원뿔 안에서 빛의 속도나 그보다 느린 속도로 일어나야만 한다.</description>
    </item>
    <item>
      <title>상자와 지도</title>
      <link>http://localhost:1313/docs/hobby/book/book21/</link>
      <pubDate>Tue, 18 Feb 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/book/book21/</guid>
      <description>상자와 지도 # #2025-02-18&#xA;#1&#xA;더 나은 의사 결정을 하기 위해, 정보에 접근하고 해석하는 방식을 더 체계화할 필요는 없다. 머신러닝이 우리를 그런 방향으로 이끌 것이라고 예상하게 되지만 사실 그 반대다. 알고리즘은 복잡성과 무작위성 속에서 역할을 수행하며, 환경의 변화에 효율적으로 반응하는 능력이 탁월하다. 단순한 패턴을 추구하는 경향은 아이러니하게도 인간의 사고방식에서 나타난다.&#xA;기계는 복잡한 현실을 전체적인 데이터 집합의 또 다른 일부로 여겨 단순하게 접근하는 데 반해, 정작 그로부터 도피하는 것은 우리 인간이다.</description>
    </item>
    <item>
      <title>혼돈과 관점</title>
      <link>http://localhost:1313/docs/hobby/book/book29/</link>
      <pubDate>Thu, 30 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/book/book29/</guid>
      <description>혼돈과 관점 # #2025-01-30&#xA;#1&#xA;나는 그에게 통쾌하게 반박해줄 말이 있었으면 싶었다. 우리는 중요하다고, 우리는 사실 아주 중요하다고 말해줄 방법. 그러나 주먹이 올라가는 게 느껴지자마자 내 뇌가 주먹을 다시 잡아당겼다. 왜냐하면 당연히, 우리는 중요하지 않기 때문이다. 이것이 우주의 냉엄한 진실이다. 정말 이상한 일이지만, 이 진실을 무시하는 것은 정확히 데이비드 스타 조던과 똑같이 행동하는 것이다.&#xA;#2&#xA;천천히 그것이 초점 속으로 들어왔다. 서로서로 가라앉지 않도록 띄워주는 이 사람들의 작은 그물망이, 이 모든 작은 주고받음-다정하게 흔들어주는 손, 연필로 그린 스케치, 나일론 실에 꿴 플라스틱 구슬들-이 밖에서 보는 사람들에게는 그리 대단치 않은 것일지도 모른다.</description>
    </item>
    <item>
      <title>운명의 형태</title>
      <link>http://localhost:1313/docs/hobby/book/book27/</link>
      <pubDate>Tue, 28 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/book/book27/</guid>
      <description>운명의 형태 # #2025-01-28&#xA;#1&#xA;“넌 중요하지 않아”라는 말은 아버지의 모든 걸음, 베어 무는 모든 것에 연료를 공급하는 것 같았다. “그러니 너 좋은 대로 살아.” 아버지는 수년 동안 오토바이를 몰고, 엄청난 양의 맥주를 마시고, 물에 들어가는 게 가능할 때마다 큰 배로 풍덩 수면을 치며 물속으로 뛰어들었다. 아버지는 언제나 게걸스러운 자신의 쾌락주의에 한계를 설정하는 자기만의 도덕률을 세우고 또 지키고자 자신에게 단 하나의 거짓말만을 허용했다. 그 도덕률은 “다른 사람들도 중요하지 않기는 매한가지지만, 그들에게는 그들이 중요한 것처럼 행동하며 살아가라”는 것이었다.</description>
    </item>
    <item>
      <title>대학원생 면접대비캠프</title>
      <link>http://localhost:1313/docs/study/career/career0/</link>
      <pubDate>Wed, 01 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/career/career0/</guid>
      <description>대학원생 면접대비캠프 # #2025-01-01&#xA;대학원생 대상으로 면접대비 강의가 있길래 신청해봤다!&#xA;화수목은 5시부터 9시이구 금요일은 1시부터 6시반이라서 금요일은 일찍 퇴근할수있으면 퇴근하고 듣는게 좋을듯. 토요일은 10시부터 오프라인으로 한다.&#xA;이번주 랩미팅이 목요일 2시에 있고 논문 미팅은 금요일 아침 9시라서 크게 겹치지는 않아 매우 다행이다!!&#xA;cf)&#xA;원래 이런문자 다 무시하는데 ㅋㅋ 갑자기 눈에 들어와서 신청함..&#xA;1일차 - 면접 기초 # 1.9 오후 7시에 질문 받음. 1.10은 논문 기반 세미나 pt 면접 시뮬레이션. 목요일에 신청받는다.</description>
    </item>
    <item>
      <title>DE 분석 (DESeq2)</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi1/</link>
      <pubDate>Tue, 31 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi1/</guid>
      <description>DE 분석 (DESeq2) # #2024-12-31&#xA;Tool&#xA;Bioconductor - DESeq2 https://bioconductor.org/packages/release/bioc/html/DESeq2.html&#xA;# 1. Load package # suppressMessages({ library(&amp;#34;DESeq2&amp;#34;) library(pheatmap) library(withr) #library(tidyverse) library(RColorBrewer) library(gplots) library(dplyr) }) # 2. Set path # setwd(&amp;#34;/data-blog/bi1&amp;#34;) getwd() &amp;#39;/data-blog/bi1&amp;#39; # 3. Run DESeq2 # S1 &amp;lt;- &amp;#39;33&amp;#39; S2 &amp;lt;- &amp;#39;150&amp;#39; countdata &amp;lt;- read.csv(&amp;#34;results.csv&amp;#34;, header=TRUE, sep=&amp;#39;,&amp;#39;) colnames(countdata) &amp;lt;- c(&amp;#39;GeneID&amp;#39;,&amp;#39;150-1&amp;#39;,&amp;#39;150-2&amp;#39;,&amp;#39;150-3&amp;#39;,&amp;#39;33-1&amp;#39;,&amp;#39;33-2&amp;#39;,&amp;#39;33-3&amp;#39;,&amp;#39;con-1&amp;#39;,&amp;#39;con-2&amp;#39;,&amp;#39;con-3&amp;#39;) countdata &amp;lt;- countdata[, c(&amp;#39;GeneID&amp;#39;,&amp;#39;150-1&amp;#39;,&amp;#39;150-2&amp;#39;,&amp;#39;150-3&amp;#39;,&amp;#39;33-1&amp;#39;,&amp;#39;33-2&amp;#39;,&amp;#39;33-3&amp;#39;,&amp;#39;con-1&amp;#39;,&amp;#39;con-2&amp;#39;,&amp;#39;con-3&amp;#39;)] selected_columns &amp;lt;- paste(c(&amp;#39;GeneID&amp;#39;,paste0(S2,&amp;#34;-1&amp;#34;), paste0(S2,&amp;#34;-2&amp;#34;), paste0(S2,&amp;#34;-3&amp;#34;),paste0(S1,&amp;#34;-1&amp;#34;), paste0(S1,&amp;#34;-2&amp;#34;), paste0(S1,&amp;#34;-3&amp;#34;)), sep=&amp;#34;&amp;#34;) countdata &amp;lt;- countdata[, selected_columns] countdata &amp;lt;- countdata[rowSums(countdata[, -1]) !</description>
    </item>
    <item>
      <title>EndNote 사용법</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi16/</link>
      <pubDate>Tue, 31 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi16/</guid>
      <description>EndNote 사용법 # #2024-12-31&#xA;1. EndNote 설치 및 계정 설정 # 계정 설정: 공식 웹사이트에서 End note 계정을 생성한다.&#xA;설치: 나의 경우 여기에서 다운로드해줬다.&#xA;# 2. 레퍼런스 추가 방법 # Google Scholar에 논문 제목을 검색해서 인용&amp;gt;EndNote를 클릭하면 .enw 파일이 다운로드된다. # 3. 레퍼런스 관리 # Endnote에 접속한다. Collect&amp;gt;Import References로 들어간다 파일 선택&amp;gt;아까 저장한 .enw 파일을 선택해준다 Import Option&amp;gt;EndNote Import를 선택해준다 To&amp;gt;New Group을 하면 논문 주제별로 그룹을 생성하여 정리 가능. 생성한 그룹이 이미 있으면 원하는 그룹 선택해준다.</description>
    </item>
    <item>
      <title>Github #1 There was an error committing your changes: File could not be edited 오류</title>
      <link>http://localhost:1313/docs/study/be/be49/</link>
      <pubDate>Tue, 31 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be49/</guid>
      <description> Github #1 There was an error committing your changes: File could not be edited 오류 # #2024-12-31&#xA;갑자기 모든 파일의 수정이 안되고 page deployment도 오류가 났다. 브라우저 캐시 문제인가 해서 방문기록이랑 캐시를 모두 삭제해보았다. 그래도 오류가 났다. 구글링하니까 내 경우랑 맞아떨어지는 한국인 블로그글이 있어서 시키는대로 https://www.githubstatus.com/에 들어가봤다. 블로그 글이랑 같은 창이 떴는데 그냥 기다려야된다길래 그냥 기다림. 2시간 뒤에 들어가니까 이 창으로 바뀌었다. 그리고 된다. 또 블로그 부셔진줄&amp;hellip; 다행이다&amp;hellip;.&#xA;# </description>
    </item>
    <item>
      <title>Hugo #1 사이트 생성, 깃허브 배포</title>
      <link>http://localhost:1313/docs/study/fe/fe4/</link>
      <pubDate>Tue, 31 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/fe/fe4/</guid>
      <description>Hugo #1 사이트 생성, 깃허브 배포 # #2024-12-31&#xA;1. Hugo 설치 # $ brew install hugo $ hugo version hugo v0.131.0+extended darwin/arm64 BuildDate=2024-08-02T09:03:48Z VendorInfo=brew Hugo v0.112.0 이상인지 확인하면 된다.&#xA;2. Hugo 사이트 생성 # 작업하고 싶은 위치에 Hugo 디렉토리를 만들어준다.&#xA;$ mkdir Hugo $ cd Hugo Hugo로 들어가서 hugo 사이트 틀을 생성해준다. 나는 blog라는 이름으로 생성하였다.&#xA;$ pwd /Users/yshmbid/Hugo $ hugo new site blog blog 디렉토리에 빈 Git 저장소를 초기화한다.</description>
    </item>
    <item>
      <title>Hugo #2 Favicon 변경, Giscus 댓글창 추가</title>
      <link>http://localhost:1313/docs/study/fe/fe5/</link>
      <pubDate>Tue, 31 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/fe/fe5/</guid>
      <description>Hugo #2 Favicon 변경, Giscus 댓글창 추가 # #2024-12-31&#xA;1. Favicon 변경 # Hugo-book 테마의 github에서 README 파일을 읽어보면, logo와 favicon 이미지의 경로 정보를 찾을 수 있다.&#xA;(logo 정보) (favicon 정보) 확인 결과 static 디렉토리에 각각 logo.png, favicon.png로 저장해두면 반영되는것 같다.&#xA;참고로 Hugo-book 테마의 오리지널 웹사이트는 아래와 같이 디자인되어있고&#xA;최상단 탭에 들어가는 이미지가 logo.png, 블로그 이름 옆에 들어가는 이미지가 favicon.png이다.&#xA;먼저 static 디렉토리에 넣고 싶은 로고와 파비콘을 logo.png, favicon.png 로 저장해준다.</description>
    </item>
    <item>
      <title>RNA-seq 전처리: EBV genome</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi11/</link>
      <pubDate>Tue, 31 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi11/</guid>
      <description>RNA-seq 전처리: EBV genome # #2024-12-31&#xA;0 # 분석 목적&#xA;제공받은 fastq를 human genome에 매핑해서 전처리, 분석 후 DE 결과 보냄 DE 분석시에 EBV 유전자도 포함해달라는 요청 해야하는것&#xA;fastq를 EBV genome에 매핑해서 전처리, EBV count 생성 human count에 EBV count를 붙이기 통합 count로 DE 분석 재수행 # 1. Alignment # Load package, Set Path&#xA;library(edgeR) library(Rsubread) library(org.Hs.eg.db) setwd(&amp;#34;/data/home/ysh980101/2311/RNA-seq_ebv/Rsubread&amp;#34;) getwd() &amp;#39;/data1/home/ysh980101/2311/RNA-seq_ebv/Rsubread&amp;#39; Build Index&#xA;# build index ref &amp;lt;- &amp;#34;/data3/PUBLIC_DATA/ref_genomes/Human_gammaherpesvirus_4_EBV/NC_007605.1.fa&amp;#34; output_basename &amp;lt;- &amp;#34;NC_007605.</description>
    </item>
    <item>
      <title>공동창업자의 자격</title>
      <link>http://localhost:1313/docs/hobby/book/book36/</link>
      <pubDate>Tue, 31 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/book/book36/</guid>
      <description>공동창업자의 자격 # #2024-12-31&#xA;#1&#xA;2002년 1월의 어느 일요일, 창고를 빌려 그 아마추어 엔진의 제작에 열중하던 중 가비가 뮬러에게 일론 머스크라는 인터넷 백만장자가 그를 만나고 싶어 한다고 말했다.&#xA;머스크가 저스틴과 함께 도착했을 때, 뮬러는 줄에 매단 80파운드짜리 엔진을 어깨로 떠받친 채 프레임에 고정하기 위해 볼트를 조이고 있었다. 머스크는 다짜고짜 그에게 질문을 퍼붓기 시작했다. &amp;ldquo;그게 추력은 얼마나 되나요?&amp;rdquo; 뮬러는 1만 3,000파운드라고 답했다. &amp;ldquo;더 큰 것도 만들어본 적이 있나요?&amp;rdquo; 뮬러는 얼마 전부터 TRW에서 65만 파운드의 추력을 가진 TR-106의 제작에 참여하고 있다고 설명했다.</description>
    </item>
    <item>
      <title>공부를 안해서 오는 스트레스는 사실 공부를 해야 없어진다.</title>
      <link>http://localhost:1313/docs/hobby/book/book24/</link>
      <pubDate>Tue, 31 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/book/book24/</guid>
      <description>공부를 안해서 오는 스트레스는 사실 공부를 해야 없어진다. # #2024-12-31&#xA;#1&#xA;카드 다섯 장을 쥐고 하는 포커판에서 나올 수 있는 카드패에는 2,598,960개 종류가 있다고 한다. 즉, 최고의 카드패를 쥘 사람은 약 260만명 중의 한 명이다. 하지만 포커에서 그런 카드패를 갖고 있지 않아도 당신은 이길 수 있다. 그저 포커 게임에 참석한 사람들보다 조금 더 좋은 패를 갖고 있으면 된다. 그러므로 최고의 카드를 받은 잘난 사람들은 무시해라. 그들의 포커판에는 비슷한 사람들이 몰려 있다.</description>
    </item>
    <item>
      <title>그릿을 획득하기 vs 진실로의 창을 열어놓기.</title>
      <link>http://localhost:1313/docs/hobby/book/book28/</link>
      <pubDate>Tue, 31 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/book/book28/</guid>
      <description>그릿을 획득하기 vs 진실로의 창을 열어놓기. # #2024-12-31&#xA;#1&#xA;나는 전문가들은 이 문제에 관해 뭐라고 이야기하는지 알아보기로 했다. 자기기만이 데이비드와 내 아버지가 경고한 것만큼 그렇게 위험한 것인가 하는 문제 말이다.&#xA;20세기에는 의학 전문가들이 일치된 의견을 내놓았다. 지그문트 프로이트, 에이브러햄 매슬로, 에릭 에릭슨 같은 영향력 있는 심리학자들은 자기기만을 정신적 결함이자 시각에 생긴 문제여서 치료로 교정해야 한다고 보았다. 반면 정확한 시각은 &amp;ldquo;정신의 건강을 보여주는 표지&amp;quot;라고 여겼다.&#xA;그러나 20세기가 기운차게 달려가는 동안, 임상심리학자들은 이상한 일들을 목격하기 시작했다.</description>
    </item>
    <item>
      <title>리스크 중독</title>
      <link>http://localhost:1313/docs/hobby/book/book34/</link>
      <pubDate>Tue, 31 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/book/book34/</guid>
      <description>리스크 중독 # #2024-12-31&#xA;#1&#xA;레브친은 머스크를 어떻게 이해하면 좋을지 고민이 됐다. 그의 팔씨름 제안은 진담이었을까? 바보 같은 유머와 게임 플레이로 간간이 중단되곤 하는 일련의 광적인 격렬함은 계산된 것일까, 아니면 그저 발광일 뿐인가? 레브친은 말한다. “그가 하는 모든 일에는 아이러니가 있어요. 그는 11까지 올라가지만 4 이하로는 내려가지 않는 아이러니 설정 상태에서 움직입니다.” 머스크의 힘 중 하나는 다른 사람들을 자신의 아이러니 서클로 끌어들여 자기들만 아는 농담을 공유할 수 있게 하는 것이다.</description>
    </item>
    <item>
      <title>밀고 당기는 협상</title>
      <link>http://localhost:1313/docs/hobby/book/book33/</link>
      <pubDate>Tue, 31 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/book/book33/</guid>
      <description>밀고 당기는 협상 # #2024-12-31&#xA;#1&#xA;신규 가입 고객의 이름을 모니터링하던 중, 머스크는 이름 하나에 시선이 머물렀다. 바로 피터 틸이었다.&#xA;그는 엑스닷컴과 같은 건물에 있다가 지금은 거리 아래쪽으로 사무실을 옮긴 컨피니티Confinity라는 회사의 창업자 중 한 명이었다. 틸과 그의 주요 공동창업자 맥스 레브친은 모두 머스크만큼이나 열정적이었지만, 비교적 절제된 태도를 견지하는 사람들이었다. 엑스닷컴과 마찬가지로 컨피니티도 개인 간 결제 서비스를 제공했는데, 컨피니티의 시스템은 페이팔PayPal이라고 불렸다.&#xA;2000년 초 인터넷 거품이 꺼질 조짐이 보이기 시작하던 무렵, 엑스닷컴과 페이팔은 신규 고객을 유치하기 위해 치열한 경쟁을 벌이고 있었다.</description>
    </item>
    <item>
      <title>우리가 빛의 속도로 갈 수 없다면</title>
      <link>http://localhost:1313/docs/hobby/book/book14/</link>
      <pubDate>Tue, 31 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/book/book14/</guid>
      <description>우리가 빛의 속도로 갈 수 없다면 # #2024-12-31&#xA;#순례자들은 왜 돌아오지 않는가&#xA;소피. 마지막으로 한 가지 말할 것이 남았어. 내가 처음으로 마을에 대해 의문을 품게 되었던 계기, 그 오두막 뒤에 있던 귀환자 말야. 정해진 성년식보다 조금 더 빨리 지구에 가기로 결심했을 때 나는 그 남자에게 몰래 찾아가 물었어. 혹시 지구에서 무슨 일이 있었던 거냐고.&#xA;그는 슬픈 진실을 말해주었지. 지구에서 그가 사랑했던 사람과 그의 쓸쓸한 죽음에 관해. 그가 남겼던, 행복해지라는 유언에 관해.</description>
    </item>
    <item>
      <title>인간의 사교적인 행동을 배우려는 다른 행성의 관찰자</title>
      <link>http://localhost:1313/docs/hobby/book/book31/</link>
      <pubDate>Tue, 31 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/book/book31/</guid>
      <description>인간의 사교적인 행동을 배우려는 다른 행성의 관찰자 # #2024-12-31&#xA;#1&#xA;그는 아버지처럼 공학에 끌렸기에 물리학을 전공하기로 결정했다. 그가 느낀 엔지니어의 본질은 어떤 문제든 물리학의 가장 근본적인 원리를 파고들어 해결책을 찾는 것이었다. 그는 또한 공동 학위 과정을 밟아 경영학도 전공하기로 했다. “경영학을 공부하지 않으면 경영학을 공부한 누군가의 밑에서 일하게 될까 봐 걱정이 되었지요.” 그는 말한다. “내 목표는 물리학의 감각으로 제품을 설계 및 제작하는 것, 그리고 경영학을 전공한 보스를 위해 일할 필요가 없게 되는 것이었어요.</description>
    </item>
    <item>
      <title>인적 네트워크</title>
      <link>http://localhost:1313/docs/hobby/book/book35/</link>
      <pubDate>Tue, 31 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/book/book35/</guid>
      <description>인적 네트워크 # #2024-12-31&#xA;#1&#xA;머스크는 러시아인들이 받아내려 했던 터무니없는 가격을 곱씹으면서, 제 1원리(First Principles-다른 경험적 데이터를 필요로 하지 않는 &amp;lsquo;자명한 진리&amp;rsquo;)에 입각한 사고를 동원해 그 상황에 대한 기본 물리학을 파고들었고 거기서부터 차근차근 쌓아 올려나갔다. 그리고 이를 통해 완제품이 기본 재료비보다 얼마나 더 비싼지 계산하는 &amp;lsquo;바보 지수idiot index&amp;rsquo;를 개발했다. 제품의 &amp;lsquo;바보 지수&amp;rsquo;가 높으면 보다 효율적인 제조기술을 고안하여 비용을 크게 줄일 수 있다는 것을 의미했다.&#xA;로켓은 &amp;lsquo;바보 지수&amp;rsquo;가 극도로 높았다. 머스크는 로켓에 들어가는 탄소섬유와 금속, 연료 및 기타 재료의 원가를 계산하기 시작했다.</description>
    </item>
    <item>
      <title>인터넷, 지속 가능한 에너지, 우주여행</title>
      <link>http://localhost:1313/docs/hobby/book/book32/</link>
      <pubDate>Tue, 31 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/book/book32/</guid>
      <description>인터넷, 지속 가능한 에너지, 우주여행 # #2024-12-31&#xA;#1&#xA;머스크는 여름이 끝날 무렵 스탠퍼드대학원에 진학하여 재료과학을 공부할 계획을 세웠다. 여전히 커패시터에 매료된 그는 그것으로 전기자동차에 전력을 공급할 수 있는 방법을 연구하고 싶었다. “첨단 칩 제조 장비를 활용하여 자동차의 주행거리를 늘리기에 충분한 에너지 밀도를 가진 고체 소자 울트라 커패시터를 만들어볼 생각이었어요.” 그는 말한다. 하지만 등록기간이 가까워지면서 걱정이 들기 시작했다. “스탠퍼드에서 몇 년을 보내고 박사학위까지 받았는데 그 커패시터가 실현 불가능한 것으로 밝혀지면 어떻게 해야 할 것인가, 하는 걱정이 들었어요.</description>
    </item>
    <item>
      <title>인테그리티</title>
      <link>http://localhost:1313/docs/hobby/book/book26/</link>
      <pubDate>Tue, 31 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/book/book26/</guid>
      <description>인테그리티 # #2024-12-31&#xA;1998년 워런 버핏은 플로리다대학교에서 MBA 학생들에게 사람을 고용할 때 살펴보는 3가지를 언급하였다. 지능이 좋은지(머리가 잘 돌아가는지, 똑똑한지, 어리바리하지는 않은지), 일을 선도적으로 열정을 갖고 이끌어 나갈 수 있는지(시키는 것만 하는지, 해야 할 것들을 알아서 챙기는지), 그리고 integrity가 있는지 살펴봐야 한다. 머리도 좋고 일을 주도적으로 이끌어 나갈 열정도 있으나 integrity가 없는 자는 회사를 망칠 사람이다. integrity가 없는 사람을 고용하면 직원들을 게으름뱅이, 멍청이로 만들려는 것이기 때문이다.&#xA;인테그리티란 자신이 옳다고 믿거나 생각하는 것을 말과 행동을 통해 일관성 있게 실천하는 것이다.</description>
    </item>
    <item>
      <title>좀비를 줄 세우는 방법</title>
      <link>http://localhost:1313/docs/hobby/book/book30/</link>
      <pubDate>Tue, 31 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/book/book30/</guid>
      <description>좀비를 줄 세우는 방법 # #2024-12-31&#xA;#1&#xA;일론 머스크가 물려받은 유산과 혈통은 그의 뇌 배선과 어우러져 때때로 그를 냉담하게도, 충동적이게도 만들었다. 그리고 그것은 또한 리스크에 대한 극도로 높은 수준의 내성으로 이어졌다. 그는 리스크를 냉정하게 계산할 수도 있었고, 열정적으로 수용할 수도 있었다. “일론은 리스크 그 자체를 원합니다.” 페이팔PayPal 초창기에 머스크의 파트너로 일했던 피터 틸은 말한다. “그는 리스크를 즐기는 듯합니다. 때로는 정말 리스크에 중독된 것처럼 보이기도 하고요.”&#xA;머스크는 태풍이 몰려올 때 가장 강력한 생기를 느끼는 그런 사람 중 한 명이다.</description>
    </item>
    <item>
      <title>진전의 가시화</title>
      <link>http://localhost:1313/docs/hobby/book/book18/</link>
      <pubDate>Tue, 31 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/book/book18/</guid>
      <description>진전의 가시화 # #2024-12-31&#xA;1 # Q. 우리가 시간 관리를 좀 더 잘하기 위해서는 무엇에 집중해야 할까요?&#xA;A. 저는 가장 중요한 요소가 ‘진전의 가시화’라고 생각합니다. 대개의 경우 일이 얼마나 진척됐는지 확인하기가 쉽지 않죠. 그런데 이메일 답장 같은 쉬운 일이라면, 1000통의 이메일에 답장한다고 해도 자신이 답장한 이메일을 한눈에 파악할 수 있습니다. 반면 어려운 문제를 처리할 때는 마치 30시간은 헛되이 보냈고 마지막 30분만 유용했던 것처럼 느껴집니다. 왜냐하면 마지막 30분 동안에 아이디어가 떠올랐기 때문이죠.</description>
    </item>
    <item>
      <title>크림치즈스콘</title>
      <link>http://localhost:1313/docs/hobby/daily/baking11/</link>
      <pubDate>Sat, 07 Sep 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/daily/baking11/</guid>
      <description>크림치즈스콘 # #2024-09-07&#xA;식탁일기 크림치즈스콘 레시피가 이뻐보여서 시작한 크림치즈스콘&#xA;비주얼 노릇노릇 넘 이쁘구 맛도 너무맛있다 ㅎㅎ&#xA;첫판에서 반죽이 좀 퍼진거같애서 냉장을 더시켜서 구워줬더니 미친비주얼이.. 너무 맛있게 생겨서 웃김 ㅋㅋㅋ&#xA;같은 판 아님 여기저기 선물한다고 엄청구웠다&#xA;굽기전엔 좀 애매한가? 싶어도&#xA;굽고나면 마싯는 비주얼이 된다.&#xA;선물용으로 엄청 구운 모습&#xA;아빠가 식빵구운거랑 같이 추석선물로 포장ㅎㅎㅋㅋ 며칠동안 집이 빵공장이었다.</description>
    </item>
    <item>
      <title>주말아침의 대파치즈스콘</title>
      <link>http://localhost:1313/docs/hobby/daily/baking10/</link>
      <pubDate>Sat, 24 Aug 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/daily/baking10/</guid>
      <description>주말아침의 대파치즈스콘 # #2024-08-24&#xA;여느 주말아침,, 고요비 유튜브 보다가 갑자기 삘받아서 대파치즈스콘 만들었다 ㅋㅋ 레시피는 자도르 콘치즈 스콘 레시피에서 콘 빼고 파 넣었음.&#xA;생각보다 너무너무 맛있게 나와서 행복 ㅎㅎㅎ 특히 아빠가 넘맛있다구 해줬당</description>
    </item>
    <item>
      <title>포카치아</title>
      <link>http://localhost:1313/docs/hobby/daily/baking8/</link>
      <pubDate>Thu, 15 Aug 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/daily/baking8/</guid>
      <description>포카치아 # #2024-08-15&#xA;발효빵 중에서도 수공이 꽤많이들어가는편인 포카치아..!! 발효도 16시간정도 엄청 오래 시켜야하구 발효중에도 한번씩 반죽접기 해줘야돼서 해볼까말까 고민했는데, 신경쓸게 많다고 생각하니까 오히려 도전욕구가 자극되었다. ㅎ&#xA;레시피는 자도르 포카치아 레시피에서 변형 없이 그대로 해줬다!&#xA;토마토 정갈하게 썰린게 예뻐서 찍음 ㅎㅎ&#xA;토마토랑 올리브오일 로즈마리로 데코하기. 굽기전인데 벌써 이쁘다&#xA;조금 남아서 시식용도 만듦 ㅋㅋ&#xA;결과물!! 이정도면 성공이라고본다 ㅎㅎㅎ&#xA;단면샷을 안찍어놨는데 구멍이 엄청많진않았지만 포카치아에서 중요한 쫄깃바삭 속성은 충분했구 엄청 맛있게 먹었다 ㅎㅎ</description>
    </item>
    <item>
      <title>황치즈 비스코티</title>
      <link>http://localhost:1313/docs/hobby/daily/baking9/</link>
      <pubDate>Thu, 15 Aug 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/daily/baking9/</guid>
      <description>황치즈 비스코티 # #2024-08-15&#xA;올드패션 황치즈 비스코티 레시피 보고 넘 예쁘고 맛있어보여서 만들어봤다 ㅎㅎ&#xA;벽돌아님&amp;hellip; 반죽임&#xA;간단해보였는데 얘도 은근 손이 많이간다. 벽돌상태로 1차 굽기 해준담에 쿠키두께되게 썰어서 펼쳐주고 2차굽기 -&amp;gt; 뒤집에서 3차굽기 해줘야함.&#xA;결과물 ㅎㅎ 생긴건 유튜브보단 투박한데 맛이 진짜 미쳤다. 파마산치즈가루가 신의 한수인듯.&#xA;유명한 베이킹 유튜브들이 많지만 이사람 레시피가 전체적으로 찐인듯거같다. 왜그렇게 느껴지나 생각해봤는데 ㅋㅋ 대부분 유튜브가 본인 기술력으로 쇼부보는데 이사람은 맛있을수밖에 없는 특정 재료를 넣어서 맛을 강화함. 그래서 나같은 초짜가 만들어도 웬만하면 마싯게 출력되는거같다.</description>
    </item>
    <item>
      <title>버터롤빵</title>
      <link>http://localhost:1313/docs/hobby/daily/baking6/</link>
      <pubDate>Thu, 08 Aug 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/daily/baking6/</guid>
      <description>버터롤빵 # #2024-08-08&#xA;구움과자 아니라 발효가 들어가는 빵은 처음 구워봤다!! (그래서 실패할까봐 엄청 조금 굽기..)&#xA;레시피는 식탁일기 버터롤빵 레시피대로 했다.&#xA;반죽성형 해줌&#xA;칼집내서 굽기. 근데 칼집 넘깊게내서 결은 엄청많은데 모양은 좀 깨진거같다 ㅋㅋ&#xA;그리구 무엇보다 촉촉한 느낌보다는 좀 딱딱한느낌이었는데 구운시간의 문제보다는 발효가 부족했던듯. 그래두 맛있게먹었다 ㅎㅎ</description>
    </item>
    <item>
      <title>레몬 쿠키</title>
      <link>http://localhost:1313/docs/hobby/daily/baking5/</link>
      <pubDate>Wed, 07 Aug 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/daily/baking5/</guid>
      <description>레몬 쿠키 # #2024-08-07&#xA;색다른 쿠키를 만들고싶어서 레몬 쿠키 도전!&#xA;요 레시피를 따라하긴했는데 내가 쓴 밀가루가 문제인지 정량대로 넣으니까 너무 묽어져서 ㅠㅠ 밀가루 훨씬더넣고 근데 연해져서 레몬제스트 넣고 슈가파우더 넣고&amp;hellip; 점도 산미 단맛 3개만 맞추자 하고 맘대로 커스텀해버려서 재현은 불가능한 쿠키가 됐다.&#xA;노릇노릇 기여운 결과물 ㅎㅎ 레몬쿠키는 요런 클래식한 쿠키커터가 잘 어울리는둣.&#xA;맛도 엄청맛있었다! 근데 다시 만들려면 레시피를 재창조해야대서 아쉽다 ㅠㅠ</description>
    </item>
    <item>
      <title>통밀쿠키 / 빼곰스튜디오 쿠키커터</title>
      <link>http://localhost:1313/docs/hobby/daily/baking4/</link>
      <pubDate>Sun, 04 Aug 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/daily/baking4/</guid>
      <description>통밀쿠키 / 빼곰스튜디오 쿠키커터 # #2024-08-04&#xA;빼곰스튜디오랑 치치공작소에서 쿠키커터를 엄청 쇼핑했는데 첫개시하기!!&#xA;레시피는 실패없는 자도르 통밀 쿠키 레시피대로 했다.&#xA;노릇노릇&#xA;굽고나니깐 약간 흐려져서 슬픔 ㅠㅠ&#xA;딸기펜으로 점찍어주니까 더 기여워졋당</description>
    </item>
    <item>
      <title>휘낭시에</title>
      <link>http://localhost:1313/docs/hobby/daily/baking3/</link>
      <pubDate>Sun, 04 Aug 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/daily/baking3/</guid>
      <description>휘낭시에 # #2024-08-04&#xA;조빵이 레시피대로 만든 휘낭시에!!&#xA;첫트라서 웬만하면 그대로 갈려고 했는데 ㅠ 인간적으로 버터랑 설탕이 너무많이들어가서 버터는 정량 / 설탕은 절반 넣었는데 그래도 단것같은 기분 ㅋㅋ ㅠㅠ&#xA;맛은 맛있었지만 휘낭시에의 빠쟉함은 설탕량에서 나오는게 일부 있는거같다. 건강한 맛 바라면 안대는 메뉴니깐 휘낭시에는 그냥 사먹는걸로&amp;hellip;ㅋ</description>
    </item>
    <item>
      <title>무품곰 (무화과 품은 곰) 쿠키</title>
      <link>http://localhost:1313/docs/hobby/daily/baking2/</link>
      <pubDate>Tue, 30 Jul 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/daily/baking2/</guid>
      <description>무품곰 (무화과 품은 곰) 쿠키 # #2024-07-30&#xA;보통 아품곰(아몬드 품은 쿠키) 만드는 쿠키틀이지만 아몬드가 없어서 무화과를 넣어보았다.&#xA;쿠키 레시피는 그냥 자도르 통밀 쿠키 레시피 배합대로 했는데 반죽 문제라기보다는 모양 흐트러질까봐 좀 두껍게 구웠더니 좀 덜 바삭한 쿠키가 댓다&#xA;그래두 모양이 귀여우니깐 ㅎㅎ 만족</description>
    </item>
    <item>
      <title>그래놀라</title>
      <link>http://localhost:1313/docs/hobby/daily/baking1/</link>
      <pubDate>Sat, 13 Jul 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/daily/baking1/</guid>
      <description>그래놀라 # #2024-07-13&#xA;집에 있는 재료 이것저것 넣고 구웠는데 생각보다 너무 맛있었던..!&#xA;재료는 오트밀/호두/아몬드/해바라기씨/크랜베리/꿀 넣었다&#xA;레시피는 자도르 유튜브 봤긴 한데 &amp;lsquo;노릇하게 굽고-&amp;gt;섞어주고-&amp;gt;다시 굽고 반복&amp;rsquo;이라는 개념만 가져가구 나머진 그냥 내 오븐에 맞춰서 했다.&#xA;요건 굽기 전 버전.&#xA;크랜베리 대신 건포도 버전. 근데 크랜베리 넣은게 훨 맛있다.</description>
    </item>
  </channel>
</rss>
