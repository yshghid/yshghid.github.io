<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>2025-08 on  </title>
    <link>http://localhost:1313/tags/2025-08/</link>
    <description>Recent content in 2025-08 on  </description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 04 Aug 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/2025-08/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Docker #3</title>
      <link>http://localhost:1313/docs/study/sw/sw16/</link>
      <pubDate>Mon, 04 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/sw/sw16/</guid>
      <description>Docker #3 # #2025-08-04&#xA;1. 레지스트리에 접속하고 이미지를 pull/push하기 # # Docker 로그인 $ docker login https://{실습링크}.com # ID: * # Password: * $ Login Succeeded # 이미지 Pull (이미지 내려받기): 예를 들어 container-linux:1.1 이미지를 다운로드 $ docker pull {실습링크}.com/{실습id}/container-linux:1.1 # 이미지 Push (Image Push 정보 사용): Push 권한은 일반 계정이 아니라 로봇 계정(CI/CD 용)을 사용합니다. # 로봇 계정 로그인 $ docker login https://{실습링크}.com # ID: robot$skala25a # Password: 1qB9cyusbNComZPHAdjNIFWinf52xaBJ # 태깅 (Tag local image) $ docker tag container-linux:1.</description>
    </item>
    <item>
      <title>결단</title>
      <link>http://localhost:1313/docs/hobby/book/book52/</link>
      <pubDate>Mon, 04 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/book/book52/</guid>
      <description>결단 # #2025-08-04&#xA;#1&#xA;머스크는 로켓이 산소가 희박한 높이로 충분히 솟아올라 불꽃이 꺼지길 바랐다. 그러나 로켓은 추락하기 시작했다. 비디오 피드에서 오멜렉이 가까이 다가오더니 더 이상 화면에 아무것도 비치지 않았다. 그리고 불타는 파편들이 바다로 떨어졌다. “위장이 뒤틀렸지요.” 머스크의 말이다. 1시간 후, 머스크는 뮬러, 쾨니스만, 부자, 톰슨 등 수석 팀원들과 함께 잔해를 둘러보기 위해 육군 헬리콥터에 올랐다.&#xA;그날 밤 모두가 콰즈의 야외 바에 모여 조용히 맥주를 마셨다. 몇몇 엔지니어는 눈물을 흘렸다. 머스크는 돌처럼 굳은 얼굴과 먼 곳을 응시하는 눈빛으로 조용히 생각에 잠겼다.</description>
    </item>
    <item>
      <title>EBVaGC DHT 연구 #1 method contribution 정리</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi32/</link>
      <pubDate>Sun, 03 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi32/</guid>
      <description>EBVaGC DHT 연구 #1 method contribution 정리 # #2025-08-03&#xA;0. 제목 # Dihydrotestosterone-androgen receptor signaling suppresses EBV-positive gastric cancer through DNA demethylation-mediated viral reactivation&#xA;1. 참여 파트 # Materials and Methods └── 2. *RNA-seq analysis └── 13. *Whole genome bisulfite sequencing (WGBS) └── 14. *Bioinformatics analysis of methylome 2. RNA-seq analysis # RNA-seq analysis was performed on SNU719 cells treated with 100 nM DHT for 24 h, with EtOH-treated cells as control.</description>
    </item>
    <item>
      <title>skala 강의자료공부 #1 DL-CNN, RNN</title>
      <link>http://localhost:1313/docs/study/ai/ai11/</link>
      <pubDate>Sun, 03 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai11/</guid>
      <description>skala 강의자료공부 #1 DL-CNN, RNN # #2025-08-03&#xA;#1 p.90-92&#xA;Convolution, 즉 합성곱은 CNN의 가장 핵심적인 연산이다. 말 그대로 &amp;lsquo;겹쳐서 곱하고 더하는&amp;rsquo; 방식이다. 이는 우리가 이미지를 처리할 때, 그 이미지의 일부분만을 보며 특징을 추출하는 원리와 매우 유사하다. CNN에서는 이 연산을 통해 이미지 속에서 선, 모서리, 윤곽선 같은 패턴을 뽑아낸다.&#xA;p.90에서는 합성곱을 아주 직관적으로 보여준다. 왼쪽에 있는 초록색 격자는 이미지이고, 그 위에 씌워진 주황색 네모는 필터(또는 커널)다. 이 필터는 보통 3x3 크기를 가지며, 그 내부에 있는 값들은 학습을 통해 결정된다.</description>
    </item>
    <item>
      <title>Docker #1 Python 실행 컨테이너 만들기</title>
      <link>http://localhost:1313/docs/study/sw/sw14/</link>
      <pubDate>Fri, 01 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/sw/sw14/</guid>
      <description>Docker #1 Python 실행 컨테이너 만들기 # #2025-08-01&#xA;0. RDE 런처 실행 # RDE #1 Local PC에서 RDE 환경 구성에서 Harbor registry로부터 RdE Container download를 수행했고 아이콘을 클릭해서 RDE 런처를 실행한다.&#xA;1. 웹 서비스 실행 컨테이너 만들기 # #1 /config/workspace/cloud/container/00.container-linux 경로로 이동&#xA;cd /config/workspace/cloud/container/00.container-linux #2 디렉토리 구조는?&#xA;00.container-linux/ ├── Dockerfile // 컨테이너 환경 설정 ├── Dockerfile.pytho-slim ├── Dockerfile.ubuntu ├── docker-build.sh ├── docker-push.sh ├── mycode.py ├── fastserver.py ├── webserver.py └── mydata/ #3 Dockerfile 내용 확인하기</description>
    </item>
    <item>
      <title>Docker #2 netmhcpan 작년 작업 복기</title>
      <link>http://localhost:1313/docs/study/sw/sw15/</link>
      <pubDate>Fri, 01 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/sw/sw15/</guid>
      <description>Docker #2 netmhcpan 작년 작업 복기 # #2025-08-01&#xA;1 # 2024.11.24 MutClust 작업중에 netmhcpan을 돌려야되는 상황이 왓었는데&#xA;netmhcpan이 유료였나 그래서 패키지 다운은 안되고.. 서버 뒤지다가 아래 README.txt 파일 발견해서 결과물 저장까진 했던 기억이있다.&#xA;이때먼가 의문이 들었던게 새로운 conda 환경에 접속한거같은 느낌이 아니라 완전 다른 제2의서버에 접속한 느낌이었는데 이상하게 연구실 디렉토리들은 그대로 접근이 가능해서 혼란스럽지만 그냥 절대경로 다 박고 수행했는데 결과들이 문제없이 저장됐다.&#xA;그래서 그뒤로 잊어버리고있었는데 docker 배우고나니까 먼가 이해돼서 이해된김에 정리해보기!</description>
    </item>
    <item>
      <title>MutClust 코드 리펙토링 #2 arg_parser</title>
      <link>http://localhost:1313/docs/study/algorithm/algo2/</link>
      <pubDate>Fri, 01 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/algorithm/algo2/</guid>
      <description>MutClust 코드 리펙토링 #2 arg_parser # #2025-08-01&#xA;MutClust 알고리즘의 코드 구성은 아래와 같은데&#xA;MutClust ├── sc/ │ └── lib.py │ └── arg_parser.py // 실행 설정 │ └── utils.py └── Test arg_parser.py는 실험 환경 파라미터 세팅 및 CLI 인자 파싱을 포함한다.&#xA;# === arg_parser.py === import argparse from os.path import exists from src.mlib import ( DIMINISHING_FACTOR, EPSILON, EPSILON_SCALING_FACTOR, MAX_EPS, MIN_CLUSTER_LENGTH, CCM_MIN_PERCENTAGE_SUM ) class ArgsInfo: def __init__(self): self.args = {} self.fin = &amp;#39;&amp;#39; self.</description>
    </item>
    <item>
      <title>MutClust 코드 리펙토링 #3 utils</title>
      <link>http://localhost:1313/docs/study/algorithm/algo9/</link>
      <pubDate>Fri, 01 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/algorithm/algo9/</guid>
      <description>MutClust 코드 리펙토링 #3 utils # #2025-08-01&#xA;MutClust 알고리즘의 코드 구성은 아래와 같은데&#xA;MutClust ├── sc/ │ └── lib.py │ └── arg_parser.py │ └── utils.py // 전처리 및 분석 └── Test utils.py는 데이터 전처리 및 분석 함수를 포함한다.&#xA;# === Fasta 전처리 === def fasta2csv(home_dir, nation_dir, filechunk, ref, outdir): for file in filechunk: path = os.path.join(home_dir, nation_dir, file) filename = os.path.splitext(os.path.basename(file))[0] outpath = os.path.join(outdir, f&amp;#34;{filename}.csv&amp;#34;) if not os.path.exists(outpath): df = DataFrame({&amp;#39;ref&amp;#39;: ref.</description>
    </item>
  </channel>
</rss>
