<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>2025-08 on  </title>
    <link>http://localhost:1313/tags/2025-08/</link>
    <description>Recent content in 2025-08 on  </description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 31 Aug 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/2025-08/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>POINT of VIEW 포인트오브뷰 서울</title>
      <link>http://localhost:1313/docs/hobby/daily/daily19/</link>
      <pubDate>Sun, 31 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/daily/daily19/</guid>
      <description>POINT of VIEW 포인트오브뷰 서울 # #2025-08-31&#xA;사람 많은것만 빼면 다 좋은 곳 ㅎㅎ 몇번 가봤는데 갈때마다 점점 맘에 든당&#xA;# 그러고 그냥 서울 소품샵 방앗간이 되겠다~ 생각하고 말았었는데&#xA;찾고싶은 물건이 있어서 홈페이지를어쩌다가 들어갔는데 너무너무 내취향이어서 충격받았다.&#xA;여기를 대하는 마음가짐이 홈페이지를 보기 전이랑 후가 완전히 달라져서, 주중 오전쯤 사람 별로 없을때 가면 진짜 행복한 시간을 보낼수있을것같아서 벌써 설렌다 ㅎㅎ&#xA;물건이 너무 많아서 다보진 못했구 TOOLS 들어가서 한 22페이지까지만 봤다.</description>
    </item>
    <item>
      <title>DBMS 및 SQL 활용 #3 집계함수, 고급 객체기능, 고급 인덱스</title>
      <link>http://localhost:1313/docs/study/be/be37/</link>
      <pubDate>Thu, 28 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be37/</guid>
      <description>DBMS 및 SQL 활용 #3 집계함수, 고급 객체기능, 고급 인덱스 # #2025-08-28&#xA;1. GROUPBY # GROUP BY&#xA;테이블 안에 있는 데이터를 특정 기준으로 묶어서 요약.&#xA;테이블 embedding_store에서&#xA;id, user_id, cluster_id, similarity, tag 5개 컬럼이 있는데 있는 그대로보면 큰 그림을 보기 힘들다 즉 해석이 어렵다. GROUP BY를 쓰면 요약 정보를 만들수있는데 user_id로 묶으면 “사용자 A는 총 10건, 사용자 B는 총 5건” 같은 식으로 정리 / cluster_id로 묶으면 “클러스터 1은 평균 유사도가 0.</description>
    </item>
    <item>
      <title>DBMS 및 SQL 활용 #4 pgvector 기반 유사도 검색 &#43; FastAPI 연동</title>
      <link>http://localhost:1313/docs/study/be/be38/</link>
      <pubDate>Thu, 28 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be38/</guid>
      <description>DBMS 및 SQL 활용 #4 pgvector 기반 유사도 검색 + FastAPI 연동 # #2025-08-28&#xA;1. 실습 시나리오 # -- 1. 확장 설치 및 테이블 생성 -- 2. 예시 데이터 삽입 (10건만 임시) -- 3. 인덱스 생성 및 분석 -- 4. 성능 비교: LIMIT 5 vs LIMIT 50 -- 5. 인덱스 종류별 비교 (코사인 vs L2) -- 6. 사용자 입력 벡터를 Python에서 API로 전달하여 동적 쿼리 구성 예시 (FastAPI 측에서 처리) # 2.</description>
    </item>
    <item>
      <title>DBMS 및 SQL 활용 #1 설계안 데이터 적재 (postgresql, pgvector)</title>
      <link>http://localhost:1313/docs/study/be/be35/</link>
      <pubDate>Wed, 27 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be35/</guid>
      <description>DBMS 및 SQL 활용 #1 설계안 데이터 적재 (postgresql, pgvector) # #2025-08-27&#xA;1. 실습1 # 실습 시나리오&#xA;사용자가 설계안 텍스트(예: description)를 입력 해당 텍스트에 대해 Python에서 AI 임베딩을 수행 임베딩 결과가 유효할 경우 design 테이블에 등록 (COMMIT) 실패하면 아무 데이터도 등록하지 않음 (ROLLBACK) PostgreSQL + pgvector 확장 사용 Python에서 psycopg2 + 임베딩 처리 # 코드&#xA;#1 SQL&#xA;CREATE EXTENSION IF NOT EXISTS vector; CREATE TABLE IF NOT EXISTS design ( id SERIAL PRIMARY KEY, description TEXT, embedding VECTOR(1536) -- OpenAI 임베딩 차원 ); # #2 python</description>
    </item>
    <item>
      <title>DBMS 및 SQL 활용 #2 트랜젝션 격리수준, pgaudit, AI 시스템 운영</title>
      <link>http://localhost:1313/docs/study/be/be36/</link>
      <pubDate>Wed, 27 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be36/</guid>
      <description>DBMS 및 SQL 활용 #2 트랜젝션 격리수준, pgaudit, AI 시스템 운영 # #2025-08-27&#xA;1. 트랜젝션 격리수준 # 트랜젝션&#xA;데이터베이스에서 하나의 작업 단위. 여러 개의 쿼리나 연산이 묶여 하나로 실행되는데 그 결과는 전부 성공하거나 아니면 전부 실패해서 원래 상태로 되돌아가야 한다. 그렇지 않으면 데이터가 꼬인다. 문제는?&#xA;여러 사람이 동시에 같은 데이터베이스를 건드린다. 그래서 데이터가 뒤섞이지 않도록 격리 수준이라는 규칙을 둬야한다. 데이터가 뒤섞인다?&#xA;은행 계좌에서 A 트랜잭션이 “잔액 100만 원에서 10만 원 빼기” 작업을 하고 있고 동시에 B 트랜잭션이 “잔액 100만 원에서 20만 원 빼기” 작업을 한다고 하면 각각 따로 실행하면 당연히 최종 잔액은 70만 원이 되어야 한다.</description>
    </item>
    <item>
      <title>MLops #2 mlflow 파이프라인</title>
      <link>http://localhost:1313/docs/study/ai/ai25/</link>
      <pubDate>Fri, 22 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai25/</guid>
      <description>MLops #2 mlflow 파이프라인 # #2025-08-22&#xA;1. 코드 # #1 트래킹 서버 설정&#xA;import os import mlflow # 1. 로그를 저장할 서버/위치 지정 mlflow.set_tracking_uri(uri=os.getenv(&amp;#34;MLFLOW_TRACKING_URI&amp;#34;, &amp;#34;&amp;#34;)) # MLFLOW_TRACKING_URI로 MLflow 서버를 연결 current_uri = mlflow.get_tracking_uri() print(f&amp;#34;Current Tracking URI: {current_uri}&amp;#34;) # #2 Experiment 생성&#xA;# 2. Experiment 생성 experiment = mlflow.set_experiment(&amp;#34;new_experiment&amp;#34;) print(f&amp;#34;Experiment ID: {experiment.experiment_id}&amp;#34;) print(f&amp;#34;Experiment Name: {experiment.name}&amp;#34;) print(f&amp;#34;Artifact Location: {experiment.artifact_location}&amp;#34;) print(f&amp;#34;Lifecycle Stage: {experiment.lifecycle_stage}&amp;#34;) Experiment ID: 2 Experiment Name: new_experiment Artifact Location: /mlflow/mlruns/2 Lifecycle Stage: active # #3 information 확인, 로그 기록</description>
    </item>
    <item>
      <title>MLops #1 mlflow 설치 &amp; 실습</title>
      <link>http://localhost:1313/docs/study/ai/ai24/</link>
      <pubDate>Thu, 21 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai24/</guid>
      <description>MLops #1 mlflow 설치 &amp;amp; 실습 # #2025-08-21&#xA;1. mlflow 설치 및 docker 띄우기 # $ export CR_PAT=* # *: github token 블라인드 처리 $ echo $CR_PAT | docker login ghcr.io -u yshghid --password-stdin Login Succeeded 로그인햇으면 도커를 켠다음에 다음을 수행.&#xA;$ docker pull ghcr.io/mlflow/mlflow:v2.0.1 v2.0.1: Pulling from mlflow/mlflow 7a6db449b51b: Pull complete e238bceb2957: Pull complete ce77f44508b5: Pull complete 455a39ac3ab8: Pull complete f8c2fbfe5046: Pull complete 60e3c6e8536b: Pull complete Digest: sha256:1e1f28a6134e7e6c4b0d0a4f5f8647ff31c953ad53eb3bb5af4c51ae4e8dd14d Status: Downloaded newer image for ghcr.</description>
    </item>
    <item>
      <title>python #3 pgvector 유사 리뷰 검색</title>
      <link>http://localhost:1313/docs/study/be/be48/</link>
      <pubDate>Wed, 20 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be48/</guid>
      <description>python #3 pgvector 유사 리뷰 검색 # #2025-08-20&#xA;1. 목적 # 고객 리뷰 문장을 벡터로 임베딩하고 PostgreSQL의 pgvector 기능을 활용하여 비슷한 리뷰를 검색하는 기능을 구현&#xA;# 2. 코드 # import torch import transformers import sentence_transformers import sklearn import numpy import scipy print(f&amp;#34;torch: {torch.__version__}&amp;#34;) print(f&amp;#34;transformers: {transformers.__version__}&amp;#34;) print(f&amp;#34;sentence-transformers: {sentence_transformers.__version__}&amp;#34;) print(f&amp;#34;scikit-learn: {sklearn.__version__}&amp;#34;) print(f&amp;#34;numpy: {numpy.__version__}&amp;#34;) print(f&amp;#34;scipy: {scipy.__version__}&amp;#34;) from dotenv import load_dotenv import os load_dotenv() # 같은 폴더에 있는 .env 로드 torch: 2.2.2 transformers: 4.</description>
    </item>
    <item>
      <title>LLM #2 LLM과 AI 기술요소를 활용하여 비즈니스 서비스 기획안 작성</title>
      <link>http://localhost:1313/docs/study/be/be8/</link>
      <pubDate>Tue, 19 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be8/</guid>
      <description>LLM #2 LLM과 AI 기술요소를 활용하여 비즈니스 서비스 기획안 작성 # #2025-08-19&#xA;1. 목적 # 등기부등본/건축물대장 업로드 시 AI가 자동으로 문서를 분석하여 전세사기 위험 요소를 탐지하고 수치화한다. # 2. 모델 구성도 # #1 데이터 수집및 정규화&#xA;기술요소: PaddleOCR 선택 이유: 한국어 인식 정확도와 속도가 좋고, 오픈소스+온프레미스 운영 가능(비용·보안 유리), 표 레이아웃/좌표 추출 지원. 입력 파일: PDF/스캔 이미지(JPG/PNG) 매개변수: lang=&amp;ldquo;korean&amp;rdquo;, det+rec 사용, dpi(≥300) 출력 텍스트 블록: [{page, bbox, text}] 정규화 결과: 주소/금액/날짜/권리유형 표준화(JSON) #2 위험 특약/권리 분석</description>
    </item>
    <item>
      <title>데이터 분석 #4 리뷰 데이터 분석</title>
      <link>http://localhost:1313/docs/study/ai/ai22/</link>
      <pubDate>Tue, 19 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai22/</guid>
      <description>데이터 분석 #4 리뷰 데이터 분석 # #2025-08-19&#xA;1. 목적 # 리뷰 데이터를 보고&#xA;감성 점수와 평점의 관계 리뷰 길이와 감성 점수의 관계 카테고리별 감성 차이 Review_length가 AI 임베딩 유사도에 영향을 줄 수 있는지 인사이트 생성하기.&#xA;# 2. 코드 # import os import pandas as pd import numpy as np import seaborn as sns import matplotlib.pyplot as plt import matplotlib.pyplot as plt import matplotlib as mpl from sentence_transformers import SentenceTransformer, util # Mac 환경 한글 폰트 설정 plt.</description>
    </item>
    <item>
      <title>LLM #1 LLM 이해와 Transformer</title>
      <link>http://localhost:1313/docs/study/be/be7/</link>
      <pubDate>Mon, 18 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be7/</guid>
      <description>LLM #1 LLM 이해와 Transformer # #2025-08-11&#xA;1. LLM 기본이해 # #1 Word Embedding (p.27-28)&#xA;Word Embedding&#xA;핵심 아이디어는 단어가 어떤 맥락에서 자주 함께 등장하는지를 학습. “you say goodbye and I say hello”에서 ‘goodbye’주변에는 ‘you’, ‘say’, ‘and’, ‘I’ 같은 단어가 함께 등장하고 그 관계를 학습하도록 신경망을 훈련시킨다. 학습이 반복되면 각 단어는 벡터로 표현되고 의미가 비슷한 단어일수록 벡터 공간에서 가깝게 위치한다. Input이 ‘goodbye’이고 Target이 ‘you’, ‘say’, ‘and’, ‘I’여도 된다. Word Embedding - 신경망 구조 그림</description>
    </item>
    <item>
      <title>논문어셉..</title>
      <link>http://localhost:1313/docs/study/career/career7/</link>
      <pubDate>Sat, 16 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/career/career7/</guid>
      <description> 논문어셉.. # #2025-08-16&#xA;학위논문이랑 skala 병행하면서 신체/정신적 체력이슬슬 고갈되던중이었는데&#xA;여느날처럼 새벽에 깼는데 어셉메일이 와있었다 ㅎㅎㅎ&#xA;# 리비전때 사실 잘못적은내용이있어서 계속걸렸었고 2차리비전 각오도 하고있었는데 돼버리니깐 안와닿는데 너무 좋다. ㅎㅎ 진짜 한시름 덜었따&#xA;어제오늘 좀쳐져서 잠도너무많이자고그랬는데 진짜이번주안에 학위논문이랑 피피티 마무리할수있을거같다 ㅎㅎㅎ&#xA;# # </description>
    </item>
    <item>
      <title>python #2 객체지향 프로그래밍, 병렬처리</title>
      <link>http://localhost:1313/docs/study/be/be47/</link>
      <pubDate>Wed, 13 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be47/</guid>
      <description>python #2 객체지향 프로그래밍, 병렬처리 # #2025-08-13&#xA;1. 객체지향 프로그래밍 # #1 property &amp;amp; dataclass (p.139-140)&#xA;@property&#xA;diameter 메서드는 사실 _radius * 2라는 계산을 수행하지만 외부에선 c.diameter라고 쓰면 바로 10이라는 결과를 얻을 수 있다. @diameter.setter를 사용하면 c.diameter = 20 형태로 diameter을 수정할수있고 내부에서는 diameter을 받아 _radius=10으로 변환 저장한다. fastapi에서 젤많이쓰는 기능이 속성화이다. @dataclass&#xA;보통 클래스를 만들면 __init__으로 생성자, __repr__으로 객체 출력 형식, __eq__로 동등성 비교 등을 직접 정의해야 하는데 @dataclass를 붙이면 이런 메서드들이 자동 생성된다.</description>
    </item>
    <item>
      <title>python #1 기본문법, 가상환경, 로깅</title>
      <link>http://localhost:1313/docs/study/be/be45/</link>
      <pubDate>Tue, 12 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be45/</guid>
      <description>python #1 기본문법, 가상환경, 로깅 # #2025-08-12&#xA;1. 기본문법 # #1 break와 continue의 차이 (p.29)&#xA;# break for i in range(10): if i==5: break print(i) # continue for i in range(5): if i==2: continue print(i) break 0부터 9까지 세는 반복문에서 i가 5가 되는 순간 break를 만나면 그 뒤의 숫자는 전혀 세지 않고 반복이 끝난다. continue 0부터 4까지 세는 반복문에서 i가 2인 경우 continue를 만나면 2를 출력하지 않고 바로 다음 숫자인 3으로 넘어가고 반복문 자체는 끝나지 않는다.</description>
    </item>
    <item>
      <title>python #2 리스트 vs 제너레이터 비교 실습</title>
      <link>http://localhost:1313/docs/study/be/be46/</link>
      <pubDate>Tue, 12 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be46/</guid>
      <description>python #2 리스트 vs 제너레이터 비교 실습 # #2025-08-12&#xA;1. 100만 개의 숫자 합 구하기 # 1) 리스트 방식&#xA;import sys # 1) 리스트 방식 numbers = list(range(1000000)) # 0부터 999,999 리스트 생성 list_sum = sum(numbers) # 합계 구하기 list_mem = sys.getsizeof(numbers) # 메모리 사용량 확인 (리스트 객체 크기) print(f&amp;#34;리스트 합: {list_sum:,}&amp;#34;) print(f&amp;#34;리스트 메모리 사용량: {list_mem} bytes&amp;#34;) 리스트 합: 499,999,500,000 리스트 메모리 사용량: 8000056 bytes numbers=list(range(1000000)) -&amp;gt; sum(numbers) 0~999,999를 리스트(numbers)로 만들어 합계를 구함 sys.</description>
    </item>
    <item>
      <title>Devops #1 Python 프로젝트 CI/CD &amp; 클라우드 빌드</title>
      <link>http://localhost:1313/docs/study/be/be10/</link>
      <pubDate>Mon, 11 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be10/</guid>
      <description>Devops #1 Python 프로젝트 CI/CD &amp;amp; 클라우드 빌드 # #2025-08-11&#xA;실습 # 메이크파일, 린팅, 테스트와 같이 파이썬 프로젝트 스캐폴딩에 필수적인 요소가 포함된 깃허브 저장소를 생성해보자. 그리고 간단하게 코드 포매팅을 수행하도록 메이크파일 스크립트를 작성해보자.&#xA;깃허브 액션을 사용하여 두개 이상의 파이썬 버전에 대해 깃허브 프로젝트 테스트를 수행해보자.&#xA;클라우드 네이티브 빌드 서버(AWS 코드빌드, GCP 클라우드 빌드, 애저 DevOps 파이프라인)를 사용하여 지속적 통합을 수행해보자.&#xA;깃허브 프로젝트를 도커 파일로 컨테이너화하고, 자동으로 컨테이너 레지스트리에 새로운 컨테이너가 등록되도록 만들어보자.</description>
    </item>
    <item>
      <title>생성형 AI #1 생성형 AI 기초 및 Prompt Engineering</title>
      <link>http://localhost:1313/docs/study/ai/ai18/</link>
      <pubDate>Sat, 09 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai18/</guid>
      <description>생성형 AI #1 생성형 AI 기초 및 Prompt Engineering # #2025-08-09&#xA;#1 RAG (p.27)&#xA;RAG의 역할?&#xA;질문을 LLM에 던지기 전에 knowledge corpus에 질문을 미리 검색한다(회사 데이터에 대한 지식 벡터 db). 질문과 연관된 문서를 찾고 적절하게 만들어서 retrieval 던지면 의도대로 답변이 잘 나온다. # #2 LLM 출력 구성 (p.42-45)&#xA;Output Length (Max Tockens)&#xA;500자로 제한을 걸면 500자로 맞춰주는게 아니라 500자 넘으면 출력을 멈춘다. Sampling Controls&#xA;LLM은 다음에 올 단어를 고를 때 미리 계산된 사전 확률분포를 가지고 거기서 하나를 뽑는다</description>
    </item>
    <item>
      <title>생성형 AI #2 Prompt Engineering 실습 미리돌려보기</title>
      <link>http://localhost:1313/docs/study/ai/ai19/</link>
      <pubDate>Sat, 09 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai19/</guid>
      <description>생성형 AI #2 Prompt Engineering 실습 미리돌려보기 # #2025-08-09&#xA;1. VOC 분석 # setting&#xA;https://openrouter.ai/ Model: GPT-5 Temperature: 0.2 (낮게: 일관성 있는 분류 결과) Top-k / Top-p: default Max tokens: 1024 system prompt&#xA;너는 IT 시스템의 평가전문가야. 이번에 개발한 AI를 적용한 회계세무 시스템을 테스트한 고객의 평가내용인 VOC를 분석하는 것이 너의 역할이야. 판단근거를 2가지로 함께 제시해줘. user prompt&#xA;아래에 제공하는 모든 VOC 문장을 긍정, 중립, 부정 중 하나로 분류하고, 특히 부정일 경우 그렇게 판단한 이유를 2가지로 요약해줘.</description>
    </item>
    <item>
      <title>데이터 분석 #3 회귀분석</title>
      <link>http://localhost:1313/docs/study/ai/ai17/</link>
      <pubDate>Thu, 07 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai17/</guid>
      <description>데이터 분석 #3 회귀분석 # #2025-08-07&#xA;#1 Oversampling Techinique (p.69-71)&#xA;SMOTE&#xA;소수 클래스 포인트 중 하나를 랜덤하게 고르고 이웃 포인트 k개를 찾고 이 이웃들과의 연결선을 따라 중간 어딘가에 새로운 샘플을 만든다. 즉 원본과 이웃 사이에 위치한 점들을 생성한다. 소수 클래스 포인트들 사이의 직선 위에서만 새로운 데이터를 만들기 때문에 실제로는 decision boundary 근처에서 중요한 데이터를 놓칠 수 있다 Borderline-SMOTE&#xA;소수 클래스의 포인트에 대해 kNN을 수행해서 이웃들을 찾는데 이때 이웃 중에서 과반수 이상이 다수 클래스인 경우 위험한 샘플(danger set)으로 간주된다 즉 이 샘플은 결정 경계에 가깝기 때문에 모델 입장에서 헷갈릴 가능성이 높다.</description>
    </item>
    <item>
      <title>데이터 분석 #2 Preprocessing</title>
      <link>http://localhost:1313/docs/study/ai/ai16/</link>
      <pubDate>Wed, 06 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai16/</guid>
      <description>데이터 분석 #2 Preprocessing # #2025-08-06&#xA;#1 머신러닝 프로세스 (p.25)&#xA;test data가 필요한 이유? hyperparameter tuning을 하면서 validation data는 모델이 이미 참고했다 즉 간접적으로 학습에 영향을 줬기 때문에 모델 학습 과정에서 한번도 보지않은 데이터가 필요함. # #2 Box plot (p.38)&#xA;그림이 7개 차종에서 연비 플롯이라고 가정&#xA;투입됏을때 예측에 긍정적영향을 줄수잇는건?&#xA;납작한애들. 두꺼우면 대표성이 떨어진다. 2번에서 이상치들이 많으니까 잘 처리해야하겠다.&#xA;만약 그림같지 않고 y축 높이가 다 비슷비슷했다면?&#xA;이 변수들이 연비를 결정하는데 큰 영향을 못줌.</description>
    </item>
    <item>
      <title>데이터 분석 #1 기초통계</title>
      <link>http://localhost:1313/docs/study/ai/ai14/</link>
      <pubDate>Tue, 05 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai14/</guid>
      <description>데이터 분석 #1 기초통계 # #2025-08-05&#xA;1. 기술 통계 # #1 IQR (p.34)&#xA;IQR은? 가운데 50%의 거리.&#xA;그림 설명&#xA;그림의 2,3: 각각 IQR의 1.5배 선, median 값 선. 그림의 B: ⚬ 가 많으면 특이값이 많은 것. 그림의 1,2,3: 1,2는 각각 IQR의 1.5배 선이라고 했는데 3과의 거리가 서로 다른 이유는? 1.5배 안쪽에 데이터들이 다 분포해서. 즉max가 1.5배보다 작아서. # #2 변이 계수(Coefficient of Variables)&#xA;평균치가 다른 집단 비교. 변이 계수 = 표준편차 / 평균.</description>
    </item>
    <item>
      <title>Docker #3 레지스트리 접속, 이미지 관리</title>
      <link>http://localhost:1313/docs/study/be/be42/</link>
      <pubDate>Mon, 04 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be42/</guid>
      <description>Docker #3 # #2025-08-04&#xA;1. 레지스트리에 접속하고 이미지를 pull/push하기 # # Docker 로그인 $ docker login https://{실습링크}.com # ID: * # Password: * $ Login Succeeded # 이미지 Pull (이미지 내려받기): 예를 들어 container-linux:1.1 이미지를 다운로드 $ docker pull {실습링크}.com/{실습id}/container-linux:1.1 # 이미지 Push (Image Push 정보 사용): Push 권한은 일반 계정이 아니라 로봇 계정(CI/CD 용)을 사용합니다. # 로봇 계정 로그인 $ docker login https://{실습링크}.com # ID: robot$skala25a # Password: 1qB9cyusbNComZPHAdjNIFWinf52xaBJ # 태깅 (Tag local image) $ docker tag container-linux:1.</description>
    </item>
    <item>
      <title>Docker #4 자신의 Frontend 개발 코드를 컨테이너로 만들고 이것을 실행시켜 보자</title>
      <link>http://localhost:1313/docs/study/be/be43/</link>
      <pubDate>Mon, 04 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be43/</guid>
      <description>Docker #4 자신의 Frontend 개발 코드를 컨테이너로 만들고 이것을 실행시켜 보자 # #2025-08-04&#xA;#조건&#xA;nginx:alpine 이미지를 사용 노출 Port는80 nginx를실행하는방식은 -nginx -g daemon off; nginx의 routing 설정은 default.conf에설정한다. #path&#xA;$ pwd /Users/yshmbid/rde/config/workspace/exec-template $ ls Dockerfile default.conf deploy deploy.yaml docker-build.sh docker-push.sh service.yaml src # 1. docker-build.sh와 docker-push.sh 복사 # $ pwd /Users/yshmbid/rde/config/workspace/container/05.webserver $ ls Dockerfile default.conf deploy docker-build.sh docker-push.sh src # docker-build.sh #!/bin/bash NAME=sk019 IMAGE_NAME=&amp;#34;healthcheck-server&amp;#34; #IMAGE_NAME=&amp;#34;webserver&amp;#34; VERSION=&amp;#34;1.0.0&amp;#34; CPU_PLATFORM=arm64 #amd64 # Docker 이미지 빌드 docker build \ --tag ${NAME}-${IMAGE_NAME}:${VERSION} \ --file Dockerfile \ --platform linux/${CPU_PLATFORM} \ ${IS_CACHE} .</description>
    </item>
    <item>
      <title>Docker #5 kubernetes 환경에 나의 앱을 배포해보자</title>
      <link>http://localhost:1313/docs/study/be/be44/</link>
      <pubDate>Mon, 04 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be44/</guid>
      <description>Docker #5 kubernetes 환경에 나의 앱을 배포해보자 # #2025-08-04&#xA;#path&#xA;$ pwd /Users/yshmbid/rde/config/workspace/exec-template #파일 구조&#xA;/workspace └── exec-template ├── Dockerfile ├── default.conf ├── docker-build.sh ├── docker-push.sh ├── cicd.sh ├── deploy/ │ ├── deploy.t │ ├── deploy.sh │ ├── service.t │ ├── service.sh │ └── env.properties └── src/ ├── index.html └── media/ #이전 실습과의 차이?&#xA;cicd.sh를 쓴다. deploy 디렉토리를 쓴다. docker-build.sh와 docker-push.sh에서 amd였던걸 arm으로 바꿔줬는데 이걸다시 amd로 바꿔준다. # 1. cicd.</description>
    </item>
    <item>
      <title>결단</title>
      <link>http://localhost:1313/docs/hobby/book/book52/</link>
      <pubDate>Mon, 04 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/book/book52/</guid>
      <description>결단 # #2025-08-04&#xA;#1&#xA;머스크는 로켓이 산소가 희박한 높이로 충분히 솟아올라 불꽃이 꺼지길 바랐다. 그러나 로켓은 추락하기 시작했다. 비디오 피드에서 오멜렉이 가까이 다가오더니 더 이상 화면에 아무것도 비치지 않았다. 그리고 불타는 파편들이 바다로 떨어졌다. “위장이 뒤틀렸지요.” 머스크의 말이다. 1시간 후, 머스크는 뮬러, 쾨니스만, 부자, 톰슨 등 수석 팀원들과 함께 잔해를 둘러보기 위해 육군 헬리콥터에 올랐다.&#xA;그날 밤 모두가 콰즈의 야외 바에 모여 조용히 맥주를 마셨다. 몇몇 엔지니어는 눈물을 흘렸다. 머스크는 돌처럼 굳은 얼굴과 먼 곳을 응시하는 눈빛으로 조용히 생각에 잠겼다.</description>
    </item>
    <item>
      <title>Docker #1 Python 실행 컨테이너 만들기</title>
      <link>http://localhost:1313/docs/study/be/be40/</link>
      <pubDate>Fri, 01 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be40/</guid>
      <description>Docker #1 Python 실행 컨테이너 만들기 # #2025-08-01&#xA;Background # RDE #1 Local PC에서 RDE 환경 구성에서 Harbor registry로부터 RdE Container download를 수행했음 아이콘을 클릭해서 RDE 런처를 실행한다. # 1. 웹 서비스 실행 컨테이너 만들기 # /config/workspace/cloud/container/00.container-linux 경로로 이동 cd /config/workspace/cloud/container/00.container-linux 디렉토리 구조는? 00.container-linux/ ├── Dockerfile // 컨테이너 환경 설정 ├── Dockerfile.pytho-slim ├── Dockerfile.ubuntu ├── docker-build.sh ├── docker-push.sh ├── mycode.py ├── fastserver.py ├── webserver.py └── mydata/ Dockerfile 내용 확인하기 FROM python:3.</description>
    </item>
    <item>
      <title>Docker #2 작년 작업 복기: netmhcpan image 불러와서 패키지 돌리기</title>
      <link>http://localhost:1313/docs/study/be/be41/</link>
      <pubDate>Fri, 01 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be41/</guid>
      <description>Docker #2 작년 작업 복기: netmhcpan image 불러와서 패키지 돌리기 # #2025-08-01&#xA;1 # 2024.11.24 MutClust 작업중에 netmhcpan을 돌려야되는 상황이 왓었는데&#xA;netmhcpan이 유료였나 그래서 패키지 다운은 안되고 담당 박사님은 그만두셧고.. 서버 뒤지다가 위 README 파일 발견해서 결과물 저장까진 했던 기억이있다.&#xA;# 이때먼가 의문이 들었던게 새로운 conda 환경에 접속한거같은 느낌이 아니라 완전 다른 제2의서버에 접속한 느낌이었는데 이상하게 연구실 디렉토리들은 그대로 접근이 가능해서 혼란스럽지만 그냥 절대경로 다 박고 수행했는데 결과들이 문제없이 저장됐었다.</description>
    </item>
  </channel>
</rss>
