<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>2026-02 on  </title>
    <link>http://localhost:1313/tags/2026-02/</link>
    <description>Recent content in 2026-02 on  </description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 28 Feb 2026 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/2026-02/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>VAE 기반 신약 분자 생성 #1 VAE와 KL 발산</title>
      <link>http://localhost:1313/docs/study/dl/dl11/</link>
      <pubDate>Sat, 28 Feb 2026 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/dl/dl11/</guid>
      <description>VAE 기반 신약 분자 생성 #1 VAE와 KL 발산 # #2026-02-28&#xA;#1&#xA;약을 만드는 과정의 첫 번째 관문은 &amp;ldquo;어떤 분자를 약으로 쓸 것인가&amp;quot;를 정하는 것이다. 자연에 존재하는 분자 중에서 고르는 것도 있지만, 완전히 새로운 분자를 설계하는 것이 현대 신약 개발의 핵심이다.&#xA;그런데 여기서 문제의 규모를 실감해야 한다. 약이 될 수 있는 분자의 종류가 대략 10의 60제곱 개 이상이라고 추정된다. 이게 얼마나 큰 수인지 감을 잡기 위해 비교하면, 우주에 존재하는 원자의 수가 약 10의 80제곱 개다.</description>
    </item>
    <item>
      <title>VAE 기반 신약 분자 생성 #2 데이터 로드 및 토큰화</title>
      <link>http://localhost:1313/docs/study/dl/dl12/</link>
      <pubDate>Sat, 28 Feb 2026 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/dl/dl12/</guid>
      <description>VAE 기반 신약 분자 생성 #2 데이터 로드 및 토큰화 # #2026-02-28&#xA;#1 MUV 데이터셋 가져오기&#xA;import deepchem as dc tasks, datasets, transformers = dc.molnet.load_muv() train_dataset, valid_dataset, test_dataset = datasets train_smiles = train_dataset.ids # → [&amp;#39;CCO&amp;#39;, &amp;#39;CC(=O)Oc1ccccc1C(=O)O&amp;#39;, &amp;#39;Cn1cnc2c1c(=O)n(c(=O)n2C)C&amp;#39;, ...] DeepChem 라이브러리로 MUV 데이터셋을 자동으로 다운로드해준다. MUV는 Maximum Unbiased Validation의 약자로, 신약 후보 물질을 가상으로 스크리닝하는 벤치마크 데이터셋이다. 수만 개의 분자가 SMILES 문자열 형태로 들어 있다.&#xA;DNA 데이터에서는 .ids는 샘플의 식별자였는데 chr22:20208963-20209064 같은 게놈 좌표가 ID였다.</description>
    </item>
    <item>
      <title>VAE 기반 신약 분자 생성 #3 AspuruGuzikAutoEncoder 모델 구성</title>
      <link>http://localhost:1313/docs/study/dl/dl13/</link>
      <pubDate>Sat, 28 Feb 2026 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/dl/dl13/</guid>
      <description>VAE 기반 신약 분자 생성 #3 AspuruGuzikAutoEncoder 모델 구성 # #2026-02-28&#xA;3단계: AspuruGuzikAutoEncoder 모델 구성 (vae.py 20~25행) # from deepchem.models.optimizers import ExponentialDecay from deepchem.models.seqtoseq import AspuruGuzikAutoEncoder batch_size = 100 batches_per_epoch = len(train_smiles) / batch_size learning_rate = ExponentialDecay(0.001, 0.95, batches_per_epoch) model = AspuruGuzikAutoEncoder( tokens, max_length, model_dir=&amp;#39;vae&amp;#39;, batch_size=batch_size, learning_rate=learning_rate) AspuruGuzikAutoEncoder 내부 구조 # 이 모델은 2018년 Aspuru-Guzik 연구실의 논문 &amp;ldquo;Automatic Chemical Design Using a Data-Driven Continuous Representation of Molecules&amp;rdquo; 에서 제안한 아키텍처다.</description>
    </item>
    <item>
      <title>Conv1D 기반 DNA 분석 #1 유전체 서열 분석하기</title>
      <link>http://localhost:1313/docs/study/dl/dl1/</link>
      <pubDate>Fri, 27 Feb 2026 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/dl/dl1/</guid>
      <description>Conv1D 기반 DNA 분석 #1 유전체 서열 분석하기 # #2026-02-27&#xA;#1 CNN으로 유전체 서열 분석하기&#xA;DNA는 A, T, G, C 4개의 문자로 이루어진 긴 문자열이다. 이 문자열 어딘가에는 단백질이 달라붙는 자리(결합 부위)가 있고, 어딘가에는 RNA 간섭(RNAi)을 잘 일으키는 서열이 있다.&#xA;눈으로는 도저히 찾을 수 없다. 딥러닝으로 학습시키면?&#xA;유전체 서열 분석하는 3가지 실험을 한다:&#xA;실험 목표 문제 유형 1 전사인자 JUND가 결합하는 DNA 서열 예측 이진 분류 2 결합 예측 + 크로마틴 접근성 추가 이진 분류 (다중 입력) 3 siRNA 서열의 유전자 침묵 효율 예측 회귀 # #2 DNA 서열을 컴퓨터에 입력하는 방법: 원-핫 인코딩 (One-Hot Encoding)</description>
    </item>
    <item>
      <title>Conv1D 기반 DNA 분석 #2 전사인자 결합 부위 예측</title>
      <link>http://localhost:1313/docs/study/dl/dl2/</link>
      <pubDate>Fri, 27 Feb 2026 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/dl/dl2/</guid>
      <description>Conv1D 기반 DNA 분석 #2 전사인자 결합 부위 예측 # #2026-02-27&#xA;#0 분석 목적&#xA;우리 몸의 세포 안에는 DNA라는 아주 긴 문자열이 있고 A, C, G, T 네 글자로 이루어져 있다. DNA는 유전자라는 &amp;ldquo;레시피&amp;quot;를 담고 있는데, 이 레시피가 항상 켜져 있는 건 아니며 특정 단백질이 DNA의 특정 위치에 물리적으로 달라붙어야 그 근처 유전자가 켜진다. 이렇게 달라붙어서 유전자를 켜고 끄는 단백질을 전사인자라고 부른다.&#xA;JUND가 전사인자 중 하나인데, 아무 데나 붙는 게 아니라 특정한 글자 패턴이 있는 곳에만 붙는다.</description>
    </item>
    <item>
      <title>Conv1D 기반 DNA 분석 #3 크로마틴 접근성 추가</title>
      <link>http://localhost:1313/docs/study/dl/dl3/</link>
      <pubDate>Fri, 27 Feb 2026 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/dl/dl3/</guid>
      <description>Conv1D 기반 DNA 분석 #3 크로마틴 접근성 추가 # #2026-02-27&#xA;이전 모델에서 우리는 DNA 서열 101글자만 보고 JUND가 붙을지 말지를 예측했고 꽤 잘 작동했다. 그런데 생물학의 현실은 좀 더 복잡한데 JUND가 좋아하는 서열 패턴(TGACTCA 같은 모티프)이 거기 있어도, 그 DNA 구간이 물리적으로 접근 불가능한 상태라면 JUND는 절대 결합할 수 없다.&#xA;열린 크로마틴 (Open): ====○==== ← TF 접근 가능, 결합 가능성 높음 닫힌 크로마틴 (Closed): ████████ ← TF 접근 불가, 결합 가능성 낮음 우리 세포 안의 DNA는 그냥 풀어져서 떠다니는 게 아니라 히스톤이라는 작은 단백질 뭉치에 실타래처럼 감겨 있고 이렇게 DNA가 히스톤에 감긴 구조를 크로마틴이라고 부른다.</description>
    </item>
    <item>
      <title>Conv1D 기반 DNA 분석 #4 RNAi 효율 예측</title>
      <link>http://localhost:1313/docs/study/dl/dl4/</link>
      <pubDate>Fri, 27 Feb 2026 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/dl/dl4/</guid>
      <description>Conv1D 기반 DNA 분석 #4 RNAi 효율 예측 # #2026-02-27&#xA;#1 RNA 간섭(RNAi)이란?&#xA;세포 안에서 유전자가 단백질을 만드는 과정은 DNA에서 mRNA라는 복사본이 만들어지고, 이 mRNA를 리보솜이라는 기계가 읽어서 단백질을 찍어낸다. 유전자 → mRNA → 단백질, 이 흐름이 생명의 기본 공정이다.&#xA;그런데 세포 안에 짧은 RNA 조각을 집어넣으면, 그 RNA가 특정 mRNA를 찾아가서 분해한다. mRNA가 사라지면 리보솜이 읽을 게 없으니 단백질도 안 만들어진다 즉 특정 유전자를 &amp;ldquo;조용히 시키는&amp;rdquo; 것이다. 이걸 RNA 간섭, RNAi라고 한다.</description>
    </item>
    <item>
      <title>Conv1D 기반 DNA 분석 #5 분석 정리</title>
      <link>http://localhost:1313/docs/study/dl/dl5/</link>
      <pubDate>Fri, 27 Feb 2026 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/dl/dl5/</guid>
      <description>Conv1D 기반 DNA 분석 #5 분석 정리 # #2026-02-27&#xA;Conv1D 기반 DNA 분석에서 세 가지 실험을 했는데 전사인자 결합 예측, 크로마틴 접근성을 추가한 결합 예측, 그리고 RNAi 효율 예측을 수행했다. 세부 사항은 다 달랐지만 DNA(또는 RNA) 서열을 숫자로 바꾸고, 1차원 합성곱 필터로 패턴을 찾고, 그 패턴들을 종합해서 하나의 답을 내놓는 공통 로직으로 작동한다.&#xA;# #1 모델 구조&#xA;DNA 서열 (원-핫 인코딩) ↓ Conv1D → ReLU → Dropout ← 로컬 모티프 탐지 ↓ Conv1D → ReLU → Dropout ← 복합 패턴 학습 ↓ [Conv1D → ReLU → Dropout] ← (선택적 추가 레이어) ↓ Flatten ↓ [+ 크로마틴 접근성] ← (실험 2만 해당) ↓ Dense(1) ↓ Sigmoid → 출력 Conv1D 레이어</description>
    </item>
    <item>
      <title>ResNet 기반 망막증 분류 #1 Conv2D 기반 이미지 분류</title>
      <link>http://localhost:1313/docs/study/dl/dl6/</link>
      <pubDate>Fri, 27 Feb 2026 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/dl/dl6/</guid>
      <description>ResNet 기반 망막증 분류 #1 Conv2D 기반 이미지 분류 # #2026-02-27&#xA;#1&#xA;당뇨병 환자의 몸에서는 혈당이 오랜 기간 높은 상태로 유지된다. 이 높은 혈당이 온몸의 작은 혈관들을 서서히 망가뜨리는데, 눈의 망막에 있는 미세 혈관도 예외가 아니다. 혈관이 손상되면 피가 새고, 비정상적인 새 혈관이 자라나고, 결국 망막이 제 기능을 못 하게 되면서 시력을 잃을 수 있다. 이것이 당뇨병성 망막증이다. 안과 의사는 이 병을 진단하기 위해 안저 사진을 찍는다. 안저란 눈 뒤쪽의 망막 바닥 면을 말하는데, 특수 카메라로 동공을 통해 들여다보면 망막의 혈관 구조가 고스란히 보인다.</description>
    </item>
    <item>
      <title>ResNet 기반 망막증 분류 #2 이미지 전처리</title>
      <link>http://localhost:1313/docs/study/dl/dl7/</link>
      <pubDate>Fri, 27 Feb 2026 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/dl/dl7/</guid>
      <description>ResNet 기반 망막증 분류 #2 이미지 전처리 # #2026-02-27&#xA;#1 망막 이미지 데이터&#xA;Kaggle에서 받은 안저 사진들은 전 세계 다양한 병원에서 서로 다른 장비로 찍힌 것이다. 어떤 사진은 2000픽셀짜리이고, 어떤 사진은 5000픽셀이 넘는다. 어떤 사진은 거의 정사각형이고, 어떤 사진은 직사각형이다. 공통적인 건 하나인데, 망막은 원형이라 사진 한가운데에 둥근 밝은 영역으로 찍히고, 그 주변은 까만 여백으로 채워져 있다는 것이다. 신경망에 이미지를 넣으려면 모든 이미지의 크기가 같아야 한다. 행렬 연산이 고정된 차원을 요구하기 때문이다.</description>
    </item>
    <item>
      <title>ResNet 기반 망막증 분류 #3 데이터 증강</title>
      <link>http://localhost:1313/docs/study/dl/dl8/</link>
      <pubDate>Fri, 27 Feb 2026 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/dl/dl8/</guid>
      <description>ResNet 기반 망막증 분류 #3 데이터 증강 # #2026-02-27&#xA;#1&#xA;딥러닝 모델은 데이터를 많이 볼수록 잘 배운다. 그런데 의료 이미지는 구하기 어렵다. 수만 장이 있다고 해도 수백만 개의 파라미터를 가진 신경망을 학습시키기에는 부족할 수 있다. 데이터가 부족하면 모델은 훈련 이미지의 세부 사항까지 통째로 외워버리고, 처음 보는 이미지에서는 엉뚱한 판단을 내린다. 과적합이다.&#xA;데이터 증강의 핵심 아이디어는 하나의 이미지를 살짝씩 변형해서 여러 버전을 만들면, 모델 입장에서는 마치 더 많은 데이터를 본 것과 같은 효과가 난다.</description>
    </item>
    <item>
      <title>ResNet 기반 망막증 분류 #4 분류모델 학습</title>
      <link>http://localhost:1313/docs/study/dl/dl9/</link>
      <pubDate>Fri, 27 Feb 2026 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/dl/dl9/</guid>
      <description>ResNet 기반 망막증 분류 #4 분류모델 학습 # #2026-02-27&#xA;#1 아키텍처 개요&#xA;self.inputs = tf.keras.Input(shape=(512, 512, 3), dtype=tf.float32) in_layer = DRAugment(self.augment, batch_size, size=(512, 512))(self.inputs) 이전 단계에서 512×512 크기의 깔끔한 망막 이미지와 등급 레이블, 그리고 클래스 가중치가 준비되었다. 이제 이 이미지를 받아서 &amp;ldquo;이 망막은 등급 몇이다&amp;quot;라고 판정하는 모델을 만들 차례다.&#xA;이전 챕터에서 DNA 서열을 분석할 때는 Conv1D를 썼다. DNA는 1차원이니까. 이미지는 2차원(가로×세로)이므로 Conv2D를 쓴다. 하지만 단순히 Conv2D를 몇 겹 쌓는 것만으로는 부족하다.</description>
    </item>
    <item>
      <title>ResNet 기반 망막증 분류 #5 평가 지표와 전체 파이프라인</title>
      <link>http://localhost:1313/docs/study/dl/dl10/</link>
      <pubDate>Fri, 27 Feb 2026 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/dl/dl10/</guid>
      <description>ResNet 기반 망막증 분류 #5 평가 지표와 전체 파이프라인 # #2026-02-27&#xA;모델이 학습을 마쳤다. 512×512 망막 사진을 넣으면 5개 등급에 대한 확률을 내놓는다. 이제 가장 중요한 질문이 남았다. 이 모델이 실제로 쓸 만한가? 이걸 판단하려면 적절한 평가 지표가 필요하다.&#xA;이 프로젝트에서는 세 가지 평가 도구를 쓴다. 단순 정확도, 이차 가중 카파, 그리고 혼동행렬이다. 각각이 모델의 다른 측면을 보여주는데, 특히 두 번째 지표가 이 문제의 핵심을 찌른다.&#xA;# #1 단순 정확도(DRAccuracy)</description>
    </item>
    <item>
      <title>기업 순위 정리</title>
      <link>http://localhost:1313/docs/study/career/career20/</link>
      <pubDate>Fri, 27 Feb 2026 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/career/career20/</guid>
      <description>기업 순위 정리 # #2026-02-27&#xA;순위판단기준: 매출액 &amp;gt; 직원수 &amp;gt; 시가총액/기업가치 &amp;gt; 모그룹 소속 &amp;gt; 상장여부&#xA;# #1 대기업/중견기업&#xA;셀트리온&#xA;매출액: ~3조 5,573억 (2024, 연결) 직원수: 3,000명 시가총액: 약 30조+ 직무: AI Engineering &amp;amp; Platforms (BI/AI 신약개발 - 타겟발굴) 비고: 대기업. 코스피 상장. 바이오시밀러 글로벌 1위권. 램시마·짐펜트라 등 11개 제품 포트폴리오 삼양식품&#xA;매출액: ~1조 7,280억 (2024, 연결) 직원수: 2,880명 시가총액: 약 8~10조 직무: OMICS Bioinformatics 연구원 비고: 중견기업. 코스피 상장.</description>
    </item>
    <item>
      <title>기업조사 #5 셀트리온</title>
      <link>http://localhost:1313/docs/study/career/career19/</link>
      <pubDate>Thu, 26 Feb 2026 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/career/career19/</guid>
      <description>기업조사 #5 셀트리온 # #2026-02-26&#xA;희망 직무를 수행하기 위해 준비한 것과 직무와 관련된 본인 역량 BI/AI 신약개발의 타겟발굴 직무는 신약 개발 파이프라인에서 타겟 선택의 과학적 근거를 멀티오믹스 분석 및 AI로 제공하는 직무입니다. 신약 타겟 발굴의 속도와 신뢰도를 높이는 이 직무에서, 해당 직무를 수행하기 위해 이 두 가지 핵심역량을 키웠습니다.&#xA;첫째, 멀티오믹스 데이터에서 생물학적 인과관계를 규명하는 분석 역량입니다. 저는 EBV 양성 위암 연구에서 RNA-seq, BS-seq, ChIP-seq 세 가지 오믹스를 직접 전처리하고 통합 분석하여, DHT 약물이 면역 반응을 유도하는 인과 경로를 규명했습니다.</description>
    </item>
    <item>
      <title>기업조사 #3 엑소시스템즈</title>
      <link>http://localhost:1313/docs/study/career/career17/</link>
      <pubDate>Wed, 25 Feb 2026 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/career/career17/</guid>
      <description>기업조사 #3 엑소시스템즈 # #2026-02-25&#xA;#1 엑소시스템즈에서 희망하시는 역할과 지원자님이 기대하시는 바가 궁금합니다.&#xA;엑소시스템즈에서 생체신호 기반의 디지털 바이오마커 분석 알고리즘 개발 및 사용자 데이터 기반의 Key Index 설계 업무를 희망하고 있습니다.&#xA;Random Forest와 SHAP을 활용해 COVID-19 질병 악화 사이토카인 마커를 발굴하고, 개인별 해석이 가능한 분석 결과를 제시한 경험은 엑소시스템즈의 MFI와 같은 디지털 바이오마커를 고도화하고 새로운 질환 영역에 확장하는 업무에 기여할 수 있을 것으로 생각합니다. 또한 Mutclust 연구에서 돌연변이 핫스팟 탐지 알고리즘의 downstream 분석 및 performance evaluation을 직접 설계하고 SCIE 논문 1저자로 성과를 낸 경험은, 임상시험에서 사용할 핵심 지표를 정의하고 검증 체계를 설계하는 업무에 기여할 수 있을 것으로 생각합니다.</description>
    </item>
    <item>
      <title>기업조사 #4 AMC사이언스</title>
      <link>http://localhost:1313/docs/study/career/career18/</link>
      <pubDate>Wed, 25 Feb 2026 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/career/career18/</guid>
      <description>기업조사 #4 AMC사이언스 # #2026-02-25&#xA;본인의 회사 선택 기준은 무엇이며, HD현대가 어떤 측면에서 그 기준에 적합하다고 생각하십니까? (최대 2,000자 입력가능) 저의 회사 선택 기준은 두 가지입니다. 첫째, 제가 보유한 멀티오믹스 분석 역량과 엔지니어링 역량이 회사의 핵심 사업에 직접 기여할 수 있는 구조인지, 둘째, 그 사업이 장기적으로 성장할 수 있는 차별화된 경쟁우위를 갖추고 있는지입니다.&#xA;첫 번째 기준에서, AMC사이언스의 오믹스 분석 직무는 제 경험이 가장 직접적으로 기여할 수 있는 자리라고 생각합니다. 저는 석사과정에서 RNA-seq, BS-seq, ChIP-seq 세 가지 오믹스 데이터를 하나의 프로젝트 안에서 전처리부터 통합 분석까지 수행하며 멀티오믹스 분석의 전체 사이클을 경험하였고, 질병관리청 협업 과제에서는 444명 환자의 임상 데이터와 사이토카인 프로파일을 분석하며 의료 데이터의 특성에 맞는 분석 설계를 수행하였습니다.</description>
    </item>
    <item>
      <title>2월말 공고</title>
      <link>http://localhost:1313/docs/study/career/career16/</link>
      <pubDate>Tue, 24 Feb 2026 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/career/career16/</guid>
      <description>2월말 공고 # #2026-02-24&#xA;#1 추가공고&#xA;메디플렉서스 https://www.jobkorea.co.kr/Recruit/GI_Read/48605718?Oem_Code=C1&amp;sc=9 직무: 의료 빅데이터 기반 통계 연구원 규모: 12명 주요사업: 응용 소프트웨어 개발 및 공급업 잡코리아 지원완료 엑소시스템즈 https://www.jobkorea.co.kr/Recruit/GI_Read/48478200?Oem_Code=C1 마감일: 2026.02.28 직무: AI 엔지니어 규모: 14명 주요사업: 전기식 진단 및 요법 기기 제조업 홈페이지 지원 엑스모 https://www.jobkorea.co.kr/Recruit/GI_Read/48595013?sc=727&amp;sn=102 직무: 의료 데이터 분석 연구원 규모: -명 주요사업 - 잡코리아 지원완료 한컴케어링크 https://www.jobkorea.co.kr/Recruit/GI_Read/48518349?sc=727&amp;sn=102&#xA;직무: 바이오인포매틱스 및 AI 융합 연구원 규모: 42명 주요사업: 종합건강관리,외국인환자 유치,유전자분석 알선/전자상거래 잡코리아 지원완료 히츠</description>
    </item>
    <item>
      <title>2월공고</title>
      <link>http://localhost:1313/docs/study/career/career15/</link>
      <pubDate>Fri, 13 Feb 2026 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/career/career15/</guid>
      <description>2월공고 # #2026-02-13&#xA;#공고정리&#xA;에비드넷 https://www.jobkorea.co.kr/Recruit/GI_Read/48465409?Oem_Code=C1&amp;sc=7&#xA;마감일: 2026.03.23 직무: 의료 데이터사이언티스트 규모: 62명 홈페이지 지원완료 24일 재지원 목암생명과학연구소 https://www.jobkorea.co.kr/Recruit/GI_Read/48538386?Oem_Code=C1&amp;sc=7&#xA;마감일: 2026.02.18 직무: Computational Biology &amp;amp; AI Drug Discovery 규모: 63명 블록스퀘어랩스 https://www.jobkorea.co.kr/Recruit/GI_Read/48481031?Oem_Code=C1&amp;sc=7&#xA;직무: 암호화폐 데이터 분석가 규모: 40명 주요사업: 인공지능을 통한 암호화폐 시장 분석 및 실시 잡코리아 지원완료 제이시스메디칼 https://www.jobkorea.co.kr/Recruit/GI_Read/48593208?Oem_Code=C1&amp;sc=9&#xA;마감일: 2026.03.04 직무: 의료기기 Medical Publication 학술연구 규모: 322명 잡코리아 지원완료 AMC사이언스 https://www.jobkorea.co.kr/Recruit/GI_Read/48560721?Oem_Code=C1&amp;sc=9&#xA;마감일: 2026.02.28 15시 00분 직무: 연구부문 &amp;gt; 생물정보학 &amp;gt; 오믹스분석 규모: 50명 안랩 https://www.</description>
    </item>
    <item>
      <title>SQL #8 role postgres does not exist 에러</title>
      <link>http://localhost:1313/docs/study/be/be60/</link>
      <pubDate>Fri, 13 Feb 2026 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be60/</guid>
      <description>SQL #8 role postgres does not exist 에러 # #2026-02-08&#xA;#에러&#xA;asyncpg.exceptions.InvalidAuthorizationSpecificationError: role &amp;#34;postgres&amp;#34; does not exist #트러블슈팅&#xA;SiLok 백엔드의 .env에 DB 접속 정보가 이렇게 설정되어 있음&#xA;DATABASE_URL=&amp;#34;postgresql+asyncpg://postgres:1234@localhost:5432/septime-db&amp;#34; postgres 유저로 접속하려 하는데, 로컬 PostgreSQL에는 yshmbid, myuser role만 존재하고 postgres role이 없었음&#xA;psql -c &amp;#34;SELECT usename FROM pg_catalog.pg_user;&amp;#34; 2&amp;gt;/dev/null || psql -U yshmbid -d postgres -c &amp;#34;SELECT usename FROM pg_catalog.pg_user;&amp;#34; 2&amp;gt;/dev/null || whoami usename --------- yshmbid myuser (2 rows) 아래 커맨드로 role 생성해줌.</description>
    </item>
    <item>
      <title>AWS #3 terraform tfstate 트러블슈팅</title>
      <link>http://localhost:1313/docs/study/be/be54/</link>
      <pubDate>Sun, 08 Feb 2026 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be54/</guid>
      <description>AWS #3 terraform tfstate 트러블슈팅 # #2026-02-08&#xA;#1 terraform 트러블슈팅&#xA;git add . 하려는데 아래 경고가 떴다&#xA;warning: 내장 깃 저장소 추가: terraform/.terraform/modules/vpc hint: You&amp;#39;ve added another git repository inside your current repository. hint: Clones of the outer repository will not contain the contents of hint: the embedded repository and will not know how to obtain it. hint: If you meant to add a submodule, use: hint: hint: git submodule add &amp;lt;url&amp;gt; terraform/.</description>
    </item>
    <item>
      <title>AWS #4 ECS 파이프라인 트러블슈팅</title>
      <link>http://localhost:1313/docs/study/be/be58/</link>
      <pubDate>Sun, 08 Feb 2026 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be58/</guid>
      <description>AWS #4 ECS 파이프라인 트러블슈팅 # #2026-02-08&#xA;#1&#xA;Docker 이미지를 ECR에 푸시하는 원래 코드는 아래와 같았다.&#xA;# ECR 로그인 aws ecr get-login-password --region ap-northeast-2 | docker login --username AWS --password-stdin 949346723599.dkr.ecr.ap-northeast-2.amazonaws.com # 백엔드 빌드 &amp;amp; 푸시 cd /Users/yshmbid/Documents/home/github/StudyNote/backend docker build -t studynote-backend . docker tag studynote-backend:latest 949346723599.dkr.ecr.ap-northeast-2.amazonaws.com/studynote-backend:latest docker push 949346723599.dkr.ecr.ap-northeast-2.amazonaws.com/studynote-backend:latest # 프론트엔드 빌드 &amp;amp; 푸시 cd /Users/yshmbid/Documents/home/github/StudyNote/frontend docker build -t studynote-frontend . docker tag studynote-frontend:latest 949346723599.dkr.ecr.ap-northeast-2.amazonaws.com/studynote-frontend:latest docker push 949346723599.dkr.ecr.ap-northeast-2.amazonaws.com/studynote-frontend:latest # 푸시 후 ECS 서비스를 재시작 aws ecs update-service --cluster studynote-cluster --service studynote-backend-service --force-new-deployment aws ecs update-service --cluster studynote-cluster --service studynote-frontend-service --force-new-deployment 그 다음 url로 접속한다: http://studynote-alb-123356897.</description>
    </item>
    <item>
      <title>AWS #5 SiLok 프로젝트 ECS 파이프라인 빌드</title>
      <link>http://localhost:1313/docs/study/be/be59/</link>
      <pubDate>Sun, 08 Feb 2026 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be59/</guid>
      <description>AWS #5 SiLok 프로젝트 ECS 파이프라인 빌드 # #2026-02-08&#xA;#1&#xA;StudyNote와 동일한 방식으로 ECS 파이프라인을 빌드했고 파일 구조는 아래와 같다&#xA;VitalTime/ ├── backend/Dockerfile # Python 3.11 + ML libs, 포트 8001 ├── frontend/ │ ├── Dockerfile # nginx:alpine, 정적 파일 서빙 │ ├── nginx.conf # SPA 라우팅 + 캐싱 │ └── docker-entrypoint.sh # 런타임 config.js 생성 (API키 주입) ├── docker-compose.yml # 로컬: backend + frontend + postgres ├── .github/workflows/deploy.yml # CI/CD: test → ECR push → ECS 배포 ├── .</description>
    </item>
    <item>
      <title>AWS #5 SiLok 프로젝트 ECS 파이프라인 빌드</title>
      <link>http://localhost:1313/docs/study/be/portfolio_db/</link>
      <pubDate>Sun, 08 Feb 2026 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/portfolio_db/</guid>
      <description>AWS #5 SiLok 프로젝트 ECS 파이프라인 빌드 # #2026-02-08&#xA;🗄️ Silok - Database 구축 포트폴리오 # 프로젝트 개요 # AI 기반 주간 업무 보고서 자동 생성 서비스의 데이터베이스를 설계하고 구축한 프로젝트입니다. PostgreSQL과 pgvector 확장을 활용하여 다중 플랫폼 협업 데이터를 통합 저장하고, 벡터 임베딩 기반의 시맨틱 검색 기능을 구현했습니다.&#xA;항목 내용 프로젝트 기간 2024년 역할 Database Engineer / Backend Developer 기술 스택 PostgreSQL 15, pgvector, SQLAlchemy (Async), Docker 프로젝트 유형 Enterprise B2B SaaS 📋 목차 # 기술적 의사결정 데이터베이스 아키텍처 스키마 설계 벡터 검색 구현 ORM 및 비동기 처리 API 엔드포인트 설계 Docker 컨테이너화 성능 최적화 문제 해결 사례 프로젝트 성과 1.</description>
    </item>
    <item>
      <title>AWS #5 SiLok 프로젝트 ECS 파이프라인 빌드</title>
      <link>http://localhost:1313/docs/study/be/portfolio_vitaltime_db/</link>
      <pubDate>Sun, 08 Feb 2026 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/portfolio_vitaltime_db/</guid>
      <description>AWS #5 SiLok 프로젝트 ECS 파이프라인 빌드 # #2026-02-08&#xA;🏥 VitalTime - Database 구축 포트폴리오 # 프로젝트 개요 # AI 기반 환자 전원 의뢰 시스템의 데이터베이스를 설계하고 구축한 프로젝트입니다. PostgreSQL 14와 SQLAlchemy 2.0 비동기 ORM을 활용하여 시계열 임상 데이터를 저장하고, LATERAL JOIN 기반의 예측 NEWS Score 조회 및 LSTM 모델 학습 파이프라인을 구현했습니다.&#xA;항목 내용 프로젝트 기간 2025년 역할 Database Engineer / Backend Developer 기술 스택 PostgreSQL 14, SQLAlchemy 2.</description>
    </item>
    <item>
      <title>bash #1 venv 가상환경 설정</title>
      <link>http://localhost:1313/docs/study/be/be56/</link>
      <pubDate>Sun, 08 Feb 2026 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be56/</guid>
      <description> bash #1 venv 가상환경 설정 # #2026-02-08&#xA;스칼라 하면서 개조돼서 이젠 conda보다 venv가 훨씬 익숙해져버렸다 ㅠ&#xA;# 가상환경 생성 python3 -m venv venv # 가상환경 활성화 source venv/bin/activate # 패키지 설치 pip install -r requirements.txt </description>
    </item>
    <item>
      <title>Github #4 .env 히스토리에서 제거</title>
      <link>http://localhost:1313/docs/study/be/be57/</link>
      <pubDate>Sun, 08 Feb 2026 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be57/</guid>
      <description> Github #4 .env 히스토리에서 제거 # #2026-02-08&#xA;.env를 gitignore에 안넣고 잘못 Push 했을때.&#xA;# .env를 git 히스토리에서 제거 grep -n &amp;#39;\.env&amp;#39; .gitignore 2&amp;gt;/dev/null || echo &amp;#34;.env not in .gitignore&amp;#34; # 과거 커밋에 .env 제거 FILTER_BRANCH_SQUELCH_WARNING=1 git filter-branch --force --index-filter &amp;#39;git rm --cached --ignore-unmatch .env&amp;#39; --prune-empty -- --all 2&amp;gt;&amp;amp;1 # stash를 복원하고 push git stash pop 2&amp;gt;&amp;amp;1 git push -u origin main 2&amp;gt;&amp;amp;1 </description>
    </item>
    <item>
      <title>SQL #7 postgreSQL 실행상태 확인</title>
      <link>http://localhost:1313/docs/study/be/be55/</link>
      <pubDate>Sun, 08 Feb 2026 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be55/</guid>
      <description> SQL #7 postgreSQL 실행상태 확인 # #2026-02-08&#xA;PostgreSQL 실행 확인하고 트러블슈팅&#xA;# PostgreSQL 17 서비스 중지 brew services stop postgresql@17 # pg14로 초기화된 데이터 디렉토리 삭제 rm -rf /opt/homebrew/var/postgresql@17 # pg17 initdb로 데이터 디렉토리 새로 초기화 (PATH의 initdb가 pg14여서 직접 지정) /opt/homebrew/opt/postgresql@17/bin/initdb /opt/homebrew/var/postgresql@17 --locale=C -E UTF-8 # PostgreSQL 17 서비스 시작 brew services start postgresql@17 cf) postgreSQL 초기 세팅하는법&#xA;# 유저 및 데이터베이스 생성 /opt/homebrew/opt/postgresql@17/bin/createuser -s myuser /opt/homebrew/opt/postgresql@17/bin/createdb mydatabase -O myuser /opt/homebrew/opt/postgresql@17/bin/psql -U myuser -d mydatabase -c &amp;#34;ALTER USER myuser PASSWORD &amp;#39;mypassword&amp;#39;;&amp;#34; </description>
    </item>
    <item>
      <title>AWS #1 프로젝트 배포하기</title>
      <link>http://localhost:1313/docs/study/be/be52/</link>
      <pubDate>Sat, 07 Feb 2026 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be52/</guid>
      <description>AWS #1 프로젝트 배포하기 # #2026-02-07&#xA;StudyNote/ ├── backend/ # FastAPI 서버 ├── frontend/ # React + Vite ├── docs/ # 노트북 및 마크다운 문서 └── data/ # 노트북 실행용 데이터 위 구조로 1) 학습 코드를 ipynb 파일로 업로드하면 2) ui는 블로그 형식으로 보여지면서 구글 colab처럼 코드 실행도 할수있는 StudyNote라는 프로젝트를 만들었다.&#xA;깃허브에 push했고 local로 띄워볼수있게 만들었는데 local이 아닌 실제 url로 볼수있게 배포해보려고한다.&#xA;# 일단 추천받은 방법 3개는 다음과 같다</description>
    </item>
    <item>
      <title>AWS #2 Docker &#43; AWS ECS 파이프라인 구성</title>
      <link>http://localhost:1313/docs/study/be/be53/</link>
      <pubDate>Sat, 07 Feb 2026 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be53/</guid>
      <description>AWS #2 Docker + AWS ECS 파이프라인 구성 # #2026-02-07&#xA;#1 배포 파일 생성&#xA;StudyNote/ ├── backend/Dockerfile # 백엔드 컨테이너 ├── frontend/Dockerfile # 프론트엔드 멀티스테이지 빌드 ├── frontend/nginx.conf # Nginx 설정 ├── docker-compose.yml # 로컬 Docker 실행 ├── .github/workflows/deploy.yml # CI/CD 파이프라인 ├── .aws/ │ ├── task-definition-backend.json │ └── task-definition-frontend.json ├── terraform/main.tf # AWS 인프라 (VPC, ECS, ALB, ECR) └── README.md # 배포 가이드 먼저 필요한 파일들을 위 구조로 생성해줬다.</description>
    </item>
    <item>
      <title>Github #3 리포지토리에 초기화 push 하기</title>
      <link>http://localhost:1313/docs/study/be/be51/</link>
      <pubDate>Fri, 06 Feb 2026 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be51/</guid>
      <description>Github #3 리포지토리에 초기화 push 하기 # #2026-02-06&#xA;rm -rf .git git init git remote add origin https://github.com/yshghid/StudyNote.git git add -A git commit -m &amp;#34;Initial commit&amp;#34; git push -u origin main --force 원래 github 커밋, 푸시는 그냥 내가 하는데, 한번 귀찮아서 클로드에 맡겼더니 contributor에 클로드가 추가돼서 근데 리포지토리 삭제했다가 다시 해도 여전히 남아있었다 ㅠ 위 코드가 완전 초기화 후 push 하는 코드다.</description>
    </item>
  </channel>
</rss>
