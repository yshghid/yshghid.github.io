<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>2025-07 on  </title>
    <link>http://localhost:1313/tags/2025-07/</link>
    <description>Recent content in 2025-07 on  </description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 31 Jul 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/2025-07/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>HTML #2 SKCT 공부용 메모장&#43;계산기 만들기</title>
      <link>http://localhost:1313/docs/study/fe/fe18/</link>
      <pubDate>Thu, 31 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/fe/fe18/</guid>
      <description>HTML #2 SKCT 공부용 메모장+계산기 만들기 # #2025-07-31&#xA;1. 문제 # SKCT는 응시화면이 아래와같이 돼잇는데&#xA;연습하기 불편한거같애서 html로 만들어봣다&#xA;# 2. SKCT 공부용 메모장+계산기 # #구조&#xA;/skct ├── index.html └── script.js #링크&#xA;https://github.com/yshghid/skct-tools/tree/main&#xA;#활용&#xA;요렇게 문제옆에 띄워놓고 쓰면됨 ㅎㅎㅎ&#xA;# 3. 수정사항 # #메모장&#xA;메모장 ↔ 그림판 전환 버튼 메모장일때는 &amp;lsquo;🎨 그림판&amp;rsquo;, 그림판일때는 &amp;lsquo;📝 메모장&amp;rsquo;이 뜨게 수정 # #그림판&#xA;선 굵기 조절하는 슬라이더 넣기 html: 슬라이더 UI 추가 javascript: 초기 선 굵기 1로 설정 / 그림판 상태일때만 보기로 설정 &amp;lt;!</description>
    </item>
    <item>
      <title>SQL #6 AI 서비스 리뷰 시스템</title>
      <link>http://localhost:1313/docs/study/be/be39/</link>
      <pubDate>Thu, 31 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be39/</guid>
      <description>SQL #6 AI 서비스 리뷰 시스템 # #2025-07-31&#xA;1. 문제 # AI 서비스 리뷰 시스템: 키워드 기반 텍스트 필터링과 AI 기반 방식의 비교를 통해 유사도 기반 검색에 대한 개념 이해&#xA;테이블 개요&#xA;Day 3 – ai_service_creator_ranking.sql 주제: AI 서비스 리뷰 (WITH (CTE) + 집계로 인기 기획자 추출) 목적: CTE(Common Table Expression)로 집계 테이블을 구성, AVG(평점)과 COUNT(리뷰)를 기준으로 인기 있는 기획자 선정, ROW_NUMBER()로 랭킹 부여, 향후 AI 추천(예: 유사도 기반 + 평점 기반 추천) 전단 필터링에 활용 실습 문제</description>
    </item>
    <item>
      <title>SQL #4 AI 피드백 분석 시스템의 테이블 정규화</title>
      <link>http://localhost:1313/docs/study/be/be22/</link>
      <pubDate>Wed, 30 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be22/</guid>
      <description>SQL #4 AI 피드백 분석 시스템의 테이블 정규화 # #2025-07-30&#xA;1. 문제 # AI 피드백 분석 시스템의 테이블 정규화&#xA;시나리오&#xA;여러분은 AI 피드백 분석 시스템을 위한 데이터 모델링을 맡았습니다. 현재는 여러 실험 데이터를 한 테이블에 모아두었지만, 벡터 임베딩 처리, 학습데이터 전처리, RAG 문서 기반 검색 등을 고려해 정규화 설계가 필요합니다. [비정규 테이블 예시: Day 2 – 정규화와 제약조건_실습1_예제_ai_feedback_raw.csv] 실습 목표&#xA;LLM Feedback 데이터 정규화 (3NF까지 고려) model, user, prompt-response, tags 분리 tags 필드는:TEXT[ ] 배열로 유지한 구조 (빠른 전처리, FAISS 등 용이) feedback_tag라는 별도 테이블로 정규화 (통계, RAG 전처리 유리) AI 분석 목적의 전처리 성능 관점에서 두 방식 비교 설명 # 2.</description>
    </item>
    <item>
      <title>SQL #5 소셜미디어 포스트 리뷰 시스템</title>
      <link>http://localhost:1313/docs/study/be/be23/</link>
      <pubDate>Wed, 30 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be23/</guid>
      <description>SQL #5 소셜미디어 포스트 리뷰 시스템 # #2025-07-30&#xA;1. 문제 # JSONB 기반의 메타정보 필드 설계 + 검색 + AI 분석 연계&#xA;테이블 개요&#xA;Day 2 – jsonb_metadata_sql_practice.sql 주제: 소셜미디어 포스트 리뷰 목적: 포스트에 대한 사용자 평가 + 해시태그/속성을 JSONB로 저장하여 AI 추천/필터 기반 만들기 실습 준비&#xA;특정 메타 속성 포함 검색(JSONB 검색 쿼리 실습) GIN 인덱스 생성 AI 필터링 활용 시나리오 (Hybrid Filtering 기반) 문제&#xA;sentiment가 negative인 리뷰만 출력 메타데이터에 &amp;ldquo;language&amp;rdquo; 키가 포함된 행 찾기 (?</description>
    </item>
    <item>
      <title>SQL #1 학사 관리 시스템 설계 - 엔터티 도출 및 ERD 작성</title>
      <link>http://localhost:1313/docs/study/be/be19/</link>
      <pubDate>Tue, 29 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be19/</guid>
      <description>SQL #1 학사 관리 시스템 설계 - 엔터티 도출 및 ERD 작성 # #2025-07-29&#xA;1. 문제 # AI 기반 학사 관리 시스템 (Learning Management System) 설계를 위한 엔터티 도출 및 ERD 작성 실습입니다.&#xA;요구사항 . 교육과정, 수강생, 과정운영자, 강사, 과정 설명 텍스트, Review 등으로 구성 . 과정 설명 텍스트는 향후 AI 임베딩 대상이므로 충분한 길이와 자유 텍스트로 정의&#xA;순서 . 학사관리시스템 엔티티 도출 및 검증 . ERD 변환 작업 .</description>
    </item>
    <item>
      <title>SQL #2 학사 관리 시스템 설계 - 스키마 분리 및 멀티 프로젝트 설계</title>
      <link>http://localhost:1313/docs/study/be/be20/</link>
      <pubDate>Tue, 29 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be20/</guid>
      <description>SQL #2 학사 관리 시스템 설계 - 스키마 분리 및 멀티 프로젝트 설계 # #2025-07-29&#xA;1. 문제 # 이전에 만든 ERD를 기반으로 PostgreSQL 로 스키마 분리 및 멀티 프로젝트 설계합니다.&#xA;주제 . 서울캠퍼스/제주캠퍼스별 학사 관리 시스템 (Learning Management System) 동일한 학사관리 시스템 구조를 기반으로, 캠퍼스에 따라 데이터를 스키마 단위로 분리 설계하고 향후 AI 분석 결과의 멀티 벡터 저장 구조로 확장 가능하도록 구조 설계 요구사항 . 교육과정, 수강생 과정운영자, 강사, 과정 설명 텍스트, Review 등으로 구성하되, 캠퍼스별 특성을 고려하여 스키마 분리 .</description>
    </item>
    <item>
      <title>SQL #3 스키마 분리와 AI 분석</title>
      <link>http://localhost:1313/docs/study/be/be21/</link>
      <pubDate>Tue, 29 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be21/</guid>
      <description>SQL #3 스키마 분리와 AI 분석 # #2025-07-29&#xA;생각 정리&#xA;AI 분석이 들어갈 때 왜 별도 스키마로 나누는 것이 유리할까요? 스키마 vs. 테이블 분리, 어떤 방식이 어떤 상황에 적합할까요? 향후 pgvector 또는 AI 모델 결과를 넣기 위해 어떻게 테이블을 확장할 수 있을까요? # AI 분석이 들어갈 때 왜 별도 스키마로 나누는 것이 유리할까요? AI 분석이 포함된 시스템에서 데이터를 다룰 때, 별도 스키마로 나누는 것이 유리한 이유는 (1) 데이터의 사용 목적이 다르기 때문이고, (2) 데이터의 구조와 속성이 근본적으로 다르기 때문입니다.</description>
    </item>
    <item>
      <title>DBSCAN #2 슈도코드</title>
      <link>http://localhost:1313/docs/study/ai/ai9/</link>
      <pubDate>Mon, 28 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai9/</guid>
      <description>DBSCAN #2 슈도코드 # #2025-07-28&#xA;1 # Input: - D: 데이터 포인트 집합 - eps: 이웃 거리 임계값 - minPts: 최소 이웃 수 (밀도 기준) Output: - cluster_labels: 각 데이터 포인트에 대한 클러스터 라벨 (노이즈는 -1) Initialize: - cluster_id ← 0 - label[x] ← UNVISITED for all x in D 데이터 집합 D, 파라미터 eps와 minPts가 들어간다.&#xA;2 # For each point x in D: If label[x] ≠ UNVISITED: continue N ← regionQuery(x, eps) // x 주변의 eps 이내 이웃 포인트 탐색 If |N| &amp;lt; minPts: label[x] ← NOISE // Else: // cluster_id ← cluster_id + 1 // expandCluster(x, N, cluster_id, eps, minPts, label) Function regionQuery(x, eps): return { all points y in D such that distance(x, y) ≤ eps } 주석 처리 안된 부분만 보기.</description>
    </item>
    <item>
      <title>DBSCAN: #1 1D 클러스터링의 성능 평가</title>
      <link>http://localhost:1313/docs/study/ai/ai8/</link>
      <pubDate>Mon, 28 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai8/</guid>
      <description>DBSCAN: #1 1D 클러스터링의 성능 평가 # #2025-07-28&#xA;1. Problem # 클러스터 응집도는 보통 클러스터 내 데이터 간의 평균 거리나 분산, 혹은 실루엣 계수처럼 군집 내 응집도와 군집 간 분리도를 동시에 평가한다.&#xA;하지만 1차원 데이터에서는 클러스터 응집도(Cluster Cohesion) 또는 실루엣 계수(Silhouette coefficient) 같은 지표가 잘 작동하지 않는다.&#xA;2. 클러스터 응집도 # 클러스터링 성능을 평가하는 지표 중 하나인 응집도(Cohesion)는 클러스터 내부의 데이터들이 얼마나 서로 가까운지를 측정하는 지표다. 대표적으로는 클러스터 내 모든 점 간의 평균 거리, 클러스터 중심과 각 점 사이의 평균 거리, 혹은 분산을 사용하는 방식 등이 있다.</description>
    </item>
    <item>
      <title>DMR 분석 (methylKit)</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi31/</link>
      <pubDate>Mon, 28 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi31/</guid>
      <description>DMR 분석 (methylKit) # #2025-07-28&#xA;# #1 Load packages&#xA;library(&amp;#34;methylKit&amp;#34;) library(&amp;#34;genomation&amp;#34;) library(&amp;#34;GenomicRanges&amp;#34;) # #2 Set path&#xA;setwd(&amp;#34;/data/home/ysh980101/2309_5-aza/Bismark/sorted_n&amp;#34;) getwd() &amp;#39;/data1/home/ysh980101/2309_5-aza/Bismark/sorted_n&amp;#39; # #3 Load data&#xA;# Define the list containing the bismark coverage files. covlist &amp;lt;- list( &amp;#34;KEB1/KEB01_1_bismark_bt2_pe.sorted_n.deduplicated.bismark.cov.gz&amp;#34;, &amp;#34;KEB2/KEB02_1_bismark_bt2_pe.sorted_n.deduplicated.bismark.cov.gz&amp;#34;, &amp;#34;KEB4/KEB04_1_bismark_bt2_pe.sorted_n.deduplicated.bismark.cov.gz&amp;#34;) myobj_lowCov &amp;lt;- methRead(covlist, sample.id=list(&amp;#34;KEB01&amp;#34;,&amp;#34;KEB02&amp;#34;,&amp;#34;KEB04&amp;#34;), pipeline = &amp;#34;bismarkCoverage&amp;#34;, assembly=&amp;#34;hg38&amp;#34;, treatment=c(0,1,2), mincov = 3 ) tiles &amp;lt;- tileMethylCounts(myobj_lowCov,win.size=1000,step.size=1000,cov.bases = 3 tiles.norm &amp;lt;- normalizeCoverage(tiles, method = &amp;#34;median&amp;#34;) meth.tiles &amp;lt;- unite(tiles.norm, destrand=FALSE) meth.tiles meth.tilesDf = getData(meth.</description>
    </item>
    <item>
      <title>Influenza 시퀀스 크롤링 (Selenium)</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi28/</link>
      <pubDate>Mon, 28 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi28/</guid>
      <description>Influenza 시퀀스 크롤링 (Selenium) # #2025-07-28&#xA;1. Load package # import pandas as pd import numpy as np import os # 2. Set path # os.chdir(&amp;#39;/Users/yshmbid/Desktop/workspace/gisaid&amp;#39;) os.getcwd() &amp;#39;/Users/yshmbid/Desktop/workspace/gisaid&amp;#39; # 3. Run crawling # # ChromeDriver 경로를 설치하고 Service 객체로 전달 chrome_service = Service(ChromeDriverManager().install()) try: # ChromeDriver 실행 crawler = webdriver.Chrome(service=chrome_service) except: # 크롬드라이버가 없을 때 autoinstaller로 설치 chromedriver_autoinstaller.install(True) crawler = webdriver.Chrome(service=chrome_service) crawler.implicitly_wait(6) # 크롤러 대기 시간 설정 crawler.get(&amp;#39;https://gisaid.org/&amp;#39;) # 웹사이트 열기 # login 선택 engine = WebDriverWait(crawler, 10).</description>
    </item>
    <item>
      <title>MAFFT 작업 #1 Fasta 파일 전처리</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi29/</link>
      <pubDate>Mon, 28 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi29/</guid>
      <description>MAFFT 작업 #1 Fasta 파일 전처리 # #2025-07-28&#xA;1. Load package # import pandas as pd import numpy as np import os import matplotlib.pyplot as plt import random os.sys.path.append(&amp;#34;/data/home/ysh980101/2410/Mutclust2&amp;#34;) from Bin.sc import * # 2. Objective # Influenza type A의 H1N1 strain의 fasta 파일을 확인해보면?&#xA;&amp;gt;로 시작하는 행에 해당 시퀀스의 메타데이터가 있고&#xA;다음 &amp;gt;로 시작하는 행 이전까지 해당 시퀀스 정보가 있다.&#xA;&amp;gt;로 시작하는 행을 |로 분리했을때 제일 마지막값에 유전자 정보가 있다.</description>
    </item>
    <item>
      <title>MAFFT 작업 #2 MAFFT 실행</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi30/</link>
      <pubDate>Mon, 28 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi30/</guid>
      <description>MAFFT 작업 #2 MAFFT 실행 # #2025-07-28&#xA;1. Objective # Influenza의 Reference squence는 길이가 fix되어있지만,&#xA;각 sequence는 삽입/탈락 mutation이 일어남에 따라 모두 길이가 같지 않다. 이 길이를 맞춰주는 padding을 하기 위해 MAFFT를 이용해 정렬(Multiple Sequence Alignment)한다. # 2. MAFFT 실행 bash script # #data&#xA;/Influenza └── Preprocessed/ ├── HA/ │ ├── A-H1N1.fasta │ ├── A-H1N1.fasta │ ├── ... │ └── B.fasta └── ... └── (HA와 동일 구조) └── MAFFT/ └── (empty) #!</description>
    </item>
    <item>
      <title>MutClust 슈도코드 작성하기</title>
      <link>http://localhost:1313/docs/study/ai/ai10/</link>
      <pubDate>Mon, 28 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai10/</guid>
      <description>MutClust 슈도코드 작성하기 # #2025-07-28&#xA;1 # Input: - D: 데이터 포인트 집합 - Efactor: 이웃 거리 조정값 - DiminFactor: 클러스터 경계 조정값 - minPts: 최소 이웃 수 (밀도 기준) Output: - cluster_labels: 각 데이터 포인트에 대한 클러스터 라벨 (노이즈는 -1) Initialize: - cluster_id ← 0 - Label[x] ← UNVISITED for all x in D 데이터 집합 D, 파라미터 eps와 minPts가 들어간다.&#xA;2. H-중요도 계산 # For each point x in D: x.</description>
    </item>
    <item>
      <title>Hugo #4 Markdown HTML 렌더링 문제</title>
      <link>http://localhost:1313/docs/study/fe/fe3/</link>
      <pubDate>Thu, 24 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/fe/fe3/</guid>
      <description>Hugo #4 Markdown HTML 렌더링 문제 # #2025-07-24&#xA;1. 문제 # &amp;lt;details&amp;gt; &amp;lt;summary&amp;gt; 토글 &amp;lt;/summary&amp;gt; 토글 내용 &amp;lt;/details&amp;gt; Hugo book Theme는 원래 위 코드를 작성하면 아래처럼 토글이 나온다.&#xA;토글 토글 내용 어느날부터 갑자기 토글이든 문단나누기든 다 안먹어서, 근데 원인을 몰라서 그냥 shortcode 기능 없는대로 쓰다가, 너무 불편해서 좀 찾아봤고 hugo.toml에 다음 내용 넣어준 뒤로는 잘 작동했다.&#xA;[markup] [markup.goldmark] [markup.goldmark.renderer] unsafe = true 근데 이후에 html 관련 포스팅을 작성했는데 넣어준 코드가 다 깨졌다.</description>
    </item>
    <item>
      <title>JavaScript #1 쇼핑몰 주문 처리</title>
      <link>http://localhost:1313/docs/study/fe/fe2/</link>
      <pubDate>Wed, 23 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/fe/fe2/</guid>
      <description>JavaScript #1 쇼핑몰 주문 처리 # #2025-07-23&#xA;1. 문제 # 당신은 온라인 쇼핑몰의 개발자로, 고객 주문을 처리하는 프로그램을 작성하고 있습니다. 주문 처리 과정에서는 여러 조건을 고려해야 합니다. 예를 들어, 상품의 재고 여부, 고객의 회원 등급, 주문 금액, 배송 옵션 등을 확인하여 적절한 메시지와 할인율을 적용해야 합니다. 아래의 세부 조건에 맞도록 JavaScript 함수를 구현하고, 최종 결과를 console.log 또는 alert로 출력해보세요.&#xA;#세부 조건&#xA;상품 재고 확인&#xA;재고가 1개 이상일 경우: 주문을 진행한다.</description>
    </item>
    <item>
      <title>netMHCpan 작업 #1 환자 시퀀스 생성</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi24/</link>
      <pubDate>Wed, 23 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi24/</guid>
      <description>netMHCpan 작업 #1 환자 시퀀스 생성 # #2025-07-23&#xA;path&#xA;data/ ├── clusters.tsv ├── meta.csv └── codon ├── reference_codon.csv └── *.codon.csv (*: patient id) # #1 Load package&#xA;import pandas as pd import numpy as np import os import sys import re sys.path.append(&amp;#39;/data/home/ysh980101/2409/bin&amp;#39;) from mhc_epitope import * # #2 Load data&#xA;import pandas as pd import os def make_sequence_df(): # 참조 시퀀스 파일 불러오기 및 컬럼 이름 변경 ref_sequence = pd.</description>
    </item>
    <item>
      <title>netMHCpan 작업 #2 HLA-I 펩타이드 추출</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi25/</link>
      <pubDate>Wed, 23 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi25/</guid>
      <description>netMHCpan 작업 #2 HLA-I 펩타이드 추출 # #2025-07-23&#xA;# #1 Patient id 추출&#xA;#data&#xA;data/ ├── c315 │ └── allprot.fasta └── c442 └── allprot.fasta #patients.bash&#xA;#!/bin/bash # FASTA에서 patient ID 추출하여 patient_id.txt로 저장 ALLPROT_PATH=&amp;#34;data/c315/allprot.fasta&amp;#34; OUT_FILE=&amp;#34;data/patient_id.txt&amp;#34; # 스크립트가 있는 디렉터리로 이동 cd &amp;#34;$(dirname &amp;#34;$0&amp;#34;)&amp;#34; # patient_id.txt 파일 초기화 &amp;gt; &amp;#34;$OUT_FILE&amp;#34; # FASTA 파일에서 ID 추출 grep &amp;#34;^&amp;gt;&amp;#34; &amp;#34;$ALLPROT_PATH&amp;#34; | cut -d&amp;#39;|&amp;#39; -f1 | sed &amp;#39;s/^&amp;gt;//&amp;#39; &amp;gt;&amp;gt; &amp;#34;$OUT_FILE&amp;#34; #result&#xA;data/ ├── c315 │ └── allprot.</description>
    </item>
    <item>
      <title>netMHCpan 작업 #3 HLA-peptide affinity 분석</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi26/</link>
      <pubDate>Wed, 23 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi26/</guid>
      <description>netMHCpan 작업 #3 HLA-peptide affinity 분석 # #2025-07-23&#xA;#data&#xA;data/ ├── c315 │ ├── allprot.fasta │ └── * (*: patient id) │ ├── proteome.fasta │ └── peptides_HLA-I.csv ├── c442 │ └── (c315와 동일한 구조로 생성됨) ├── patient_id.txt └── common_mhc.txt # #predict_affinity.bash&#xA;#!/bin/bash # 입력: # 1) 클러스터명 (예: c315) # 2) 병렬 프로세스 수 (NUM_PROC) # 출력: # 환자별 binding_affinities_HLA-I.csv CLUSTER=$1 NUM_PROC=$2 netMHCpan=&amp;#34;../netMHCpan-4.1/netMHCpan&amp;#34; OUT_DIR=&amp;#34;data/${CLUSTER}&amp;#34; PATIENT_TXT=&amp;#34;data/patient_id.txt&amp;#34; HLA_I_ALLELES_FILE=&amp;#34;data/common_mhc.txt&amp;#34; # 스크립트가 있는 디렉터리로 이동 cd &amp;#34;$(dirname &amp;#34;$0&amp;#34;)&amp;#34; # 환자별로 netMHCpan 예측 수행 while read -r PATIENT_ID; do PATIENT_DIR=&amp;#34;$OUT_DIR/$PATIENT_ID&amp;#34; RAW_DIR=&amp;#34;$PATIENT_DIR/raw_predictions&amp;#34; mkdir -p &amp;#34;$RAW_DIR&amp;#34; PEPTIDES_TABLE=&amp;#34;$PATIENT_DIR/peptides_HLA-I.</description>
    </item>
    <item>
      <title>netMHCpan 작업 #4 결과 확인 및 heatmap 시각화</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi27/</link>
      <pubDate>Wed, 23 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi27/</guid>
      <description>netMHCpan 작업 #4 결과 확인 및 heatmap 시각화 # #2025-07-23&#xA;# #1 netMHCpan 결과 확인&#xA;#data&#xA;data/ ├── c315 │ └── * (*: patient id) │ ├── peptides_HLA-I.csv │ └── binding_affinities_HLA-I.csv ├── c442 │ └── (c315와 동일한 구조로 생성됨) └── patient_id.txt result/ └── (empty) # Load package import pandas as pd import numpy as np import os # Load patient id f = open(&amp;#34;/data/patient_id.txt&amp;#34;, &amp;#34;r&amp;#34;) patients = f.read().split(&amp;#34;\n&amp;#34;) # Merge epitope table hotspots = [&amp;#34;c315&amp;#34;, &amp;#34;c442&amp;#34;] peptide_df_list = [] for hotspot in hotspots: for patient in patients: peptide_df = pd.</description>
    </item>
    <item>
      <title>TFT 항생제 연구 #1 연구 방향</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi12/</link>
      <pubDate>Wed, 23 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi12/</guid>
      <description>TFT 항생제 연구 #1 연구 방향 # #2025-07-23&#xA;(#2025-05-31 작성)&#xA;#1&#xA;사용하고자 하는 데이터는?&#xA;feature Clinical feature (17, float): Creatinine, Hemoglobin, LDH, Lymphocytes, Neutrophils, Platelet count, WBC count, hs-CRP, D-Dimer, BDTEMP, BREATH, DBP, SBP, PULSE, SPO2, O2_APPLY Antibiotics feature (2, str) Treatment (list, str): 투여한 항생제, 결측값일수도있고 2개 이상일수도 있음 Strain (str): 환자가 감염된 균주, 1개 NEWS (int): 중증도 Code (int/str): 환자 등록번호 time-series 10개 시점 (항생제 투여 기준 D-3 ~ D+6) TFT input 형식은?</description>
    </item>
    <item>
      <title>TFT 항생제 연구 #2 입력 시퀀스 생성</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi13/</link>
      <pubDate>Wed, 23 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi13/</guid>
      <description>TFT 항생제 연구 #2 입력 시퀀스 생성 # #2025-07-23&#xA;1. Load package # %load_ext autoreload %autoreload 2 import sys import pandas as pd import numpy as np import os import pickle import ast sys.path.append(&amp;#39;/data3/projects/2025_Antibiotics/YSH/bin&amp;#39;) from sc import * os.chdir(&amp;#39;/data3/projects/2025_Antibiotics/YSH/workspace&amp;#39;) 2. Load raw data # #data&#xA;/data ├── PreprocessedData/ │ └── TimecourseData/ │ └── * (*: patient id) │ ├── SeverityScore.csv │ ├── Laboratory_processed.csv │ └── Medication.csv ├── PreprocessedData_knuh/ │ └── (PreprocessedData와 동일) └── 병원체자원은행 균주현황(2014-2024.</description>
    </item>
    <item>
      <title>TFT 항생제 연구 #3 입력 feature 생성</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi14/</link>
      <pubDate>Wed, 23 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi14/</guid>
      <description>TFT 항생제 연구 #3 입력 feature 생성 # #2025-07-23&#xA;1. Load package # %load_ext autoreload %autoreload 2 import sys import pandas as pd import numpy as np import os import pickle import ast sys.path.append(&amp;#39;/data3/projects/2025_Antibiotics/YSH/bin&amp;#39;) from sc import * os.chdir(&amp;#39;/data3/projects/2025_Antibiotics/YSH/workspace&amp;#39;) 2. Make feature1 # #data&#xA;/data └── all_meds.txt /data_knuch └── sequence └── *.pkl (*: antibiotics) /data_knuh └── sequence └── *.pkl (*: antibiotics) medinfo = &amp;#39;/data/all_meds.txt&amp;#39; with open(medinfo, &amp;#39;r&amp;#39;) as f: meds = [line.</description>
    </item>
    <item>
      <title>TFT 항생제 연구 #4 모델 학습</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi15/</link>
      <pubDate>Wed, 23 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi15/</guid>
      <description>TFT 항생제 연구 #4 모델 학습 # #2025-07-23&#xA;1. Load package # import pytorch_lightning as pl from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor from pytorch_lightning.loggers import TensorBoardLogger from pytorch_forecasting import TimeSeriesDataSet from pytorch_forecasting.models import TemporalFusionTransformer from pytorch_forecasting.models.baseline import Baseline from pytorch_forecasting.metrics import QuantileLoss from pytorch_forecasting.metrics import MAE from pytorch_forecasting.data import GroupNormalizer, NaNLabelEncoder import numpy as np import pandas as pd import torch import pickle import matplotlib.pyplot as plt #data&#xA;/data └── Sequence.</description>
    </item>
    <item>
      <title>HTML #1 프로필 웹페이지 작성</title>
      <link>http://localhost:1313/docs/study/fe/fe1/</link>
      <pubDate>Tue, 22 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/fe/fe1/</guid>
      <description>HTML #1 프로필 웹페이지 작성 # #2025-07-22&#xA;1 # #구조&#xA;/HTML ├── 자기소개1.html ├── 자기소개2.html └── media/ ├── 증명사진.jpg ├── blog.jpg ├── net1.jpg ├── net2.jpg ├── net3.jpg ├── net4.jpg └── playlist.jpg #코드&#xA;&amp;lt;!DOCTYPE html&amp;gt; &amp;lt;html lang=&amp;#34;ko&amp;#34;&amp;gt; &amp;lt;head&amp;gt; &amp;lt;meta charset=&amp;#34;UTF-8&amp;#34;&amp;gt; &amp;lt;title&amp;gt;윤소현의 프로필&amp;lt;/title&amp;gt; &amp;lt;/head&amp;gt; &amp;lt;body&amp;gt; &amp;lt;!-- 헤더 --&amp;gt; &amp;lt;header&amp;gt; &amp;lt;h1&amp;gt;윤소현의 프로필&amp;lt;/h1&amp;gt; &amp;lt;/header&amp;gt; &amp;lt;!-- 자기소개 섹션 --&amp;gt; &amp;lt;section&amp;gt; &amp;lt;h2&amp;gt;자기소개&amp;lt;/h2&amp;gt; &amp;lt;p&amp;gt;안녕하세요! 저는 윤소현입니다. 생명공학과 바이오인포메틱스를 전공하였습니다. 취미는 넷플릭스, 음악 감상 입니다.&amp;lt;/p&amp;gt; &amp;lt;/section&amp;gt; &amp;lt;!-- 정보 목록 섹션 --&amp;gt; &amp;lt;section&amp;gt; &amp;lt;h2&amp;gt;취미&amp;lt;/h2&amp;gt; &amp;lt;ul&amp;gt; &amp;lt;li&amp;gt;넷플릭스&amp;lt;/li&amp;gt; &amp;lt;li&amp;gt;음악 감상&amp;lt;/li&amp;gt; &amp;lt;li&amp;gt;산책&amp;lt;/li&amp;gt; &amp;lt;/ul&amp;gt; &amp;lt;/section&amp;gt; &amp;lt;!</description>
    </item>
    <item>
      <title>Linux #1 NPM 과 PIP 명령어 목록</title>
      <link>http://localhost:1313/docs/study/be/be1/</link>
      <pubDate>Tue, 22 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be1/</guid>
      <description>Linux #1 NPM 과 PIP 명령어 목록 # #2025-07-22&#xA;1. NPM (Node Package Manager) # 패키지 설치&#xA;npm install &amp;lt;패키지명&amp;gt; - 패키지 설치 npm install -g &amp;lt;패키지명&amp;gt; - 전역 설치 npm install --save-dev &amp;lt;패키지명&amp;gt; - 개발 의존성으로 설치 npm install - package.json의 모든 의존성 설치 패키지 관리&#xA;npm uninstall &amp;lt;패키지명&amp;gt; - 패키지 제거 npm update &amp;lt;패키지명&amp;gt; - 패키지 업데이트 npm list - 설치된 패키지 목록 보기 npm list -g - 전역 설치된 패키지 목록 프로젝트 관리</description>
    </item>
    <item>
      <title>RDE #1 Local PC에서 RDE 환경 구성</title>
      <link>http://localhost:1313/docs/study/be/be2/</link>
      <pubDate>Mon, 21 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be2/</guid>
      <description>RDE #1 Local PC에서 RDE 환경 구성 # #2025-07-22&#xA;1 # Docker Desktop 설치 링크 - https://www.docker.com/products/docker-desktop/&#xA;RdE Container download Harbor registry로부터 이미지 다운로드 (*에 이미지 경로)&#xA;docker pull * 다운로드 확인하면?&#xA;잘들어가있다!&#xA;# 2 # Local RDE 설치하기 https://mattermost..com 접속해서 다운로드. (: 링크 블라인드처리)&#xA;실행 아이콘 클릭해서 실행&#xA;============================================= RDE Launcher 시작 중... ============================================= 시작 시간: 2025-07-22 16:55:56 작업 디렉토리: /Users/yshmbid/rde 실행 파일: rde-launcher-macos-arm64 로그 파일: /Users/yshmbid/rde/rde-launcher.log 작업 디렉토리로 이동했습니다.</description>
    </item>
    <item>
      <title>개발환경 설정 (GIT, Docker, VScode, RDE 컨테이너)</title>
      <link>http://localhost:1313/docs/study/be/be4/</link>
      <pubDate>Mon, 21 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be4/</guid>
      <description>개발환경 설정 (GIT, Docker, VScode, RDE 컨테이너) # #2025-07-21&#xA;1. GIT 사용자 정보 설정 # [Git 설치 확인] git --version [사용자 이름 설정] git config --global user.name &amp;#34;윤소현&amp;#34; [이메일 주소 설정] GitHub에 등록된 이메일 주소와 일치하는지 확인 필요 git config --global user.email &amp;#34;yshggid@gmail.com&amp;#34; [설정 확인] git config --global --list 2. 로컬 GIT Repository 생성 # vscode에서 좌측 SOURCE CONTRIL 아이콘 &amp;gt; Initialize Repository &amp;gt; 로컬 폴더를 git repository로 생성</description>
    </item>
    <item>
      <title>RAG #2 출력 파서의 개념, Pydantic/Json 출력 파서</title>
      <link>http://localhost:1313/docs/study/ai/ai2/</link>
      <pubDate>Sat, 19 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai2/</guid>
      <description>RAG #2 출력 파서의 개념, Pydantic/Json 출력 파서 # #2025-07-19&#xA;1. 출력 파서의 개념과 종류 그리고 세가지 주요 메서드 # 출력 파서(output parser)는 LLM에서 생성된 응답을 받아서 우리가 원하는 형식으로 변환해주는 역할을 한다. 쉽게 말해, LLM은 텍스트만 생성하지만 우리는 그 텍스트를 리스트, 딕셔너리, JSON, 숫자 등 구조화된 데이터로 바꾸어서 프로그램에 넘기거나, 다음 단계 체인으로 활용하길 원할 때가 많다. 출력 파서는 이 연결고리 역할을 한다. 출력 파서는 LLM이라는 기계가 말한 인간 언어를 다시 기계가 이해할 수 있는 언어로 &amp;lsquo;번역&amp;rsquo;하는 통역사 같은 존재이다.</description>
    </item>
    <item>
      <title>RAG #3 자동 대화 이력 관리</title>
      <link>http://localhost:1313/docs/study/ai/ai3/</link>
      <pubDate>Sat, 19 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai3/</guid>
      <description>RAG #3 자동 대화 이력 관리 # #2025-07-19&#xA;1. 자동 대화 이력 관리 # ChatPromptTemplate을 통해 시스템 메시지를 포함하는 프롬프트를 만든다. 시스템 메시지는 모델에게 “너는 금융 상담사야”라고 역할을 부여하는 것이다. 이어지는 (&amp;quot;placeholder&amp;quot;, &amp;quot;{messages}&amp;quot;)는 실제 사용자의 질문과 AI의 답변이 이 자리에 채워질 것이라는 의미다. 이 프롬프트는 chat = ChatOpenAI(model=&amp;quot;gpt-4o-mini&amp;quot;)와 연결되는데, 이는 OpenAI의 gpt-4o-mini 모델을 사용하는 챗 인터페이스이다. 이 프롬프트와 모델을 prompt | chat이라는 LCEL 표현으로 묶으면, 하나의 체인이 만들어진다. 이 체인은 주어진 메시지 목록을 받아, GPT 모델에 전달하고 응답을 생성하는 구조다.</description>
    </item>
    <item>
      <title>RAG #1 랭체인, LCEL, 프롬프트</title>
      <link>http://localhost:1313/docs/study/ai/ai1/</link>
      <pubDate>Thu, 17 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai1/</guid>
      <description>RAG #1 랭체인, LCEL, 프롬프트 # #2025-07-17&#xA;1. 랭체인 생태계의 주요 패키지 # 랭체인(LangChain)은 LLM(Large Language Model)을 활용한 애플리케이션을 쉽게 만들 수 있도록 돕는 프레임워크이다. 이 생태계는 단일 라이브러리로 구성된 것이 아니라 여러 개의 하위 패키지로 나뉘어 있고, 각각의 역할이 명확하게 분리되어 있다. 랭체인의 주요 목적은 LLM을 단순한 텍스트 생성 도구가 아니라, 여러 시스템과 결합하여 유의미한 작업을 수행하는 &amp;ldquo;생각하고 행동하는&amp;rdquo; 에이전트로 만드는 것이다. 이 생태계의 핵심 구성 요소들을 쉽게 설명하자면, 마치 LLM이라는 뇌에 주변 감각기관과 기억장치, 도구들, 그리고 의사결정 능력을 붙여주는 것이라고 보면 된다.</description>
    </item>
    <item>
      <title>카페 코잔타</title>
      <link>http://localhost:1313/docs/hobby/daily/daily18/</link>
      <pubDate>Sat, 12 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/daily/daily18/</guid>
      <description>카페 코잔타 # #2025-07-12&#xA;여름 분위기 그자체였던 카페 코잔타 ㅎㅎ&#xA;브런치카페긴 한데 밥을 먹고가서 초코브라우니랑 당근케이크를 시켰다. 브라우니는 무난했구 당근케이크가 좀 맛있었는데 인스타 찾아보니까 실제로도 요게 제일 잘나가는듯 ㅎ&#xA;그리고 커피가 진짜 맛있었다!!! 나는 오트라떼 마셨는데 내기준 1위인 폴바셋 오트라떼에 준하는 엄청 맛있는 라떼였다 ㅎㅎㅎ 그리고 컵이 진짜 이뻤음&#xA;별채 소품샵도 구경했는데 ㅎ 카페랑 한몸인듯한 감성이었다 키링 그릇 이런거 판매중이었고 이쁘다고 생각한 컵도 팔고있었는데 5마넌이어서 그냥 나옴 ㅋㅋㅎ&#xA;카페메뉴 3마넌이상 구매해서 캘린더두 받았당</description>
    </item>
    <item>
      <title>2025 하반기 일정</title>
      <link>http://localhost:1313/docs/study/career/career6/</link>
      <pubDate>Sat, 05 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/career/career6/</guid>
      <description>2025 하반기 일정 # #2025-07-05&#xA;1. 졸업 일정 # 2025학년도 1학기 대학원 수료생 등록 안내 https://cse.knu.ac.kr/bbs/board.php?bo_table=sub5_1&amp;wr_id=28393&amp;sca=대학원&amp;amp;page=3&#xA;신청-2025. 2. 24.(월)~2. 26.(수) 등록-2025. 3. 10.(월)~3. 11.(화) 2025학년도 1학기 대학원생 연구윤리교육 시행 안내 https://cse.knu.ac.kr/bbs/board.php?bo_table=sub5_1&amp;wr_id=28426&amp;sca=대학원&amp;amp;page=3&#xA;수강신청-2025. 3. 5.(수)~3. 10.(월) 교육기간-2025. 3. 12.(수)~6. 23.(월) 2025학년도 1학기 재학생 등록금 수납 https://cse.knu.ac.kr/bbs/board.php?bo_table=sub5_1&amp;wr_id=28429&amp;sca=대학원&amp;amp;page=3&#xA;납부기간-2025. 2. 18.(화) 9:00 ~ 2. 21.(금) 16:00 고지서 출력-2025. 2. 15.(토) 14:00부터 조회 가능 2025.1학기 학위논문 제출 예정자 신청안내 https://cse.knu.ac.kr/bbs/board.php?bo_table=sub5_1&amp;wr_id=28447&amp;sca=대학원&amp;amp;page=2&#xA;신청기간-2025. 3. 17.(월)~3. 19.</description>
    </item>
    <item>
      <title>파인만 공부법</title>
      <link>http://localhost:1313/docs/hobby/book/book48/</link>
      <pubDate>Sat, 05 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/book/book48/</guid>
      <description>파인만 공부법 # #2025-07-05&#xA;#1&#xA;정전기학에 관한 내용처럼 어려운 부분을 만나면 저만의 요령이 하나 있었습니다.&#xA;뭐냐면 처음 두세 문단이 이해가 안 되더라도 내용 전체를 읽어요. 처음에는 전체를 흐릿하게 이해하지만 다시 읽으면 조금 나아지고 계속 그러다 보면 전부 이해가 되지요(예외도 있는데 그건 나중에 설명하겠습니다). 그다음 책에다 요점을 적어놓으면 완성됩니다. 가령 타원형 축전기의 정전용량 계산 같은 건 건너뛰는데, 내용 전체를 읽어보면 그런 기능이나 복잡한 계산은 뒤에 다시 나오지 않는 지엽적인 사안임을 이미 알기 때문이지요.</description>
    </item>
    <item>
      <title>나눔과 버팀</title>
      <link>http://localhost:1313/docs/hobby/book/book46/</link>
      <pubDate>Fri, 04 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/book/book46/</guid>
      <description>나눔과 버팀 # #2025-07-04&#xA;#1&#xA;짧고 평범한 인생이지만 그래도 살면서 한 가지 명확해진 사실이 있다. 인생은 그야말로 운의 상승과 하락의 반복이라는 점이다. 언뜻 보면, 모든 것은 자신의 노력이나 선택에 달려 있을 것 같지만, 실상은 그렇지 않다. 어떤 때는 아무리 노력해도 모든 것이 뜻대로 풀리지 않고, 반대로 마치 모든 일이 잘될 운명인 듯 일이 술술 풀리기도 한다.&#xA;가장 먼저 깨달은 것은, 모든 것이 잘 풀리는 운의 상승기에 있을 때야말로 주위 사람들에게 아낌없이 베풀어야 한다는 사실이다.</description>
    </item>
    <item>
      <title>비정상성, 궤도의 이탈과 행복</title>
      <link>http://localhost:1313/docs/hobby/book/book45/</link>
      <pubDate>Thu, 03 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/book/book45/</guid>
      <description>비정상성, 궤도의 이탈과 행복 # #2025-07-03&#xA;#1&#xA;‘행복이란 무엇인가?’라는 질문을 보면 어떠한 생각이 드는가? 너무 닳고 닳은 질문이면서 질문 자체가 명확할 수 없는 난제다. 사실 행복한 순간에는 이 질문이 떠오르지 않는다. 그럴 필요가 없기 때문이다. 지금 불만 없고 행복한데 저런 쓰잘머리 없는 질문이 떠오를 이유가 없다. 저 질문이 떠올랐다는 건 애초에 지금 행복하지 않고 불만이 많은 것이다.&#xA;사실 이 답도 없는 질문은 평생 죽을 때까지 내 곁에 있을 것 같다.</description>
    </item>
    <item>
      <title>가치</title>
      <link>http://localhost:1313/docs/hobby/daily/blog1/</link>
      <pubDate>Wed, 02 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/daily/blog1/</guid>
      <description>가치 # #2025-07-02&#xA;#1&#xA;나는왜케 커리어욕심을 내는지?&#xA;내가 중요하게 생각하는것은 사람과 성취감이다. 살면서 주변으로 접하는사람들이랑 좋은시간을 보내는게 행복하고 무언가를 노력해서 얻었을때 행복하다 그리고 그 성취라는게 대단한게 아니라 이쁜쿠키를 구웠을때도 마싯는커피를 내렷을때도 성취감은 든다. 꼭 NLP 모델링이어야하는 이유가 있나?&#xA;면접이 애매했던 이유도 그건거같다 지원동기가 애매했다. 면접관들도 의아했을것이다 지원동기가 명확하지 않은데 어떻게이렇게 의지가명확한지? 사실 이번&amp;rsquo;면접&amp;rsquo;에 붙고싶던 이유는 명확했다 &amp;lsquo;나도 대기업 갈수있는 사람인걸 인정받고 싶어&amp;rsquo; &amp;lsquo;이 연구실에 남아있는것 말고는 할수있는게 없는 사람이 아닌걸 증명하고싶어&amp;rsquo; &amp;lsquo;내가 이정도라는걸 보여주고싶어&amp;rsquo; 하지만 그게 해당 교육과정과 기업에 대한 동기였냐 하면 아니었다 그냥 석사와 취준을하면서 조금내려간 자존감을 이번지원을 통해서 해소하고싶었던거같다.</description>
    </item>
    <item>
      <title>기술적으로 완벽하지 않다는 두려움</title>
      <link>http://localhost:1313/docs/hobby/book/book44/</link>
      <pubDate>Wed, 02 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/book/book44/</guid>
      <description>기술적으로 완벽하지 않다는 두려움 # #2025-07-02&#xA;#1&#xA;이직을 고민할 때마다 내 머릿속을 짓눌렀던 의문이 하나 있었다. “내가 이 일을 그만두고 아예 새로운 다른 일을 할 수 있을까?” 이 의문은 나만의 것이 아니라, 비슷한 길을 걸어온 사람들에게 공통적으로 다가오는 두려움이기도 했다&#xA;그러나 이직을 생각하며 내가 겪어 본 다양한 경험과 그로부터 얻은 깨달음은 나의 두려움을 조금씩 덜어 주었다. 나는 여러 분야에서 다양한 사람들과 일을 하면서 조금씩 알아차렸다. 세상에서 완벽하게 돌아가는 일은 거의 없다는 것을, 그리고 그 속에서 중요한 것은 완벽한 준비보다는 오히려 부딪히며 배우고 적응하는 과정이라는 것을 말이다.</description>
    </item>
    <item>
      <title>지키기 위해서는 변해야 한다</title>
      <link>http://localhost:1313/docs/hobby/book/book42/</link>
      <pubDate>Tue, 01 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/hobby/book/book42/</guid>
      <description>지키기 위해서는 변해야 한다 # #2025-07-01&#xA;#1&#xA;난 그냥 나에게 맞는 직업을 찾아 이동했을 뿐이다. 내 주관적인 적성 그 외에는 어떠한 의미 부여도 가치 판단도 하고 싶지 않다.&#xA;#2&#xA;이직을 고민하면서 가장 핵심으로 생각한 질문은 이것이다. ‘내 인생에서 직장과 관련하여 단 하나를 잡는다면 무엇을 잡을 것이냐?’ 돈인가, 명예인가, 여유인가, 전문성인가, 꿈인가.&#xA;난 신이 아니기에 일을 하면서 모든 것을 얻을 수 없다. 돈도 명예도 여유도 전문성도 꿈도 모든 것을 갖고 싶지만 불완전한 인간이기에 당연히 무엇인가는 놓칠 수밖에 없다.</description>
    </item>
    <item>
      <title>첫면접</title>
      <link>http://localhost:1313/docs/study/career/career5/</link>
      <pubDate>Tue, 01 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/career/career5/</guid>
      <description>첫면접 # #2025-07-01&#xA;새로산기여운케이스랑 마고플레인이랑 저속노화좌 없었으면 멘탈 부셔졌을거같은데 다행히 마무리까지끝냈다&#xA;준비하는동안 24기광수책이랑 정희원의저속노화 너무 읽고싶었는데 이제읽을수있으니까 좋다.</description>
    </item>
  </channel>
</rss>
