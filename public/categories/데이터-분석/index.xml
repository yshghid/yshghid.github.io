<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>데이터 분석 on  </title>
    <link>http://localhost:1313/categories/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%B6%84%EC%84%9D/</link>
    <description>Recent content in 데이터 분석 on  </description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 15 Jan 2026 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/categories/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%B6%84%EC%84%9D/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>데이터 분석 #8 확률밀도, t-검정</title>
      <link>http://localhost:1313/docs/study/ai/ai43/</link>
      <pubDate>Thu, 15 Jan 2026 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai43/</guid>
      <description>데이터 분석 #8 확률밀도, t-검정 # #2026-01-15&#xA;#1 이산과 연속변수&#xA;이산과 연속변수&#xA;암 유전체 데이터에서 1개 위치에 나타는 돌연변이 횟수 같은 정수 데이터 -&amp;gt; 이산(discrete) 변수 실수 값 데이터 -&amp;gt; 연속(continuous) 변수 확률적으로 이 데이터를 처리하기 위해서는 정규분포를 써야한다. # #2 확률밀도&#xA;연속확률분포&#xA;연속확률변수를 표현하기 위해서는 &amp;lsquo;범위&amp;rsquo;를 사용해야한다. 170cm인 사람은 실제로는 169.5~170.5cm 이므로 키를 재보니 170인 사람이 3%였다는 것은 P(키=170)=3% 라고 쓸수없고 P(169.5&amp;lt;키&amp;lt;170.5)=3% 와 같이 써야한다. 연속확률분포로 가장 유명한 것은 정규분포이고 파라미터는 평균과 표준편차.</description>
    </item>
    <item>
      <title>데이터 분석 #7 확률분포, 카이제곱검정</title>
      <link>http://localhost:1313/docs/study/ai/ai41/</link>
      <pubDate>Tue, 13 Jan 2026 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai41/</guid>
      <description>데이터 분석 #7 확률분포, 카이제곱검정 # #2026-01-13&#xA;#1 통계적 유의성&#xA;통계적 유의성&#xA;실험 결과로 나온 수치가 우연인지, 주장을 뒷받침할만큼 확률(빈도)이 높은 것인지 그 의미를 검증할수만 있으면 된다. 어떤 실험 결과가 통계적으로 유의하다는 말은 그 결과가 우연히 일어난 것이 아니라는 것 통계 분석을 통해 어떤 암에서 특정 유전자가 빈번하게 발현되는것을 발견했다고 할때 이것이 우연히 관측된 결과인지 중복된 관찰을 통해 큰 의미가 있는 것으로 결론지을수 있는 것인지 정량적으로 밝힐 수 있다. p-value</description>
    </item>
    <item>
      <title>데이터 분석 #6 pandas numpy 데이터 처리</title>
      <link>http://localhost:1313/docs/study/ai/ai40/</link>
      <pubDate>Fri, 09 Jan 2026 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai40/</guid>
      <description>데이터 분석 #6 pandas numpy 데이터 처리 # #2026-01-09&#xA;#1 데이터 처리&#xA;pandas scipy sklearn&#xA;pandas로 데이터프레임으로 데이터를 확인하고 scipy와 sklearn에서 통계 패키지와 머신러닝 패키지를 사용한다 numpy&#xA;python이 제공하는 머신러닝 패키지는 sklearn인데 이를 사용하려면 numpy를 알아야 한다. tensorflow같은 딥러닝 패키지들이 입출력을 위해 numpy를 사용한다 numpy는 다차원 배열인데 포함된 모든 데이터는 같은 형식이어야한다 머신러닝을 하고싶으면 float 형식으로 만들어진 다차원 배열이 필요하다. pandas 쓰는 이유&#xA;데이터가 표 형식이라도 그 안에는 여러 type의 데이터가 혼재되어 있고 행과 열의 라벨 등이 문자열일것인데, 이를 읽어들이는 도구가 pandas.</description>
    </item>
    <item>
      <title>데이터 분석 #5 bash python과 bioinformatics</title>
      <link>http://localhost:1313/docs/study/ai/ai42/</link>
      <pubDate>Tue, 06 Jan 2026 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai42/</guid>
      <description>데이터 분석 #5 bash python과 bioinformatics # #2026-01-06&#xA;#1 생물정보학의 데이터&#xA;정보학&#xA;서로다른 두 종류의 데이터를 연결해서 새로운 데이터를 만들수있다. 일일이 알고리즘을 설계하고 직접 구현하기가 어렵기 때문에 툴을 사용하면 된다. 다만, 툴을 쓰면서 정보학 지식에 대해서 필요성을 느끼고 지속적으로 갖춰가야한다. ex. 데이터 더미에서 불필요한 부분을 없애는것과 정렬 작업 중 무엇을 먼저 할까? 생물정보학&#xA;수학, 통계, 컴퓨터과학을 이용해서 방대한 양의 생물학 데이터를 분석하고 유전자의 발현과 같은 생명 현상을 이해하는 학문. 질병 관련 단백질 찾기 - 항원항체 반응</description>
    </item>
    <item>
      <title>데이터 분석 #4 리뷰 데이터 분석</title>
      <link>http://localhost:1313/docs/study/ai/ai22/</link>
      <pubDate>Tue, 19 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai22/</guid>
      <description>데이터 분석 #4 리뷰 데이터 분석 # #2025-08-19&#xA;1. 목적 # 리뷰 데이터를 보고&#xA;감성 점수와 평점의 관계 리뷰 길이와 감성 점수의 관계 카테고리별 감성 차이 Review_length가 AI 임베딩 유사도에 영향을 줄 수 있는지 인사이트 생성하기.&#xA;# 2. 코드 # import os import pandas as pd import numpy as np import seaborn as sns import matplotlib.pyplot as plt import matplotlib.pyplot as plt import matplotlib as mpl from sentence_transformers import SentenceTransformer, util # Mac 환경 한글 폰트 설정 plt.</description>
    </item>
    <item>
      <title>데이터 분석 #3 회귀분석</title>
      <link>http://localhost:1313/docs/study/ai/ai17/</link>
      <pubDate>Thu, 07 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai17/</guid>
      <description>데이터 분석 #3 회귀분석 # #2025-08-07&#xA;#1 Oversampling Techinique (p.69-71)&#xA;SMOTE&#xA;소수 클래스 포인트 중 하나를 랜덤하게 고르고 이웃 포인트 k개를 찾고 이 이웃들과의 연결선을 따라 중간 어딘가에 새로운 샘플을 만든다. 즉 원본과 이웃 사이에 위치한 점들을 생성한다. 소수 클래스 포인트들 사이의 직선 위에서만 새로운 데이터를 만들기 때문에 실제로는 decision boundary 근처에서 중요한 데이터를 놓칠 수 있다 Borderline-SMOTE&#xA;소수 클래스의 포인트에 대해 kNN을 수행해서 이웃들을 찾는데 이때 이웃 중에서 과반수 이상이 다수 클래스인 경우 위험한 샘플(danger set)으로 간주된다 즉 이 샘플은 결정 경계에 가깝기 때문에 모델 입장에서 헷갈릴 가능성이 높다.</description>
    </item>
    <item>
      <title>데이터 분석 #2 Preprocessing</title>
      <link>http://localhost:1313/docs/study/ai/ai16/</link>
      <pubDate>Wed, 06 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai16/</guid>
      <description>데이터 분석 #2 Preprocessing # #2025-08-06&#xA;#1 머신러닝 프로세스 (p.25)&#xA;test data가 필요한 이유? hyperparameter tuning을 하면서 validation data는 모델이 이미 참고했다 즉 간접적으로 학습에 영향을 줬기 때문에 모델 학습 과정에서 한번도 보지않은 데이터가 필요함. # #2 Box plot (p.38)&#xA;그림이 7개 차종에서 연비 플롯이라고 가정&#xA;투입됏을때 예측에 긍정적영향을 줄수잇는건?&#xA;납작한애들. 두꺼우면 대표성이 떨어진다. 2번에서 이상치들이 많으니까 잘 처리해야하겠다.&#xA;만약 그림같지 않고 y축 높이가 다 비슷비슷했다면?&#xA;이 변수들이 연비를 결정하는데 큰 영향을 못줌.</description>
    </item>
    <item>
      <title>데이터 분석 #1 기초통계</title>
      <link>http://localhost:1313/docs/study/ai/ai14/</link>
      <pubDate>Tue, 05 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai14/</guid>
      <description>데이터 분석 #1 기초통계 # #2025-08-05&#xA;1. 기술 통계 # #1 IQR (p.34)&#xA;IQR은? 가운데 50%의 거리.&#xA;그림 설명&#xA;그림의 2,3: 각각 IQR의 1.5배 선, median 값 선. 그림의 B: ⚬ 가 많으면 특이값이 많은 것. 그림의 1,2,3: 1,2는 각각 IQR의 1.5배 선이라고 했는데 3과의 거리가 서로 다른 이유는? 1.5배 안쪽에 데이터들이 다 분포해서. 즉max가 1.5배보다 작아서. # #2 변이 계수(Coefficient of Variables)&#xA;평균치가 다른 집단 비교. 변이 계수 = 표준편차 / 평균.</description>
    </item>
  </channel>
</rss>
