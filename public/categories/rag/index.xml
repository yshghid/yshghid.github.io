<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>RAG on  </title>
    <link>http://localhost:1313/categories/rag/</link>
    <description>Recent content in RAG on  </description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 19 Jul 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/categories/rag/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>RAG #2 출력 파서의 개념, Pydantic/Json 출력 파서</title>
      <link>http://localhost:1313/docs/study/ai/ai2/</link>
      <pubDate>Sat, 19 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai2/</guid>
      <description>RAG #2 출력 파서의 개념, Pydantic/Json 출력 파서 # #2025-07-19&#xA;1. 출력 파서의 개념과 종류 그리고 세가지 주요 메서드 # 출력 파서(output parser)는 LLM에서 생성된 응답을 받아서 우리가 원하는 형식으로 변환해주는 역할을 한다. 쉽게 말해, LLM은 텍스트만 생성하지만 우리는 그 텍스트를 리스트, 딕셔너리, JSON, 숫자 등 구조화된 데이터로 바꾸어서 프로그램에 넘기거나, 다음 단계 체인으로 활용하길 원할 때가 많다. 출력 파서는 이 연결고리 역할을 한다. 출력 파서는 LLM이라는 기계가 말한 인간 언어를 다시 기계가 이해할 수 있는 언어로 &amp;lsquo;번역&amp;rsquo;하는 통역사 같은 존재이다.</description>
    </item>
    <item>
      <title>RAG #3 자동 대화 이력 관리</title>
      <link>http://localhost:1313/docs/study/ai/ai3/</link>
      <pubDate>Sat, 19 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai3/</guid>
      <description>RAG #3 자동 대화 이력 관리 # #2025-07-19&#xA;1. 자동 대화 이력 관리 # ChatPromptTemplate을 통해 시스템 메시지를 포함하는 프롬프트를 만든다. 시스템 메시지는 모델에게 “너는 금융 상담사야”라고 역할을 부여하는 것이다. 이어지는 (&amp;quot;placeholder&amp;quot;, &amp;quot;{messages}&amp;quot;)는 실제 사용자의 질문과 AI의 답변이 이 자리에 채워질 것이라는 의미다. 이 프롬프트는 chat = ChatOpenAI(model=&amp;quot;gpt-4o-mini&amp;quot;)와 연결되는데, 이는 OpenAI의 gpt-4o-mini 모델을 사용하는 챗 인터페이스이다. 이 프롬프트와 모델을 prompt | chat이라는 LCEL 표현으로 묶으면, 하나의 체인이 만들어진다. 이 체인은 주어진 메시지 목록을 받아, GPT 모델에 전달하고 응답을 생성하는 구조다.</description>
    </item>
    <item>
      <title>RAG #1 랭체인, LCEL, 프롬프트</title>
      <link>http://localhost:1313/docs/study/ai/ai1/</link>
      <pubDate>Thu, 17 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai1/</guid>
      <description>RAG #1 랭체인, LCEL, 프롬프트 # #2025-07-17&#xA;1. 랭체인 생태계의 주요 패키지 # 랭체인(LangChain)은 LLM(Large Language Model)을 활용한 애플리케이션을 쉽게 만들 수 있도록 돕는 프레임워크이다. 이 생태계는 단일 라이브러리로 구성된 것이 아니라 여러 개의 하위 패키지로 나뉘어 있고, 각각의 역할이 명확하게 분리되어 있다. 랭체인의 주요 목적은 LLM을 단순한 텍스트 생성 도구가 아니라, 여러 시스템과 결합하여 유의미한 작업을 수행하는 &amp;ldquo;생각하고 행동하는&amp;rdquo; 에이전트로 만드는 것이다. 이 생태계의 핵심 구성 요소들을 쉽게 설명하자면, 마치 LLM이라는 뇌에 주변 감각기관과 기억장치, 도구들, 그리고 의사결정 능력을 붙여주는 것이라고 보면 된다.</description>
    </item>
  </channel>
</rss>
