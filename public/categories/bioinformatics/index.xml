<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Bioinformatics on  </title>
    <link>http://localhost:1313/categories/bioinformatics/</link>
    <description>Recent content in Bioinformatics on  </description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 04 Aug 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/categories/bioinformatics/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>MutClust 연구: method contribution</title>
      <link>http://localhost:1313/docs/study/algorithm/algo10/</link>
      <pubDate>Mon, 04 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/algorithm/algo10/</guid>
      <description> MutClust 연구: method contribution # #2025-08-04&#xA;#Paper&#xA;Identification of Severity Related Mutation Hotspots in SARS-CoV-2 Using a Density-Based Clustering Approach&#xA;0. 참여 파트 # #Algorithm └── Computing the H-score └── Density-based mutation hotspot clustering #Omics-analysis └── Selection of severity related hotspots └── Differentially expressed gene analysis └── Evaluation of HLA-peptide affinity #Validation └── Validation on Influenza genome └── K-dist plot </description>
    </item>
    <item>
      <title>EBV DHT 연구:  contribution 정리</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi32/</link>
      <pubDate>Sun, 03 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi32/</guid>
      <description>EBV DHT 연구: contribution 정리 # #2025-08-03&#xA;0. Contribution # #Paper1&#xA;Dihydrotestosterone Enhances MICA-Mediated Immune Responses to Epstein–Barr Virus-Associated Gastric Carcinoma&#xA;#Paper2&#xA;Dihydrotestosterone-androgen receptor signaling suppresses EBV-positive gastric cancer through DNA demethylation-mediated viral reactivation&#xA;#Paper1 └── 3. ChIP-Seq Assay #Paper2 └── 2. RNA-seq analysis └── 14. Bioinformatics analysis of methylome 1. ChIP-Seq Assay # Among the above p65 ChIP samples, the sample treated with 100 nM DHT for 30 min showed the strong p65 enrichment on the SNU719 genome.</description>
    </item>
    <item>
      <title>MAFFT #1 Fasta 파일 전처리</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi29/</link>
      <pubDate>Mon, 28 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi29/</guid>
      <description>MAFFT #1 Fasta 파일 전처리 # #2025-07-28&#xA;1. Load package # import pandas as pd import numpy as np import os import matplotlib.pyplot as plt import random os.sys.path.append(&amp;#34;/data/home/ysh980101/2410/Mutclust2&amp;#34;) from Bin.sc import * 2. Objective # Influenza type A의 H1N1 strain의 fasta 파일을 확인해보면?&#xA;&amp;gt;로 시작하는 행에 해당 시퀀스의 메타데이터가 있고&#xA;다음 &amp;gt;로 시작하는 행 이전까지 해당 시퀀스 정보가 있다.&#xA;&amp;gt;로 시작하는 행을 |로 분리했을때 제일 마지막값에 유전자 정보가 있다. Raw 데이터는 아래와 같이 구성돼있는데</description>
    </item>
    <item>
      <title>MAFFT #2 MAFFT 실행</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi30/</link>
      <pubDate>Mon, 28 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi30/</guid>
      <description>MAFFT #2 MAFFT 실행 # #2025-07-28&#xA;1. Objective # Influenza의 Reference squence는 길이가 fix되어있지만,&#xA;각 sequence는 삽입/탈락 mutation이 일어남에 따라 모두 길이가 같지 않다. 이 길이를 맞춰주는 padding을 하기 위해 MAFFT를 이용해 정렬(Multiple Sequence Alignment)한다. 2. MAFFT 실행 bash script # #data&#xA;/Influenza └── Preprocessed/ ├── HA/ │ ├── A-H1N1.fasta │ ├── A-H1N1.fasta │ ├── ... │ └── B.fasta └── ... └── (HA와 동일 구조) └── MAFFT/ └── (empty) #!</description>
    </item>
    <item>
      <title>methylKit: DMR 분석</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi31/</link>
      <pubDate>Mon, 28 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi31/</guid>
      <description>methylKit: DMR 분석 # #2025-07-28&#xA;1. Load packages # library(&amp;#34;methylKit&amp;#34;) library(&amp;#34;genomation&amp;#34;) library(&amp;#34;GenomicRanges&amp;#34;) 2. Set path # setwd(&amp;#34;/data/home/ysh980101/2309_5-aza/Bismark/sorted_n&amp;#34;) getwd() &amp;#39;/data1/home/ysh980101/2309_5-aza/Bismark/sorted_n&amp;#39; 3. Load data # # Define the list containing the bismark coverage files. covlist &amp;lt;- list( &amp;#34;KEB1/KEB01_1_bismark_bt2_pe.sorted_n.deduplicated.bismark.cov.gz&amp;#34;, &amp;#34;KEB2/KEB02_1_bismark_bt2_pe.sorted_n.deduplicated.bismark.cov.gz&amp;#34;, &amp;#34;KEB4/KEB04_1_bismark_bt2_pe.sorted_n.deduplicated.bismark.cov.gz&amp;#34;) myobj_lowCov &amp;lt;- methRead(covlist, sample.id=list(&amp;#34;KEB01&amp;#34;,&amp;#34;KEB02&amp;#34;,&amp;#34;KEB04&amp;#34;), pipeline = &amp;#34;bismarkCoverage&amp;#34;, assembly=&amp;#34;hg38&amp;#34;, treatment=c(0,1,2), mincov = 3 ) tiles &amp;lt;- tileMethylCounts(myobj_lowCov,win.size=1000,step.size=1000,cov.bases = 3 tiles.norm &amp;lt;- normalizeCoverage(tiles, method = &amp;#34;median&amp;#34;) meth.tiles &amp;lt;- unite(tiles.norm, destrand=FALSE) meth.tiles meth.tilesDf = getData(meth.</description>
    </item>
    <item>
      <title>Selenium: Influenza fasta 파일 크롤링</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi28/</link>
      <pubDate>Mon, 28 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi28/</guid>
      <description>Selenium: Influenza fasta 파일 크롤링 # #2025-07-28&#xA;1. Load package # import pandas as pd import numpy as np import os 2. Set path # os.chdir(&amp;#39;/Users/yshmbid/Desktop/workspace/gisaid&amp;#39;) os.getcwd() &amp;#39;/Users/yshmbid/Desktop/workspace/gisaid&amp;#39; 3. Run crawling # # ChromeDriver 경로를 설치하고 Service 객체로 전달 chrome_service = Service(ChromeDriverManager().install()) try: # ChromeDriver 실행 crawler = webdriver.Chrome(service=chrome_service) except: # 크롬드라이버가 없을 때 autoinstaller로 설치 chromedriver_autoinstaller.install(True) crawler = webdriver.Chrome(service=chrome_service) crawler.implicitly_wait(6) # 크롤러 대기 시간 설정 crawler.get(&amp;#39;https://gisaid.org/&amp;#39;) # 웹사이트 열기 # login 선택 engine = WebDriverWait(crawler, 10).</description>
    </item>
    <item>
      <title>netMHCpan #1 환자 시퀀스 생성</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi25/</link>
      <pubDate>Wed, 23 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi25/</guid>
      <description>netMHCpan #1 환자 시퀀스 생성 # #2025-07-23&#xA;#path&#xA;data/ ├── clusters.tsv ├── meta.csv └── codon ├── reference_codon.csv └── *.codon.csv (*: patient id) 1. Load package # import pandas as pd import numpy as np import os import sys import re sys.path.append(&amp;#39;/data/home/ysh980101/2409/bin&amp;#39;) from mhc_epitope import * 2. Load data # import pandas as pd import os sequence_df = make_sequence_df() sequence_df 3. Make allprot.fasta # # 데이터 로드 sequence_df = make_sequence_df() cluster_df = pd.</description>
    </item>
    <item>
      <title>netMHCpan #2 HLA-I 펩타이드 추출</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi24/</link>
      <pubDate>Wed, 23 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi24/</guid>
      <description>netMHCpan #2 HLA-I 펩타이드 추출 # #2025-07-23&#xA;1. Patient id 추출 # #data&#xA;data/ ├── c315 │ └── allprot.fasta └── c442 └── allprot.fasta #patients.bash&#xA;#!/bin/bash # FASTA에서 patient ID 추출하여 patient_id.txt로 저장 ALLPROT_PATH=&amp;#34;data/c315/allprot.fasta&amp;#34; OUT_FILE=&amp;#34;data/patient_id.txt&amp;#34; # 스크립트가 있는 디렉터리로 이동 cd &amp;#34;$(dirname &amp;#34;$0&amp;#34;)&amp;#34; # patient_id.txt 파일 초기화 &amp;gt; &amp;#34;$OUT_FILE&amp;#34; # FASTA 파일에서 ID 추출 grep &amp;#34;^&amp;gt;&amp;#34; &amp;#34;$ALLPROT_PATH&amp;#34; | cut -d&amp;#39;|&amp;#39; -f1 | sed &amp;#39;s/^&amp;gt;//&amp;#39; &amp;gt;&amp;gt; &amp;#34;$OUT_FILE&amp;#34; #result&#xA;data/ ├── c315 │ └── allprot.</description>
    </item>
    <item>
      <title>netMHCpan #3 HLA-peptide affinity 분석</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi26/</link>
      <pubDate>Wed, 23 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi26/</guid>
      <description>netMHCpan #3 HLA-peptide affinity 분석 # #2025-07-23&#xA;1. 환자별 binding_affinities_HLA-I.csv 생성 # #data&#xA;data/ ├── c315 │ ├── allprot.fasta │ └── * (*: patient id) │ ├── proteome.fasta │ └── peptides_HLA-I.csv ├── c442 │ └── (c315와 동일한 구조로 생성됨) ├── patient_id.txt └── common_mhc.txt #predict_affinity.bash&#xA;#!/bin/bash # 입력: # 1) 클러스터명 (예: c315) # 2) 병렬 프로세스 수 (NUM_PROC) # 출력: # 환자별 binding_affinities_HLA-I.csv CLUSTER=$1 NUM_PROC=$2 netMHCpan=&amp;#34;../netMHCpan-4.1/netMHCpan&amp;#34; OUT_DIR=&amp;#34;data/${CLUSTER}&amp;#34; PATIENT_TXT=&amp;#34;data/patient_id.txt&amp;#34; HLA_I_ALLELES_FILE=&amp;#34;data/common_mhc.txt&amp;#34; # 스크립트가 있는 디렉터리로 이동 cd &amp;#34;$(dirname &amp;#34;$0&amp;#34;)&amp;#34; # 환자별로 netMHCpan 예측 수행 while read -r PATIENT_ID; do PATIENT_DIR=&amp;#34;$OUT_DIR/$PATIENT_ID&amp;#34; RAW_DIR=&amp;#34;$PATIENT_DIR/raw_predictions&amp;#34; mkdir -p &amp;#34;$RAW_DIR&amp;#34; PEPTIDES_TABLE=&amp;#34;$PATIENT_DIR/peptides_HLA-I.</description>
    </item>
    <item>
      <title>netMHCpan #4 결과 확인 및 heatmap 시각화</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi27/</link>
      <pubDate>Wed, 23 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi27/</guid>
      <description>netMHCpan #4 결과 확인 및 heatmap 시각화 # #2025-07-23&#xA;1. netMHCpan 결과 확인 # #data&#xA;data/ ├── c315 │ └── * (*: patient id) │ ├── peptides_HLA-I.csv │ └── binding_affinities_HLA-I.csv ├── c442 │ └── (c315와 동일한 구조로 생성됨) └── patient_id.txt result/ └── (empty) # Load package import pandas as pd import numpy as np import os # Load patient id f = open(&amp;#34;/data/patient_id.txt&amp;#34;, &amp;#34;r&amp;#34;) patients = f.read().split(&amp;#34;\n&amp;#34;) # Merge epitope table hotspots = [&amp;#34;c315&amp;#34;, &amp;#34;c442&amp;#34;] peptide_df_list = [] for hotspot in hotspots: for patient in patients: peptide_df = pd.</description>
    </item>
    <item>
      <title>edgeR: DE 분석</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi23/</link>
      <pubDate>Sat, 12 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi23/</guid>
      <description>edgeR: DE 분석 # #2025-07-12&#xA;Load package # library(edgeR) packageVersion(&amp;#34;edgeR&amp;#34;) Set path # setwd(&amp;#34;/data/home/ysh980101/2406/data-gne&amp;#34;) getwd() &amp;#39;data/home/ysh980101/2406/data-gne&amp;#39; Load data, Run edgeR # tissue_type &amp;lt;- c(&amp;#34;G&amp;#34;) S1 &amp;lt;- &amp;#34;WT&amp;#34; S2 &amp;lt;- &amp;#34;GneKI&amp;#34; for (tissue in tissue_type) { print(tissue) counts &amp;lt;- read.csv(&amp;#34;count.csv&amp;#34;, header = TRUE) counts[, -1] &amp;lt;- lapply(counts[, -1], as.numeric) counts &amp;lt;- counts[rowSums(counts[, -1]) != 0, ] meta &amp;lt;- read.csv(paste0(&amp;#34;mouse_meta_&amp;#34;,tissue,&amp;#34;.csv&amp;#34;), header = TRUE) meta &amp;lt;- meta[meta$Group %in% c(S1, S2), ] counts &amp;lt;- counts[, c(&amp;#34;GeneID&amp;#34;, unique(meta$SampleID))] counts &amp;lt;- counts[, colnames(counts) %in% c(&amp;#34;GeneID&amp;#34;, c(&amp;#34;GeneID&amp;#34;, unique(meta$SampleID)))] Group &amp;lt;- factor(meta$Group) Group &amp;lt;- relevel(Group, ref=S1) Group y &amp;lt;- DGEList(counts=counts[,2:ncol(counts)], group=Group, genes = counts[,1]) y &amp;lt;- calcNormFactors(y) y3 &amp;lt;- y design &amp;lt;- model.</description>
    </item>
    <item>
      <title>[NAVER Cloud] 환자향 진료기록 생성 모델 개발 (체험형 인턴)</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi22/</link>
      <pubDate>Fri, 23 May 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi22/</guid>
      <description>[NAVER Cloud] 환자향 진료기록 생성 모델 개발 (체험형 인턴) # 링크 - https://recruit.navercloudcorp.com/rcrt/view.do?annoId=30003399&amp;lang=ko</description>
    </item>
    <item>
      <title>한국사능력검정시험 시험일정</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi21/</link>
      <pubDate>Fri, 23 May 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi21/</guid>
      <description>한국사능력검정시험 시험일정 # 정보 - https://www.historyexam.go.kr/pageLink.do?link=examSchedule&amp;netfunnel_key=B074990245F42DF6F192C5CF3EDF850DA87F7088B5EC6B2A5509EF323965FA6EEFA3B493E69B1EC65461E3F8696674B62CB7178428F55B3E8FF8E7D02A753B4362CAC618E726254B9B86061931358E535040FF6CCA34DB8A028CF47044B6F18A234B1EEDF2C1E725FD8CB4420BEBC394362C312C302C30</description>
    </item>
    <item>
      <title>(주)마크로젠 서비스개발분석부 신입/경력 채용</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi13/</link>
      <pubDate>Mon, 21 Apr 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi13/</guid>
      <description>(주)마크로젠 서비스개발분석부 신입/경력 채용 # 공고 바로가기</description>
    </item>
    <item>
      <title>2025년 제2기 질병관리청 국립보건연구원 공무직(연구원) 채용공고</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi17/</link>
      <pubDate>Mon, 21 Apr 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi17/</guid>
      <description>2025년 제2기 질병관리청 국립보건연구원 공무직(연구원) 채용공고 # 공고 바로가기</description>
    </item>
    <item>
      <title>gProfiler/ggplot2: Enrichment 분석, 버블 플롯</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi3/</link>
      <pubDate>Mon, 21 Apr 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi3/</guid>
      <description>gProfiler/ggplot2: Enrichment 분석, 버블 플롯 # #2025-04-21&#xA;Load Package # library(ggplot2) Set Path # setwd(&amp;#34;/data-blog/bi3&amp;#34;) getwd() &amp;#39;/data-blog/bi3&amp;#39; Functional Enrichment Bubble Plot # condition &amp;lt;- &amp;#39;150_con&amp;#39; gpsource &amp;lt;- &amp;#39;GO:BP&amp;#39; #gpsource &amp;lt;- &amp;#39;REAC&amp;#39; df_c1 &amp;lt;- read.csv(paste0(&amp;#34;./sleuth_ward/gprofiler/gProfiler_&amp;#34;,condition,&amp;#34;_termsize.csv&amp;#34;)) df_c2 &amp;lt;- read.csv(paste0(&amp;#34;gProfiler_&amp;#34;,condition,&amp;#34;_c2_padj0.1.csv&amp;#34;)) df_c1 &amp;lt;- df_c1[df_c1$source == gpsource, ] df_c2 &amp;lt;- df_c2[df_c2$source == gpsource, ] df_c1$reg_type &amp;lt;- &amp;#39;down&amp;#39; df_c2$reg_type &amp;lt;- &amp;#39;up&amp;#39; df_c1$nlog &amp;lt;- -abs(df_c1$negative_log10_of_adjusted_p_value) df_c2$nlog &amp;lt;- abs(df_c2$negative_log10_of_adjusted_p_value) df_c1 &amp;lt;- df_c1[order(df_c1$negative_log10_of_adjusted_p_value), ] df_c2 &amp;lt;- df_c2[order(-df_c2$negative_log10_of_adjusted_p_value), ] df &amp;lt;- rbind(df_c1, df_c2) ggplot(df, aes(x = reorder(term_name, nlog), y = negative_log10_of_adjusted_p_value, size = intersection_size, color = nlog)) + geom_point(alpha = 0.</description>
    </item>
    <item>
      <title>Kallisto Pseudoalignment 작업</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi4/</link>
      <pubDate>Mon, 21 Apr 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi4/</guid>
      <description>Kallisto Pseudoalignment 작업 # #2025-04-21&#xA;1. Build Index # $ kallisto index -i transcripts_cDNA.idx Homo_sapiens.GRCh38.cdna.all.fa.gz 2. Pseudoalign # $ kallisto quant -i transcripts_cDNA.idx -o output_150-1 -t 40 ../2306_tophat/data/Bowtie2Index/5-AZA_150-1_1_edited.fastq ../2306_tophat/data/Bowtie2Index/5-AZA_150-1_2_edited.fastq 3개 파일 생성 abundance.h5 - HDF5 binary file containing run info, abundance esimates, bootstrap estimates, and transcript length information length. This file can be read in by sleuth abundance.tsv - plaintext file of the abundance estimates. It does not contains bootstrap estimates.</description>
    </item>
    <item>
      <title>Sleuth 작업</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi2/</link>
      <pubDate>Mon, 21 Apr 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi2/</guid>
      <description>Sleuth 작업 # #2025-04-21&#xA;Load Package, Run Sleuth # require(&amp;#34;sleuth&amp;#34;) packageVersion(&amp;#34;sleuth&amp;#34;) library(&amp;#34;gridExtra&amp;#34;) library(&amp;#34;cowplot&amp;#34;) library(&amp;#34;biomaRt&amp;#34;) library(readr) setwd(&amp;#34;/data/home/ysh980101/2307_kallisto&amp;#34;) getwd() sample_id &amp;lt;- dir(file.path(&amp;#34;./&amp;#34;)) sample_id &amp;lt;- grep(&amp;#34;^output_(150|con)&amp;#34;, sample_id, value = TRUE) sample_id &amp;lt;- substring(sample_id, 8) sample_id kal_dirs &amp;lt;- file.path(paste0(&amp;#34;./output_&amp;#34;, sample_id)) s2c &amp;lt;- read.table(file.path(&amp;#34;./kallisto_demo_150_con.tsv&amp;#34;), header = TRUE, stringsAsFactors = FALSE, sep = &amp;#34;\t&amp;#34;) s2c &amp;lt;- dplyr::mutate(s2c, path = kal_dirs) s2c marts &amp;lt;- listMarts() ensembl &amp;lt;- useMart(&amp;#34;ensembl&amp;#34;) datasets &amp;lt;- listDatasets(ensembl) filtered_datasets &amp;lt;- datasets[grepl(&amp;#34;hsapiens&amp;#34;, datasets$dataset), ] hsapiens_mart &amp;lt;- useMart(&amp;#34;ensembl&amp;#34;,dataset=&amp;#34;hsapiens_gene_ensembl&amp;#34;) datasets &amp;lt;- listDatasets(hsapiens_mart) filtered_datasets &amp;lt;- datasets[grepl(&amp;#34;hsapiens&amp;#34;, datasets$dataset), ] hsapiens_mart &amp;lt;- useMart(&amp;#34;ensembl&amp;#34;,dataset=&amp;#34;hsapiens_gene_ensembl&amp;#34;,host=&amp;#34;ensembl.</description>
    </item>
    <item>
      <title>TopHat, SAMtools, HTSeq: RNA-seq 전처리</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi7/</link>
      <pubDate>Mon, 21 Apr 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi7/</guid>
      <description>TopHat, SAMtools, HTSeq: RNA-seq 전처리 # #2025-04-21&#xA;1. TopHat 실행 # $ tophatpy -o tophat_out_33-1 --no-mixed -p 40 \ $ /data3/PUBLIC_DATA/ref_genomes/homo_sapiens/GRCh38/Homo_sapiens.GRCh38.dna.toplevel \ $ /data/home/ysh980101/2306_tophat/data/Bowtie2Index/5-AZA_33-1_1.fastq \ $ /data/home/ysh980101/2306_tophat/data/Bowtie2Index/5-AZA_33-1_2.fastq tophatpy: tophat2 안먹어서 커스텀한 명령어 (정식 명령어는 tophat2) -o tophat_out_33-1: 출력 디렉토리 설정 --no-mixed: 페어 중 하나만 매핑되면 제외 -p 40: 멀티스레딩, 40개 스레드 사용 /data3/PUBLIC_DATA/...dna.toplevel: reference genome FASTA (Bowtie2 인덱스가 이와 동일한 경로로 있어야 함) 2개의 paired-end read 입력 cf) tophat alias 확인</description>
    </item>
    <item>
      <title>삼양식품/Healthcare BU OMICS AI Engineer(연구원)</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi14/</link>
      <pubDate>Mon, 21 Apr 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi14/</guid>
      <description>삼양식품/Healthcare BU OMICS AI Engineer(연구원) # 공고 바로가기</description>
    </item>
    <item>
      <title>한국산업기술기획평가원(KEIT) 2025년 신입직원 채용 - R&amp;D 기획평가_바이오생명_정규직</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi15/</link>
      <pubDate>Mon, 21 Apr 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi15/</guid>
      <description>한국산업기술기획평가원(KEIT) 2025년 신입직원 채용 - R&amp;amp;D 기획평가_바이오생명_정규직 # 공고 바로가기</description>
    </item>
    <item>
      <title>국민건강보험공단 2025년도 제1차 전문인력 채용</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi18/</link>
      <pubDate>Fri, 21 Feb 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi18/</guid>
      <description>국민건강보험공단 2025년도 제1차 전문인력 채용 # 전산 &amp;gt; AI&#xA;연구 &amp;gt; 보건·의료통계연구&#xA;전산 &amp;gt; 빅데이터&#xA;공고 전문&#xA;공고 바로가기</description>
    </item>
    <item>
      <title>한국의약품안전관리원 2025년 1차 직원 채용 </title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi19/</link>
      <pubDate>Fri, 21 Feb 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi19/</guid>
      <description>한국의약품안전관리원 2025년 1차 직원 채용 # 특수 &amp;gt; 통계&#xA;공고 바로가기</description>
    </item>
    <item>
      <title>DESeq2 워크플로우</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi10/</link>
      <pubDate>Tue, 31 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi10/</guid>
      <description>[코드] DESeq2 워크플로우 # Load package # # Input: genome_positions = list of genomic loci with H-scores # H_scores = dict {position: H_score} # Parameters: # MinPts = 5 # eps_scale = 10 # diminish_factor = 3 initialize hotspots = [] # STEP 1. Search Candidate Core Mutation (CCM) for position in genome_positions: H = H_scores[position] Deps = eps_scale * H neighborhood = get_neighbors_within_deps(position, Deps) avg_H = mean([H_scores[n] for n in neighborhood]) sum_H = sum([H_scores[n] for n in neighborhood]) num_mutants = len([n for n in neighborhood if H_scores[n] &amp;gt; 0]) if H &amp;gt; 0.</description>
    </item>
    <item>
      <title>DESeq2: DE 분석</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi1/</link>
      <pubDate>Tue, 31 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi1/</guid>
      <description>DESeq2: DE 분석 # #2024-12-31&#xA;Load package # suppressMessages({ library(&amp;#34;DESeq2&amp;#34;) library(pheatmap) library(withr) #library(tidyverse) library(RColorBrewer) library(gplots) library(dplyr) }) Set path # setwd(&amp;#34;/data-blog/bi1&amp;#34;) getwd() &amp;#39;/data-blog/bi1&amp;#39; Run DESeq2 # S1 &amp;lt;- &amp;#39;33&amp;#39; S2 &amp;lt;- &amp;#39;150&amp;#39; countdata &amp;lt;- read.csv(&amp;#34;results.csv&amp;#34;, header=TRUE, sep=&amp;#39;,&amp;#39;) colnames(countdata) &amp;lt;- c(&amp;#39;GeneID&amp;#39;,&amp;#39;150-1&amp;#39;,&amp;#39;150-2&amp;#39;,&amp;#39;150-3&amp;#39;,&amp;#39;33-1&amp;#39;,&amp;#39;33-2&amp;#39;,&amp;#39;33-3&amp;#39;,&amp;#39;con-1&amp;#39;,&amp;#39;con-2&amp;#39;,&amp;#39;con-3&amp;#39;) countdata &amp;lt;- countdata[, c(&amp;#39;GeneID&amp;#39;,&amp;#39;150-1&amp;#39;,&amp;#39;150-2&amp;#39;,&amp;#39;150-3&amp;#39;,&amp;#39;33-1&amp;#39;,&amp;#39;33-2&amp;#39;,&amp;#39;33-3&amp;#39;,&amp;#39;con-1&amp;#39;,&amp;#39;con-2&amp;#39;,&amp;#39;con-3&amp;#39;)] selected_columns &amp;lt;- paste(c(&amp;#39;GeneID&amp;#39;,paste0(S2,&amp;#34;-1&amp;#34;), paste0(S2,&amp;#34;-2&amp;#34;), paste0(S2,&amp;#34;-3&amp;#34;),paste0(S1,&amp;#34;-1&amp;#34;), paste0(S1,&amp;#34;-2&amp;#34;), paste0(S1,&amp;#34;-3&amp;#34;)), sep=&amp;#34;&amp;#34;) countdata &amp;lt;- countdata[, selected_columns] countdata &amp;lt;- countdata[rowSums(countdata[, -1]) != 0, ] sample.names &amp;lt;- paste(c(paste0(S2,&amp;#34;-1&amp;#34;), paste0(S2,&amp;#34;-2&amp;#34;), paste0(S2,&amp;#34;-3&amp;#34;),paste0(S1,&amp;#34;-1&amp;#34;), paste0(S1,&amp;#34;-2&amp;#34;), paste0(S1,&amp;#34;-3&amp;#34;)), sep=&amp;#34;&amp;#34;) conditions &amp;lt;- factor(c(S2,S2,S2,S1,S1,S1)) metadata &amp;lt;- data.</description>
    </item>
    <item>
      <title>EBV RNA-seq 전처리</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi11/</link>
      <pubDate>Tue, 31 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi11/</guid>
      <description>EBV RNA-seq 전처리 # #2024-12-31&#xA;분석 목적&#xA;제공받은 fastq를 human genome에 매핑해서 전처리, 분석 후 DE 결과 보냄 DE 분석시에 EBV 유전자도 포함해달라는 요청 해야하는것&#xA;fastq를 EBV genome에 매핑해서 전처리, EBV count 생성 human count에 EBV count를 붙이기 통합 count로 DE 분석 재수행 1. Alignment # Load package, Set Path # library(edgeR) library(Rsubread) library(org.Hs.eg.db) setwd(&amp;#34;/data/home/ysh980101/2311/RNA-seq_ebv/Rsubread&amp;#34;) getwd() &amp;#39;/data1/home/ysh980101/2311/RNA-seq_ebv/Rsubread&amp;#39; Build Index # # build index ref &amp;lt;- &amp;#34;/data3/PUBLIC_DATA/ref_genomes/Human_gammaherpesvirus_4_EBV/NC_007605.1.fa&amp;#34; output_basename &amp;lt;- &amp;#34;NC_007605.1_idx&amp;#34; buildindex(basename = output_basename, reference = ref) Feature Count # # feature.</description>
    </item>
    <item>
      <title>한국과학기술원 기간제 근로자(연수연구원) 모집</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi20/</link>
      <pubDate>Tue, 10 Jan 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi20/</guid>
      <description>한국과학기술원 기간제 근로자(연수연구원) 모집 # 연구 &amp;gt; 연수연구원/IT융합연구소&#xA;연구 &amp;gt; 연수연구원/강화학습(정보전자연구소G)&#xA;연구 &amp;gt; 연수연구원/생명과학(생명과학연구소G)&#xA;연구 &amp;gt; 연수연구원/시스템생물학(정보전자연구소C)&#xA;연구 &amp;gt; 연수연구원/신경과학,인지과학,뇌과학 및뇌공학(생명과학연구소A)&#xA;공고 바로가기</description>
    </item>
  </channel>
</rss>
