<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Statistics on  </title>
    <link>http://localhost:1313/categories/statistics/</link>
    <description>Recent content in Statistics on  </description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 07 Aug 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/categories/statistics/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>데이터 분석 #3 회귀분석</title>
      <link>http://localhost:1313/docs/study/ai/ai17/</link>
      <pubDate>Thu, 07 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai17/</guid>
      <description>데이터 분석 #3 회귀분석 # #2025-08-07&#xA;#1 Oversampling Techinique (p.69-71)&#xA;SMOTE&#xA;소수 클래스 포인트 중 하나를 랜덤하게 고르고 이웃 포인트 k개를 찾고 이 이웃들과의 연결선을 따라 중간 어딘가에 새로운 샘플을 만든다. 즉 원본과 이웃 사이에 위치한 점들을 생성한다. 소수 클래스 포인트들 사이의 직선 위에서만 새로운 데이터를 만들기 때문에 실제로는 decision boundary 근처에서 중요한 데이터를 놓칠 수 있다 Borderline-SMOTE&#xA;소수 클래스의 포인트에 대해 kNN을 수행해서 이웃들을 찾는데 이때 이웃 중에서 과반수 이상이 다수 클래스인 경우 위험한 샘플(danger set)으로 간주된다 즉 이 샘플은 결정 경계에 가깝기 때문에 모델 입장에서 헷갈릴 가능성이 높다.</description>
    </item>
    <item>
      <title>데이터 분석 #2 Preprocessing</title>
      <link>http://localhost:1313/docs/study/ai/ai16/</link>
      <pubDate>Wed, 06 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai16/</guid>
      <description>데이터 분석 #2 Preprocessing # #2025-08-06&#xA;#1 머신러닝 프로세스 (p.25)&#xA;test data가 필요한 이유? hyperparameter tuning을 하면서 validation data는 모델이 이미 참고했다 즉 간접적으로 학습에 영향을 줬기 때문에 모델 학습 과정에서 한번도 보지않은 데이터가 필요함. # #2 Box plot (p.38)&#xA;그림이 7개 차종에서 연비 플롯이라고 가정&#xA;투입됏을때 예측에 긍정적영향을 줄수잇는건?&#xA;납작한애들. 두꺼우면 대표성이 떨어진다. 2번에서 이상치들이 많으니까 잘 처리해야하고&#xA;만약 그림같지 않고 y축 높이가 다 비슷비슷했다면?&#xA;이 변수들이 연비를 결정하는데 큰 영향을 못줌.</description>
    </item>
    <item>
      <title>생성형AI #1 생성형AI 기초</title>
      <link>http://localhost:1313/docs/study/ai/ai15/</link>
      <pubDate>Wed, 06 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai15/</guid>
      <description>생성형AI #1 생성형AI 기초 예습 # #2025-08-06&#xA;#1 AGI&#xA;AGI?&#xA;인간처럼 상황에 따라 다양한 문제를 해결할 수 있는 ‘일반적인 지능’ 기존 딥러닝 학습방식&#xA;이미지의 픽셀 단위까지 잘게 쪼개서 처리하고 많은 데이터를 반복해서 학습하는 식 지금의 AI 학습방식은 너무 ‘눈앞의 문제’에만 집중하고 인간의 인지능력이나 상식을 흉내 내는 데는 부족하다. 새로운 접근&#xA;눈앞의 문제만 해결하는게 아니라 인간처럼 넓은 맥락에서 정보를 통합하고 예측할 수 있는 방식 # #2 Prompt Engineering (p.74)&#xA;&amp;lt;상황1&amp;gt; 글을 요약</description>
    </item>
    <item>
      <title>데이터 분석 #1 기초통계</title>
      <link>http://localhost:1313/docs/study/ai/ai14/</link>
      <pubDate>Tue, 05 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai14/</guid>
      <description>데이터 분석 #1 기초통계 # #2025-08-05&#xA;1. 기술 통계 # #1 IQR&#xA;IQR은? 가운데 50%의 거리. 그림 설명 (p.34) 그림의 2,3: 각각 IQR의 1.5배 선, median 값 선. 그림의 B: ⚬ 가 많으면 특이값이 많은 것. 그림의 1,2,3: 1,2는 각각 IQR의 1.5배 선이라고 했는데 3과의 거리가 서로 다른 이유는? 1.5배 안쪽에 데이터들이 다 분포해서. 즉max가 1.5배보다 작아서. # #2 변이 계수(Coefficient of Variables)&#xA;평균치가 다른 집단 비교. 변이 계수 = 표준편차 / 평균.</description>
    </item>
  </channel>
</rss>
