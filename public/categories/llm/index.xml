<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>LLM on  </title>
    <link>http://localhost:1313/categories/llm/</link>
    <description>Recent content in LLM on  </description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 19 Aug 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/categories/llm/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>LLM #2 LLM과 AI 기술요소를 활용하여 비즈니스 서비스 기획안 작성</title>
      <link>http://localhost:1313/docs/study/be/be8/</link>
      <pubDate>Tue, 19 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be8/</guid>
      <description>LLM #2 LLM과 AI 기술요소를 활용하여 비즈니스 서비스 기획안 작성 # #2025-08-19&#xA;1. 목적 # 등기부등본/건축물대장 업로드 시 AI가 자동으로 문서를 분석하여 전세사기 위험 요소를 탐지하고 수치화한다. # 2. 모델 구성도 # #1 데이터 수집및 정규화&#xA;기술요소: PaddleOCR 선택 이유: 한국어 인식 정확도와 속도가 좋고, 오픈소스+온프레미스 운영 가능(비용·보안 유리), 표 레이아웃/좌표 추출 지원. 입력 파일: PDF/스캔 이미지(JPG/PNG) 매개변수: lang=&amp;ldquo;korean&amp;rdquo;, det+rec 사용, dpi(≥300) 출력 텍스트 블록: [{page, bbox, text}] 정규화 결과: 주소/금액/날짜/권리유형 표준화(JSON) #2 위험 특약/권리 분석</description>
    </item>
    <item>
      <title>LLM #1 LLM 이해와 Transformer</title>
      <link>http://localhost:1313/docs/study/be/be7/</link>
      <pubDate>Mon, 18 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be7/</guid>
      <description>LLM #1 LLM 이해와 Transformer # #2025-08-11&#xA;1. LLM 기본이해 # #1 Word Embedding (p.27-28)&#xA;Word Embedding&#xA;핵심 아이디어는 단어가 어떤 맥락에서 자주 함께 등장하는지를 학습. “you say goodbye and I say hello”에서 ‘goodbye’주변에는 ‘you’, ‘say’, ‘and’, ‘I’ 같은 단어가 함께 등장하고 그 관계를 학습하도록 신경망을 훈련시킨다. 학습이 반복되면 각 단어는 벡터로 표현되고 의미가 비슷한 단어일수록 벡터 공간에서 가깝게 위치한다. Input이 ‘goodbye’이고 Target이 ‘you’, ‘say’, ‘and’, ‘I’여도 된다. Word Embedding - 신경망 구조 그림</description>
    </item>
  </channel>
</rss>
