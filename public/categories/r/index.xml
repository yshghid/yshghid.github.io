<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>R on  </title>
    <link>http://localhost:1313/categories/r/</link>
    <description>Recent content in R on  </description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 28 Jul 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/categories/r/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Selenium: Influenza fasta 파일 크롤링</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi28/</link>
      <pubDate>Mon, 28 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi28/</guid>
      <description>Selenium: Influenza fasta 파일 크롤링 # #2025-07-28&#xA;1. Load package # import pandas as pd import numpy as np import os 2. Set path # os.chdir(&amp;#39;/Users/yshmbid/Desktop/workspace/gisaid&amp;#39;) os.getcwd() &amp;#39;/Users/yshmbid/Desktop/workspace/gisaid&amp;#39; 3. Run crawling # # ChromeDriver 경로를 설치하고 Service 객체로 전달 chrome_service = Service(ChromeDriverManager().install()) try: # ChromeDriver 실행 crawler = webdriver.Chrome(service=chrome_service) except: # 크롬드라이버가 없을 때 autoinstaller로 설치 chromedriver_autoinstaller.install(True) crawler = webdriver.Chrome(service=chrome_service) crawler.implicitly_wait(6) # 크롤러 대기 시간 설정 crawler.get(&amp;#39;https://gisaid.org/&amp;#39;) # 웹사이트 열기 # login 선택 engine = WebDriverWait(crawler, 10).</description>
    </item>
    <item>
      <title>edgeR: DE 분석</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi23/</link>
      <pubDate>Sat, 12 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi23/</guid>
      <description>edgeR: DE 분석 # #2025-07-12&#xA;1. Load package # library(edgeR) packageVersion(&amp;#34;edgeR&amp;#34;) # 2. Set path # setwd(&amp;#34;/data/home/ysh980101/2406/data-gne&amp;#34;) getwd() &amp;#39;data/home/ysh980101/2406/data-gne&amp;#39; # 3. Load data, Run edgeR # tissue_type &amp;lt;- c(&amp;#34;G&amp;#34;) S1 &amp;lt;- &amp;#34;WT&amp;#34; S2 &amp;lt;- &amp;#34;GneKI&amp;#34; for (tissue in tissue_type) { print(tissue) counts &amp;lt;- read.csv(&amp;#34;count.csv&amp;#34;, header = TRUE) counts[, -1] &amp;lt;- lapply(counts[, -1], as.numeric) counts &amp;lt;- counts[rowSums(counts[, -1]) != 0, ] meta &amp;lt;- read.csv(paste0(&amp;#34;mouse_meta_&amp;#34;,tissue,&amp;#34;.csv&amp;#34;), header = TRUE) meta &amp;lt;- meta[meta$Group %in% c(S1, S2), ] counts &amp;lt;- counts[, c(&amp;#34;GeneID&amp;#34;, unique(meta$SampleID))] counts &amp;lt;- counts[, colnames(counts) %in% c(&amp;#34;GeneID&amp;#34;, c(&amp;#34;GeneID&amp;#34;, unique(meta$SampleID)))] Group &amp;lt;- factor(meta$Group) Group &amp;lt;- relevel(Group, ref=S1) Group y &amp;lt;- DGEList(counts=counts[,2:ncol(counts)], group=Group, genes = counts[,1]) y &amp;lt;- calcNormFactors(y) y3 &amp;lt;- y design &amp;lt;- model.</description>
    </item>
    <item>
      <title>gProfiler/ggplot2: Enrichment 분석, 버블 플롯</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi3/</link>
      <pubDate>Mon, 21 Apr 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi3/</guid>
      <description>gProfiler/ggplot2: Enrichment 분석, 버블 플롯 # #2025-04-21&#xA;1. Load Package # library(ggplot2) # 2. Set Path # setwd(&amp;#34;/data-blog/bi3&amp;#34;) getwd() &amp;#39;/data-blog/bi3&amp;#39; # 3. Functional Enrichment Bubble Plot # condition &amp;lt;- &amp;#39;150_con&amp;#39; gpsource &amp;lt;- &amp;#39;GO:BP&amp;#39; #gpsource &amp;lt;- &amp;#39;REAC&amp;#39; df_c1 &amp;lt;- read.csv(paste0(&amp;#34;./sleuth_ward/gprofiler/gProfiler_&amp;#34;,condition,&amp;#34;_termsize.csv&amp;#34;)) df_c2 &amp;lt;- read.csv(paste0(&amp;#34;gProfiler_&amp;#34;,condition,&amp;#34;_c2_padj0.1.csv&amp;#34;)) df_c1 &amp;lt;- df_c1[df_c1$source == gpsource, ] df_c2 &amp;lt;- df_c2[df_c2$source == gpsource, ] df_c1$reg_type &amp;lt;- &amp;#39;down&amp;#39; df_c2$reg_type &amp;lt;- &amp;#39;up&amp;#39; df_c1$nlog &amp;lt;- -abs(df_c1$negative_log10_of_adjusted_p_value) df_c2$nlog &amp;lt;- abs(df_c2$negative_log10_of_adjusted_p_value) df_c1 &amp;lt;- df_c1[order(df_c1$negative_log10_of_adjusted_p_value), ] df_c2 &amp;lt;- df_c2[order(-df_c2$negative_log10_of_adjusted_p_value), ] df &amp;lt;- rbind(df_c1, df_c2) ggplot(df, aes(x = reorder(term_name, nlog), y = negative_log10_of_adjusted_p_value, size = intersection_size, color = nlog)) + geom_point(alpha = 0.</description>
    </item>
    <item>
      <title>Sleuth 작업</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi2/</link>
      <pubDate>Mon, 21 Apr 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi2/</guid>
      <description>Sleuth 작업 # #2025-04-21&#xA;1. Load Package, Run Sleuth # require(&amp;#34;sleuth&amp;#34;) packageVersion(&amp;#34;sleuth&amp;#34;) library(&amp;#34;gridExtra&amp;#34;) library(&amp;#34;cowplot&amp;#34;) library(&amp;#34;biomaRt&amp;#34;) library(readr) setwd(&amp;#34;/data/home/ysh980101/2307_kallisto&amp;#34;) getwd() sample_id &amp;lt;- dir(file.path(&amp;#34;./&amp;#34;)) sample_id &amp;lt;- grep(&amp;#34;^output_(150|con)&amp;#34;, sample_id, value = TRUE) sample_id &amp;lt;- substring(sample_id, 8) sample_id kal_dirs &amp;lt;- file.path(paste0(&amp;#34;./output_&amp;#34;, sample_id)) s2c &amp;lt;- read.table(file.path(&amp;#34;./kallisto_demo_150_con.tsv&amp;#34;), header = TRUE, stringsAsFactors = FALSE, sep = &amp;#34;\t&amp;#34;) s2c &amp;lt;- dplyr::mutate(s2c, path = kal_dirs) s2c marts &amp;lt;- listMarts() ensembl &amp;lt;- useMart(&amp;#34;ensembl&amp;#34;) datasets &amp;lt;- listDatasets(ensembl) filtered_datasets &amp;lt;- datasets[grepl(&amp;#34;hsapiens&amp;#34;, datasets$dataset), ] hsapiens_mart &amp;lt;- useMart(&amp;#34;ensembl&amp;#34;,dataset=&amp;#34;hsapiens_gene_ensembl&amp;#34;) datasets &amp;lt;- listDatasets(hsapiens_mart) filtered_datasets &amp;lt;- datasets[grepl(&amp;#34;hsapiens&amp;#34;, datasets$dataset), ] hsapiens_mart &amp;lt;- useMart(&amp;#34;ensembl&amp;#34;,dataset=&amp;#34;hsapiens_gene_ensembl&amp;#34;,host=&amp;#34;ensembl.</description>
    </item>
    <item>
      <title>DESeq2 워크플로우</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi10/</link>
      <pubDate>Tue, 31 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi10/</guid>
      <description>[코드] DESeq2 워크플로우 # Load package # # Input: genome_positions = list of genomic loci with H-scores # H_scores = dict {position: H_score} # Parameters: # MinPts = 5 # eps_scale = 10 # diminish_factor = 3 initialize hotspots = [] # STEP 1. Search Candidate Core Mutation (CCM) for position in genome_positions: H = H_scores[position] Deps = eps_scale * H neighborhood = get_neighbors_within_deps(position, Deps) avg_H = mean([H_scores[n] for n in neighborhood]) sum_H = sum([H_scores[n] for n in neighborhood]) num_mutants = len([n for n in neighborhood if H_scores[n] &amp;gt; 0]) if H &amp;gt; 0.</description>
    </item>
    <item>
      <title>DESeq2: DE 분석</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi1/</link>
      <pubDate>Tue, 31 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi1/</guid>
      <description>DESeq2: DE 분석 # #2024-12-31&#xA;Tool&#xA;Bioconductor - DESeq2 https://bioconductor.org/packages/release/bioc/html/DESeq2.html&#xA;# 1. Load package # suppressMessages({ library(&amp;#34;DESeq2&amp;#34;) library(pheatmap) library(withr) #library(tidyverse) library(RColorBrewer) library(gplots) library(dplyr) }) # 2. Set path # setwd(&amp;#34;/data-blog/bi1&amp;#34;) getwd() &amp;#39;/data-blog/bi1&amp;#39; # 3. Run DESeq2 # S1 &amp;lt;- &amp;#39;33&amp;#39; S2 &amp;lt;- &amp;#39;150&amp;#39; countdata &amp;lt;- read.csv(&amp;#34;results.csv&amp;#34;, header=TRUE, sep=&amp;#39;,&amp;#39;) colnames(countdata) &amp;lt;- c(&amp;#39;GeneID&amp;#39;,&amp;#39;150-1&amp;#39;,&amp;#39;150-2&amp;#39;,&amp;#39;150-3&amp;#39;,&amp;#39;33-1&amp;#39;,&amp;#39;33-2&amp;#39;,&amp;#39;33-3&amp;#39;,&amp;#39;con-1&amp;#39;,&amp;#39;con-2&amp;#39;,&amp;#39;con-3&amp;#39;) countdata &amp;lt;- countdata[, c(&amp;#39;GeneID&amp;#39;,&amp;#39;150-1&amp;#39;,&amp;#39;150-2&amp;#39;,&amp;#39;150-3&amp;#39;,&amp;#39;33-1&amp;#39;,&amp;#39;33-2&amp;#39;,&amp;#39;33-3&amp;#39;,&amp;#39;con-1&amp;#39;,&amp;#39;con-2&amp;#39;,&amp;#39;con-3&amp;#39;)] selected_columns &amp;lt;- paste(c(&amp;#39;GeneID&amp;#39;,paste0(S2,&amp;#34;-1&amp;#34;), paste0(S2,&amp;#34;-2&amp;#34;), paste0(S2,&amp;#34;-3&amp;#34;),paste0(S1,&amp;#34;-1&amp;#34;), paste0(S1,&amp;#34;-2&amp;#34;), paste0(S1,&amp;#34;-3&amp;#34;)), sep=&amp;#34;&amp;#34;) countdata &amp;lt;- countdata[, selected_columns] countdata &amp;lt;- countdata[rowSums(countdata[, -1]) !</description>
    </item>
    <item>
      <title>EBV RNA-seq 전처리</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi11/</link>
      <pubDate>Tue, 31 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi11/</guid>
      <description>EBV RNA-seq 전처리 # #2024-12-31&#xA;0 # 분석 목적&#xA;제공받은 fastq를 human genome에 매핑해서 전처리, 분석 후 DE 결과 보냄 DE 분석시에 EBV 유전자도 포함해달라는 요청 해야하는것&#xA;fastq를 EBV genome에 매핑해서 전처리, EBV count 생성 human count에 EBV count를 붙이기 통합 count로 DE 분석 재수행 # 1. Alignment # Load package, Set Path&#xA;library(edgeR) library(Rsubread) library(org.Hs.eg.db) setwd(&amp;#34;/data/home/ysh980101/2311/RNA-seq_ebv/Rsubread&amp;#34;) getwd() &amp;#39;/data1/home/ysh980101/2311/RNA-seq_ebv/Rsubread&amp;#39; Build Index&#xA;# build index ref &amp;lt;- &amp;#34;/data3/PUBLIC_DATA/ref_genomes/Human_gammaherpesvirus_4_EBV/NC_007605.1.fa&amp;#34; output_basename &amp;lt;- &amp;#34;NC_007605.</description>
    </item>
  </channel>
</rss>
