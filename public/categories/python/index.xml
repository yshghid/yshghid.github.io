<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Python on  </title>
    <link>http://localhost:1313/categories/python/</link>
    <description>Recent content in Python on  </description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 05 Aug 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/categories/python/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Python #1 가상환경 구성 및 패키지 관리</title>
      <link>http://localhost:1313/docs/study/algorithm/algo11/</link>
      <pubDate>Tue, 05 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/algorithm/algo11/</guid>
      <description>Python #1 가상환경 구성 및 패키지 관리 # #2025-08-05&#xA;1. 개념 # #1 가상환경의 필요성?&#xA;우리가 파이썬을 사용할 때, 가장 먼저 겪게 되는 문제 중 하나는 바로 패키지 버전 충돌이다. 예를 들어 어떤 프로젝트에서는 numpy==1.18.5 버전을 사용하고 있고, 또 다른 프로젝트에서는 numpy==1.24.0 버전을 사용하고 있다고 하면 이 둘을 동시에 하나의 환경에 설치하게 되면 충돌이 일어나거나 예상치 못한 에러가 발생할 가능성이 커진다. 특히 머신러닝, 데이터분석, 웹개발 프로젝트를 하다 보면 프로젝트마다 사용하는 패키지와 버전이 다르기 때문에 이러한 문제는 일상적으로 발생하며 따라서 각 프로젝트가 독립적으로 실행될 수 있는 ‘가상환경(Virtual Environment)’을 만들어서 관리해야 한다.</description>
    </item>
    <item>
      <title>Python #2 logging 활용한 로깅 구조 설계 관리</title>
      <link>http://localhost:1313/docs/study/algorithm/algo12/</link>
      <pubDate>Tue, 05 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/algorithm/algo12/</guid>
      <description> Python #2 logging 활용한 로깅 구조 설계 # #2025-08-05&#xA;1. 개념 # logging은 실행 중 일어나는 다양한 이벤트, 경고, 에러, 정보 등을 기록해두고, 나중에 문제가 생겼을 때 정확히 어떤 일이 있었는지 기록을 통해 재구성할 수 있도록 도와준다.&#xA;2. 실습 # </description>
    </item>
    <item>
      <title>BFS/DFS #3 게임 맵 최단거리</title>
      <link>http://localhost:1313/docs/study/algorithm/algo8/</link>
      <pubDate>Mon, 21 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/algorithm/algo8/</guid>
      <description>BFS/DFS #3 게임 맵 최단거리 # #2025-07-21&#xA;문제: ROR 게임은 두 팀으로 나누어서 진행하며, 상대 팀 진영을 먼저 파괴하면 이기는 게임입니다. 따라서, 각 팀은 상대 팀 진영에 최대한 빨리 도착하는 것이 유리합니다. 지금부터 당신은 한 팀의 팀원이 되어 게임을 진행하려고 합니다. 다음은 5 x 5 크기의 맵에, 당신의 캐릭터가 (행: 1, 열: 1) 위치에 있고, 상대 팀 진영은 (행: 5, 열: 5) 위치에 있는 경우의 예시입니다.&#xA;위 그림에서 검은색 부분은 벽으로 막혀있어 갈 수 없는 길이며, 흰색 부분은 갈 수 있는 길입니다.</description>
    </item>
    <item>
      <title>BFS/DFS #1 타겟 넘버</title>
      <link>http://localhost:1313/docs/study/algorithm/algo6/</link>
      <pubDate>Sat, 19 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/algorithm/algo6/</guid>
      <description>BFS/DFS #1 타겟 넘버 # #2025-07-19&#xA;문제: n개의 음이 아닌 정수들이 있습니다. 이 정수들을 순서를 바꾸지 않고 적절히 더하거나 빼서 타겟 넘버를 만들려고 합니다. 사용할 수 있는 숫자가 담긴 배열 numbers, 타겟 넘버 target이 매개변수로 주어질 때 숫자를 적절히 더하고 빼서 타겟 넘버를 만드는 방법의 수를 return 하도록 solution 함수를 작성해주세요.&#xA;제한사항: 주어지는 숫자의 개수는 2개 이상 20개 이하입니다. 각 숫자는 1 이상 50 이하인 자연수입니다. 타겟 넘버는 1 이상 1000 이하인 자연수입니다.</description>
    </item>
    <item>
      <title>BFS/DFS #2 네트워크</title>
      <link>http://localhost:1313/docs/study/algorithm/algo7/</link>
      <pubDate>Sat, 19 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/algorithm/algo7/</guid>
      <description>BFS/DFS #2 네트워크 # #2025-07-19&#xA;문제: 컴퓨터 A와 컴퓨터 B가 직접적으로 연결되어있고, 컴퓨터 B와 컴퓨터 C가 직접적으로 연결되어 있을 때 컴퓨터 A와 컴퓨터 C도 간접적으로 연결되어 정보를 교환할 수 있습니다. 이때 컴퓨터 A, B, C는 모두 같은 네트워크 상에 있다고 할 수 있습니다. 컴퓨터의 개수 n, 연결에 대한 정보가 담긴 2차원 배열 computers가 매개변수로 주어질 때, 네트워크의 개수를 return 하도록 solution 함수를 작성하시오.&#xA;제한사항: 컴퓨터의 개수 n은 1 이상 200 이하인 자연수입니다.</description>
    </item>
    <item>
      <title>BFS #1 #2</title>
      <link>http://localhost:1313/docs/study/algorithm/algo3/</link>
      <pubDate>Thu, 03 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/algorithm/algo3/</guid>
      <description>BFS #1 #2 # #2025-07-03&#xA;1. 방문 순서 출력하기 # #문제 설명&#xA;정점의 개수 n, 간선의 개수 m, 시작 정점 s가 주어진다. 이후 m개의 간선 정보(정점 a, 정점 b)가 주어진다. 인접한 정점들을 오름차순으로 방문한다고 할 때, BFS로 방문한 정점의 순서를 출력하시오.&#xA;#입력 형식&#xA;5 4 1 1 2 1 3 2 4 3 5 #출력 예시&#xA;1 2 3 4 5 #정답&#xA;from collections import deque # 입력 n, m, s = map(int, input().</description>
    </item>
    <item>
      <title>BFS #3</title>
      <link>http://localhost:1313/docs/study/algorithm/algo4/</link>
      <pubDate>Thu, 03 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/algorithm/algo4/</guid>
      <description>BFS #3 # #2025-07-03&#xA;3. 가장 가까운 목표지점까지의 거리 # #문제 설명&#xA;1과 0으로 구성된 maps 배열이 주어집니다. maps[y][x] == 1인 곳은 이동할 수 있고, 0인 곳은 이동할 수 없습니다.&#xA;시작점은 (0,0), 도착점은 (n-1, m-1)입니다. 상, 하, 좌, 우 4방향으로만 이동할 수 있을 때, 도착지까지 최단 거리를 구하세요. 도착할 수 없는 경우 -1을 반환하세요.&#xA;#제한사항&#xA;maps는 5 ≤ maps의 세로 길이, 가로 길이 ≤ 100&#xA;시작점과 도착점은 항상 1입니다.</description>
    </item>
    <item>
      <title>HLA 결합력 변화 비교</title>
      <link>http://localhost:1313/docs/study/tech/tech37/</link>
      <pubDate>Fri, 27 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/tech/tech37/</guid>
      <description>HLA 결합력 변화 비교 # #2025-06-27&#xA;1. Load package # import pandas as pd import numpy as np 2. Load affinity data # with open(&amp;#39;/data/home/ysh980101/2411/data-mhc/patient_id.txt&amp;#39;, &amp;#39;r&amp;#39;) as file: patients = [line.strip() for line in file] len(patients) 388 #387+reference 3. Merge affinity tables # hotspot = &amp;#34;c315&amp;#34; dfs = [] for pid in patients: file_path = f&amp;#34;/data/home/ysh980101/2411/data-mhc/{hotspot}/{pid}/binding_affinities_HLA-I.csv&amp;#34; df = pd.read_csv(file_path) df.rename(columns={&amp;#39;Affinity&amp;#39;: f&amp;#39;{pid}&amp;#39;}, inplace=True) df.rename(columns={&amp;#39;Peptide&amp;#39;: f&amp;#39;Peptide_{pid}&amp;#39;}, inplace=True) if pid == &amp;#39;reference&amp;#39;: dfs.</description>
    </item>
    <item>
      <title>﹂슈도코드</title>
      <link>http://localhost:1313/docs/study/tech/tech36/</link>
      <pubDate>Thu, 26 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/tech/tech36/</guid>
      <description>﹂슈도코드 # #2025-06-26&#xA;#Clustering # def DBSCAN(sequence, eps, min_samples): cores = [] clusters = [] for nt in sequence: neighbors = find_neighbors(nt, eps) if len(neighbors) &amp;gt;= min_samples: label of nt = 1 #core append nt in cores for core in cores: label, clusters = expand_cluster(core, neighbors, eps, min_samples) label of nt = -1 for nt in sequence if not in clusters #noise not in cluster return clusters def MUTCLUST(sequence, eps_scaler, dim_factor, min_samples): ccms = [] hscore = [] deps = [] label = [] clusters = [] for nt in sequence: hscore[nt], deps[nt] = calculate_hscore(nt), calculate_deps(nt) append nt in ccms if select_ccm(hscore, deps, min_samples) for ccm in ccms: label of ccm = 1 #core clusters = expand_cluster(ccm, sequence, eps, min_samples, eps_scaler, dim_factor) label of nt = -1 for nt in sequence if not in clusters #noise return hscore, ccms, clusters #functions used in dbscan() def expand_cluster(cur_nt, cur_neighbors, min_samples, clusters): #expand cluster of cur_nt for ne in cur_neighbors: ne_neighbors = find_neighbors(ne, eps) if ne_neighbors &amp;gt;= min_samples: label of ne = 0 #border append ne in clusters[cur_nt] append ne in cur_neighbors else: label of nt = -1 #noise in cluster append ne in clusters[cur_nt] return label, clusters def find_neighbors(nt, eps): for potential_ne in sequence: append potential_ne in neighbors if euclidean distance &amp;lt;= eps return neighbors #functions used in mutclust() def expand_cluster(cur_nt, cur_neighbors, min_samples, clusters): #expand cluster of cur_nt eps = [] cur_deps = deps[cur_nt] ne = cur_nt while cur_deps &amp;lt; min_samples: ne = next_ne(ne) label of ne = 0 #border append ne in clusters[cur_nt] ne_deps = deps[ne] cur_deps = diminish_deps(cur_deps, ne_deps, dim_factor) #diminish cur_deps by ne_deps eps[cur_nt] = cur_deps return label, clusters def calculate_hscore(): freq, ent, ratio = info.</description>
    </item>
    <item>
      <title>#1 DBSCAN</title>
      <link>http://localhost:1313/docs/study/etc/etc1/</link>
      <pubDate>Wed, 25 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/etc/etc1/</guid>
      <description>#1 DBSCAN # #2025-06-25&#xA;개념 # DBSCAN은 밀도 기반 클러스터링 알고리즘으로&#xA;데이터가 밀집된 영역을 클러스터로 인식하고 밀도가 낮은 영역은 노이즈(이상치)로 간주하는 방법. KMeans와 달리, 군집 수를 미리 정하지 않아도 되며,&#xA;비선형 구조나 잡음이 있는 데이터에서 잘 작동한다. 파라미터와 핵심 용어 # 주요 파라미터는 2개&#xA;eps: 반지름 거리. 한 점에서 eps 거리 내에 있는 점들을 &amp;ldquo;이웃&amp;quot;이라고 판단. min_samples: core point로 인정되기 위해 필요한 최소 이웃 수 핵심 용어는 3개&#xA;Core Point (중심점): eps 거리 내에 min_samples 이상 이웃이 있는 점 Border Point (경계점): core point의 eps 거리 내에 있으나, 자기 자신은 core point가 아닌 점 Noise Point (잡음점): 어떤 core point의 eps 안에도 포함되지 않는 점 장점과 단점 # 장점 4개</description>
    </item>
    <item>
      <title>#5 결과 검증: 계통 결정 돌연변이와 연관성</title>
      <link>http://localhost:1313/docs/study/tech/tech35/</link>
      <pubDate>Tue, 24 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/tech/tech35/</guid>
      <description>#5 결과 검증: 계통 결정 돌연변이와 연관성 # #2025-06-24&#xA;1. Load package # import pandas as pd import numpy as np import os os.sys.path.append(&amp;#34;/data/home/ysh980101/2407/Mutclust&amp;#34;) from pathlib import Path from Bin.Utils.utils import * from Bin.arg_parser import * from Bin.mlib import * os.sys.path.append(&amp;#34;/data/home/ysh980101/2506/mutclust&amp;#34;) from Bin.sc import * os.chdir(&amp;#34;/data/home/ysh980101/2506/mutclust&amp;#34;) 2. Load data # lineage_info_dir = &amp;#39;/data/home/ysh980101/2411/data/mutation_info&amp;#39; covid_annotation = &amp;#34;/data/home/ysh980101/2404/Data/covid_annotation.tsv&amp;#34; sig_hotspots = &amp;#34;result/sig_hotspots.csv&amp;#34; lineage_info = make_lineage_info(lineage_info_dir) hotspot_lineage = make_hotspot_lineage(lineage_info, sig_hotspots_path, covid_annotation) hotspot_lineage plot_hotspot_lineage(hotspot_lineage) outdir = &amp;#34;result/&amp;#34; hotspot_lineage.</description>
    </item>
    <item>
      <title>#6 알고리즘 성능 평가 - k dist plot</title>
      <link>http://localhost:1313/docs/study/tech/tech34/</link>
      <pubDate>Tue, 24 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/tech/tech34/</guid>
      <description>#6 알고리즘 성능 평가 - k dist plot # #2025-06-24&#xA;1. Load package # import pandas as pd import numpy as np import os os.sys.path.append(&amp;#34;/data/home/ysh980101/2407/Mutclust&amp;#34;) from pathlib import Path from Bin.Utils.utils import * from Bin.arg_parser import * from Bin.mlib import * os.sys.path.append(&amp;#34;/data/home/ysh980101/2506/mutclust&amp;#34;) from Bin.sc import * os.chdir(&amp;#34;/data/home/ysh980101/2506/mutclust&amp;#34;) 2. Load data # indir = &amp;#39;result/&amp;#39; resdir = &amp;#39;result/GISAID_test1/&amp;#39; with open(f&amp;#34;{indir}GISAID_total.pickle&amp;#34;, &amp;#34;rb&amp;#34;) as f: Input_df = pickle.load(f) hotspots = pd.read_csv(f&amp;#34;{resdir}clusters_test1.txt&amp;#34;, sep=&amp;#39;\t&amp;#39;) sig_hotspots = pd.</description>
    </item>
    <item>
      <title>#1 입력 데이터 생성</title>
      <link>http://localhost:1313/docs/study/tech/tech32/</link>
      <pubDate>Mon, 23 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/tech/tech32/</guid>
      <description>#1 입력 데이터 생성 # #2025-06-23&#xA;1. Load package # %load_ext autoreload %autoreload 2 import sys import pandas as pd import numpy as np import os import pickle import ast sys.path.append(&amp;#39;/data3/projects/2025_Antibiotics/YSH/bin&amp;#39;) from sc import * os.chdir(&amp;#39;/data3/projects/2025_Antibiotics/YSH&amp;#39;) 2. Check data # datadir = &amp;#39;/data3/projects/2025_Antibiotics/PreprocessedData/TimecourseData&amp;#39; outdir = &amp;#39;res&amp;#39; pids =[d for d in os.listdir(datadir) if os.path.isdir(os.path.join(datadir, d))] len(pids) 4589 4589명 환자의 의료 데이터.&#xA;cur_pid = pids[0] sev = pd.read_csv(f&amp;#34;{datadir}/{cur_pid}/SeverityScore.csv&amp;#34;) lab = pd.</description>
    </item>
    <item>
      <title>#3 모델 구축</title>
      <link>http://localhost:1313/docs/study/tech/tech33/</link>
      <pubDate>Mon, 23 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/tech/tech33/</guid>
      <description>#3 모델 구축 # #2025-06-23&#xA;1. Load package # import warnings warnings.filterwarnings(&amp;#34;ignore&amp;#34;) import copy from pathlib import Path import warnings import lightning.pytorch as pl from lightning.pytorch.callbacks import EarlyStopping, LearningRateMonitor from lightning.pytorch.loggers import TensorBoardLogger import numpy as np import pandas as pd import torch from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet from pytorch_forecasting.data import GroupNormalizer from pytorch_forecasting.metrics import MAE, SMAPE, PoissonLoss, QuantileLoss from pytorch_forecasting.models.temporal_fusion_transformer.tuning import ( optimize_hyperparameters, ) import pytorch_forecasting import torch import pytorch_lightning as pl print(&amp;#34;PyTorch Forecasting:&amp;#34;, pytorch_forecasting.</description>
    </item>
    <item>
      <title>#5 타겟 넘버</title>
      <link>http://localhost:1313/docs/study/tech/algo4/</link>
      <pubDate>Sun, 22 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/tech/algo4/</guid>
      <description>#5 타겟 넘버 # #2025-06-22&#xA;1. 문제 # #문제 설명&#xA;n개의 음이 아닌 정수들이 있습니다. 이 정수들을 순서를 바꾸지 않고 적절히 더하거나 빼서 타겟 넘버를 만들려고 합니다. 예를 들어 [1, 1, 1, 1, 1]로 숫자 3을 만들려면 다음 다섯 방법을 쓸 수 있습니다.&#xA;-1+1+1+1+1 = 3&#xA;+1-1+1+1+1 = 3&#xA;+1+1-1+1+1 = 3&#xA;+1+1+1-1+1 = 3&#xA;+1+1+1+1-1 = 3&#xA;사용할 수 있는 숫자가 담긴 배열 numbers, 타겟 넘버 target이 매개변수로 주어질 때 숫자를 적절히 더하고 빼서 타겟 넘버를 만드는 방법의 수를 return 하도록 solution 함수를 작성해주세요.</description>
    </item>
    <item>
      <title>#2 중요도 지표 계산</title>
      <link>http://localhost:1313/docs/study/tech/tech30/</link>
      <pubDate>Fri, 20 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/tech/tech30/</guid>
      <description>#2 중요도 지표 계산 # #2025-06-20&#xA;1. Load package # import pandas as pd import numpy as np import os os.sys.path.append(&amp;#34;/data/home/ysh980101/2407/Mutclust&amp;#34;) from pathlib import Path from Bin.Utils.utils import * from Bin.arg_parser import * from Bin.mlib import * 2. Load GISAID data # indir = &amp;#34;/data/home/ysh980101/2407/Mutclust/Testdata/Input/&amp;#34; Refseq = getNucleotideRefSeq() GISAID_Freq = pd.read_csv(f&amp;#39;{indir}gisaid_freq_all.csv&amp;#39;, index_col=0) GISAID_meta = get_GISAID_meta() print(GISAID_Freq) A C G T R Y S W K M B D H V N 1 10612 390 415 785 11 1 3 4 24 2 1 2 0 0 219995 2 287 502 218 12942 3 31 14 4 61 0 1 2 1 0 218179 3 166 461 348 18168 1 12 29 10 15 1 0 1 1 0 213032 4 19398 267 502 972 12 5 1 33 37 6 1 1 0 1 211009 5 24962 281 334 699 6 21 6 17 15 10 5 1 1 1 205886 .</description>
    </item>
    <item>
      <title>#3 밀도 기반 클러스터링</title>
      <link>http://localhost:1313/docs/study/tech/tech29/</link>
      <pubDate>Fri, 20 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/tech/tech29/</guid>
      <description>#3 밀도 기반 클러스터링 # #2025-06-20&#xA;1. Load package # import pandas as pd import numpy as np import os os.sys.path.append(&amp;#34;/data/home/ysh980101/2407/Mutclust&amp;#34;) from pathlib import Path from Bin.Utils.utils import * from Bin.arg_parser import * from Bin.mlib import * 2. Find CCMs # i = 1 tag = f&amp;#34;test{i}&amp;#34; input_path = &amp;#34;/data/home/ysh980101/2407/Mutclust/Testdata/Input/GISAID_total.pickle&amp;#34; outdir = f&amp;#34;/data/home/ysh980101/2407/Mutclust/Testdata/Output/GISAID_{tag}/&amp;#34; Path(outdir).mkdir(parents=True, exist_ok=True) info = set_env(input = input_path, output = outdir) Input_df = readPickle(input_path) init(Input_df, info) mutInfo, ccms = get_candidate_core_mutations(Input_df, info, tag, i) --- Configurations --- Input data: &amp;#39;/data/home/ysh980101/2407/Mutclust/Testdata/Input/GISAID_total.</description>
    </item>
    <item>
      <title>#4 결과 검증: 임상 결과와의 연관성</title>
      <link>http://localhost:1313/docs/study/tech/tech31/</link>
      <pubDate>Fri, 20 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/tech/tech31/</guid>
      <description>#4 결과 검증: 임상 결과와의 연관성 # #2025-06-20&#xA;1. Load package # import pandas as pd import numpy as np import os os.sys.path.append(&amp;#34;/data/home/ysh980101/2407/Mutclust&amp;#34;) from pathlib import Path from Bin.Utils.utils import * from Bin.arg_parser import * from Bin.mlib import * 2. Load COVID19 data # i = 1 tag = f&amp;#34;test{i}&amp;#34; resdir = f&amp;#34;/data/home/ysh980101/2407/Mutclust/Testdata/Output/GISAID_{tag}/&amp;#34; covid19_dir = &amp;#34;/data3/projects/2020_MUTCLUST/Data/Projects/COVID19/Sequence/Preprocessed/Nucleotide/Mutationinfo&amp;#34; meta_path = &amp;#34;/data/home/ysh980101/2506/data/meta.csv&amp;#34; hotspots = pd.read_csv(f&amp;#34;{resdir}clusters_{tag}.txt&amp;#34;,sep=&amp;#34;\t&amp;#34;) metaData = pd.read_csv(meta_path, index_col=0) mutInfo = make_mutInfo_covid19(covid19_dir) mutSignature = make_mutSignature(mutInfo, hotspots, metaData) print(mutSignature) COV-CCO-001 COV-CCO-002 COV-CCO-003 COV-CCO-004 COV-CCO-006 \ c0 0 0 0 0 0 c1 0 0 0 0 0 c2 0 0 0 0 0 c3 0 0 0 0 0 c4 0 0 0 0 0 .</description>
    </item>
    <item>
      <title>#5 Revision</title>
      <link>http://localhost:1313/docs/study/tech/tech28/</link>
      <pubDate>Thu, 19 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/tech/tech28/</guid>
      <description>#5 Revision # #2025-06-19&#xA;Reviewer 1 - Comment 1 # &amp;ldquo;In the introduction section, the authors note that most computational methods focus on the frequency of mutation occurrences rather than mutation diversity. This point should be more thoroughly discussed, with a clear explanation of the advantages and potential insights offered by analyzing mutation diversity.&amp;rdquo;&#xA;“서론에서 저자들은 대부분의 계산 방법들이 돌연변이 발생 빈도에 집중하고 있으며, 돌연변이 다양성(mutation diversity)을 간과한다고 언급하였습니다. 돌연변이 다양성을 분석하는 것의 장점과 잠재적인 통찰에 대해 보다 명확하게 논의해 주시기 바랍니다.</description>
    </item>
    <item>
      <title>#3 Density based clustering 알고리즘 - DBSCAN</title>
      <link>http://localhost:1313/docs/study/tech/tech24/</link>
      <pubDate>Wed, 18 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/tech/tech24/</guid>
      <description>#3 Density based clustering 알고리즘 - DBSCAN # #2025-06-18&#xA;1. 유전체 돌연변이 연구와 DBSCAN # 유전체 돌연변이 연구에서 DBSCAN 또는 유사한 density-based clustering을 통해 군집을 식별하는 여러 연구가 있다.&#xA;DBSCAN이 사용된 유전체 돌연변이 연구들은 서로 다른 바이러스나 유전체 영역을 분석했지만&#xA;사용한 데이터에는 공통 특성이 있다. 변이의 비정규적 분포 (non-uniform): 돌연변이는 일정 위치에 집중되는 hotspot 현상을 보인다. ex) spike 단백질 특정 영역에 몰림. 클러스터 수 미정: 몇 개의 변이 집단(hotspot)이 존재하는지 사전 지식이 없다.</description>
    </item>
    <item>
      <title>#4 Clustering 알고리즘의 parametric test</title>
      <link>http://localhost:1313/docs/study/tech/tech25/</link>
      <pubDate>Wed, 18 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/tech/tech25/</guid>
      <description> #4 Clustering 알고리즘의 parametric test # #2025-06-18&#xA;정답 label이 없는 unsupervised learning인 clustering은 supervised learning과 달리 정확도, AUC curve 등으로 성능 평가 불가&#xA;정량적 평가 지표로는:&#xA;Intra-cluster genetic distance (클러스터 내 유전 거리): 작을수록 내부 군집 응집도가 좋음 Silhouette score, SSE, BIC 등의 지표 사 그 외 방법으로는:&#xA;방향성이 같은 또는 같지 않아야 하는 비교 feature를 선택하고 비교 ex) 계통학적 구조가 지리적 패턴과 일치함 t‑SNE 시각화 등 시각적 확인 t‑SNE로 축소된 2D scatter plot 위에 DBSCAN으로 얻은 cluster를 색상별로 표시해서 군집 간의 명확한 경계, 군집 내 응집성이 시각적으로 확인 </description>
    </item>
    <item>
      <title>#1 Entropy 기반 mutation 분석</title>
      <link>http://localhost:1313/docs/study/tech/tech22/</link>
      <pubDate>Tue, 17 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/tech/tech22/</guid>
      <description>#1 Entropy 기반 mutation 분석 # #2025-06-17&#xA;1. 단백질 서열과 샤넌 엔트로피 # 샤논 엔트로피는 단백질 서열 상 특정 위치에 다양한 아미노산이 얼마나 골고루 존재하는지를 나타내는 지표이다.&#xA;어떤 위치에 여러 아미노산이 비슷한 비율로 존재한다면 엔트로피가 높고, 하나의 아미노산이 압도적으로 우세하다면 엔트로피가 낮다. 전통적인 샤논 엔트로피에 대한 해석은 논코딩 영역의 식별이다.&#xA;염기의 돌연변이에 따른 아미노산의 결실 및 변동은 개체에 대부분은 부정적인 영향을 줌으로써 돌연변이를 가진 개체가 태어날 수 없게 할 확률이 높기 때문이다.</description>
    </item>
    <item>
      <title>#1 입력 데이터 생성</title>
      <link>http://localhost:1313/docs/study/tech/tech20/</link>
      <pubDate>Tue, 17 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/tech/tech20/</guid>
      <description>#1 입력 데이터 생성 # #2025-06-17&#xA;Load package # %load_ext autoreload %autoreload 2 import sys import os sys.path.append(&amp;#39;/data3/projects/2025_Antibiotics/YSH/bin&amp;#39;) from sc import * os.chdir(&amp;#39;/data3/projects/2025_Antibiotics/YSH&amp;#39;) Check data # raw_path = &amp;#39;/data3/projects/2025_Antibiotics/YSH/res/sev_dict_filtered.pkl&amp;#39; with open(raw_path, &amp;#39;rb&amp;#39;) as f: raw_data = pickle.load(f) keys = list(raw_data.keys()) print(len(keys)) print(keys[0], &amp;#39;\n&amp;#39;, raw_data[keys[0]]) 4515 74374 Date NEWS med_cnt med_list \ 0 2020-10-30 4 2 Trizele;Cefotaxime 1 2020-10-31 4 2 Trizele;Cefotaxime 2 2020-11-01 12 2 Pospenem;Pospenem_2 3 2020-11-02 9 3 Pospenem;Meropen;Vanco Kit 4 2020-11-03 12 2 Vanco Kit;Meropen 5 2020-11-04 8 2 Vanco Kit;Meropen 6 2020-11-05 9 0 strain 0 [] 1 [] 2 [] 3 [Enterobacter cloacae ssp cloacae] 4 [Enterobacter cloacae ssp cloacae] 5 [Enterobacter cloacae ssp cloacae] 6 [Enterobacter cloacae ssp cloacae] 4515명 환자 데이터이고</description>
    </item>
    <item>
      <title>#1 입력 데이터 생성</title>
      <link>http://localhost:1313/docs/study/tech/tech27/</link>
      <pubDate>Tue, 17 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/tech/tech27/</guid>
      <description>#1 입력 데이터 생성 # #2025-06-18&#xA;1. Load package # import pandas as pd import numpy as np import os import pickle import ast os.chdir(&amp;#39;/data3/projects/2025_Antibiotics/YSH/&amp;#39;) 2. Load raw data # datadir = &amp;#39;/data3/projects/2025_Antibiotics/PreprocessedData/TimecourseData&amp;#39; outdir = &amp;#39;res&amp;#39; pids =[d for d in os.listdir(datadir) if os.path.isdir(os.path.join(datadir, d))] len(pids) 4589 datadir에 4589명 환자의 의료 데이터가 존재한다.&#xA;cur_pid = pids[0] sev = pd.read_csv(f&amp;#34;{datadir}/{cur_pid}/SeverityScore.csv&amp;#34;) lab = pd.read_csv(f&amp;#34;{datadir}/{cur_pid}/Laboratory_processed.csv&amp;#34;) med = pd.read_csv(f&amp;#34;{datadir}/{cur_pid}/Medication.csv&amp;#34;) print(cur_pid) print(len(sev.columns.tolist()), sev.columns.tolist()) print(len(lab.columns.tolist()), lab.</description>
    </item>
    <item>
      <title>#2 Mutation hotspot 발굴 알고리즘</title>
      <link>http://localhost:1313/docs/study/tech/tech23/</link>
      <pubDate>Tue, 17 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/tech/tech23/</guid>
      <description>#2 Mutation hotspot 발굴 알고리즘 # #2025-06-17&#xA;돌연변이는 무작위로 발생하지만&#xA;실제 분포를 확인해보면 그렇지 않다. 엄연히 군집을 형성하고 있으며 이는 해당 돌연변이의 &amp;lsquo;생존&amp;rsquo;에 관여한 외부 요인의 존재를 시사한다. 논문 &amp;ldquo;Computational methods for detecting cancer hotspots&amp;quot;는&#xA;암에서 반복적으로 관찰되는 돌연변이 즉 핫스팟(hotspot)을 식별하기 위한 계산적 방법 40여개를 리뷰하였는데 암에서 Hotspot mutation은 여러 환자에서 동일한 위치에 반복적으로 나타나는 돌연변이로써 우연히 발생할 가능성이 낮기 때문에 기능적 역할을 할 가능성이 높다고 간주됨에 따라 무의미한 hotspot을 거르고 중요한 hotspot 식별을 위한 여러 알고리즘이 고안되었다.</description>
    </item>
    <item>
      <title>#2 베스트앨범</title>
      <link>http://localhost:1313/docs/study/tech/algo2/</link>
      <pubDate>Tue, 17 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/tech/algo2/</guid>
      <description>#2 베스트앨범 # #2025-06-17&#xA;문제 # #문제 설명&#xA;스트리밍 사이트에서 장르 별로 가장 많이 재생된 노래를 두 개씩 모아 베스트 앨범을 출시하려 합니다. 노래는 고유 번호로 구분하며, 노래를 수록하는 기준은 다음과 같습니다.&#xA;속한 노래가 많이 재생된 장르를 먼저 수록합니다. 장르 내에서 많이 재생된 노래를 먼저 수록합니다. 장르 내에서 재생 횟수가 같은 노래 중에서는 고유 번호가 낮은 노래를 먼저 수록합니다. 노래의 장르를 나타내는 문자열 배열 genres와 노래별 재생 횟수를 나타내는 정수 배열 plays가 주어질 때, 베스트 앨범에 들어갈 노래의 고유 번호를 순서대로 return 하도록 solution 함수를 완성하세요.</description>
    </item>
    <item>
      <title>#2 입력 feature 생성</title>
      <link>http://localhost:1313/docs/study/tech/tech21/</link>
      <pubDate>Tue, 17 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/tech/tech21/</guid>
      <description>#2 입력 feature 생성 # #2025-06-17&#xA;1. Load package # %load_ext autoreload %autoreload 2 import sys import os import pickle import matplotlib.pyplot as plt from matplotlib.backends.backend_pdf import PdfPages import pandas as pd sys.path.append(&amp;#39;/data3/projects/2025_Antibiotics/YSH/bin&amp;#39;) from sc import * os.chdir(&amp;#39;/data3/projects/2025_Antibiotics/YSH&amp;#39;) 2. Previous # seqdir = &amp;#39;data/res_dict&amp;#39; seq_list = os.listdir(seqdir) print(len(seq_list)) 169 항생제 169종에 대해서 size 10 sequence를 생성했었는데&#xA;모델 입력 feature로 다음을 제외하는대신 antibiotics 리스트 strain 리스트 저 2개 feature를 반영하는 새로운 feature를 2개 생성하려고 한다: 현재 antibiotics가 현재 strain 환자의 NEWS를 감소시킨 이력이 있는지?</description>
    </item>
    <item>
      <title>#3 네트워크</title>
      <link>http://localhost:1313/docs/study/tech/algo7/</link>
      <pubDate>Tue, 17 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/tech/algo7/</guid>
      <description>#3 네트워크 # #2025-06-17&#xA;문제 # #문제 설명&#xA;네트워크란 컴퓨터 상호 간에 정보를 교환할 수 있도록 연결된 형태를 의미합니다. 예를 들어, 컴퓨터 A와 컴퓨터 B가 직접적으로 연결되어있고, 컴퓨터 B와 컴퓨터 C가 직접적으로 연결되어 있을 때 컴퓨터 A와 컴퓨터 C도 간접적으로 연결되어 정보를 교환할 수 있습니다. 따라서 컴퓨터 A, B, C는 모두 같은 네트워크 상에 있다고 할 수 있습니다.&#xA;컴퓨터의 개수 n, 연결에 대한 정보가 담긴 2차원 배열 computers가 매개변수로 주어질 때, 네트워크의 개수를 return 하도록 solution 함수를 작성하시오.</description>
    </item>
    <item>
      <title>#4 모델 학습</title>
      <link>http://localhost:1313/docs/study/tech/tech26/</link>
      <pubDate>Tue, 17 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/tech/tech26/</guid>
      <description>#4 모델 학습 # #2025-06-18&#xA;1. Load package # import warnings warnings.filterwarnings(&amp;#34;ignore&amp;#34;) import copy from pathlib import Path import warnings import lightning.pytorch as pl from lightning.pytorch.callbacks import EarlyStopping, LearningRateMonitor from lightning.pytorch.loggers import TensorBoardLogger import numpy as np import pandas as pd import torch from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet from pytorch_forecasting.data import GroupNormalizer from pytorch_forecasting.metrics import MAE, SMAPE, PoissonLoss, QuantileLoss from pytorch_forecasting.models.temporal_fusion_transformer.tuning import ( optimize_hyperparameters, ) 2. Check version # import pytorch_forecasting import torch import pytorch_lightning as pl print(&amp;#34;PyTorch Forecasting:&amp;#34;, pytorch_forecasting.</description>
    </item>
    <item>
      <title>#4 완전범죄</title>
      <link>http://localhost:1313/docs/study/tech/algo3/</link>
      <pubDate>Tue, 17 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/tech/algo3/</guid>
      <description>#4 완전범죄 # #2025-06-19&#xA;1. 문제 # #문제 설명&#xA;A도둑과 B도둑이 팀을 이루어 모든 물건을 훔치려고 합니다. 단, 각 도둑이 물건을 훔칠 때 남기는 흔적이 누적되면 경찰에 붙잡히기 때문에, 두 도둑 중 누구도 경찰에 붙잡히지 않도록 흔적을 최소화해야 합니다.&#xA;물건을 훔칠 때 조건은 아래와 같습니다.&#xA;물건 i를 훔칠 때, A도둑이 훔치면 info[i][0]개의 A에 대한 흔적을 남깁니다. B도둑이 훔치면 info[i][1]개의 B에 대한 흔적을 남깁니다. 각 물건에 대해 A도둑과 B도둑이 남기는 흔적의 개수는 1 이상 3 이하입니다.</description>
    </item>
    <item>
      <title>#1 완주하지 못한 선수</title>
      <link>http://localhost:1313/docs/study/tech/algo1/</link>
      <pubDate>Mon, 16 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/tech/algo1/</guid>
      <description>#1 완주하지 못한 선수 # #2025-06-16&#xA;#문제 설명&#xA;수많은 마라톤 선수들이 마라톤에 참여하였습니다. 단 한 명의 선수를 제외하고는 모든 선수가 마라톤을 완주하였습니다.&#xA;마라톤에 참여한 선수들의 이름이 담긴 배열 participant와 완주한 선수들의 이름이 담긴 배열 completion이 주어질 때, 완주하지 못한 선수의 이름을 return 하도록 solution 함수를 작성해주세요.&#xA;#제한사항&#xA;마라톤 경기에 참여한 선수의 수는 1명 이상 100,000명 이하입니다. completion의 길이는 participant의 길이보다 1 작습니다. 참가자의 이름은 1개 이상 20개 이하의 알파벳 소문자로 이루어져 있습니다.</description>
    </item>
    <item>
      <title>프로그래머스 알고리즘 고득점 kit - 스택/큐</title>
      <link>http://localhost:1313/docs/study/tech/tech8/</link>
      <pubDate>Wed, 09 Apr 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/tech/tech8/</guid>
      <description>프로그래머스 알고리즘 고득점 kit - 스택/큐 # 목록 # 2024-04-09 ⋯ [스택/큐] 기능개발&#xA;2024-04-10 ⋯ [스택/큐] 올바른 괄호&#xA;2024-04-10 ⋯ [스택/큐] 프로세스&#xA;2024-04-10 ⋯ [스택/큐] 다리를 지나는 트럭&#xA;기능개발 # 입출력 예 # progresses = [93, 30, 55] speeds = [1, 30, 5] return = [2, 1] 개념 # progresses = [99,99,97] speeds = [1,1,1]이면 cnt=0 progresses = [100,100,98] -&amp;gt; cnt=1 -&amp;gt; cnt=2 -&amp;gt; answer = [2] cnt=0 progresses = [99] -&amp;gt; cnt=0, answer = [2] cnt=0 progresses = [100] -&amp;gt; cnt=1 -&amp;gt; answer = [1] cnt=0 progresses = [] -&amp;gt; 종료 코드 # def solution(progresses, speeds): answer = [] while progresses: for i in range(len(progresses)): progresses[i] += speeds[i] cnt = 0 while progresses and progresses[0] &amp;gt;= 100: progresses.</description>
    </item>
    <item>
      <title>프로그래머스 알고리즘 고득점 kit - 해시, 정렬</title>
      <link>http://localhost:1313/docs/study/tech/study2/</link>
      <pubDate>Wed, 09 Apr 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/tech/study2/</guid>
      <description>프로그래머스 알고리즘 고득점 kit - 해시, 정렬 # 목록 # 2024-04-09 ⋯ [해시] 완주하지 못한 선수&#xA;2024-04-09 ⋯ [해시] 전화번호 목록&#xA;2024-04-09 ⋯ [해시] 의상&#xA;2024-04-09 ⋯ [정렬] 완주하지 못한 선수&#xA;2024-04-09 ⋯ [정렬] H-Index&#xA;2024-04-10 ⋯ [해시] 베스트앨범&#xA;완주하지 못한 선수 # 입출력 예 # participant = [&amp;#34;leo&amp;#34;, &amp;#34;kiki&amp;#34;, &amp;#34;eden&amp;#34;]&#x9;completion = [&amp;#34;eden&amp;#34;, &amp;#34;kiki&amp;#34;]&#x9;return = &amp;#34;leo&amp;#34; 개념 # Counter([&amp;#34;leo&amp;#34;, &amp;#34;kiki&amp;#34;, &amp;#34;eden&amp;#34;]) -&amp;gt; {&amp;#39;leo&amp;#39;:1, &amp;#39;kiki&amp;#39;:1, &amp;#39;eden&amp;#39;:1} Counter([&amp;#34;leo&amp;#34;, &amp;#34;kiki&amp;#34;, &amp;#34;eden&amp;#34;]) - Counter([&amp;#34;kiki&amp;#34;, &amp;#34;eden&amp;#34;]) -&amp;gt; {&amp;#39;leo&amp;#39;:1} (key별로 value를 빼서 0이나 음수되면 제거) 코드 # from collections import Counter def solution(participant, completion): answer = Counter(participant) - Counter(completion) return list(answer.</description>
    </item>
    <item>
      <title>딥러닝을 이용한 자연어 처리 입문 | BERT</title>
      <link>http://localhost:1313/docs/study/bioinformatics/cs14/</link>
      <pubDate>Tue, 31 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/cs14/</guid>
      <description>[딥러닝] 딥러닝을 이용한 자연어 처리 입문 | BERT # 목록 # 2024-12-31 ⋯ 17-02 버트(Bidirectional Encoder Representations from Transformers, BERT)&#xA;2024-12-31 ⋯ 17-03 구글 BERT의 마스크드 언어 모델&#xA;2024-12-31 ⋯ 17-04 한국어 BERT의 마스크드 언어 모델&#xA;2024-12-31 ⋯ 17-05 구글 BERT의 다음 문장 예측&#xA;2024-12-31 ⋯ 17-06 한국어 BERT의 다음 문장 예측&#xA;17-02 버트(Bidirectional Encoder Representations from Transformers, BERT) # BERT?&#xA;BERT는 문맥 정보를 반영한 임베딩(Contextual Embedding)을 사용함. 이는 단어의 의미가 문맥에 따라 달라질 수 있음을 모델이 학습하도록 설계된 방식.</description>
    </item>
    <item>
      <title>혼자 공부하는 딥러닝 | ANN</title>
      <link>http://localhost:1313/docs/study/bioinformatics/cs12/</link>
      <pubDate>Tue, 31 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/cs12/</guid>
      <description>[딥러닝] 혼자 공부하는 딥러닝 | ANN # 목록 # 2024-12-31 ⋯ 17. 간단한 인공 신경망 모델 만들기&#xA;2024-12-31 ⋯ 18. 인공 신경망에 층을 추가하여 심층 신경망 만들어 보기&#xA;2024-12-31 ⋯ 19. 인경 신경망 모델 훈련의 모범 사례 학습하기&#xA;17. 간단한 인공 신경망 모델 만들기 # 데이터 준비 fashion_mnist 데이터셋에서 학습과 테스트용 이미지 데이터를 가져온다. 학습 데이터는 60,000개의 28x28 픽셀 이미지, 테스트 데이터는 10,000개의 28x28 픽셀 이미지. train_target과 test_target은 각 이미지에 해당하는 레이블(0~9)을 갖고있다.</description>
    </item>
  </channel>
</rss>
