<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Langchain on  </title>
    <link>http://localhost:1313/categories/langchain/</link>
    <description>Recent content in Langchain on  </description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 13 Oct 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/categories/langchain/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Langchain #3 LangGraph 기반 Multi-Agent &#43; Agentic RAG 시스템</title>
      <link>http://localhost:1313/docs/study/be/be9/</link>
      <pubDate>Mon, 13 Oct 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be9/</guid>
      <description>Langchain #3 LangGraph 기반 Multi-Agent + Agentic RAG 시스템 # #2025-10-13&#xA;1. 실습 개요 # 목적&#xA;AI 헬스케어 스타트업의 투자 가치를 평가하기 위해 입력된 스타트업 정보에서 &amp;lsquo;경쟁사 유무를 자동 판별&amp;rsquo;하고, 판별 결과에 따라 워크플로우를 동적으로 분기하여 &amp;lsquo;Multi-Agent 시스템(10개 전문 에이전트)&amp;lsquo;이 각자의 역할(정보 수집, 기술력 분석, 시장성 평가, 경쟁사 비교)을 순차적으로 수행하며, 외부 문서(시장 보고서, 기술 리뷰, 규제 정보)를 &amp;lsquo;RAG 시스템(FAISS + OpenAI Embeddings)&amp;lsquo;으로 검색하여 LLM 분석에 참조 컨텍스트를 제공하고, &amp;lsquo;Scorecard Method 가중치 평가 방식&amp;rsquo;으로 6개 항목(창업자/팀, 시장성, 제품/기술력, 경쟁 우위, 실적, 투자조건)을 정량화하여 10점 만점 투자 점수를 산출한 뒤, 전체 프로세스를 &amp;lsquo;LangGraph 기반 상태 관리 워크플로우&amp;rsquo;로 자동화하고, 최종적으로 분석 결과를 Executive Summary, 기술력/시장성 평가, 경쟁 분석, 투자 판단을 포함한 전문적인 &amp;lsquo;Word/PDF 형식의 투자 평가 보고서&amp;rsquo;로 생성 실습 설계</description>
    </item>
    <item>
      <title>Langchain #2 RAG 기반 LLM API 서버 구축</title>
      <link>http://localhost:1313/docs/study/be/be29/</link>
      <pubDate>Tue, 23 Sep 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be29/</guid>
      <description>Langchain #2 RAG 기반 LLM API 서버 구축 # #2025-09-23&#xA;1. 실습1 - LLM 질문-응답 Agent 구현 # #1 작업 위치 설정&#xA;# 1. 작업 위치 $ pwd /Users/yshmbid/Documents/home/github/MLops/template/#10.code # 2. 파일 확인 $ ls __pycache__ practice_LLM_App_main.py practice_LLM_App_front.vue # #2 백엔드 띄우기&#xA;# 3. 백엔드 띄우기 $ uvicorn practice_LLM_App_main:app --port 8005 --reload INFO: Will watch for changes in these directories: [&amp;#39;/Users/yshmbid/Documents/home/github/MLops/template/#10.code&amp;#39;] INFO: Uvicorn running on http://127.0.0.1:8005 (Press CTRL+C to quit) INFO: Started reloader process [7018] using StatReload 🖥 CPU 환경에서 로드합니다.</description>
    </item>
    <item>
      <title>Langchain #1 노션 데이터로 나만의 RAG 시스템 구축하기 (스터디)</title>
      <link>http://localhost:1313/docs/study/be/be5/</link>
      <pubDate>Wed, 10 Sep 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/be/be5/</guid>
      <description>Langchain #1 노션 데이터로 나만의 RAG 시스템 구축하기 (스터디) # #2025-09-10&#xA;스터디하는친구가 만들어준코드인데 내 노션으로 돌려봤다!&#xA;실습 목적&#xA;노션 데이터를 임베딩 생성하여 FAISS 벡터 스토어에 저장하고 이를 기반으로 유사 문서 검색을 수행하며, 청킹 기법을 통해 데이터 구조를 이해하고 LLM 프롬프트 제약을 적용한 뒤, RAG 구조를 접목해 자동 답변 구현 실습 설계&#xA;임베딩 생성: SentenceTransformer(&amp;ldquo;BAAI/bge-m3&amp;rdquo;) 유사 문서 검색: 코사인 유사도 + FAISS 벡터 스토어 기반 최근접 탐색 청킹 기법: Markdown 단위 분리 + 길이 기반 추가 분할 LLM 프롬프트 제약: 근거 기반 답변(추측 금지 규칙 포함) 자동 답변 구현: RAG 구조 + &amp;ldquo;meta-llama/llama-3.</description>
    </item>
  </channel>
</rss>
