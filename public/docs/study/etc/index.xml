<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>etc on  </title>
    <link>http://localhost:1313/docs/study/etc/</link>
    <description>Recent content in etc on  </description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 26 Jun 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/docs/study/etc/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>#2 Explainable AI</title>
      <link>http://localhost:1313/docs/study/etc/etc2/</link>
      <pubDate>Thu, 26 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/etc/etc2/</guid>
      <description>#2 Explainable AI # #2025-06-26&#xA;1. Explainable AI란? # Explainable AI는 인공지능(AI) 또는 머신러닝(ML) 모델이 어떤 방식으로 특정 결과를 도출했는지 사람이 이해할 수 있도록 설명하는 기술과 방법론.&#xA;2. XAI 기법 분류 # 모델 구조&#xA;Intrinsic:&#x9;모델 자체가 설명 가능한 구조 (예: 의사결정나무, 선형회귀 등) Post-hoc:&#x9;모델 학습 후 별도로 설명 생성 (예: SHAP, LIME) 대상 Global:&#x9;전체 모델의 작동 원리를 설명 Local:&#x9;특정 샘플의 예측 결과를 설명 3. 주요 Post-hoc 설명 기법 # LIME (Local Interpretable Model-Agnostic Explanations): 주변 입력을 랜덤하게 생성하고, 단순 모델(선형 회귀 등)을 학습해 근사</description>
    </item>
    <item>
      <title>#3 Random Forest</title>
      <link>http://localhost:1313/docs/study/etc/etc3/</link>
      <pubDate>Thu, 26 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/etc/etc3/</guid>
      <description>#3 Random Forest # #2025-06-26&#xA;1. Random Forest의 분류와 회귀 # 랜덤 포레스트(Random Forest)는&#xA;RandomForestClassifier: 분류용 RandomForestRegressor: 회귀용 이다. 분류와 회귀의 핵심 차이는&#xA;분류는 각 leaf node에 속한 클래스의 비율을 기반으로 확률 예측 회귀는 leaf node에 있는 target 값들의 평균을 예측값으로 사용 랜덤 포레스트의 트리 구조(= 리프 분기 방식)는 분류나 회귀나 똑같고&#xA;단지 리프 노드에 어떤 데이터 형식이 들어가느냐에 따라 분류이면 라벨 비율(확률 분포) 회귀이면 값의 평균으로 예측을 내놓는다 2.</description>
    </item>
    <item>
      <title>#1 DBSCAN</title>
      <link>http://localhost:1313/docs/study/etc/etc1/</link>
      <pubDate>Wed, 25 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/etc/etc1/</guid>
      <description>#1 DBSCAN # #2025-06-25&#xA;개념 # DBSCAN은 밀도 기반 클러스터링 알고리즘으로&#xA;데이터가 밀집된 영역을 클러스터로 인식하고 밀도가 낮은 영역은 노이즈(이상치)로 간주하는 방법. KMeans와 달리, 군집 수를 미리 정하지 않아도 되며,&#xA;비선형 구조나 잡음이 있는 데이터에서 잘 작동한다. 파라미터와 핵심 용어 # 주요 파라미터는 2개&#xA;eps: 반지름 거리. 한 점에서 eps 거리 내에 있는 점들을 &amp;ldquo;이웃&amp;quot;이라고 판단. min_samples: core point로 인정되기 위해 필요한 최소 이웃 수 핵심 용어는 3개&#xA;Core Point (중심점): eps 거리 내에 min_samples 이상 이웃이 있는 점 Border Point (경계점): core point의 eps 거리 내에 있으나, 자기 자신은 core point가 아닌 점 Noise Point (잡음점): 어떤 core point의 eps 안에도 포함되지 않는 점 장점과 단점 # 장점 4개</description>
    </item>
  </channel>
</rss>
