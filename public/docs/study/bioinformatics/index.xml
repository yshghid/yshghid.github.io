<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>bi on Lifelog 2025</title>
    <link>http://localhost:1313/docs/study/bioinformatics/</link>
    <description>Recent content in bi on Lifelog 2025</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 23 May 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/docs/study/bioinformatics/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>[NAVER Cloud] 환자향 진료기록 생성 모델 개발 (체험형 인턴)</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi22/</link>
      <pubDate>Fri, 23 May 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi22/</guid>
      <description>[NAVER Cloud] 환자향 진료기록 생성 모델 개발 (체험형 인턴) # 링크 - https://recruit.navercloudcorp.com/rcrt/view.do?annoId=30003399&amp;lang=ko</description>
    </item>
    <item>
      <title>한국사능력검정시험 시험일정</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi21/</link>
      <pubDate>Fri, 23 May 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi21/</guid>
      <description>한국사능력검정시험 시험일정 # 정보 - https://www.historyexam.go.kr/pageLink.do?link=examSchedule&amp;netfunnel_key=B074990245F42DF6F192C5CF3EDF850DA87F7088B5EC6B2A5509EF323965FA6EEFA3B493E69B1EC65461E3F8696674B62CB7178428F55B3E8FF8E7D02A753B4362CAC618E726254B9B86061931358E535040FF6CCA34DB8A028CF47044B6F18A234B1EEDF2C1E725FD8CB4420BEBC394362C312C302C30</description>
    </item>
    <item>
      <title>(주)마크로젠 서비스개발분석부 신입/경력 채용</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi13/</link>
      <pubDate>Mon, 21 Apr 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi13/</guid>
      <description>(주)마크로젠 서비스개발분석부 신입/경력 채용 # 공고 바로가기</description>
    </item>
    <item>
      <title>2025년 제2기 질병관리청 국립보건연구원 공무직(연구원) 채용공고</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi17/</link>
      <pubDate>Mon, 21 Apr 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi17/</guid>
      <description>2025년 제2기 질병관리청 국립보건연구원 공무직(연구원) 채용공고 # 공고 바로가기</description>
    </item>
    <item>
      <title>ChIP-seq Preprocessing: Trimming, Alignment, Peak Calling</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi5/</link>
      <pubDate>Mon, 21 Apr 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi5/</guid>
      <description>ChIP-seq Preprocessing: Trimming, Alignment, Peak Calling # 1. Trimming # #chipseq_trimming.sh&#xA;#!/bin/bash # setting envs export bdir=&amp;#34;/data3/projects/2022_KNU_EBV&amp;#34; export hg38_bowtieidx=&amp;#34;/data3/PUBLIC_DATA/ref_genomes/homo_sapiens/hg38/hg38_bowtie_idx/hg38.fa&amp;#34; export hg38_bwaidx=&amp;#34;/data3/PUBLIC_DATA/ref_genomes/homo_sapiens/hg38/hg38_bwa_index/hg38.fa&amp;#34; export ebv_bowtie2idx=&amp;#34;/data3/PUBLIC_DATA/ref_genomes/Human_gammaherpesvirus_4_EBV/EBV_bowtie2_idx/NC_007605.1.fa&amp;#34; export ebv_bwaidx=&amp;#34;/data3/PUBLIC_DATA/ref_genomes/Human_gammaherpesvirus_4_EBV/EBV_bwa_index/NC_007605.1.fa&amp;#34; ### SET Path ### cd /data3/RAW_DATA/2023_KNU_EBV/ChIP-seq ### TRIMMING data ### mkdir -p trimmed sampdir=&amp;#34;/data3/RAW_DATA/2023_KNU_EBV/ChIP-seq&amp;#34; samplist=(&amp;#34;Input&amp;#34; &amp;#34;p65&amp;#34; &amp;#34;RIgG&amp;#34;) TRIMMOMATIC= &amp;#34;/data/packages/trimmomatic/Trimmomatic-0.39/trimmomatic-0.39.jar&amp;#34; for sampname in &amp;#34;${samplist[@]}&amp;#34;; do mkdir -p &amp;#34;trimmed/${sampname}&amp;#34; java -jar $TRIMMOMATIC PE -threads 40 -trimlog log1.txt $sampdir/${sampname}_1.fastq/${sampname}_1.fastq $sampdir/${sampname}_2.fastq/${sampname}_2.fastq $sampdir/trimmed/${sampname}/${sampname}_1.trimmed.fastq $sampdir/trimmed/${sampname}/${sampname}_1.up.trimmed.fastq $sampdir/trimmed/${sampname}/${sampname}_2.trimmed.fastq $sampdir/trimmed/${sampname}/${sampname}_2.up.trimmed.fastq ILLUMINACLIP:/data1/packages/trimmomatic/Trimmomatic-0.39/adapters/TruSeq3-PE.fa:2:30:10:2:True LEADING:3 TRAILING:3 MINLEN:36 done 2.</description>
    </item>
    <item>
      <title>Differential Gene Expression Analysis using Sleuth</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi2/</link>
      <pubDate>Mon, 21 Apr 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi2/</guid>
      <description>Differential Gene Expression Analysis using Sleuth # Load Package, Run Sleuth # require(&amp;#34;sleuth&amp;#34;) packageVersion(&amp;#34;sleuth&amp;#34;) library(&amp;#34;gridExtra&amp;#34;) library(&amp;#34;cowplot&amp;#34;) library(&amp;#34;biomaRt&amp;#34;) library(readr) setwd(&amp;#34;/data/home/ysh980101/2307_kallisto&amp;#34;) getwd() sample_id &amp;lt;- dir(file.path(&amp;#34;./&amp;#34;)) sample_id &amp;lt;- grep(&amp;#34;^output_(150|con)&amp;#34;, sample_id, value = TRUE) sample_id &amp;lt;- substring(sample_id, 8) sample_id kal_dirs &amp;lt;- file.path(paste0(&amp;#34;./output_&amp;#34;, sample_id)) s2c &amp;lt;- read.table(file.path(&amp;#34;./kallisto_demo_150_con.tsv&amp;#34;), header = TRUE, stringsAsFactors = FALSE, sep = &amp;#34;\t&amp;#34;) s2c &amp;lt;- dplyr::mutate(s2c, path = kal_dirs) s2c marts &amp;lt;- listMarts() ensembl &amp;lt;- useMart(&amp;#34;ensembl&amp;#34;) datasets &amp;lt;- listDatasets(ensembl) filtered_datasets &amp;lt;- datasets[grepl(&amp;#34;hsapiens&amp;#34;, datasets$dataset), ] hsapiens_mart &amp;lt;- useMart(&amp;#34;ensembl&amp;#34;,dataset=&amp;#34;hsapiens_gene_ensembl&amp;#34;) datasets &amp;lt;- listDatasets(hsapiens_mart) filtered_datasets &amp;lt;- datasets[grepl(&amp;#34;hsapiens&amp;#34;, datasets$dataset), ] hsapiens_mart &amp;lt;- useMart(&amp;#34;ensembl&amp;#34;,dataset=&amp;#34;hsapiens_gene_ensembl&amp;#34;,host=&amp;#34;ensembl.</description>
    </item>
    <item>
      <title>Functional Enrichment Bubble Plot using gProfiler/ggplot2</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi3/</link>
      <pubDate>Mon, 21 Apr 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi3/</guid>
      <description>Functional Enrichment Bubble Plot using gProfiler/ggplot2 # Load Package # library(ggplot2) Set Path # setwd(&amp;#34;/data-blog/bi3&amp;#34;) getwd() &amp;#39;/data-blog/bi3&amp;#39; Functional Enrichment Bubble Plot # condition &amp;lt;- &amp;#39;150_con&amp;#39; gpsource &amp;lt;- &amp;#39;GO:BP&amp;#39; #gpsource &amp;lt;- &amp;#39;REAC&amp;#39; df_c1 &amp;lt;- read.csv(paste0(&amp;#34;./sleuth_ward/gprofiler/gProfiler_&amp;#34;,condition,&amp;#34;_termsize.csv&amp;#34;)) df_c2 &amp;lt;- read.csv(paste0(&amp;#34;gProfiler_&amp;#34;,condition,&amp;#34;_c2_padj0.1.csv&amp;#34;)) df_c1 &amp;lt;- df_c1[df_c1$source == gpsource, ] df_c2 &amp;lt;- df_c2[df_c2$source == gpsource, ] df_c1$reg_type &amp;lt;- &amp;#39;down&amp;#39; df_c2$reg_type &amp;lt;- &amp;#39;up&amp;#39; df_c1$nlog &amp;lt;- -abs(df_c1$negative_log10_of_adjusted_p_value) df_c2$nlog &amp;lt;- abs(df_c2$negative_log10_of_adjusted_p_value) df_c1 &amp;lt;- df_c1[order(df_c1$negative_log10_of_adjusted_p_value), ] df_c2 &amp;lt;- df_c2[order(-df_c2$negative_log10_of_adjusted_p_value), ] df &amp;lt;- rbind(df_c1, df_c2) ggplot(df, aes(x = reorder(term_name, nlog), y = negative_log10_of_adjusted_p_value, size = intersection_size, color = nlog)) + geom_point(alpha = 0.</description>
    </item>
    <item>
      <title>RNA-seq Preprocessing using TopHat, SAMtools, HTSeq</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi7/</link>
      <pubDate>Mon, 21 Apr 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi7/</guid>
      <description>RNA-seq Preprocessing using TopHat, SAMtools, HTSeq # 1. TopHat 실행 # $ tophatpy -o tophat_out_33-1 --no-mixed -p 40 \ $ /data3/PUBLIC_DATA/ref_genomes/homo_sapiens/GRCh38/Homo_sapiens.GRCh38.dna.toplevel \ $ /data/home/ysh980101/2306_tophat/data/Bowtie2Index/5-AZA_33-1_1.fastq \ $ /data/home/ysh980101/2306_tophat/data/Bowtie2Index/5-AZA_33-1_2.fastq tophatpy: tophat2 안먹어서 커스텀한 명령어 (정식 명령어는 tophat2) -o tophat_out_33-1: 출력 디렉토리 설정 --no-mixed: 페어 중 하나만 매핑되면 제외 -p 40: 멀티스레딩, 40개 스레드 사용 /data3/PUBLIC_DATA/...dna.toplevel: reference genome FASTA (Bowtie2 인덱스가 이와 동일한 경로로 있어야 함) 2개의 paired-end read 입력 cf) tophat alias 확인</description>
    </item>
    <item>
      <title>RNA-seq 파이프라인 꿀조합 (Rsubread, edgeR)</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi8/</link>
      <pubDate>Mon, 21 Apr 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi8/</guid>
      <description>RNA-seq 파이프라인 꿀조합 (Rsubread, edgeR) # 가장 오류 적게나는 조합! 1. Align RNA-seq # Load Packages # library(Rsubread) library(org.Mm.eg.db) library(gridExtra) library(reshape2) Set Path # indir = &amp;#34;/data/home/ysh980101/2504/mirna/data&amp;#34; outdir = &amp;#34;/data/home/ysh980101/2504/mirna/data&amp;#34; refpath = &amp;#34;/data/home/ysh980101/2406/data-gne/mm39.fa&amp;#34; setwd(indir) getwd() &amp;#39;/data/home/ysh980101/2504/mirna/data&amp;#39; Build Index # buildindex(basename = &amp;#34;mm39&amp;#34;, reference = refpath) Read Alignment # files &amp;lt;- list.files(pattern=&amp;#34;\\.fastq\\.gz$&amp;#34;, full.names=TRUE) bams &amp;lt;- sub(&amp;#34;\\.fastq\\.gz$&amp;#34;, &amp;#34;.bam&amp;#34;, files) samples &amp;lt;- gsub(&amp;#34;^\\.\\/|\\.fastq\\.gz$&amp;#34;, &amp;#34;&amp;#34;, files) targets &amp;lt;- read.delim(&amp;#34;target.txt&amp;#34;, header=TRUE) align(index=&amp;#34;mm39&amp;#34;, readfile1=files, input_format=&amp;#34;gzFASTQ&amp;#34;, output_file=bams, nthreads=50) Quantification # fc = featureCounts(bams, isGTFAnnotationFile=TRUE, GTF.</description>
    </item>
    <item>
      <title>TopHat2&#43;HTSeq vs Rsubread 비교</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi9/</link>
      <pubDate>Mon, 21 Apr 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi9/</guid>
      <description>TopHat2+HTSeq vs Rsubread 비교 # 1. Methods # 비교 의의&#xA;Traditional 방법은 TopHat2+HTseq 조합이지만 오류도 넘 많이나고 Rsubread를 쓰면 빠르고 깔끔한데 왜 써야하지..? 싶어서 동일한 데이터(pair-end fastq)로 돌려봄. HTseq에서 아래 코드를 수행할때 파라미터가 많은데 뭐가 다르게나오는지 모르겠어서 실험해봄. Cases&#xA;Rsubread 사용 HTSeq 사용, -i gene_id --additional-attr=gene_name (exon 기준 count) HTSeq 사용, -i transcript_id --additional-attr=gene_id --additional-attr=gene_name (transcript 기준 count) HTSeq 사용, -i transcript_id --additional-attr=gene_id --additional-attr=gene_name --nonunique=all (여러 transcript에 매핑된 read는 모두 count) 2.</description>
    </item>
    <item>
      <title>Transcript Quantification using Kallisto Pseudoalignment</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi4/</link>
      <pubDate>Mon, 21 Apr 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi4/</guid>
      <description>Transcript Quantification using Kallisto Pseudoalignment # 1. Build Index # $ kallisto index -i transcripts_cDNA.idx Homo_sapiens.GRCh38.cdna.all.fa.gz 2. Pseudoalign # $ kallisto quant -i transcripts_cDNA.idx -o output_150-1 -t 40 ../2306_tophat/data/Bowtie2Index/5-AZA_150-1_1_edited.fastq ../2306_tophat/data/Bowtie2Index/5-AZA_150-1_2_edited.fastq 3개 파일 생성 abundance.h5 - HDF5 binary file containing run info, abundance esimates, bootstrap estimates, and transcript length information length. This file can be read in by sleuth abundance.tsv - plaintext file of the abundance estimates. It does not contains bootstrap estimates.</description>
    </item>
    <item>
      <title>WGBS Preprocessing using Bismark</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi6/</link>
      <pubDate>Mon, 21 Apr 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi6/</guid>
      <description> WGBS Preprocessing using Bismark # 1. Build Index # $ bowtie2-build Homo_sapiens.GRCh38.dna.toplevel.fa GRCh38 -p 40 2. Bam Sorting &amp;amp; Indexing # $ samtools sort KEB01_1_bismark_bt2_pe.bam -o KEB01_1_bismark_bt2_pe.sorted.bam $ samtools index KEB01_1_bismark_bt2_pe.sorted.bam 3. Methylation Extraction # $ bismark_methylation_extractor --gzip --bedGraph --buffer_size 10G --cytosine_report --genome_folder /data3/PUBLIC_DATA/ref_genomes/homo_sapiens/GRCh37_hg19/Homo_sapiens/Ensembl/GRCh37/Sequence/WholeGenomeFasta KEB01_1_bismark_bt2_pe.sorted.bam </description>
    </item>
    <item>
      <title>삼양식품/Healthcare BU OMICS AI Engineer(연구원)</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi14/</link>
      <pubDate>Mon, 21 Apr 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi14/</guid>
      <description>삼양식품/Healthcare BU OMICS AI Engineer(연구원) # 공고 바로가기</description>
    </item>
    <item>
      <title>한국산업기술기획평가원(KEIT) 2025년 신입직원 채용 - R&amp;D 기획평가_바이오생명_정규직</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi15/</link>
      <pubDate>Mon, 21 Apr 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi15/</guid>
      <description>한국산업기술기획평가원(KEIT) 2025년 신입직원 채용 - R&amp;amp;D 기획평가_바이오생명_정규직 # 공고 바로가기</description>
    </item>
    <item>
      <title>국민건강보험공단 2025년도 제1차 전문인력 채용</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi18/</link>
      <pubDate>Fri, 21 Feb 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi18/</guid>
      <description>국민건강보험공단 2025년도 제1차 전문인력 채용 # 전산 &amp;gt; AI&#xA;연구 &amp;gt; 보건·의료통계연구&#xA;전산 &amp;gt; 빅데이터&#xA;공고 전문&#xA;공고 바로가기</description>
    </item>
    <item>
      <title>한국의약품안전관리원 2025년 1차 직원 채용 </title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi19/</link>
      <pubDate>Fri, 21 Feb 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi19/</guid>
      <description>한국의약품안전관리원 2025년 1차 직원 채용 # 특수 &amp;gt; 통계&#xA;공고 바로가기</description>
    </item>
    <item>
      <title>대학원생 면접대비캠프</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi12/</link>
      <pubDate>Tue, 07 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi12/</guid>
      <description>대학원생 면접대비캠프 # 대학원생 대상으로 면접대비 강의가 있길래 신청해봤다!&#xA;화수목은 5시부터 9시이구 금요일은 1시부터 6시반이라서 금요일은 일찍 퇴근할수있으면 퇴근하고 듣는게 좋을듯. 토요일은 10시부터 오프라인으로 한다.&#xA;이번주 랩미팅이 목요일 2시에 있고 논문 미팅은 금요일 아침 9시라서 크게 겹치지는 않아 매우 다행이다!!&#xA;커리큘럼 # 2025-01-07 ⋯ 1일차 - 면접 기초 &amp;raquo;&#xA;2025-01-08 ⋯ 2일차 - 면접유형별 대응 전략 &amp;raquo;&#xA;2025-01-09 ⋯ 3일차 - 면접답변 노하우 &amp;raquo;&#xA;2025-01-10 ⋯ 4일차 - 모의면접(PT, 세미나) &amp;raquo;</description>
    </item>
    <item>
      <title>DESeq2 워크플로우</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi1/</link>
      <pubDate>Tue, 31 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi1/</guid>
      <description>[코드] DESeq2 워크플로우 # Load package # suppressMessages({ library(&amp;#34;DESeq2&amp;#34;) library(pheatmap) library(withr) #library(tidyverse) library(RColorBrewer) library(gplots) library(dplyr) }) Set path # setwd(&amp;#34;/data-blog/bi1&amp;#34;) getwd() &amp;#39;/data-blog/bi1&amp;#39; Run DESeq2 # S1 &amp;lt;- &amp;#39;33&amp;#39; S2 &amp;lt;- &amp;#39;150&amp;#39; countdata &amp;lt;- read.csv(&amp;#34;results.csv&amp;#34;, header=TRUE, sep=&amp;#39;,&amp;#39;) colnames(countdata) &amp;lt;- c(&amp;#39;GeneID&amp;#39;,&amp;#39;150-1&amp;#39;,&amp;#39;150-2&amp;#39;,&amp;#39;150-3&amp;#39;,&amp;#39;33-1&amp;#39;,&amp;#39;33-2&amp;#39;,&amp;#39;33-3&amp;#39;,&amp;#39;con-1&amp;#39;,&amp;#39;con-2&amp;#39;,&amp;#39;con-3&amp;#39;) countdata &amp;lt;- countdata[, c(&amp;#39;GeneID&amp;#39;,&amp;#39;150-1&amp;#39;,&amp;#39;150-2&amp;#39;,&amp;#39;150-3&amp;#39;,&amp;#39;33-1&amp;#39;,&amp;#39;33-2&amp;#39;,&amp;#39;33-3&amp;#39;,&amp;#39;con-1&amp;#39;,&amp;#39;con-2&amp;#39;,&amp;#39;con-3&amp;#39;)] selected_columns &amp;lt;- paste(c(&amp;#39;GeneID&amp;#39;,paste0(S2,&amp;#34;-1&amp;#34;), paste0(S2,&amp;#34;-2&amp;#34;), paste0(S2,&amp;#34;-3&amp;#34;),paste0(S1,&amp;#34;-1&amp;#34;), paste0(S1,&amp;#34;-2&amp;#34;), paste0(S1,&amp;#34;-3&amp;#34;)), sep=&amp;#34;&amp;#34;) countdata &amp;lt;- countdata[, selected_columns] countdata &amp;lt;- countdata[rowSums(countdata[, -1]) != 0, ] sample.names &amp;lt;- paste(c(paste0(S2,&amp;#34;-1&amp;#34;), paste0(S2,&amp;#34;-2&amp;#34;), paste0(S2,&amp;#34;-3&amp;#34;),paste0(S1,&amp;#34;-1&amp;#34;), paste0(S1,&amp;#34;-2&amp;#34;), paste0(S1,&amp;#34;-3&amp;#34;)), sep=&amp;#34;&amp;#34;) conditions &amp;lt;- factor(c(S2,S2,S2,S1,S1,S1)) metadata &amp;lt;- data.</description>
    </item>
    <item>
      <title>DESeq2 워크플로우</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi10/</link>
      <pubDate>Tue, 31 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi10/</guid>
      <description>[코드] DESeq2 워크플로우 # Load package # # Input: genome_positions = list of genomic loci with H-scores # H_scores = dict {position: H_score} # Parameters: # MinPts = 5 # eps_scale = 10 # diminish_factor = 3 initialize hotspots = [] # STEP 1. Search Candidate Core Mutation (CCM) for position in genome_positions: H = H_scores[position] Deps = eps_scale * H neighborhood = get_neighbors_within_deps(position, Deps) avg_H = mean([H_scores[n] for n in neighborhood]) sum_H = sum([H_scores[n] for n in neighborhood]) num_mutants = len([n for n in neighborhood if H_scores[n] &amp;gt; 0]) if H &amp;gt; 0.</description>
    </item>
    <item>
      <title>EndNote 사용법</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi16/</link>
      <pubDate>Tue, 31 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi16/</guid>
      <description>EndNote 사용법 # 1. EndNote 설치 및 계정 설정 # 계정 설정: 공식 웹사이트에서 End note 계정을 생성한다.&#xA;설치: 나의 경우 여기에서 다운로드해줬다.&#xA;2. 레퍼런스 추가 방법 # Google Scholar에 논문 제목을 검색해서 인용&amp;gt;EndNote를 클릭하면 .enw 파일이 다운로드된다. 3. 레퍼런스 관리 # Endnote에 접속한다. Collect&amp;gt;Import References로 들어간다 파일 선택&amp;gt;아까 저장한 .enw 파일을 선택해준다 Import Option&amp;gt;EndNote Import를 선택해준다 To&amp;gt;New Group을 하면 논문 주제별로 그룹을 생성하여 정리 가능. 생성한 그룹이 이미 있으면 원하는 그룹 선택해준다.</description>
    </item>
    <item>
      <title>RNA-seq Preprocessing: EBV genome</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi11/</link>
      <pubDate>Tue, 31 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi11/</guid>
      <description>RNA-seq Preprocessing: EBV genome # 분석 목적&#xA;제공받은 fastq를 human genome에 매핑해서 전처리, 분석 후 DE 결과 보냄 DE 분석시에 EBV 유전자도 포함해달라는 요청 해야하는것&#xA;fastq를 EBV genome에 매핑해서 전처리, EBV count 생성 human count에 EBV count를 붙이기 통합 count로 DE 분석 재수행 1. Alignment # Load package, Set Path # library(edgeR) library(Rsubread) library(org.Hs.eg.db) setwd(&amp;#34;/data/home/ysh980101/2311/RNA-seq_ebv/Rsubread&amp;#34;) getwd() &amp;#39;/data1/home/ysh980101/2311/RNA-seq_ebv/Rsubread&amp;#39; Build Index # # build index ref &amp;lt;- &amp;#34;/data3/PUBLIC_DATA/ref_genomes/Human_gammaherpesvirus_4_EBV/NC_007605.1.fa&amp;#34; output_basename &amp;lt;- &amp;#34;NC_007605.1_idx&amp;#34; buildindex(basename = output_basename, reference = ref) Feature Count # # feature.</description>
    </item>
    <item>
      <title>구글 BERT의 정석 | BERT 입문</title>
      <link>http://localhost:1313/docs/study/bioinformatics/cs16/</link>
      <pubDate>Tue, 31 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/cs16/</guid>
      <description>[딥러닝] 구글 BERT의 정석 | BERT 입문 # 목록 # 2024-12-31 ⋯ 2.3 BERT의 구조&#xA;2024-12-31 ⋯ 2.4 BERT 사전 학습&#xA;2.3 BERT의 구조 # BERT의 전체 구조 # 트랜스포머의 인코더(Encoder) 블록을 여러 개 쌓은 형태. 입력: 문장 (토큰화된 형태) 내부 구조: N개의 Transformer Encoder Blocks (기본 모델은 12개, 큰 모델은 24개) 출력: 각 토큰의 벡터 표현 (Contextual Embedding) cf) BERT의 대표적인 모델 크기&#xA;모델 # 인코더 층 숨겨진 차원 (dmodel) 어텐션 헤드 수 파라미터 수 BERT-Base 12 768 12 110M BERT-Large 24 1024 16 340M BERT의 입력 처리 # 입력 토큰 (Token Embedding) WordPiece Tokenization을 사용하며, 단어를 서브워드(subword) 단위로 분할하고 각 토큰은 고유한 임베딩 벡터로 변환된다.</description>
    </item>
    <item>
      <title>구글 BERT의 정석 | BERT의 파생 모델</title>
      <link>http://localhost:1313/docs/study/bioinformatics/cs17/</link>
      <pubDate>Tue, 31 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/cs17/</guid>
      <description>[딥러닝] 구글 BERT의 정석 | BERT의 파생 모델: ALBERT, RoBERTa, ELECTRA, SpanBERT # 목록 # 2024-12-31 ⋯ 4.1 ALBERT&#xA;2024-12-31 ⋯ 4.3 RoBERTa&#xA;2024-12-31 ⋯ 4.4 ELECTRA&#xA;4.1 ALBERT # ALBERT (A Lite BERT)는 BERT 모델의 성능을 유지하면서도 파라미터 수를 줄이고, 더 효율적인 학습을 목표로 한 모델.&#xA;크로스 레이어 변수 공유 # BERT는 각 Transformer 레이어마다 별도의 가중치와 바이어스를 갖는다. ALBERT는 동일한 파라미터 집합을 여러 레이어에 걸쳐 사용하여 모델의 파라미터 수를 크게 줄인다.</description>
    </item>
    <item>
      <title>구글 BERT의 정석 | 트랜스포머 입문</title>
      <link>http://localhost:1313/docs/study/bioinformatics/cs15/</link>
      <pubDate>Tue, 31 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/cs15/</guid>
      <description>[딥러닝] 구글 BERT의 정석 | 트랜스포머 입문 # 목록 # 2024-12-31 ⋯ 1.2 트랜스포머의 인코더 이해하기&#xA;2024-12-31 ⋯ 1.3 트랜스포머의 디코더 이해하기&#xA;1.2 트랜스포머의 인코더 이해하기 # 셀프 어텐션 # 셀프 어텐션은 문장 내 단어들이 서로 얼마나 중요한지를 계산하는 과정. 트랜스포머는 이를 위해 입력 단어를 쿼리(Query), 키(Key), 밸류(Value) 세 가지 벡터로 변환하여 연관성을 구한다. 어텐션 점수 계산 예제 # &amp;ldquo;The cat sat on the mat.&amp;rdquo;&#xA;각 단어 벡터(예: 512차원)를 가중치 행렬과 곱하여 쿼리(Q), 키(K), 밸류(V)벡터를 생성한다.</description>
    </item>
    <item>
      <title>딥러닝을 이용한 자연어 처리 입문 | BERT</title>
      <link>http://localhost:1313/docs/study/bioinformatics/cs14/</link>
      <pubDate>Tue, 31 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/cs14/</guid>
      <description>[딥러닝] 딥러닝을 이용한 자연어 처리 입문 | BERT # 목록 # 2024-12-31 ⋯ 17-02 버트(Bidirectional Encoder Representations from Transformers, BERT)&#xA;2024-12-31 ⋯ 17-03 구글 BERT의 마스크드 언어 모델&#xA;2024-12-31 ⋯ 17-04 한국어 BERT의 마스크드 언어 모델&#xA;2024-12-31 ⋯ 17-05 구글 BERT의 다음 문장 예측&#xA;2024-12-31 ⋯ 17-06 한국어 BERT의 다음 문장 예측&#xA;17-02 버트(Bidirectional Encoder Representations from Transformers, BERT) # BERT?&#xA;BERT는 문맥 정보를 반영한 임베딩(Contextual Embedding)을 사용함. 이는 단어의 의미가 문맥에 따라 달라질 수 있음을 모델이 학습하도록 설계된 방식.</description>
    </item>
    <item>
      <title>혼자 공부하는 딥러닝 | ANN</title>
      <link>http://localhost:1313/docs/study/bioinformatics/cs12/</link>
      <pubDate>Tue, 31 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/cs12/</guid>
      <description>[딥러닝] 혼자 공부하는 딥러닝 | ANN # 목록 # 2024-12-31 ⋯ 17. 간단한 인공 신경망 모델 만들기&#xA;2024-12-31 ⋯ 18. 인공 신경망에 층을 추가하여 심층 신경망 만들어 보기&#xA;2024-12-31 ⋯ 19. 인경 신경망 모델 훈련의 모범 사례 학습하기&#xA;17. 간단한 인공 신경망 모델 만들기 # 데이터 준비 fashion_mnist 데이터셋에서 학습과 테스트용 이미지 데이터를 가져온다. 학습 데이터는 60,000개의 28x28 픽셀 이미지, 테스트 데이터는 10,000개의 28x28 픽셀 이미지. train_target과 test_target은 각 이미지에 해당하는 레이블(0~9)을 갖고있다.</description>
    </item>
    <item>
      <title>한국과학기술원 기간제 근로자(연수연구원) 모집</title>
      <link>http://localhost:1313/docs/study/bioinformatics/bi20/</link>
      <pubDate>Tue, 10 Jan 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/bioinformatics/bi20/</guid>
      <description>한국과학기술원 기간제 근로자(연수연구원) 모집 # 연구 &amp;gt; 연수연구원/IT융합연구소&#xA;연구 &amp;gt; 연수연구원/강화학습(정보전자연구소G)&#xA;연구 &amp;gt; 연수연구원/생명과학(생명과학연구소G)&#xA;연구 &amp;gt; 연수연구원/시스템생물학(정보전자연구소C)&#xA;연구 &amp;gt; 연수연구원/신경과학,인지과학,뇌과학 및뇌공학(생명과학연구소A)&#xA;공고 바로가기</description>
    </item>
  </channel>
</rss>
