<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AI on  </title>
    <link>http://localhost:1313/docs/study/ai/</link>
    <description>Recent content in AI on  </description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 13 Oct 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/docs/study/ai/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Langchain #2 LangGraph 기반 Multi-Agent &#43; Agentic RAG 시스템</title>
      <link>http://localhost:1313/docs/study/ai/ai39/</link>
      <pubDate>Mon, 13 Oct 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai39/</guid>
      <description>Langchain #2 LangGraph 기반 Multi-Agent + Agentic RAG 시스템 # #2025-10-13&#xA;1. 실습 개요 # 목적&#xA;AI 헬스케어 스타트업의 투자 가치를 평가하기 위해 입력된 스타트업 정보에서 &amp;lsquo;경쟁사 유무를 자동 판별&amp;rsquo;하고, 판별 결과에 따라 워크플로우를 동적으로 분기하여 &amp;lsquo;Multi-Agent 시스템(10개 전문 에이전트)&amp;lsquo;이 각자의 역할(정보 수집, 기술력 분석, 시장성 평가, 경쟁사 비교)을 순차적으로 수행하며, 외부 문서(시장 보고서, 기술 리뷰, 규제 정보)를 &amp;lsquo;RAG 시스템(FAISS + OpenAI Embeddings)&amp;lsquo;으로 검색하여 LLM 분석에 참조 컨텍스트를 제공하고, &amp;lsquo;Scorecard Method 가중치 평가 방식&amp;rsquo;으로 6개 항목(창업자/팀, 시장성, 제품/기술력, 경쟁 우위, 실적, 투자조건)을 정량화하여 10점 만점 투자 점수를 산출한 뒤, 전체 프로세스를 &amp;lsquo;LangGraph 기반 상태 관리 워크플로우&amp;rsquo;로 자동화하고, 최종적으로 분석 결과를 Executive Summary, 기술력/시장성 평가, 경쟁 분석, 투자 판단을 포함한 전문적인 &amp;lsquo;Word/PDF 형식의 투자 평가 보고서&amp;rsquo;로 생성 실습 설계</description>
    </item>
    <item>
      <title>AI #2 HPO, XAI 실습</title>
      <link>http://localhost:1313/docs/study/ai/ai38/</link>
      <pubDate>Mon, 22 Sep 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai38/</guid>
      <description>AI #2 HPO, XAI 실습 # #2025-09-22&#xA;1. 실습 개요 # 목적 UCI Breast Cancer 데이터를 로드하고 전처리 후 XGBoost 모델을 구축 및 평가 교차검증(StratifiedKFold, KFold)과 하이퍼파라미터 탐색 기법(RandomizedSearchCV, Optuna)을 비교하여 최적 성능을 도출 SHAP을 활용하여 전역적·집단적·개별적 수준에서 해석력을 확보하고 도메인 지식과 연결 구현 데이터 로드: UCI Breast Cancer 데이터셋 데이터 전처리: 타겟(Diagnosis)을 이진화(M=1, B=0), StandardScaler로 범위 스케일링, 상관계수 0.9 이상인 중복 변수 제거 모델 구축: xgboost.XGBClassifier 모델 평가: 정확도, AUC, 분류리포트, 혼동행렬, feature importance 교차검증: KFold, StratifiedKFold 하이퍼파라미터 최적화: Random Search, Optuna TPE 모델 해석 (SHAP) Bar Summary Plot: 전역적 중요도(평균 |SHAP|)를 통해 주요 변수 확인 Beeswarm Plot: 변수 값 크기(빨강/파랑)와 방향성(+/−)에 따른 분포 해석 Force / Waterfall Plot: 3가지 개별 환자 샘플(예측 확률 극단/불확실, SHAP 영향력 최대, 도메인 특이 케이스)을 선택하여 모델이 어떤 요인 때문에 해당 예측을 내렸는지 설명 # 2.</description>
    </item>
    <item>
      <title>AI #3 SK 바이오팜 뇌전증 발작 기전 탐지 프로젝트</title>
      <link>http://localhost:1313/docs/study/ai/ai37/</link>
      <pubDate>Mon, 22 Sep 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai37/</guid>
      <description>AI #3 SK 바이오팜 뇌전증 발작 기전 탐지 프로젝트 # #2025-09-22&#xA;1. 프로젝트 배경 # Digital biomarker 생체 신호를 디지털 신호로 감지해 질병 상태를 판단하는 지표. EEG(뇌전도), ECG(심전도) 의료 데이터 병원 데이터는 실제성이 높지만 노이즈가 심하고 규모가 작음. 근데 뇌전증 분야는 오픈 데이터셋(CHB-MIT 등)이 많아 연구 접근성이 높음. 서비스 목표: 뇌전증 환자에게 경량 하드웨어 기반의 웨어러블 기기(안경, 밴드, 손목형)를 제공 실제로는 머리 전체 64채널 EEG 대신, 관자놀이 부위 2~4채널 신호만 활용해 모델을 구동해야 함.</description>
    </item>
    <item>
      <title>AI #1 ML 방법론 기초</title>
      <link>http://localhost:1313/docs/study/ai/ai36/</link>
      <pubDate>Fri, 19 Sep 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai36/</guid>
      <description>AI #1 ML 방법론 기초 # #2025-09-19&#xA;#1 ML 방법론&#xA;통계기반 방법론은? linear regression이나 logistic regression 같은걸 말함 가설과 근거가 명확히 세워져 있고 데이터가 알고리즘에 맞게 정제돼있고 통계적 유의성으로 결과가 나오는 깔끔한 방식 ML 방법론은? 작은 경연을 열듯 시행착오를 거치며 가장 적합한 모델을 찾는다는 컨셉이다. # #2 지도 비지도 준지도&#xA;모두 입력 데이터에 존재하는 구조를 추론함 준지도 이상 탐지: 처럼 라벨링 비용이 클때 딥러닝: 은 파라미터 수가 많아 안정적인 학습을 위해 충분한 데이터가 필요한데 우선 라벨이 있는 데이터로 기본 학습을 진행하고 -&amp;gt; 라벨이 없는 데이터의 구조나 의사결정 경계를 활용해 모델을 보완함 # #3 regression, instance based algorithm</description>
    </item>
    <item>
      <title>ML #1 Hyperparameter Optimization</title>
      <link>http://localhost:1313/docs/study/ai/ai35/</link>
      <pubDate>Tue, 16 Sep 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai35/</guid>
      <description> ML #1 Hyperparameter Optimization # #2025-09-16&#xA;1. 개요 # </description>
    </item>
    <item>
      <title>Langchain #1 (스터디) 노션 데이터로 나만의 RAG 시스템 구축하기</title>
      <link>http://localhost:1313/docs/study/ai/ai32/</link>
      <pubDate>Mon, 15 Sep 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai32/</guid>
      <description>Langchain #1 (스터디) 노션 데이터로 나만의 RAG 시스템 구축하기 # #2025-09-15</description>
    </item>
    <item>
      <title>Ray #1 (스터디) Batch Prediction with Ray Core</title>
      <link>http://localhost:1313/docs/study/ai/ai34/</link>
      <pubDate>Mon, 15 Sep 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai34/</guid>
      <description>Ray #1 (스터디) Batch Prediction with Ray Core # #2025-09-15&#xA;스터디때 준비해갔던 Ray Core를 사용해서 batch prediction 수행하는 예제!!&#xA;batch prediction이 batch를 예측하는건줄알았는데(..) batch로 prediction하는것이었다. 순서는 1. Task 기반 batch prediction 2. Actor 기반 batch prediction 3. GPU 기반 수행 코드 출처는 Ray Document의 Batch Prediction with Ray Core이다. # 0. 개요 # 목적 Parquet 형식의 대규모 데이터셋을 Ray를 이용해 분산 처리하며, 더미 모델을 로딩하여 배치 예측(batch prediction) 을 수행한다.</description>
    </item>
    <item>
      <title>AI #1 ML 방법론 기초</title>
      <link>http://localhost:1313/docs/study/ai/ai33/</link>
      <pubDate>Sat, 13 Sep 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai33/</guid>
      <description>AI #1 ML 방법론 기초 # #2025-09-13&#xA;#1 ML type (p.31-33)&#xA;ML의 학습방법 3가지 지도학습(Supervised) 입력 데이터와 출력 데이터가 모두 제공되고 모델은 입력을 보면 어떤 출력이 나와야 하는지를 배움. 학습한 모델은 새로운 데이터가 들어오면 예측을 하고 -&amp;gt; 결과를 실제 정답과 비교해 정확도 계산. 비지도학습(Unsupervised) 문제는 있지만 정답 라벨이 없음. 비슷한 특징을 가진 학생들을 묶어서 그룹을 만들고 어떤 그룹이 우수한지 알 수 없지만 데이터 안에서 자연스럽게 나타나는 구조를 파악한다(클러스터링) 준지도학습(Semi-Supervised) 라벨이 붙은 소량의 데이터와, 라벨이 없는 대량의 데이터를 동시에 사용하면 더 나은 모델을 만들 수 있다 왜냐하면 100% 라벨링된 데이터가 있을 때만큼 정확하지는 않지만, 현실에서는 라벨링이 부족한 경우가 많고 라벨 없는 데이터가 양은 많아서 데이터 분포를 더 잘 보여주기 때문이다.</description>
    </item>
    <item>
      <title>Langchain #1 (스터디) 노션 데이터로 나만의 RAG 시스템 구축하기</title>
      <link>http://localhost:1313/docs/study/ai/ai30/</link>
      <pubDate>Wed, 10 Sep 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai30/</guid>
      <description>Langchain #1 (스터디) 노션 데이터로 나만의 RAG 시스템 구축하기 # #2025-09-10&#xA;스터디하는친구가 만들어준코드인데 내 노션으로 돌려봤다!&#xA;실습 목적&#xA;노션 데이터를 임베딩 생성하여 FAISS 벡터 스토어에 저장하고 이를 기반으로 유사 문서 검색을 수행하며, 청킹 기법을 통해 데이터 구조를 이해하고 LLM 프롬프트 제약을 적용한 뒤, RAG 구조를 접목해 자동 답변 구현 실습 설계&#xA;임베딩 생성: SentenceTransformer(&amp;ldquo;BAAI/bge-m3&amp;rdquo;) 유사 문서 검색: 코사인 유사도 + FAISS 벡터 스토어 기반 최근접 탐색 청킹 기법: Markdown 단위 분리 + 길이 기반 추가 분할 LLM 프롬프트 제약: 근거 기반 답변(추측 금지 규칙 포함) 자동 답변 구현: RAG 구조 + &amp;ldquo;meta-llama/llama-3.</description>
    </item>
    <item>
      <title>ML #1</title>
      <link>http://localhost:1313/docs/study/ai/ai31/</link>
      <pubDate>Wed, 10 Sep 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai31/</guid>
      <description>ML #1 # #2025-09-10&#xA;1 # # !pip install numpy # !pip install pandas # !pip install seaborn # !pip install matplotlib # !pip install -U scikit-learn # !pip install xgboost # !pip install lightgbm import warnings import numpy as np import pandas as pd import seaborn as sns import matplotlib.pyplot as plt from sklearn.datasets import load_diabetes from sklearn.model_selection import train_test_split from sklearn.metrics import ( r2_score, mean_squared_error, root_mean_squared_error, mean_absolute_percentage_error, ) warnings.</description>
    </item>
    <item>
      <title>Ray #1 개요</title>
      <link>http://localhost:1313/docs/study/ai/ai29/</link>
      <pubDate>Wed, 27 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai29/</guid>
      <description>Ray #1 개요 # #2025-08-27&#xA;1. 분산 처리의 필요성 # #1 기존 분산처리 방식</description>
    </item>
    <item>
      <title>Langflow #2 구현</title>
      <link>http://localhost:1313/docs/study/ai/ai28/</link>
      <pubDate>Tue, 26 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai28/</guid>
      <description> Langflow #2 구현 # #2025-08-26&#xA;backend/ ├─ app.py # FastAPI 메인 엔트리 (엔드포인트 정의) ├─ chains/ │ ├─ __init__.py │ ├─ step1_intake.py # IntakeChain │ ├─ step2_classify.py # ClassifierChain │ ├─ step3_probe.py # ProbePlannerChain │ ├─ step4_evidence.py # EvidenceValidateChain │ ├─ step5_diagnose.py # DiagnoseChain │ ├─ step6_safety.py # SafetyChain │ └─ pipeline.py # 전체 SequentialChain or loop 파이프라인 ├─ requirements.txt # langchain, fastapi, uvicorn, openai, faiss 등 └─ README.md </description>
    </item>
    <item>
      <title>Langflow #1 개념 &#43; 에이전트 구상</title>
      <link>http://localhost:1313/docs/study/ai/ai27/</link>
      <pubDate>Mon, 25 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai27/</guid>
      <description>Langflow #1 개념 + 에이전트 구상 # #2025-08-24&#xA;1. 개념 # #1 정의&#xA;LangChain/LLM/RAG/에이전트 구성요소를 노드로 배치하고 포트를 선으로 연결해 DAG(방향 비순환 그래프) 형태로 실행하는 도구. 각 노드는 입력·출력 타입(텍스트, JSON/Dict, 문서 리스트 등)이 있고, 파라미터(모델명, 온도, top-k, 임베딩 차원 등)를 가진다. #2 주요 노드&#xA;Input/UI 노드: 사용자의 프롬프트·폼 입력을 받음. Python Function: 규칙/후처리/포맷 변환 등 로직을 코드로 구현(결정적 처리에 적합). LLM 노드: gpt-4o-mini, GPT-5 Thinking 등 대규모 언어모델 호출.</description>
    </item>
    <item>
      <title>MLflow #2 mlflow 파이프라인</title>
      <link>http://localhost:1313/docs/study/ai/ai25/</link>
      <pubDate>Fri, 22 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai25/</guid>
      <description>MLflow #2 mlflow 파이프라인 # #2025-08-22&#xA;1. 코드 # #1 트래킹 서버 설정&#xA;import os import mlflow # 1. 로그를 저장할 서버/위치 지정 mlflow.set_tracking_uri(uri=os.getenv(&amp;#34;MLFLOW_TRACKING_URI&amp;#34;, &amp;#34;&amp;#34;)) # MLFLOW_TRACKING_URI로 MLflow 서버를 연결 current_uri = mlflow.get_tracking_uri() print(f&amp;#34;Current Tracking URI: {current_uri}&amp;#34;) # #2 Experiment 생성&#xA;# 2. Experiment 생성 experiment = mlflow.set_experiment(&amp;#34;new_experiment&amp;#34;) print(f&amp;#34;Experiment ID: {experiment.experiment_id}&amp;#34;) print(f&amp;#34;Experiment Name: {experiment.name}&amp;#34;) print(f&amp;#34;Artifact Location: {experiment.artifact_location}&amp;#34;) print(f&amp;#34;Lifecycle Stage: {experiment.lifecycle_stage}&amp;#34;) Experiment ID: 2 Experiment Name: new_experiment Artifact Location: /mlflow/mlruns/2 Lifecycle Stage: active # #3 information 확인, 로그 기록</description>
    </item>
    <item>
      <title>MLflow #3</title>
      <link>http://localhost:1313/docs/study/ai/ai26/</link>
      <pubDate>Fri, 22 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai26/</guid>
      <description>MLflow #3 # #2025-08-22&#xA;1. 개념 # MLflow: 머신러닝 실험을 관리하기 위한 플랫폼. 모델을 학습하는 과정에서 파라미터, 메트릭, 아티팩트, 실행(run) 기록을 남긴다. run(실행 단위): 하나의 학습 또는 실험 과정 start_run / end_run: 새로운 run을 열고 닫는 과정 active_run: 현재 열려 있는 run last_active_run: 최근에 끝났거나 여전히 열려 있는 run log_param / log_metric: 하이퍼파라미터나 성능 지표를 기록하는 함수 # 2. 코드 # #1 active_run.py&#xA;import mlflow # Start and end a run with mlflow.</description>
    </item>
    <item>
      <title>MLflow #1 설치 &amp; 실습</title>
      <link>http://localhost:1313/docs/study/ai/ai24/</link>
      <pubDate>Thu, 21 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai24/</guid>
      <description>MLflow #1 설치 &amp;amp; 실습 # #2025-08-21&#xA;1. mlflow 설치 및 docker 띄우기 # $ export CR_PAT=* # *: github token 블라인드 처리 $ echo $CR_PAT | docker login ghcr.io -u yshghid --password-stdin Login Succeeded 로그인햇으면 도커를 켠다음에 다음을 수행.&#xA;$ docker pull ghcr.io/mlflow/mlflow:v2.0.1 v2.0.1: Pulling from mlflow/mlflow 7a6db449b51b: Pull complete e238bceb2957: Pull complete ce77f44508b5: Pull complete 455a39ac3ab8: Pull complete f8c2fbfe5046: Pull complete 60e3c6e8536b: Pull complete Digest: sha256:1e1f28a6134e7e6c4b0d0a4f5f8647ff31c953ad53eb3bb5af4c51ae4e8dd14d Status: Downloaded newer image for ghcr.</description>
    </item>
    <item>
      <title>LLM #2 LLM과 AI 기술요소를 활용하여 비즈니스 서비스 기획안 작성</title>
      <link>http://localhost:1313/docs/study/ai/ai23/</link>
      <pubDate>Tue, 19 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai23/</guid>
      <description>LLM #2 LLM과 AI 기술요소를 활용하여 비즈니스 서비스 기획안 작성 # #2025-08-19&#xA;1. 목적 # 등기부등본/건축물대장 업로드 시 AI가 자동으로 문서를 분석하여 전세사기 위험 요소를 탐지하고 수치화한다. # 2. 모델 구성도 # #1 데이터 수집및 정규화&#xA;기술요소: PaddleOCR 선택 이유: 한국어 인식 정확도와 속도가 좋고, 오픈소스+온프레미스 운영 가능(비용·보안 유리), 표 레이아웃/좌표 추출 지원. 입력 파일: PDF/스캔 이미지(JPG/PNG) 매개변수: lang=&amp;ldquo;korean&amp;rdquo;, det+rec 사용, dpi(≥300) 출력 텍스트 블록: [{page, bbox, text}] 정규화 결과: 주소/금액/날짜/권리유형 표준화(JSON) #2 위험 특약/권리 분석</description>
    </item>
    <item>
      <title>데이터분석 #4 리뷰 데이터 분석</title>
      <link>http://localhost:1313/docs/study/ai/ai22/</link>
      <pubDate>Tue, 19 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai22/</guid>
      <description>데이터분석 #4 리뷰 데이터 분석 # #2025-08-19&#xA;1. 목적 # 리뷰 데이터를 보고&#xA;감성 점수와 평점의 관계 리뷰 길이와 감성 점수의 관계 카테고리별 감성 차이 Review_length가 AI 임베딩 유사도에 영향을 줄 수 있는지 인사이트 생성하기.&#xA;# 2. 코드 # import os import pandas as pd import numpy as np import seaborn as sns import matplotlib.pyplot as plt import matplotlib.pyplot as plt import matplotlib as mpl from sentence_transformers import SentenceTransformer, util # Mac 환경 한글 폰트 설정 plt.</description>
    </item>
    <item>
      <title>LLM #1 LLM 이해와 Transformer</title>
      <link>http://localhost:1313/docs/study/ai/ai21/</link>
      <pubDate>Mon, 18 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai21/</guid>
      <description>LLM #1 LLM 이해와 Transformer # #2025-08-11&#xA;1. LLM 기본이해 # #1 Word Embedding (p.27-28)&#xA;Word Embedding&#xA;핵심 아이디어는 단어가 어떤 맥락에서 자주 함께 등장하는지를 학습. “you say goodbye and I say hello”에서 ‘goodbye’주변에는 ‘you’, ‘say’, ‘and’, ‘I’ 같은 단어가 함께 등장하고 그 관계를 학습하도록 신경망을 훈련시킨다. 학습이 반복되면 각 단어는 벡터로 표현되고 의미가 비슷한 단어일수록 벡터 공간에서 가깝게 위치한다. Input이 ‘goodbye’이고 Target이 ‘you’, ‘say’, ‘and’, ‘I’여도 된다. Word Embedding - 신경망 구조 그림</description>
    </item>
    <item>
      <title>MLOps #1</title>
      <link>http://localhost:1313/docs/study/ai/ai20/</link>
      <pubDate>Mon, 11 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai20/</guid>
      <description>MLOps #1 # #2025-08-11&#xA;실습 # 메이크파일, 린팅, 테스트와 같이 파이썬 프로젝트 스캐폴딩에 필수적인 요소가 포함된 깃허브 저장소를 생성해보자. 그리고 간단하게 코드 포매팅을 수행하도록 메이크파일 스크립트를 작성해보자.&#xA;깃허브 액션을 사용하여 두개 이상의 파이썬 버전에 대해 깃허브 프로젝트 테스트를 수행해보자.&#xA;클라우드 네이티브 빌드 서버(AWS 코드빌드, GCP 클라우드 빌드, 애저 DevOps 파이프라인)를 사용하여 지속적 통합을 수행해보자.&#xA;깃허브 프로젝트를 도커 파일로 컨테이너화하고, 자동으로 컨테이너 레지스트리에 새로운 컨테이너가 등록되도록 만들어보자.&#xA;locust 또는 loader io와 같은 부하 테스트 프레임워크를 사용하여 애플리케이션에 대한 간단한 부하 테스트 코드를 작성한다.</description>
    </item>
    <item>
      <title>생성형 AI #1 생성형 AI 기초 및 Prompt Engineering</title>
      <link>http://localhost:1313/docs/study/ai/ai18/</link>
      <pubDate>Sat, 09 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai18/</guid>
      <description>생성형 AI #1 생성형 AI 기초 및 Prompt Engineering # #2025-08-09&#xA;#1 RAG (p.27)&#xA;RAG의 역할?&#xA;질문을 LLM에 던지기 전에 knowledge corpus에 질문을 미리 검색한다(회사 데이터에 대한 지식 벡터 db). 질문과 연관된 문서를 찾고 적절하게 만들어서 retrieval 던지면 의도대로 답변이 잘 나온다. # #2 LLM 출력 구성 (p.42-45)&#xA;Output Length (Max Tockens)&#xA;500자로 제한을 걸면 500자로 맞춰주는게 아니라 500자 넘으면 출력을 멈춘다. Sampling Controls&#xA;LLM은 다음에 올 단어를 고를 때 미리 계산된 사전 확률분포를 가지고 거기서 하나를 뽑는다</description>
    </item>
    <item>
      <title>생성형 AI #2 Prompt Engineering 실습 미리돌려보기</title>
      <link>http://localhost:1313/docs/study/ai/ai19/</link>
      <pubDate>Sat, 09 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai19/</guid>
      <description>생성형 AI #2 Prompt Engineering 실습 미리돌려보기 # #2025-08-09&#xA;1. VOC 분석 # setting&#xA;https://openrouter.ai/ Model: GPT-5 Temperature: 0.2 (낮게: 일관성 있는 분류 결과) Top-k / Top-p: default Max tokens: 1024 system prompt&#xA;너는 IT 시스템의 평가전문가야. 이번에 개발한 AI를 적용한 회계세무 시스템을 테스트한 고객의 평가내용인 VOC를 분석하는 것이 너의 역할이야. 판단근거를 2가지로 함께 제시해줘. user prompt&#xA;아래에 제공하는 모든 VOC 문장을 긍정, 중립, 부정 중 하나로 분류하고, 특히 부정일 경우 그렇게 판단한 이유를 2가지로 요약해줘.</description>
    </item>
    <item>
      <title>데이터 분석 #3 회귀분석</title>
      <link>http://localhost:1313/docs/study/ai/ai17/</link>
      <pubDate>Thu, 07 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai17/</guid>
      <description>데이터 분석 #3 회귀분석 # #2025-08-07&#xA;#1 Oversampling Techinique (p.69-71)&#xA;SMOTE&#xA;소수 클래스 포인트 중 하나를 랜덤하게 고르고 이웃 포인트 k개를 찾고 이 이웃들과의 연결선을 따라 중간 어딘가에 새로운 샘플을 만든다. 즉 원본과 이웃 사이에 위치한 점들을 생성한다. 소수 클래스 포인트들 사이의 직선 위에서만 새로운 데이터를 만들기 때문에 실제로는 decision boundary 근처에서 중요한 데이터를 놓칠 수 있다 Borderline-SMOTE&#xA;소수 클래스의 포인트에 대해 kNN을 수행해서 이웃들을 찾는데 이때 이웃 중에서 과반수 이상이 다수 클래스인 경우 위험한 샘플(danger set)으로 간주된다 즉 이 샘플은 결정 경계에 가깝기 때문에 모델 입장에서 헷갈릴 가능성이 높다.</description>
    </item>
    <item>
      <title>데이터 분석 #2 Preprocessing</title>
      <link>http://localhost:1313/docs/study/ai/ai16/</link>
      <pubDate>Wed, 06 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai16/</guid>
      <description>데이터 분석 #2 Preprocessing # #2025-08-06&#xA;#1 머신러닝 프로세스 (p.25)&#xA;test data가 필요한 이유? hyperparameter tuning을 하면서 validation data는 모델이 이미 참고했다 즉 간접적으로 학습에 영향을 줬기 때문에 모델 학습 과정에서 한번도 보지않은 데이터가 필요함. # #2 Box plot (p.38)&#xA;그림이 7개 차종에서 연비 플롯이라고 가정&#xA;투입됏을때 예측에 긍정적영향을 줄수잇는건?&#xA;납작한애들. 두꺼우면 대표성이 떨어진다. 2번에서 이상치들이 많으니까 잘 처리해야하겠다.&#xA;만약 그림같지 않고 y축 높이가 다 비슷비슷했다면?&#xA;이 변수들이 연비를 결정하는데 큰 영향을 못줌.</description>
    </item>
    <item>
      <title>데이터 분석 #1 기초통계</title>
      <link>http://localhost:1313/docs/study/ai/ai14/</link>
      <pubDate>Tue, 05 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai14/</guid>
      <description>데이터 분석 #1 기초통계 # #2025-08-05&#xA;1. 기술 통계 # #1 IQR (p.34)&#xA;IQR은? 가운데 50%의 거리.&#xA;그림 설명&#xA;그림의 2,3: 각각 IQR의 1.5배 선, median 값 선. 그림의 B: ⚬ 가 많으면 특이값이 많은 것. 그림의 1,2,3: 1,2는 각각 IQR의 1.5배 선이라고 했는데 3과의 거리가 서로 다른 이유는? 1.5배 안쪽에 데이터들이 다 분포해서. 즉max가 1.5배보다 작아서. # #2 변이 계수(Coefficient of Variables)&#xA;평균치가 다른 집단 비교. 변이 계수 = 표준편차 / 평균.</description>
    </item>
    <item>
      <title>RF-SHAP 연구 #1 모델 학습</title>
      <link>http://localhost:1313/docs/study/ai/ai12/</link>
      <pubDate>Mon, 04 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai12/</guid>
      <description>RF-SHAP 연구 #1 모델 학습 # #2025-08-04&#xA;1. Load data # import pandas as pd import numpy as np from sklearn.ensemble import RandomForestClassifier from sklearn.model_selection import train_test_split, cross_val_score from sklearn.metrics import accuracy_score import pickle with open(&amp;#39;/preprocessing/processed_data.pickle&amp;#39;,&amp;#39;rb&amp;#39;) as f: preproc_data = pickle.load(f) cytokine_df = preproc_data[&amp;#39;cytokine_data&amp;#39;] patient_meta = preproc_data[&amp;#39;metadata&amp;#39;] patient_info = preproc_data[&amp;#39;clinical&amp;#39;] 2. Train data split # normal_df = cytokine_df[cytokine_df.index.str.contains(&amp;#39;Healthy&amp;#39;)] severe_samples = patient_meta[patient_meta.Severity &amp;gt;= 6] severe_df = cytokine_df[cytokine_df.index.isin(severe_samples.Sample)] normal_df[&amp;#39;source&amp;#39;] = 0 severe_df[&amp;#39;source&amp;#39;] = 1 normal_df,severe_df ( CXCL9 LIF CXCL11 IL25 IL12B IL10 \ Healthy1 6.</description>
    </item>
    <item>
      <title>RF-SHAP 연구 #2 SHAP 분석</title>
      <link>http://localhost:1313/docs/study/ai/ai13/</link>
      <pubDate>Mon, 04 Aug 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai13/</guid>
      <description>RF-SHAP 연구 #2 SHAP 분석 # #2025-08-04&#xA;1. Load data # import pandas as pd import numpy as np import pickle import joblib import shap import matplotlib.pyplot as plt import seaborn as sns #Load rf model with open(&amp;#39;/model/rf_model.pkl&amp;#39;,&amp;#39;rb&amp;#39;) as f: rf_model = joblib.load(f) #Load dataset with open(&amp;#39;/preprocessing/processed_data.pickle&amp;#39;,&amp;#39;rb&amp;#39;) as f: preproc_data = pickle.load(f) cytokine_df = preproc_data[&amp;#39;cytokine_data&amp;#39;] patient_meta = preproc_data[&amp;#39;metadata&amp;#39;] patient_info = preproc_data[&amp;#39;clinical&amp;#39;] 2. Model evaluation - feature importance # # Get feature importances importances = rf_model.</description>
    </item>
    <item>
      <title>DBSCAN #2 슈도코드</title>
      <link>http://localhost:1313/docs/study/ai/ai9/</link>
      <pubDate>Mon, 28 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai9/</guid>
      <description>DBSCAN #2 슈도코드 # #2025-07-28&#xA;1 # Input: - D: 데이터 포인트 집합 - eps: 이웃 거리 임계값 - minPts: 최소 이웃 수 (밀도 기준) Output: - cluster_labels: 각 데이터 포인트에 대한 클러스터 라벨 (노이즈는 -1) Initialize: - cluster_id ← 0 - label[x] ← UNVISITED for all x in D 데이터 집합 D, 파라미터 eps와 minPts가 들어간다.&#xA;2 # For each point x in D: If label[x] ≠ UNVISITED: continue N ← regionQuery(x, eps) // x 주변의 eps 이내 이웃 포인트 탐색 If |N| &amp;lt; minPts: label[x] ← NOISE // Else: // cluster_id ← cluster_id + 1 // expandCluster(x, N, cluster_id, eps, minPts, label) Function regionQuery(x, eps): return { all points y in D such that distance(x, y) ≤ eps } 주석 처리 안된 부분만 보기.</description>
    </item>
    <item>
      <title>DBSCAN: #1 1D 클러스터링의 성능 평가</title>
      <link>http://localhost:1313/docs/study/ai/ai8/</link>
      <pubDate>Mon, 28 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai8/</guid>
      <description>DBSCAN: #1 1D 클러스터링의 성능 평가 # #2025-07-28&#xA;1. Problem # 클러스터 응집도는 보통 클러스터 내 데이터 간의 평균 거리나 분산, 혹은 실루엣 계수처럼 군집 내 응집도와 군집 간 분리도를 동시에 평가한다.&#xA;하지만 1차원 데이터에서는 클러스터 응집도(Cluster Cohesion) 또는 실루엣 계수(Silhouette coefficient) 같은 지표가 잘 작동하지 않는다.&#xA;2. 클러스터 응집도 # 클러스터링 성능을 평가하는 지표 중 하나인 응집도(Cohesion)는 클러스터 내부의 데이터들이 얼마나 서로 가까운지를 측정하는 지표다. 대표적으로는 클러스터 내 모든 점 간의 평균 거리, 클러스터 중심과 각 점 사이의 평균 거리, 혹은 분산을 사용하는 방식 등이 있다.</description>
    </item>
    <item>
      <title>MutClust 슈도코드 작성하기</title>
      <link>http://localhost:1313/docs/study/ai/ai10/</link>
      <pubDate>Mon, 28 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai10/</guid>
      <description>MutClust 슈도코드 작성하기 # #2025-07-28&#xA;1 # Input: - D: 데이터 포인트 집합 - Efactor: 이웃 거리 조정값 - DiminFactor: 클러스터 경계 조정값 - minPts: 최소 이웃 수 (밀도 기준) Output: - cluster_labels: 각 데이터 포인트에 대한 클러스터 라벨 (노이즈는 -1) Initialize: - cluster_id ← 0 - Label[x] ← UNVISITED for all x in D 데이터 집합 D, 파라미터 eps와 minPts가 들어간다.&#xA;2. H-중요도 계산 # For each point x in D: x.</description>
    </item>
    <item>
      <title>TFT #0 연구 방향</title>
      <link>http://localhost:1313/docs/study/ai/ai4/</link>
      <pubDate>Wed, 23 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai4/</guid>
      <description>TFT #0 연구 방향 # #2025-07-23&#xA;(#2025-05-31 작성)&#xA;#1&#xA;사용하고자 하는 데이터는?&#xA;feature Clinical feature (17, float): Creatinine, Hemoglobin, LDH, Lymphocytes, Neutrophils, Platelet count, WBC count, hs-CRP, D-Dimer, BDTEMP, BREATH, DBP, SBP, PULSE, SPO2, O2_APPLY Antibiotics feature (2, str) Treatment (list, str): 투여한 항생제, 결측값일수도있고 2개 이상일수도 있음 Strain (str): 환자가 감염된 균주, 1개 NEWS (int): 중증도 Code (int/str): 환자 등록번호 time-series 10개 시점 (항생제 투여 기준 D-3 ~ D+6) TFT input 형식은?</description>
    </item>
    <item>
      <title>TFT #1 입력 시퀀스 생성</title>
      <link>http://localhost:1313/docs/study/ai/ai5/</link>
      <pubDate>Wed, 23 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai5/</guid>
      <description>TFT #1 입력 시퀀스 생성 # #2025-07-23&#xA;1. Load package # %load_ext autoreload %autoreload 2 import sys import pandas as pd import numpy as np import os import pickle import ast sys.path.append(&amp;#39;/data3/projects/2025_Antibiotics/YSH/bin&amp;#39;) from sc import * os.chdir(&amp;#39;/data3/projects/2025_Antibiotics/YSH/workspace&amp;#39;) 2. Load raw data # #data&#xA;/data ├── PreprocessedData/ │ └── TimecourseData/ │ └── * (*: patient id) │ ├── SeverityScore.csv │ ├── Laboratory_processed.csv │ └── Medication.csv ├── PreprocessedData_knuh/ │ └── (PreprocessedData와 동일) └── 병원체자원은행 균주현황(2014-2024.</description>
    </item>
    <item>
      <title>TFT #2 입력 feature 생성</title>
      <link>http://localhost:1313/docs/study/ai/ai6/</link>
      <pubDate>Wed, 23 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai6/</guid>
      <description>TFT #2 입력 feature 생성 # #2025-07-23&#xA;1. Load package # %load_ext autoreload %autoreload 2 import sys import pandas as pd import numpy as np import os import pickle import ast sys.path.append(&amp;#39;/data3/projects/2025_Antibiotics/YSH/bin&amp;#39;) from sc import * os.chdir(&amp;#39;/data3/projects/2025_Antibiotics/YSH/workspace&amp;#39;) 2. Make feature1 # #data&#xA;/data └── all_meds.txt /data_knuch └── sequence └── *.pkl (*: antibiotics) /data_knuh └── sequence └── *.pkl (*: antibiotics) medinfo = &amp;#39;/data/all_meds.txt&amp;#39; with open(medinfo, &amp;#39;r&amp;#39;) as f: meds = [line.</description>
    </item>
    <item>
      <title>TFT #3 모델 학습</title>
      <link>http://localhost:1313/docs/study/ai/ai7/</link>
      <pubDate>Wed, 23 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai7/</guid>
      <description>TFT #3 모델 학습 # #2025-07-23&#xA;1. Load package # import pytorch_lightning as pl from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor from pytorch_lightning.loggers import TensorBoardLogger from pytorch_forecasting import TimeSeriesDataSet from pytorch_forecasting.models import TemporalFusionTransformer from pytorch_forecasting.models.baseline import Baseline from pytorch_forecasting.metrics import QuantileLoss from pytorch_forecasting.metrics import MAE from pytorch_forecasting.data import GroupNormalizer, NaNLabelEncoder import numpy as np import pandas as pd import torch import pickle import matplotlib.pyplot as plt #data&#xA;/data └── Sequence.pkl 2. Load data # sequence = pd.</description>
    </item>
    <item>
      <title>RAG #2 출력 파서의 개념, Pydantic/Json 출력 파서</title>
      <link>http://localhost:1313/docs/study/ai/ai2/</link>
      <pubDate>Sat, 19 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai2/</guid>
      <description>RAG #2 출력 파서의 개념, Pydantic/Json 출력 파서 # #2025-07-19&#xA;1. 출력 파서의 개념과 종류 그리고 세가지 주요 메서드 # 출력 파서(output parser)는 LLM에서 생성된 응답을 받아서 우리가 원하는 형식으로 변환해주는 역할을 한다. 쉽게 말해, LLM은 텍스트만 생성하지만 우리는 그 텍스트를 리스트, 딕셔너리, JSON, 숫자 등 구조화된 데이터로 바꾸어서 프로그램에 넘기거나, 다음 단계 체인으로 활용하길 원할 때가 많다. 출력 파서는 이 연결고리 역할을 한다. 출력 파서는 LLM이라는 기계가 말한 인간 언어를 다시 기계가 이해할 수 있는 언어로 &amp;lsquo;번역&amp;rsquo;하는 통역사 같은 존재이다.</description>
    </item>
    <item>
      <title>RAG #3 자동 대화 이력 관리</title>
      <link>http://localhost:1313/docs/study/ai/ai3/</link>
      <pubDate>Sat, 19 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai3/</guid>
      <description>RAG #3 자동 대화 이력 관리 # #2025-07-19&#xA;1. 자동 대화 이력 관리 # ChatPromptTemplate을 통해 시스템 메시지를 포함하는 프롬프트를 만든다. 시스템 메시지는 모델에게 “너는 금융 상담사야”라고 역할을 부여하는 것이다. 이어지는 (&amp;quot;placeholder&amp;quot;, &amp;quot;{messages}&amp;quot;)는 실제 사용자의 질문과 AI의 답변이 이 자리에 채워질 것이라는 의미다. 이 프롬프트는 chat = ChatOpenAI(model=&amp;quot;gpt-4o-mini&amp;quot;)와 연결되는데, 이는 OpenAI의 gpt-4o-mini 모델을 사용하는 챗 인터페이스이다. 이 프롬프트와 모델을 prompt | chat이라는 LCEL 표현으로 묶으면, 하나의 체인이 만들어진다. 이 체인은 주어진 메시지 목록을 받아, GPT 모델에 전달하고 응답을 생성하는 구조다.</description>
    </item>
    <item>
      <title>RAG #1 랭체인, LCEL, 프롬프트</title>
      <link>http://localhost:1313/docs/study/ai/ai1/</link>
      <pubDate>Thu, 17 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/ai1/</guid>
      <description>RAG #1 랭체인, LCEL, 프롬프트 # #2025-07-17&#xA;1. 랭체인 생태계의 주요 패키지 # 랭체인(LangChain)은 LLM(Large Language Model)을 활용한 애플리케이션을 쉽게 만들 수 있도록 돕는 프레임워크이다. 이 생태계는 단일 라이브러리로 구성된 것이 아니라 여러 개의 하위 패키지로 나뉘어 있고, 각각의 역할이 명확하게 분리되어 있다. 랭체인의 주요 목적은 LLM을 단순한 텍스트 생성 도구가 아니라, 여러 시스템과 결합하여 유의미한 작업을 수행하는 &amp;ldquo;생각하고 행동하는&amp;rdquo; 에이전트로 만드는 것이다. 이 생태계의 핵심 구성 요소들을 쉽게 설명하자면, 마치 LLM이라는 뇌에 주변 감각기관과 기억장치, 도구들, 그리고 의사결정 능력을 붙여주는 것이라고 보면 된다.</description>
    </item>
    <item>
      <title></title>
      <link>http://localhost:1313/docs/study/ai/readme/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/study/ai/readme/</guid>
      <description>AI Startup Investment Evaluation Agent # 본 프로젝트는 인공지능 스타트업의 투자 가능성을 자동으로 평가하는 멀티 에이전트 + Agentic RAG 시스템입니다. PDF/텍스트 근거 기반 평가와 스코어카드 방식의 의사결정을 결합하여 투자 유망 / 조건부 / 보류를 산출합니다.&#xA;LangGraph로 구성된 상태 기계(StateGraph) 위에 기술/시장/경쟁 분석 노드를 배치하고, FAISS 기반 RAG로 IR·보고서·논문 등 자료를 근거로 활용합니다.&#xA;Overview # Objective : AI 스타트업의 기술력, 시장성, 리스크를 기준으로 투자 적합성 분석 Method : AI Agent + Agentic RAG (근거 우선 평가) Tools : LangGraph, LangChain, OpenAI API, FAISS, PyPDF, python-docx, reportlab Features # PDF 자료 기반 정보 추출 (IR, 기사, 리포트 등) 투자 기준별 판단 분류 (시장성, 팀, 기술력, 경쟁우위, 실적, 밸류에이션) Scorecard Method 기반 가중 합산 점수 및 최종 의견 산출 최종 투자 보고서 생성 (DOCX, PDF 내보내기) Tech Stack # Category Details Framework LangGraph, LangChain, Python LLM GPT-4o-mini via OpenAI API Retrieval FAISS, Chroma (옵션) Parsing PyPDF, python-docx Report python-docx, reportlab Agents # Agent A: 기술 경쟁력 평가 (혁신성, 차별성, 특허/지재권, 구현 가능성) Agent B: 시장성/팀/규제/진입장벽 평가 및 요약 (옵션) 경쟁사 에이전트: 경쟁사 기술/시장성 동등 기준 비교 Architecture # (check_competitor) → collect_startup ─→ analyze_tech ─→ evaluate_market ─╮ └→ collect_competitor → analyze_competitor_tech → evaluate_competitor_market ─→ compare ─→ decide ─→ report → END ╰──────────────────────────────────────╯ LangGraph 상태 전이로 경쟁사 유무에 따른 분기 및 병합이 구현되어 있습니다.</description>
    </item>
  </channel>
</rss>
