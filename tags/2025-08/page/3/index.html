<!doctype html><html lang=en-us dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="https://yshghid.github.io/tags/2025-08/"><meta property="og:site_name" content=" "><meta property="og:title" content="2025-08"><meta property="og:locale" content="en_us"><meta property="og:type" content="website"><title>2025-08 |</title><link rel=icon href=/favicon.png><link rel=manifest href=/manifest.json><link rel=canonical href=https://yshghid.github.io/tags/2025-08/><link rel=stylesheet href=/book.min.30a7836b6a89342da3b88e7afd1036166aeced16c8de12df060ded2031837886.css integrity="sha256-MKeDa2qJNC2juI56/RA2Fmrs7RbI3hLfBg3tIDGDeIY=" crossorigin=anonymous><script defer src=/fuse.min.js></script><script defer src=/en.search.min.8575bdc0ca02b9d35ac83cf3086aa234089a0f48cdce980be8704064bf26f8c3.js integrity="sha256-hXW9wMoCudNayDzzCGqiNAiaD0jNzpgL6HBAZL8m+MM=" crossorigin=anonymous></script><link rel=alternate type=application/rss+xml href=https://yshghid.github.io/tags/2025-08/index.xml title=" "></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><img src=/logo.png alt=Logo class=book-icon><span></span></a></h2><div class="book-search hidden"><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><script>document.querySelector(".book-search").classList.remove("hidden")</script><ul><li class=book-section-flat><span>기록</span><ul><li><a href=/docs/hobby/daily/>일상</a><ul></ul></li><li><a href=/docs/hobby/book/>글</a><ul></ul></li></ul></li><li class=book-section-flat><span>공부</span><ul><li><a href=/docs/study/ai/>AI</a><ul></ul></li><li><a href=/docs/study/bioinformatics/>Bioinformatics</a><ul></ul></li><li><a href=/docs/study/be/>BE</a><ul></ul></li><li><a href=/docs/study/fe/>FE</a><ul></ul></li><li><a href=/docs/study/career/>취업</a><ul></ul></li></ul></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu></label><h3>2025-08</h3><label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents></nav></aside></header><article class="markdown book-article"><p><em>2025-08-09</em> ⋯ 생성형 AI #2 Prompt Engineering 실습 미리돌려보기</p><p style=height:4.5em;overflow:hidden><a href=/docs/study/ai/ai19/>1. VOC 분석 setting - https://openrouter.ai/ - Model: GPT-5 - Temperature: 0.2 (낮게: 일관성 있는 분류 결과) - Top-k / Top-p: default - Max tokens: 1024 system prompt user prompt result | 번호 | VOC 내용 | 분류 | 판단 근거 | |------|---------|------|----------| | 1 | 복잡한 엑셀 정리에서 해방됐어요. 기존 수작업으로 처리하던 매출/비용 분석을 자동화해 시간 절약 효과를 체감했습니다. | 긍정 | - | | 2 | 회계 비전문가인 마케팅 담당자도 재무 지표의 의미를 쉽게 파악할 수 있었습니다. | 긍정 | - | | 3 | AI 추천 덕분에 세무 위험을 미리 인지했어요. 실제로 부가세 누락 가능성을 사전에 알림 받아, 실제 신고 전에 정정할 수 있었던 점이 유용했습니다. | 긍정 | - | | 4 | 실시간으로 현금흐름을 추적할 수 있어 좋았습니다. 회계팀 없이도 매주 자금 흐름을 파악하고 의사결정에 반영할 수 있었습니다. | 긍정 | - | | 5 | 처음에만 가이드를 받고 나니 반복 작업이 놀랍도록 간단해졌습니다. 설정만 끝나면 이후 반복 업무에서 자동화된 결과물이 기대 이상으로 좋네요. | 긍정 | - | | 6 | 기능은 흥미롭지만, 실제 업무에 어떻게 녹여야 할지 고민이 됩니다. 시스템이 낯설고 기존 워크플로우와 맞물리는 데 시간이 필요해 보입니다. | 부정 | 1. 적용 방법에 대한 명확한 가이드 부족
2. 기존 시스템과의 통합 어려움 | | 7 | 예쁜 그래프가 많긴 하지만 실무상 의미가 뚜렷하게 와 닿지는 않았습니다. | 부정 | 1. 시각적 효과는 있으나 실용성 미흡
2. 구체적인 데이터 분석 기능 부재 | | 8 | AI가 추천해주는 분석은 흥미로웠지만, 최종 결정은 여전히 사람이 해야겠더라고요. 완전한 자동화보다는 보조 도구로 보는 것이 현실적이라 느꼈습니다. | 부정 | 1. AI의 신뢰도 및 정확성 한계
2. 의사결정 과정에서의 자동화 미비 | | 9 | 피벗 기능이나 드릴다운 기능이 있었으면 더 좋을 것 같긴 해요. 보고서 결과는 직관적이지만, 좀 더 상세 데이터를 보고 싶을 때 아쉬움이 있습니다. | 중립 | - | | 10 | 회계 전문가 입장에서는 보안이 필요해 보이지만, 일반 사용자에겐 적합할 수도 있겠네요. 어떤 고객을 주 대상으로 할지 더 명확하면 좋겠습니다. | 중립 | - | | 11 | 일부 기능은 대기업 회계 기준에 맞춰져 있어 간편한 사용을 기대한 소규모 기업에는 과도했습니다. | 부정 | 1. 소규모 기업의 요구사항 미반영
2. 기능의 복잡성으로 인한 사용 장벽 | | 12 | AI 설명이 부족해 불안했어요. AI가 어떤 기준으로 판단했는지, 근거가 불투명해 검토에 시간이 걸렸습니다. | 부정 | 1. AI 프로세스의 투명성 부족
2. 결과 검증에 추가 리소스 소모 | | 13 | 엑셀 연동 시 포맷 오류가 잦았습니다. 업로드한 자료가 표준 포맷이 아닐 경우 오류가 자주 발생했습니다. | 부정 | 1. 데이터 호환성 문제
2. 사용자 입력 오류에 대한 유연성 부족 | | 14 | 초기 세팅에 시간이 좀 걸렸습니다. 계정과목 연결, 은행 계좌 연동 등 초기 설정을 마치기까지 다소 복잡하게 느껴졌습니다. | 부정 | 1. 초기 설정의 복잡성
2. 사용자 편의성 저하 | | 15 | 사용자별 접근 권한 설정이 더 세분화되었으면 합니다. 팀 내 다양한 역할별로 보기 권한을 구분하고 싶었는데 현재는 제한적이었습니다. | 부정 | 1. 권한 관리 기능의 제한성
2. 조직 내 역할별 맞춤형 설정 미지원 | 2. 관리를 위한 규격화된(JSON) 정보 생성 setting - https://openrouter.ai/ - Model: Gemma 3 27B (free) - Temperature: 0.2 - Top-k / Top-p: default - Max tokens: 1024 system prompt user prompt result 3. 컨설팅 리서치 & 전략 수립 setting - https://openrouter.ai/ - Model: Gemma 3 27B (free) - Temperature: 0.2 - Top-k / Top-p: default - Max tokens: 1024 system prompt user prompt result 4. 신상품 출시 프로모션(행사) 기획안 작성 setting - https://openrouter.ai/ - Model: Gemma 3 27B (free) - Temperature: 0.2 - Top-k / Top-p: default - Max tokens: 1024 system prompt user prompt result 5. 이력서 파일 검토 setting - https://openrouter.ai/ - Model: Gemma 3 27B (free) - Temperature: 0.2 - Top-k / Top-p: default - Max tokens: 1024 system prompt user prompt result 6. 비용관리 엑셀 템플릿 생성 setting - https://openrouter.ai/ - Model: Gemma 3 27B (free) - Temperature: 0.2 - Top-k / Top-p: default - Max tokens: 1024 system prompt user prompt result ~*링크가 없는데..*~ 7. 마케팅용 기술 블로그 작성 setting - https://openrouter.ai/ - Model: Gemma 3 27B (free) - Temperature: 0.2 - Top-k / Top-p: default - Max tokens: 2048 (1024하니까 말이 끊김) system prompt user prompt - 근데 첨부할 파일이 없길래 그냥했다. result</a></p><hr><p><em>2025-08-09</em> ⋯ 생성형 AI #1 생성형 AI 기초 및 Prompt Engineering</p><p style=height:4.5em;overflow:hidden><a href=/docs/study/ai/ai18/>RAG (p.27) RAG의 역할? - 질문을 LLM에 던지기 전에 knowledge corpus에 질문을 미리 검색한다(회사 데이터에 대한 지식 벡터 db). - 질문과 연관된 문서를 찾고 적절하게 만들어서 retrieval 던지면 의도대로 답변이 잘 나온다. LLM 출력 구성 (p.42-45) Output Length (Max Tockens) - 500자로 제한을 걸면 500자로 맞춰주는게 아니라 500자 넘으면 출력을 멈춘다. Sampling Controls - LLM은 다음에 올 단어를 고를 때 미리 계산된 사전 확률분포를 가지고 거기서 하나를 뽑는다 - temperature로 무작위성의 정도를 조절. - temperature를 0으로하면 확률이 가장 높은 단어만 거의 항상 선택 - 그림에서 원래의 확률분포가 가운데 그림처럼 생겼더라도 temp를 0으로 낮추면 첫 번째 그림처럼 가장 높은 확률에 몰빵되어 다른 선택지는 거의 배제된다. - 반대로 temperature를 2로 올리면 확률이 평평해져서 원래 1등이 아니었던 단어들도 선택될 가능성이 높아진다. - 이렇게 임의성을 높이면 흔하지 않은 단어가 튀어나올 확률이 커지고 결과가 예측 불가능해지고 창의성이 늘어난다. - TopK - 다음에 올 단어 후보 중에서 확률이 가장 높은 K개만 남기고 나머지는 버림 - K값이 크면 후보 폭이 넓어져서 더 다양한 결과가 나오고 창의성이 높아진다. - K값이 작으면 몇 개의 후보만 남아서 결과가 더 안정적이고 사실적인 방향으로 수렴한다. - TopP - 누적 확률이 특정 값 p에 도달할 때까지의 상위 후보만 남기기 예를 들어 p가 0이면 항상 가장 가능성이 높은 단어 하나만 선택하고, p가 1이면 거의 모든 단어가 후보에 포함. - TopK TopP를 통과하고나서 temperature 값이 적용된다. - temperature가 낮으면 이 후보 중에서 가장 확률이 높은 단어를 고르는 쪽으로 기울어지고, 높으면 확률 분포를 평평하게 만들어 무작위성이 커진다. 낮은 temperature에서는 사실상 Greedy decoding처럼 정답 하나를 뽑는 느낌이고, 높은 temperature에서는 후보 중에서 랜덤하게 섞어 뽑는 Sampling 방식이 된다. - 흐름예시 1. 다음 토큰 후보마다 사전확률을 계산하고 이 후보들을 확률이 높은 순으로 정렬한 뒤 TopK를 적용하면 예를 들어 K=2일 때 가장 높은 두 개만 남기고 나머지는 모두 버린다. TopP를를 쓰면 누적 확률이 p에 도달할 때까지 후보를 남기고 이후는 잘라낸다. 2. 필터링을 하고 남은 후보들에 temperature를 적용한다. temperature가 낮으면 확률 분포가 뾰족해져서 가장 가능성이 높은 후보를 뽑을 확률이 커지고, 높이면 분포가 평평해져서 확률이 낮은 후보도 비슷한 기회로 선택된다.</a></p><hr><p><em>2025-08-07</em> ⋯ 데이터 분석 #3 회귀분석</p><p style=height:4.5em;overflow:hidden><a href=/docs/study/ai/ai17/>Oversampling Techinique (p.69-71) - SMOTE - 소수 클래스 포인트 중 하나를 랜덤하게 고르고 - 이웃 포인트 k개를 찾고 - 이 이웃들과의 연결선을 따라 중간 어딘가에 새로운 샘플을 만든다. - 즉 원본과 이웃 사이에 위치한 점들을 생성한다. - 소수 클래스 포인트들 사이의 직선 위에서만 새로운 데이터를 만들기 때문에 실제로는 decision boundary 근처에서 중요한 데이터를 놓칠 수 있다 - Borderline-SMOTE - 소수 클래스의 포인트에 대해 kNN을 수행해서 이웃들을 찾는데 - 이때 이웃 중에서 과반수 이상이 다수 클래스인 경우 위험한 샘플(danger set)으로 간주된다 즉 이 샘플은 결정 경계에 가깝기 때문에 모델 입장에서 헷갈릴 가능성이 높다. - 그런 danger set에 대해서만 SMOTE를 수행하여 새로운 데이터를 생성해서 decision boundary 근처의 소수 클래스 밀도를 높인다. - 이렇게 하면 모델이 중요한 경계 영역에서의 소수 클래스를 더 잘 인식하도록 도와줄 수 있다. - ADASYN - 소수 클래스 포인트마다 kNN을 사용해서 가까운 이웃을 찾고 - 이웃들 중에 다수 클래스 비율 ri를 계산하고 이 ri값이 높을수록 더 많은 데이터를 그 샘플 주변에 생성한다. - 이렇게 하면 학습 데이터에서 어렵고 복잡한 영역에 더 많은 정보를 제공할 수 있기 때문에 모델이 보다 정밀한 분류를 수행할 수 있게 된다. Learning vs Inference (p.3) - Learning - 컴퓨터에게 어떤 일을 시키기 위해서는 먼저 그 일을 어떻게 해야 하는지를 가르쳐야 하는데 이게 Learning. - 예를 들어 "이 사진이 사람 얼굴인지 개 얼굴인지 맞혀봐"라고 한다고 치면 처음에는 컴퓨터가 제대로 못 맞히지만 많은 사진을 보여주고 정답을 알려주고를 반복하면서 컴퓨터는 '이런 모양이면 사람 얼굴이고', '이런 구조면 개 얼굴이구나' 하는 규칙을 배우고 - 예측을 해보고 틀리면 왜 틀렸는지 되돌아가서 네트워크 구조를 수정하는 과정을 계속 반복한다(forward/backward 과정). 이 반복을 통해 점점 더 잘 맞히는 모델로 발전한다. - Inference - 학습이 끝난 다음에 새로운 사진을 주고 "이건 뭐야?"라고 물어보는 단계. 이때는 정답을 알려주지 않는다. - 예를 들어 처음 보는 사람 얼굴 사진을 주면 학습 때 봤던 예시들과 비교해서 '이건 사람 얼굴이네'라고 추측한다. - 이 과정에서는 이미 학습된 모델만 사용하고 그 내부 구조를 바꾸지 않는다 즉 지식을 시험 보듯이 적용만 하는 단계. 상관 분석은 왜 필요할까? (p.15) - (a)와 (b)는 모두 x와 y의 평균값과 퍼짐 정도 즉 표준편차는 동일하다. - 근데 a는 데이터가 거의 직선인반면 b는 흩어져 있어서 서로의 관계가 약해 보인다. - 즉 단순한 통계량만 보면 같아 보이지만 실제로는 전혀 다른 패턴이다. - 상관분석은 두 변수 간의 방향과 강도 다시 말해 x가 커질 때 y도 커지는지 혹은 반대로 작아지는지, 그리고 그 관계가 얼마나 뚜렷한지를 숫자로 나타내서 평균과 표준편차가 말해주지 못하는 두 변수 간의 관계를 정량적으로 보여준다. 자유도 (p.18) - 일부 샘플만으로 진짜 모집단의 표준편차를 추정하려면 그냥 단순히 샘플의 평균으로 계산하면 안 되고 조정을 해줘야한다 왜냐면 샘플은 모집단 전체를 대표하지 못하기 때문에 항상 약간의 편향(bias)이 생긴다. - 그 보정법이 'n-1'이라는 자유도의 개념인데 1을 빼줌으로써 계산된 분산이 모집단 분산보다 작게 나오는 경향을 보완해즌다. - 예를 들어 10개의 데이터를 가지고 표준편차를 계산할때 10이아닌 9로 나눠서 평균을 내는데 그 이유는 실제로 자유롭게 움직일 수 있는 값이 10개 중 9개밖에 없기 때문. - 편차가 1개밖에 없을 때 즉 데이터가 하나뿐일 때? - 이때는 표준편차를 구할수없다 왜냐하면 분산을 계산할 때 0으로 나눈 값은 정해질 수 없기 때문에. - 이 경우는 부정형(indeterminate form)이라고 부른다. 말 그대로 "알 수 없다"는 뜻이다. - 올해 10% 수익이면 내년도 10% 수익이 확실하다는 의미? - 데이터가 하나밖에 없기 때문에 변동성 즉 편차를 측정할 수 없다 - 표준편차가 0이라고 해서 수익이 고정됐다는 뜻이 아니라 아예 그 불확실성을 판단할 방법이 없다. cf) n-1이 아니라 만약 -2를 하면?? - 모델이 실제보다 데이터의 불확실성을 과대평가하는셈. 상관계수와 z-score (p.20) - 각 관측치에 대해 x와 y의 z-score를 각각 계산할 수 있고 - 모든 관측치에 대해 z_x * z_y를 계산하고 다 더하고 평균낸 값과 똑같다. - 엄밀히는 n이아니라 n-1로 나눈거랑 똑같다. 인과관계 (p.25) - 인과관계는 x와 y의 시차를 틀었을때 regression의 결과가 어떻게 달라지는지를 통해 선후관계를 파악한다. 시계열 데이터 (p.33) - 시계열 데이터에서 일반적인 회귀분석의 가정이 깨진다. 그러면 어떻게 회귀분석을 돌리지? -> 시계열 분석의 시작. 회귀직선과 상관계수 (p.34-37) - 평균보다 키가 1표준편차 큰 사람은 몸무게도 1표준편차 클 것이다? - 아님 왜냐면 두 변수 간의 관계가 완벽한 선형이 아니기 때문에. 상관계수가 얼만큼 변하는지에 관여한다. - 즉 키가 평균보다 1표준편차 클 때 몸무게는 평균보다 정확히 1표준편차가 아니라 r배 만큼 증가한다. - 예를 들어 상관계수가 0.8이면 몸무게는 0.8 표준편차만큼만 증가하고 0.5라면 절반 정도만 따라간다. - 모의고사 본고사 시험 사이의 점수를 회귀분석으로 분석. - 모의고사와 본고사 점수 사이에는 어느 정도 상관관계가있다. - 근데 이게 완벽하게 1:1로 이어지지는 않는데 예를 들어 모의고사에서 160점을 받은 사람이 본고사에서는 약간 낮은 점수를 받는 경우가 많고, 반대로 모의고사에서 평균보다 낮은 110점을 받은 학생들이 본고사에서도 꼭 110점 아래를 받는 게 아니라 평균적으로는 오히려 그보다는 약간 높은 120점 정도를 받는 경향이 있다. - 그러니까 한쪽으로 극단적인 값을 보였던 사람들은 다음 측정에서는 평균 쪽으로 다시 돌아오는 듯한 모습을 보인다(평균으로의 회귀 현상) - 점수라는 건 단지 실력만 반영하는 게 아니라 시험 당일의 컨디션이나 운, 문제 유형 같은 우연한 요소들도 영향을 주기때문에 모의고사에서 아주 높은 점수를 받은 사람은 실력이 좋았을 뿐만 아니라 우연히 좋은 조건이 겹쳤을 수도 있어서 본고사에서는 점수가 조금 낮아질 가능성이 크고 반대로 모의고사에서 낮은 점수를 받은 사람도 사실은 실력보다 약간 덜 나온 걸 수 있어서 본고사에서는 평균으로 되돌아오는 경향을 보인다. - 그래프로 보면 모의고사 점수가 x축, 본고사 점수가 y축일 때, 모든 점들을 연결하면 하나의 퍼진 구름처럼 보이고 - 그 위에 회귀선을 그리면 이 선은 꼭 대각선이 아니라 약간 눕는다. 즉 극단적인 점수를 받은 사람일수록 그 다음 점수는 평균 쪽으로 더 가까워진다. 결론 - 회귀효과는 실력과 운이 섞여 있는 측정 결과에서, 두 번째 측정에서는 우연한 요소가 줄어들면서 평균으로 돌아가는 현상. 회귀모형의 평가 (p.41) 설명력 - 어떤 현상을 설명하기 위해 회귀선을 그린다 - 예를 들어 키로부터 몸무게를 예측하거나, 공부 시간으로부터 시험 점수를 예측하기위해 회귀선을 그린다. - 이때 회귀선에서 궁금한건? - 이 직선 즉 회귀식이 실제 데이터를 얼마나 잘 설명하고 있을까? - 이걸 수치화한게 결정계수 R². 오차 - 그림의 데이터를 보면 각 점(실제 관측값)이 퍼져 있고 회귀직선은 이 점들을 가장 잘 통과하는 직선. - 그리고 실제 데이터와 예측값 사이에는 늘 오차가 존재하는데 두가지로 나누면 - 회귀선으로 설명할 수 있는 부분 즉 데이터가 평균에서 얼마나 벗어났는지를 회귀선이 얼마나 잘 설명했는지(SSR) - 회귀선이 설명하지 못한 부분 즉 예측값과 실제값 사이의 차이(SSE). R²의 해석 - SSR / SST는 전체 변화량 중에서 회귀선이 설명한 비율. (R² = SSR / SST) - 회귀선이 설명하지 못한 부분 SSE 기준으로는 R² = 1 - SSE / SST. - R²이 0.6이면 전체 y의 분산 중 60%는 x로부터 설명된다는 뜻이고, 나머지 40%는 다른 요인이나 노이즈 때문이라는 뜻. cf) R²도 음수가 나온다? - 이 지표는 train data가 회귀선에 얼마나 잘붙었는지 지표이니깐 train data로 계산해야 제대로 나오는데 test data에 대고 계산하면 엉뚱한 값으로 -가 나올수 있다. 회귀분석 결과 해석 (p.45-46) - 목적: 쿠폰을 얼마나 배포하고 가격을 어떻게 책정해야 구매고객 수가 늘어나는지 확인 - 독립변수(쿠폰배포매수와 판매가격)가 종속변수(구매고객수)에 미치는 영향 분석. - 회귀분석 결과 - 회귀식 y = 0.109·x₁ + 0.003·x₂ + 274.375 (x₁은 쿠폰매수, x₂는 판매가격이고 y는 예상 구매고객수) - 쿠폰을 1장 더뿌릴수록 고객 수 0.109명 늘어난다 - 판매가격이 1원 올라가면 고객 수는 0.003명 늘어난다 - 근데 단순히 계수 값만 보고 판단하면 안 되고 그 값이 실제로 통계적으로 의미 있는지를 봐야 한다. - 쿠폰배포매수의 P-값 3.795E-05: 유의미하다 - 판매가격의 P-값은 0.813: 유의하지 않다 즉 가격이 변한다고 해서 구매고객 수가 유의미하게 달라진다고 보기 어렵다. - 판매가격 제거하고 회귀모델을 구성: y = 0.108·x + 282.892 - 조정된 결정계수는 0.735 - 즉 이 회귀모델이 전체 구매고객 수의 약 73.5%를 설명할 수 있다. - (조정: 변수의 개수를 고려해서 모델의 설명력을 평가) - 유의확률 F가 0.000: 회귀모형이 전체적으로 통계적으로 유의하다. - 적어도 하나의 독립변수가 종속변수에 영향을 준다. (실제로 2개 중 1개가 유의했음) cf) F 통계량이 유의히다 = 3개중에 하나라도 유의하다. 모두라는 표현은 아니다. 회귀방정식의 가정 - 등분산성 (p.51) - 등분산성? - x값이 작든 크든 관계없이 y값의 퍼짐 정도 즉 오차의 분산이 항상 일정해야 한다. - 예를 들어 교육수준이 10년인 사람들과 20년인 사람들 모두 소득이 평균을 중심으로 비슷하게 퍼져 있어야 한다. - 오차가 일정하다는 말은 예측이 고르게 잘 맞는다는 뜻이기도한데 회귀선에서 멀리 떨어진 사람도 있고 가까운 사람도 있지만, 그 거리(오차)의 평균적인 크기가 x의 값에 따라 달라지는것만 아니면 된다. - 실제 데이터를 보면 - 교육수준이 낮은 사람들은 대부분 소득이 비슷하게 모여 있다 예를 들어 평균이 500만 원이면 대부분이 450~550만 원 안에 있다. 그런데 교육수준이 높아지면 예를 들어 22년 이상 교육을 받은 사람들의 경우 평균은 800만 원이지만 어떤 사람은 600만 원 벌고 어떤 사람은 1200만 원 넘게 벌기도 하는 등 퍼짐이 훨씬 커진다. - 이건 등분산이 아니라 이분산이고 회귀모델의 중요한 가정을 깨뜨린다. - 이 가정이 깨지면? - 겉으로 보기엔 회귀선이 잘 맞는 것처럼 보여도 실제로는 예측의 신뢰도가 높지 않아진다 즉 평균적인 소득은 맞힐 수 있지만 개별 사람에 대해서는 예측이 크게 틀릴 수 있다. 불편 추정량 (p.53) - 어떤 값을 추정할 때 그 추정값이 평균적으로 진짜 값을 잘 맞히는지를 판단하는 기준. - 모집단의 평균이나 계수를 추정한다고 할 때 표본 데이터를 여러 번 뽑아서 그때마다 계산된 추정값들을 평균 내봤더니 그게 진짜 값과 일치한다면 그 추정량이 "편향이 없다" 즉 불편(unbiased)하다고 한다. - 추정값들이 우연히 왼쪽으로 쏠리거나 오른쪽으로 쏠리지 않고, 중심이 진짜 값을 잘 둘러싸고 있다는 뜻. - ^β2는 변수 X가 Y에 얼마나 영향을 주는지를 나타내는 기울기. - 기대값과 실제값의 차이를 제곱해서 평균내는 방식 즉 분산 공식 그대로 분산을 구한다. - 식을 보면 - 오차항 ei의 분산인 σ2에 영향을 받고 - X의 분산에도 영향을받는다. - n이 커질수록 분산이 작아진다. ​ - 결론적으로 불편 추정량의 의의? - 어떤 계수를 추정할 때 그 값이 정확하냐는 문제를 통계적으로 따질 수 있다. - 정확하다는 건 단순히 한 번의 추정이 맞았다는 뜻이 아니라 여러 번 뽑았을 때 평균적으로 참값 근처에 있다는 것(불편 추정량) - 회귀계수가 불편 추정량이라면 우리는 평균적으로 정확한 값을 얻고 있다. - 들어온중에 젤어려웠던수업.. - oversampling technique 설명들으면서 좋은알고리즘만큼 중요한게 알고리즘을 잘보여주는 예시데이터와 플롯 같다고 생각들었다. ~그런의미에서 내학위심사ppt는 어떡하지?..~ - 자유도 개념이 애매했는데 -1 왜하는지 완전이해할수있어서 좋앗고 등분산성이 헷갈렸는데 위 그림의 예시는 어쨌든 등분산성이 깨진 예시인게 맞겠지? 그러면 제대로 이해했다. - 그리고 불편 추정량을 처음들었는데 개념은 이해했는데 그래서 이게왜나오는건지는 잘모르겠다.</a></p><hr><p><em>2025-08-06</em> ⋯ 데이터 분석 #2 Preprocessing</p><p style=height:4.5em;overflow:hidden><a href=/docs/study/ai/ai16/>머신러닝 프로세스 (p.25) - test data가 필요한 이유? - hyperparameter tuning을 하면서 validation data는 모델이 이미 참고했다 즉 간접적으로 학습에 영향을 줬기 때문에 모델 학습 과정에서 한번도 보지않은 데이터가 필요함. Box plot (p.38) 그림이 7개 차종에서 연비 플롯이라고 가정 1. 투입됏을때 예측에 긍정적영향을 줄수잇는건? - 납작한애들. 두꺼우면 대표성이 떨어진다. 2. 2번에서 이상치들이 많으니까 잘 처리해야하겠다. 3. 만약 그림같지 않고 y축 높이가 다 비슷비슷했다면? - 이 변수들이 연비를 결정하는데 큰 영향을 못줌. 조건수 (p.52) 조건수(Condition number)? - 어떤 계산 문제에서 입력값이 조금만 바뀌어도 결과가 얼마나 크게 바뀌는지를 나타내는 값 (민감도 개념). 조건수가 큰 경우? - 데이터에 조금의 노이즈나 오차만 있어도 결과가 달라져버려서 예측이나 계산을 할 때 신뢰하기 어려워진다. - 머신러닝에서 여러 개의 입력값(피처)이 있을 때 이 피처들 사이에 스케일 차이가 너무 크거나 비슷한 성향을 가지면 조건수가 커진다. - 예를 들어 Feature 1은 0에서 10 사이 값인데 Feature 2는 1,000에서 100,000 사이 값이라면, 둘을 같은 선형 모델에 넣었을 때 Feature 2의 작은 변화가 모델 결과에 훨씬 큰 영향을 줄 수 있어서 값의 Feature 2 쪽이 모델을 지배하게 됨. - 이를 방지하기 위해 Feature Scaling이 필요하다. Ideation bin counting (p.60) Bin Counting? - 범주형 변수의 값을 단순히 숫자나 벡터로 바꾸는 것이 아니라 그 값이 결과 변수(Target)와 어떤 관련이 있는지를 통계적으로 계산해서 숫자로 바꾸는 방식 - 학생들의 이름이 있고 이 학생들이 시험을 통과했는지(합격/불합격)를 예측하려고 할 때? - 각 학생 이름을 그대로 피쳐로 쓰면(One-hot encoding) 100,000명의 학생 이름마다 새로운 열이 생기고 그러면 데이터가 너무 커지고 희소해져서 계산도 느려지고 모델도 과적합되기 쉬워진다. - Bin Counting은 이름마다 그동안 시험에 합격한 비율을 계산한다. 예를 들어 ‘김민수’라는 이름이 10번 나왔고 그 중 7번은 시험에 합격했다면, ‘김민수’라는 값은 0.7이라는 숫자로 바뀐다. - 이름이라는 범주형 값을 단순히 분리해서 다루는 게 아니라, 그 값이 결과 변수와 얼마나 관련이 있는지를 반영한 숫자로 바꾸는 것. (이름 자체는 중요한 의미를 갖는게 아니니깐) *TFT연구 feature디자인할때 항생제 인코딩 이런식으로 할걸!!!! 이런게잇엇다니</a></p><hr><p><em>2025-08-05</em> ⋯ 데이터 분석 #1 기초통계</p><p style=height:4.5em;overflow:hidden><a href=/docs/study/ai/ai14/>1. 기술 통계 IQR (p.34) - IQR은? 가운데 50%의 거리. - 그림 설명 - 그림의 2,3: 각각 IQR의 1.5배 선, median 값 선. - 그림의 B: ⚬ 가 많으면 특이값이 많은 것. - 그림의 1,2,3: 1,2는 각각 IQR의 1.5배 선이라고 했는데 3과의 거리가 서로 다른 이유는? 1.5배 안쪽에 데이터들이 다 분포해서. 즉max가 1.5배보다 작아서. 변이 계수(Coefficient of Variables) - 평균치가 다른 집단 비교. - 변이 계수 = 표준편차 / 평균. - 값이 작을수록? 평균 가까이에 분포한다. - 평균 관점에서 퍼짐의 해석 -> 이상치에 민감하다. - IQR은? 중앙값 관점에서 퍼짐의 해석 -> 이상치에 강건하다. 2. 추론 통계 모집단과 표본집단 - 모집단의 모수(parameters): 관심의 대상이 되는 특성. - 표본집단의 통계량(statistics): 표본을 대표하는 값. 확률분포 (이전자료 p.81) 이산형 확률변수 X - 확률질량함수(PMF): f(x)=P[X=x] - 시점(x)의 값이 확률. 연속형 확률변수 X - 확률밀도함수(PDF): ∫(a,b)f(x)=P[a≤X≤b] - 넓이(a~b)가 확률. 확률의 3가지 정의 (p.50) - 확률이란 어떤 일이 일어날 가능성을 숫자로 표현한 것. - 라플라스의 정의 - 동전을 던졌을 때 처럼 가능한 모든 경우가 서로 동등한 기회를 가지고 있다고 보고 사건이 일어나는 경우의 수를 전체 가능한 경우의 수로 나누기. - 예를 들어 동전을 던질 때 앞면이 나올 확률은 두 가지 중 하나니까 1/2. - 빈도주의적 정의 - 동전을 100번 던졌는데 앞면이 18번 나왔다면 앞면이 나올 확률은 0.18이라고 추정하듯이 실험을 여러 번 해보는 방식 - 공리적 정의 - 확률이 어떤 성질을 가져야 하는지(공리)를 정해놓고 그 성질을 만족하는 값을 확률이라고 정의. - 전체 가능한 경우의 집합(표본공간)에 대한 확률은 무조건 1이어야 하고 어떤 사건도 확률이 0보다 작거나 1보다 클 수 없다. 서로 동시에 일어날 수 없는 두 사건이 있을 때 그 둘 중 하나라도 일어날 확률은 각 사건의 확률을 더한 것과 같다(상호배반적). 68-95-99.7의 법칙 (p.59) - 어떤 데이터를 측정하거나 관찰했을 때 그 값들이 평균을 중심으로 어떻게 퍼져 있는지 그 퍼짐 정도(모양?)가 분포이고 - 종 모양의 곡선 형태, 평균을 중심으로 좌우 대칭인 형태이면 정규분포. - 정규분포에서 평균에서 '얼마나' 떨어져 있는지를 나타내는 지표가 표준편차. - 68-95-99.7의 법칙은 평균에서 몇 개의 표준편차 범위 안에 전체 데이터의 몇 퍼센트가 포함되는지를 알려주는 규칙. - 평균에서 ±1 표준편차 범위 내에는 전체 데이터의 약 68%가 들어온다. 예를 들어 평균이 100이고 표준편차가 15인 경우에서 100에서 15를 빼고 더한 값인 85부터 115까지의 범위에 전체 데이터의 68%가 몰려 있다. - ±2 표준편차 범위 안에는 약 95%의 데이터가 포함된다. 평균이 100이고 표준편차가 15이면 70부터 130 사이에 전체 데이터의 95%가 분포하고 있다. - ±3 표준편차 범위에서는 전체 데이터의 99.7%가 들어온다. 평균이 100이고 표준편차가 15인 경우 55부터 145 사이에 전체 데이터의 거의 전부인 99.7%가 존재한다. - Z-Score는 어떤 값이 평균에서 몇 개의 표준편차만큼 떨어져 있는지 수치. - 어떤 데이터가 평균보다 1 표준편차만큼 크면 Z-Score는 +1 - 평균보다 2 표준편차만큼 작으면 Z-Score는 -2 - 정규분포에서 Z-Score가 ±1인 값은 전체의 68%, ±2인 값은 95%, ±3인 값은 99.7%를 포함한다. 불확실성과 표준오차 (p.66) - 동전을 100번 던져서 앞면이 몇 번 나오는지를 보는 실험을 반복하면 매번 정확히 50번씩 앞면이 나오지 않고 어떤 때는 47번 어떤 때는 52번처럼 약간의 오차가 생기는데 - 그 오차가 불확실성, 그 크기를 수학적으로 표현한 것이 표준편차. - 한 번의 시행에서 앞면이 나올 확률이 0.5이고, 그것의 표준편차가 0.5라고 했을 때, 100번을 시행하면 표준오차도 0.5에 100을 곱한 50이 될까? 시행횟수에 비례해서 오차의 크기도 똑같이 늘어날까? - 여러 번 시행하면 평균값에 더 가까워지는 경향이 있기 때문에 시행 횟수가 많아질수록 오차는 작아진다. - 표준오차는 단순히 표준편차에 시행 횟수를 곱하는 것이 아니라, 표준편차를 루트 시행 횟수로 나눈 값으로 변한다. (제곱근의 법칙) 제곱근의 법칙 (p.67) 표본의 수가 많아지면 평균은 더 정확해지나? - 표본이 많아질수록 그 평균은 실제 전체 집단의 평균 즉 모평균에 가까워진다 - 얼마나 가까워졌는지 알려면 뭔가 수치로 표현할 수 있어야하는데 그게 '표준오차(Standard Error, SE)'이다. - 모집단의 표준편차를 알고 있다면 표준오차 SE는 = σ/√n - 모집단의 정보를 모른다면 표본의 표준편차 s를 대신 써서 SE = s/√n - 보면 표본의 수가 많아질수록 분모에 있는 n이 커지니까 전체 SE 값은 작아지고 평균이 모평균에 더 가까워진다 표본의 수가 늘어나면, 표준오차는 얼마나 줄어들까? - '제곱근 √n'에 반비례해서 줄어든다 - 표본의 수가 1일 때는 √1 = 1, 표본 수가 4면 √4 = 2, 9면 √9 = 3, 16이면 √16 = 4처럼 증가. 그래서 표본의 수가 4배여야 표준오차는 절반으로 줄어든다. - 그래서 우리가 어떤 평균을 구할 때 표본이 많으면 더 정밀해지는 건 맞지만 그 정밀도는 점점 천천히 좋아짐 마치 10명으로 평균을 구할 때보다 100명으로 구할 때 더 정확해지긴 하는데 그 차이가 그렇게 크진 않은데 왜냐하면 √10은 약 3.16이고, √100은 10이라서 약 3배 차이만 나니까. 68-95-99.7 법칙 - 표준편차가 5인 경우 평균 ± 1σ(표준편차)인 구간, 즉 45-55에는 약 68%의 확률로 데이터가 들어오고, 평균 ± 2σ인 40-60에는 약 95%의 확률로 들어온다는 규칙 - 어떤 동전 던지기 실험을 100번 반복했더니 평균이 50이고 표준오차가 5였다면? - 표본 평균이 40에서 60 사이에 있을 확률이 약 95%. (95% 신뢰구간) - 나는 평균이 50이라고 믿는데 95% 확률로 진짜 평균은 40~60 사이에 있을 거라고 신뢰가능한구간 - 표본의 크기가 커지면 신뢰구간은 어떻게 될까? - 표본이 커지면 표준오차가 줄어들고 신뢰구간도 좁아진다. 즉 우리가 더 많은 데이터를 가지고 있다면 진짜 평균을 더 좁은 범위로 정확히 예측할 수 있다. 중심극한정리 (p.71) - 동전을 한 번 던지면 앞면이 나오거나 뒷면이 나오고 확률이 50%씩이다. - &lt;실험1> 동전을 5번 던지면 - 앞면이 5번 중 2번일 수도 있고, 4번일 수도 있고, 완전히 랜덤처럼 보이고 히스토그램으로 그려보면 이상한 모양이 나오는데 표본수가 적어서그렇다. - 동전을 500번 던지고 히스토그램으로 그려보면 가운데 몰린 종 모양이 된다. - &lt;실험2> "동전을 5번 던지고, 앞면이 몇 번 나왔는지를 기록"을 한번 하는게아니라 수백 번 반복하고 - 마찬가지로 "10번 던지고 기록", "100번 던지고 기록", "500번 던지고 기록"을 히스토그램으로 그리면 횟수가 많아질수록 분포가 가운데 몰린 정규분포 형태가된다. (중심극한정리) - 중심극한정리 - 어떤 분포에서 나오는 데이터든지 그 평균값들을 계속해서 모으면, 그 평균들의 분포는 (처음 데이터 자체가 정규분포가 아니더라도) 정규분포를 따른다. - 유의점 - &lt;실험2>에서 500번 던지고 기록한다는건 히스토그램에서 막대가 500개라는게 아니라 500개의 평균을 N번 그려서 막대는 N개이고 엄밀히는 "500번 던지고 N번 기록한다"이다. - &lt;실험1>에서 500번 던진 히스토그램이 종 모양이되는건 중심극한정리를 보여주는게 아니라 이항분포의특성을 보여준다. (p.75-76) 1이 나온 횟수의 분포 - 주사위를 10번 던지면 1이 나올 수 있는 횟수 분포는 불규칙하고 히스토그램도 불규칙함. - 주사위 던지기를 600번씩 반복해서 그때마다 '1이 나온 횟수'를 기록하고 그 결과를 모아 히스토그램을 그리면? - 분포는 점점 종 모양 정규분포에 가까워진다. - 평균(x축의)은 대략 전체 횟수의 1/6인 100 근처가 된다.(주사위의 한 면이 나올 확률이 1/6) 여론조사 - 여론조사에서 1,000명에게 물었더니 63%가 어떤 후보를 지지한다고 나왔다고 해보자. 다음에 또 1,000명을 조사하면 정확히 63%가 나올까? - &lt;질문1> 재조사 시 동일한 결과는 보장하지 못하지만, 구간을 잡으면 신뢰할 수 있지 않을까? - 다음 조사에서 63%를 보장하지 못하지만 표준오차와 중심극한정리를 바탕으로 구간은 찾을수있다. 95% 신뢰수준이라면 “우리가 100번 이런 조사를 반복했을 때 95번은 진짜 값이 이 구간 안에 들어간다”고 말할 수 있다. - &lt;질문2> 샘플링 불확실성(uncertainty)을 수량화 즉 불확실성의 정량화? - 뽑은 표본은 항상 약간씩 다르고 오차가 존재하지만 그 오차가 얼마나 될지를 수식으로 계산해서 수량화할 수 있고 그게 불확실성의 정량적 추론. - &lt;질문3> 어떻게 구간을 잡을것인가? - 표본 비율 ± (임계값 × 표준오차) - 95% 신뢰구간을 구하고 싶다면? (z = 1.96 / p = 0.63, n = 1000일때) - SE = √(p(1-p)/n) = √(0.63 × 0.37 / 1000) ≈ 0.0153 - 신뢰구간 = 0.63 ± 1.96 × 0.0153 ≈ (0.600, 0.660) - 진짜 지지율은 약 60.0% ~ 66.0% 사이일 것이다. - &lt;질문4> 95% 신뢰구간의 의미는? - 이 사람의 지지율이 95% 확률로 이 구간 안에 있다 (x) - 이런 방식으로 표본을 100번 추출해서 구간을 만들면 그 중 약 95번은 진짜 값(모비율)을 포함할 것이다. (표본이 아니라 추정 방법에 대한 신뢰) 유의수준 (p.87) - 유의수준? - 내가 어느 정도 위험을 감수하고 기각할지를 정하는 수치. - α = 0.05 면 5% 정도는 내가 틀릴 수도 있다는 걸 감안하고 귀무가설을 기각하겠다 즉 실제로는 귀무가설이 맞는데도 5% 확률로 잘못 기각할 수 있다는 걸 받아들이겠다. - α = 0.01로 정했다면? 나는 실수할 확률을 1% 이하로 줄이겠다. - 유의수준 & 신뢰도 - α = 0.05는 95% 신뢰도. (95% 확률로 맞을것이다 x 95% 확률로 이 방법을 믿는다 o) - α = 0.01이면 99% 신뢰도 / α = 0.1이면 90% 신뢰도. - 유의수준 & Z-값 - Z-값: 정규분포에서 얼마나 극단적인 값이 나와야 기각할지를 결정하는 경계값 - α = 0.1 → Z ≈ 1.645 - α = 0.05 → Z ≈ 1.96 - α = 0.01 → Z ≈ 2.575 - 유의수준 α가 작아질수록 더 멀리 떨어진 극단적인 데이터가 나와야 귀무가설을 기각할 수 있다. 중심극한정리는 모든 분포에 다 유효한가? 그러면 분포가 없는 경우에도 유효한가? - 중심극한정리가 적용되기 위해선 표본들이 서로 독립적으로 추출 / 각 표본은 같은 분포 / 모집단의 유한한 평균과 분산 / 표본의 크기가 충분히 클 것 (n ≥ 30) - 모집단의 분포가 존재하지 않거나, 분포는 있지만 기댓값이나 분산이 무한하다면, 중심극한정리는 성립하지 않음. - Cauchy 분포: 평균, 분산이 정의되지 않아서 중심극한정리 성립 안 함 - 무한 분산을 가진 분포 (heavy-tailed distributions) 적용 불가 모집단에 분포가 존재한다의 의미? - 기댓값(평균)과 분산 같은 통계량을 계산할 수 있다. 평균이랑 분산을 계산못할수도있나? - 평균이 너무 자주 바뀌면 분산이 무한할수있다(=계산할수없다). - 예시: 가상의 시험에서 대부분 학생은 80~90점 사이인데 한번씩 누가 10만 점, 1억 점을 받는다. 말도 안 되게 큰 점수가 자주 나오면 평균을 구할 수는 있더라도 평균이 계속 바뀌고 평균 근처에서 얼마나 퍼져 있는지를 따지는 분산도 엄청 커져서 계산이 불가해진다. 결론 중심극한정리는 "대부분 학생은 80~90점 사이인데 한번씩 누가 10만 점, 1억 점을 받는다" 같은 상황이나 Cauchy 분포만 아니면 모두 적용된다? (왜냐면 기댓값과 분산은 데이터만 있으면 무조건 계산 가능하므로 언급한 케이스가 아니면 모집단의 분포가 없기는 어려움)</a></p><hr><p><em>2025-08-04</em> ⋯ 결단</p><p style=height:4.5em;overflow:hidden><a href=/docs/hobby/book/book52/>머스크는 로켓이 산소가 희박한 높이로 충분히 솟아올라 불꽃이 꺼지길 바랐다. 그러나 로켓은 추락하기 시작했다. 비디오 피드에서 오멜렉이 가까이 다가오더니 더 이상 화면에 아무것도 비치지 않았다. 그리고 불타는 파편들이 바다로 떨어졌다. “위장이 뒤틀렸지요.” 머스크의 말이다. 1시간 후, 머스크는 뮬러, 쾨니스만, 부자, 톰슨 등 수석 팀원들과 함께 잔해를 둘러보기 위해 육군 헬리콥터에 올랐다. 그날 밤 모두가 콰즈의 야외 바에 모여 조용히 맥주를 마셨다. 몇몇 엔지니어는 눈물을 흘렸다. 머스크는 돌처럼 굳은 얼굴과 먼 곳을 응시하는 눈빛으로 조용히 생각에 잠겼다. 그러고는 아주 부드럽게 입을 열었다. “처음 시작할 때 우리 모두는 첫 번째 임무에서 실패할 수 있다는 것을 알고 있었습니다. 우리는 다른 로켓을 만들어 다시 시도할 것입니다. 머스크와 수석 엔지니어들은 비행기를 타고 로스앤젤레스로 돌아오는 길에 녹화 영상을 틀어놓고 분석에 들어갔다. 뮬러가 멀린 엔진에서 화염이 발생한 순간을 가리켰다. 연료 누출이 원인인 것이 분명했다. 머스크는 잠시 끙끙 앓더니 뮬러를 향해 소리쳤다. “얼마나 많은 사람들이 당신을 해고해야 한다고 내게 말했는지 알아요?” “그냥 해고하지 그래요?” 뮬러가 받아쳤다. “근데 내가 염병할 당신을 해고했소? 염병할 당신은 아직 여기 있잖소.” 머스크가 대꾸했다. 그런 다음 머스크는 긴장을 풀려는 듯 코믹 액션 풍자 영화 〈팀 아메리카: 세계 경찰〉을 틀었다. 그렇게 어둠을 실없는 유머로 바꾸는 것은 머스크에게 흔한 일이었다. 그날 늦게 그는 성명을 발표했다. “스페이스X는 장기적인 시각으로 이 일에 임하고 있습니다. 그 어떤 어려움이 닥쳐도 우리는 이 일을 해낼 것입니다.” 마크스는 제조공정의 모든 측면을 통제함으로써 얻는 이익과 관련하여 머스크의 판단이 옳았음을 인정한다. 그러면서 그는 또한 머스크에 대한 핵심적인 질문, 즉 그를 성공으로 이끈 ‘올인’ 방식의 추진력과 그의 나쁜 행동방식이 분리될 수 있는지 여부를 놓고도 고민한다. “나는 그를 스티브 잡스와 같은 범주의 사람이라고 여기게 됐는데요. 그러니까 어떤 사람들은 그냥 개자식이지만, 그들은 또한 너무 대단한 것을 성취해서 그냥 물러앉아 ‘그게 패키지인 것 같아’라고 말할 수밖에 없게 되는 것과 같은 거죠.” 내가 머스크가 이뤄낸 것이 그의 행동방식에 대한 변명이 될 수 있다고 생각하는 것이냐고 묻자, 마크스는 이렇게 답했다. “만약 이런 종류의 성취를 위해 세상 사람들이 지불해야 하는 대가가 진짜 개자식을 리더로 삼아야 하는 것이라면, 그것은 그럴 만한 가치가 있을 수도 있겠지요. 어쨌든 나는 그렇게 생각하게 되었어요.” 그러고는 잠시 생각에 잠겼다가 덧붙였다. “하지만 나는 그렇게 되고 싶지는 않아요.” 마크스가 떠난 후 머스크는 보다 냉정하고 강인한 느낌의 CEO를 영입했다. 전투 경험이 있는 이스라엘 낙하산부대 장교 출신으로 반도체 분야에서 기업가로 성공한 제브 드로리였다. 머스크는 말한다. “실제로 테슬라의 CEO가 되는 데 흔쾌히 동의한 유일한 사람이었어요. 두려워해야 할 것이 많았던 탓에 아무것도 두려워하지 않는 인물이었지요.” 하지만 드로리는 자동차 제작에 대해 아는 것이 없었다. 몇 달 후, 스트로벨이 이끄는 고위임원 대표단은 더 이상 그의 지휘 아래 일하기 어렵다고 말했고, 이사회 멤버인 아이라 에렌프라이스는 머스크에게 직접 지휘권을 잡으라고 앞장서서 설득했다. “내가 운전대를 잡아야 할 때가 된 것 같네요. 둘이 같이 운전대를 잡을 수는 없다는 점 이해해주길 바랍니다.” 머스크가 드로리에게 말했다. 드로리는 우아하게 물러났고, 머스크는 2008년 10월에 테슬라의 공식 CEO가 됨으로써 약 1년 사이에 네 번째로 그 직함을 보유한 인물이 되었다. 아들 네바다의 죽음 이후 저스틴과 일론은 가능한 한 빨리 다시 아이를 갖으려 했다. 그들은 체외수정 클리닉에 다니기 시작했고, 2004년 쌍둥이인 그리핀과 자비에를 낳았다. 2년 후 그들은 다시 체외수정으로 세쌍둥이 카이, 색슨, 데미안을 낳았다. 실리콘밸리의 작은 아파트에서 룸메이트 세 명, 온순하지 않은 닥스훈트 소형견과 함께 결혼생활을 시작했던 부부는 이제 로스앤젤레스 벨에어 언덕 구역의 170평 저택에서 톡톡 튀는 아들 다섯 명, 유모와 가정부로 구성된 직원 다섯 명, 여전히 길들여지지 않은 닥스훈트 한 마리와 함께 살게 되었다. 사납고 거친 성격에도 불구하고 두 사람 사이에 다정함이 넘쳐나던 순간들도 있었다. 부부는 서로의 허리를 감싸 안고 팰로앨토 근처의 서점 케플러스 북스까지 걸어가서 책을 구입한 후 카페로 자리를 옮겨 커피를 마시며 책을 읽곤 했다. “그 얘기를 하자면 목이 메여요.” 저스틴은 말한다. “완전한, 거의 완전한 만족감을 느끼던 순간들이었지요.” 직장에서 동료들에게 그러듯이 머스크는 아내 앞에서도 순식간에 밝음에서 어둠으로, 어둠에서 밝음으로 변하는 모습을 보였다. 그는 모욕을 퍼붓다가 잠시 멈추곤 표정을 풀며 즐거운 미소를 짓기도 했고, 엉뚱한 농담을 던지기도 했다. 저스틴은 &lt;에스콰이어>의 톰 주노드에게 이렇게 말했다. “곰처럼 의지가 강하고 힘이 센 사람이에요. 그는 재미나게 장난치고 함께 뛰어놀아주기도 하지만, 결국에는 여전히 곰을 상대하고 있음을 깨닫게 하죠.” 2008년 봄, 로켓이 폭발하고 테슬라의 혼란이 가중되던 와중에 저스틴이 교통사고를 당했다. 사고가 있고 얼마 후 그녀는 부부의 침대에서 무릎을 가슴까지 끌어올려 앉은 채 눈물을 흘렸다. 그녀는 일론에게 둘의 관계에 변화가 있어야 한다고 말했다. “수백만 달러의 장관이 펼쳐지는 남편의 인생에서 열외로 취급되는 존재가 되고 싶지 않았어요.” 그녀는 말한다. “남편이 수백만 달러를 벌기 전에 그랬던 것처럼 나는 사랑하고 사랑받고 싶었어요.” 일론은 상담을 받는 데 동의했지만, 그가 한 달 동안 세 번의 상담을 받고 난 시점에 두 사람은 결혼생활에 종지부를 찍었다. 저스틴은 일론이 최후통첩을 했다는 입장이다. 현재의 생활을 있는 그대로 받아들이지 않으면 이혼소송을 제기하겠다고 말이다. 반면 일론은 저스틴이 이혼하고 싶다고 반복해서 말했기 때문에 결국 자신이 “나는 결혼생활을 계속할 의향이 있지만, 당신이 이렇게 나에게 못되게 굴지 않겠다고 약속해야 해”라고 말했다고 주장한다. 저스틴이 지금 그대로의 상황은 받아들일 수 없다고 분명히 밝히자, 그는 이혼을 신청했다. “어이가 없어 말이 안 나왔지만, 이상하게도 안도감이 밀려왔어요.” 저스틴의 회상이다. 당시 스물두 살이던 탈룰라 라일리는 그림책에 나올 법한, 허트포드셔의 전형적인 영국 마을에서 자랐으며, 머스크를 만났을 때 이미 제인 오스틴의 《오만과 편견》을 각색한 작품에서 베넷 가의 다섯 자매 중 셋째인 음치 메리 역을 맡는 등 작지만 연기력을 요하는 배역을 훌륭히 소화해 두각을 나타내고 있었다. 큰 키에 길게 생머리를 늘어뜨린 그 미녀는 기민한 성격에 두뇌가 명석한 것이 머스크의 성향과 매우 흡사했다. 닉 하우스와 또 다른 친구 제임스 패브리컨트의 소개로 그녀는 머스크와 함께 앉게 되었다. “그는 수줍음이 많고 약간 어색해 보였어요.” 그녀는 말한다. “그는 로켓에 대해 이야기하고 있었는데 처음에는 그것들이 그의 로켓인 줄 몰랐어요.” 어느 순간 그가 “무릎에 손을 올려도 될까요?”라고 물었다. 그녀는 약간 당황했지만 고개를 끄덕이며 동의했다. 자리가 끝날 무렵, 머스크는 그녀에게 이렇게 말했다. “나는 이런 일에 아주 서툴지만, 다시 만나고 싶으니 전화번호를 알려주시면 좋겠습니다.” 라일리가 돌아갈 때가 되었을 무렵 머스크가 그녀에게 청혼했다. “정말 미안하지만, 반지는 미처 준비하지 못했소.” 그녀는 악수로 대신하자고 했고, 두 사람은 그렇게 악수를 했다. “호텔의 옥상 수영장에서 그와 함께 수영하면서 마냥 들뜬 가운데 서로를 알게 된 지 2주 정도밖에 안 되었는데 벌써 약혼을 했다는 사실이 얼마나 신기한지 이야기한 기억이 납니다.” 라일리는 그에게 모든 일이 잘 풀릴 것 같은 확신이 든다고 말했다. “우리에게 닥칠 수 있는 최악의 상황이 무엇일까요?” 그녀가 농담처럼 물었다. 머스크는 갑자기 진지한 태도로 “우리 중 한 명이 죽는 거겠지요”라고 답했다. 왠지 그 순간 그녀는 그 말이 매우 로맨틱하다고 느꼈다. 머스크는 자금이 바닥나고 있었고, 테슬라는 적자를 내고 있었으며, 스페이스X는 로켓 세 대를 연달아 추락시킨 상황이었다. 하지만 그는 포기할 준비가 되어 있지 않았다. 대신 그는 말 그대로 파산까지 갈 각오를 했다. 그는 발사 실패 몇 시간 후에 이렇게 발표했다. “스페이스X는 앞으로 나아가는 실행에 있어 결코 걸음을 멈추거나 늦추지 않을 것입니다. 스페이스X가 궤도 진입에 성공할 것이라는 데에는 의문의 여지가 없습니다. 절대 포기하지 않을 것입니다. 절대로.” 하지만 그는 로스앤젤레스 공장에 네 번째 로켓을 위한 부품이 있다고 말했다. 가능한 한 빨리 로켓을 만들어서 콰즈로 옮기라고 지시했다. 그리고 현실성이 거의 없는 기한을 제시했다. 6주 후에 네 번째 발사를 하라는 것이었다. “그는 우리에게 그냥 계속 진행하라고 말했고, 나는 놀라서 입을 다물지 못했지요.” 쾨니스만의 말이다. 돌연 낙관적인 분위기가 본사 전체에 퍼졌다. 그 당시 인사책임자로 일했던 돌리 싱은 이렇게 말한다. “그의 태도를 보고 우리 대부분은 지옥의 문이라도 선탠오일을 들고 따라 들어갈 마음이 생긴 것 같았어요. 순식간에 사옥의 기운이 절망과 패배의 분위기에서 다들 결의를 다지는 분위기로 바뀌었지요.” 머스크와 함께 2차 발사 실패를 지켜봤던 &lt;와이어드>의 칼 호프먼 기자가 머스크에게 연락해 어떻게 낙관론을 유지할 수 있는지 물었다. 머스크는 답했다. “낙관론, 비관론, 다 집어치우라고 하쇼. 우리는 해낼 거요. 염병할 신께 맹세컨대, 나는 무슨 일이 있어도 그것을 성공시킬 작정이오.” 모두 수작업으로 완성된 몇 대의 차량을 출시한 것은 작은 승리에 불과했다. 오래전에 파산하여 잊힌 많은 자동차 회사들도 이와 비슷한 과정을 거쳤다. 다음 도전은 자동차를 수익성 있게 생산할 수 있는 제조공정을 갖추는 것이었다. 지난 세기에 파산하지 않고 이를 성공시킨 유일한 미국 자동차 회사는 포드뿐이었다. 테슬라는 과연 그 두 번째 기업이 될 수 있을까? 당시에 그것은 불분명해 보였다. 대공황 이후 가장 심각한 글로벌 경기 침체로 이어질 서브프라임 모기지 사태가 막 시작되고 있었다. 테슬라의 공급망은 통제하기 힘들었고, 회사는 자금이 부족했다. 게다가 스페이스X는 아직 로켓을 궤도에 진입시키지 못했다. 머스크는 말한다. “로드스터를 손에 넣었음에도 내 인생에서 가장 고통스러운 해로 기록될 1년이 시작되고 있었을 뿐이었지요.” 머스크는 종종 합법과 위법의 경계선 근처까지 내달렸다. 그는 아직 제작되지 않은 로드스터에 대한 고객들의 예치금을 털어 2008년 상반기를 버텼다. 테슬라 경영진 및 이사회 멤버 일부는 예치금을 운영비로 사용해서는 안 되며 조건부 날인 증서로 보관해야 한다고 생각했지만, 머스크는 “이렇게 하지 않으면 우리는 죽을 거예요”라고 주장했다. 탈룰라는 매일 밤 머스크가 거칠게 잠꼬대를 중얼거리거나 때로는 팔을 마구 휘두르며 비명을 지르는 모습을 공포에 질려 지켜보았다. “그가 심장마비를 일으킬 수도 있다는 생각이 계속 들었어요.” 그녀는 말한다. “머스크는 야경증에 시달렸어요. 자다가 갑자기 비명을 지르고 저를 할퀴기도 하고 그랬어요. 정말 끔찍했어요. 그런 필사적 몸부림을 지켜보면서 저는 정말 겁이 났어요.” 때때로 그는 화장실에 가서 구토를 시작했다. “스트레스가 극심해서 속이 뒤집어지는지 화장실로 달려가 비명을 지르며 구역질을 하곤 했어요. 저는 변기 옆에 서서 그의 머리를 잡아주곤 했죠.” 머스크는 스트레스에 대한 내성이 강하지만 2008년에는 거의 한계를 넘어설 지경에 이르렀다. “묘책을 찾아 해결책을 내놔야 하고, 또 해결책을 내놔야 하는 그런 상황에서 매일 밤낮으로 일하지 않을 수 없었지요.” 머스크는 말한다. 그는 체중이 많이 늘었다가 갑자기 다 빠지고 추가로 더 빠졌다. 자세는 구부정해졌고, 걸을 때는 발가락이 뻣뻣해졌다. 하지만 그럼에도 그는 활력이 솟구쳤고 집중력이 고도로 높아졌다. 교수형 올가미가 눈앞에 아른거리며 정신을 바짝 차리도록 자극했기 때문이다. 머스크의 주변 사람들은 모두 반드시 한 가지 결정을 내려야 한다고 생각했다. 2008년이 막바지로 치달을 무렵, 머스크는 스페이스X와 테슬라 중 하나를 선택해야 할 것 같았다. 점점 줄어드는 자원을 한 곳에 집중하면, 그 회사는 살아남을 수 있을 거라는 확신이 들었다. 자원을 계속 분산시키면 둘 다 살아남지 못할 가능성이 높았다. 어느 날 그의 열정적인 소울메이트 마크 준코사가 스페이스X의 칸막이 방에 들어섰다. “저기요, 둘 중 하나는 포기하는 쪽으로 가는 게 어때요?” 그가 물었다. “스페이스X에 더 애착이 가면 테슬라는 버리자고요.” “안 돼. 그러면 ‘전기차는 안 된다’라는 푯말에 또 한 줄이 추가될 것이고, 우리는 지속 가능한 에너지에 도달할 수 없을 거야.” 머스크가 답했다. 그렇다고 스페이스X를 포기할 수도 없었다. “그러면 우리는 영영 다행성종이 될 수 없을지도 몰라.” 더 많은 사람이 선택을 강요할수록 그는 더욱 저항했다. “나는 감정적으로 두 명의 아이가 있고 식량은 부족한 상황에 놓인 것 같았어요. 두 아이에게 식량을 절반씩 나눠주면 두 아이 모두 죽을 수도 있고, 한 아이에게 음식을 몰아주면 적어도 그 아이는 살아남을 확률이 높아지죠. 하지만 내가 과연 내 아이 중 한 명은 죽게 놔두는 결정을 내릴 수 있을까요? 그래서 나는 둘 다 살리기 위해 모든 것을 바치기로 결심했지요.”</a></p><hr><p><em>2025-08-04</em> ⋯ Docker #5 kubernetes 환경에 나의 앱을 배포해보자</p><p style=height:4.5em;overflow:hidden><a href=/docs/study/be/be44/>구조 실습과의 차이? 1. cicd.sh를 쓴다. 2. deploy 디렉토리를 쓴다. 3. docker-build.sh와 docker-push.sh에서 amd였던걸 arm으로 바꿔줬는데 이걸다시 amd로 바꿔준다. ~1. cicd.sh 작성 **(불필요)**~ cicd.sh 사용하는 부분이 나오는데 ppt랑 workspace 디렉토리 안에 아무리찾아봐도 없어서... 일단 챗지피티에넣고 만들었는데 막상 뒤에서는 cicd.sh 쓰는대신 그냥 `kubectl apply -f deploy.yaml` `kubectl apply -f service.yaml` 만 해줬다. 2. deploy 디렉토리 deploy 디렉토리의 deploy.t와 service.t는 각각 .sh로 바꿔준다. - deploy.sh에서 amd를 유지해주고 - service.sh는 원래 8080 돼있었는데 8888 아닌가 싶어서 바꿔줬다. env.properties의 CPU_PLATFORM=amd64으로 설정했고 deploy.sh에서 amd64로 해주고 service.sh에서 port: 8888로 변경했다. 3. docker-build.sh와 docker-push.sh 재수정 arm을 amd로 다시바꿔줫다. 마찬가지 arm을 amd로 바꿔줌. 4. Docker 이미지 빌드, 푸시, kubernetes 환경에 배포 ~이렇게 하면 나와야되는데 계속 404 에러 나옴.~ *해결.. ㅠㅠ* 1. deploy.sh: 챗지피티에서 amd64 떼라고해서 마지막엔 `image: amdp-registry.skala-ai.com/skala25a/${USER_NAME}-posts-get:1.0`도 썼다 2. deploy.yaml: 마찬가지로 amd64 떼라고해서 `amdp-registry.skala-ai.com/skala25a/sk019-posts-get:1.0`도 썼다. 3. defalut.conf는 다음 3가지 버전을 시도했다. 4. cicd.sh -y 스크립트가 존재하지 않는 경우에 `kubectl apply -f deploy.yaml`와 `kubectl apply -f service.yaml`로 대체 가능하대서 그냥 패스했는데 그래도 되는게 맞는지 모르겟음 교수님께 질문사항 디엠 보냈는데 > 우선 deploy를 통해 자신이 만들어놓은 컨테이너 이미지를 클라우드 환경으로 잘 배포했습니다. > > 그리고 service를 통해 나의 컨테이너 내 80포트를 노출하고 있는 nginx를 외부에서 접속 가능하도록 잘 연결했습니다. 이것은 어디서든 접속가능하게 하기 위한 ingress 설정이 있는데 이것은 제가 미리 만들어놓아서 위의 URL로 접속됩니다. > > 단지 내가 외부 접속을 위한 ingress 설정에 등록했던 service 이름인 sk019-posts-get이였는데 sk019-posts-get-svc로 만들어 놓아서 이름만 변경해놓았습니다. 라고 오셔서 확인해보니까 말도안되게 service.yaml이 다음과같이 작성돼있었다 아니근데 위 작업 하면서 쓴 챗지피티 대화창에 'sk019-posts-get' 치면 어디서도 'sk019-posts-get-svc'라는 단어가 없는데....... 어디서 나온건지 모르겟음 아무튼 링크를 확인해보니까 잘들어가있다 ㅎㅎ</a></p><hr><p><em>2025-08-04</em> ⋯ Docker #4 자신의 Frontend 개발 코드를 컨테이너로 만들고 이것을 실행시켜 보자</p><p style=height:4.5em;overflow:hidden><a href=/docs/study/be/be43/>1. nginx:alpine 이미지를 사용 2. 노출 Port는80 3. nginx를실행하는방식은 -nginx -g daemon off; 4. nginx의 routing 설정은 default.conf에설정한다. 1. docker-build.sh와 docker-push.sh 복사 docker-build.sh에서 amd였던걸 arm으로 바꿔줫고 docker-push.sh에서 마찬가지 amd를 arm으로 바꿔줌. 2. Dockerfile과 default.conf 작성 원래 코드에 `COPY src/ /usr/share/nginx/html/`이 없었는데 필요한거아닌가 싶어서 넣어줬다. 3. 파일 구조 index.html이랑 이미지 디렉토리 media는 src 디렉토리에 넣었다. 4. 이미지 push build + docker run 마찬가지 run 주소도 arm으로 넣어줌. 잘 나온다 ㅎㅎㅎ 5. 헷갈리는점 1. docker-build.sh에서 - IMAGE_NAME을 healthcheck-server로 바꿔주라고 ppt에 나와있었는데 안바꾸고 webserver를 썼는데 마지막에 `sudo docker run -d --name posts-get --network bridge -p 8888:80 sk019-posts-get.arm64:1.0` 했을때 제대로 나왔다. - 근데 chatgpt 치니까 IMAGE_NAME="healthcheck-server" 해놓고 `sudo docker run -d --name posts-get` 해버리면 안된다고나옴 빌드한 이미지와 실행한 이미지 이름이 다르다고 근데 원래는 달랐는데 잘되던데... 확인 필요할듯. 2. default.conf는 사실 아래 코드로 바꿔넣어줬었다. index.html;을 추가한것임. 이부분도 확인 필요. *1에 추가: env.properties에서 SERVICE_NAME="posts-get"가 나오긴한데 docker-build.sh와 docker-push.sh 가 앞에 source ./env.properties가 붙는 식으로 진행되면 IMAGE_NAME="posts-get"이 적용되고 이미지 이름이 sk019-posts-get:1.0.0으로 만들어지고, run/push 시 모두 일관성이 유지되는게 맞는데? env.properties를 불러오지도 않고, IMAGE_NAME에 healthcheck-server이 하드코딩 대있어서 연관성을찾기 어려운상태.</a></p><hr><div class=pagination style=margin-top:2rem;display:flex;justify-content:center;align-items:center;gap:1rem><a href=/tags/2025-08/page/2/ style="padding:.5rem 1rem;text-decoration:none">←</a>
<span style=color:#666>3 / 4
</span><a href=/tags/2025-08/page/4/ style="padding:.5rem 1rem;text-decoration:none">→</a></div></article><footer class=book-footer><div class="flex flex-wrap justify-between"></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents></nav></div></aside></main></body></html>