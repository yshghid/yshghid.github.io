<!doctype html><html lang=en-us dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="https://yshghid.github.io/tags/2026-01/"><meta property="og:site_name" content=" "><meta property="og:title" content="2026-01"><meta property="og:locale" content="en_us"><meta property="og:type" content="website"><title>2026-01 |</title><link rel=icon href=/favicon.png><link rel=manifest href=/manifest.json><link rel=canonical href=https://yshghid.github.io/tags/2026-01/><link rel=stylesheet href=/book.min.30a7836b6a89342da3b88e7afd1036166aeced16c8de12df060ded2031837886.css integrity="sha256-MKeDa2qJNC2juI56/RA2Fmrs7RbI3hLfBg3tIDGDeIY=" crossorigin=anonymous><script defer src=/fuse.min.js></script><script defer src=/en.search.min.57f5759648eddc42b452dea935ff2e8969bf8eef2053838fc83c7a6765f73052.js integrity="sha256-V/V1lkjt3EK0Ut6pNf8uiWm/ju8gU4OPyDx6Z2X3MFI=" crossorigin=anonymous></script><link rel=alternate type=application/rss+xml href=https://yshghid.github.io/tags/2026-01/index.xml title=" "></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><img src=/logo.png alt=Logo class=book-icon><span></span></a></h2><div class="book-search hidden"><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><script>document.querySelector(".book-search").classList.remove("hidden")</script><ul><li class=book-section-flat><span>기록</span><ul><li><a href=/docs/hobby/daily/>일상</a><ul></ul></li><li><a href=/docs/hobby/book/>글</a><ul></ul></li></ul></li><li class=book-section-flat><span>공부</span><ul><li><a href=/docs/study/ai/>AI</a><ul></ul></li><li><a href=/docs/study/bioinformatics/>Bioinformatics</a><ul></ul></li><li><a href=/docs/study/be/>BE</a><ul></ul></li><li><a href=/docs/study/fe/>FE</a><ul></ul></li><li><a href=/docs/study/career/>취업</a><ul></ul></li></ul></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu></label><h3>2026-01</h3><label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents></nav></aside></header><article class="markdown book-article"><p><em>2026-01-09</em> ⋯ 데이터 분석 #6 pandas numpy 데이터 처리</p><p style=height:4.5em;overflow:hidden><a href=/docs/study/ai/ai40/>데이터 처리 pandas scipy sklearn
- pandas로 데이터프레임으로 데이터를 확인하고
- scipy와 sklearn에서 통계 패키지와 머신러닝 패키지를 사용한다 numpy
- python이 제공하는 머신러닝 패키지는 sklearn인데 이를 사용하려면 numpy를 알아야 한다.
- tensorflow같은 딥러닝 패키지들이 입출력을 위해 numpy를 사용한다
- numpy는 다차원 배열인데 포함된 모든 데이터는 같은 형식이어야한다
- 머신러닝을 하고싶으면 float 형식으로 만들어진 다차원 배열이 필요하다. pandas 쓰는 이유
- 데이터가 표 형식이라도 그 안에는 여러 type의 데이터가 혼재되어 있고 행과 열의 라벨 등이 문자열일것인데, 이를 읽어들이는 도구가 pandas.
- 텍스트 파일이나 엑셀 파일을 데이터프레임으로 통째로 옮겨올 수 있다. 데이터 확인 - 원래 책에서는 Variant and risk allele, P-value, P-value annotation, RAF, OR, Beta, CI, Mapped gene, Reported trait, Trait(s)를 컬럼으로 갖고있어서 수정해줬다.
- assoc를 확인해보면 비어있는 데이터도 많고
- 숫자 사이에 텍스트가 들어가있는 경우도 있다
- 파이썬은 루프를 돌면서 작업을 하는 것을 매우 꺼린다.
- 대부분의 언어에서는 for loop를 돌면서 값을 채워야 하지만 파이썬은 이런 경우에 누가 만들어두었을 가능성이 크다. 데이터 전처리 - pandas 전처리 상황
- 파일은 보통 비어있는 데이터가 있거나
- 숫자 사이에 텍스트가 들어가있어서 제대로 읽히지 않을 수 있고
- 클래스로 나눠야 할때도 있다. 텍스트로 된 열을 숫자형으로 바꾸기
- 수치로 표현되는 P-value와 OR을 확인해보기.
- 내 데이터에서는 모두 float이지만 책에서는 P-value의 dtype이 object이다.
- "8 x 10-9"와 같이 적혀있기 때문.
- pandas는 8E-9 식으로 된 문자열은 쉽게 float로 바꾼다. 따라서 'x 10' 대신에 'E'를 넣으면 된다. float가 아닌 데이터를 사용하기 위해 클래스로 나누기
- 데이터로 머신러닝을 돌려보려면 float 형식이 일반적이고
- 여기서는 2개 컬럼을 쓸수있는 셈이다
- float만 아니라 trait 같은 문자열 데이터도 사용하고 싶으면 categorial(범주형) 데이터로 바꿔주면 된다. 원핫 인코딩
- 범주값을 0,1로 표현하는 것
- 이미지를 분석하는 딥러닝 모델을 만들었을때 자동차, 비행기, 고양이, 개 이렇게 4개의 이미지를 학습시켰다고 하면
- 데이터에 1번 사진은 고양이, 2번 비행기 이런식으로 정답을 지정해줘야 하는데
- 이럴때 원핫 인코딩을 쓴다. 데이터 전처리 - numpy numpy로 만들기
- 작업을 pandas로 한 뒤에 머신러닝을 하기 위해서는 numpy로 만들어야 한다.
- 위에서 말했듯 numpy의 요소들은 모두 같은 형식을 갖게 된다. numpy로 데이터 다루기
- 수학이나 과학의 연산에서 행렬을 통째로 연산하는 경우가 많은데 이를 위한 파이썬 패키지가 numpy
- ndarray는 특정 타입의 데이터로 이루어진 다차원 배열(array).
- numpy는 파이썬의 문법만 가지고 있을 뿐 내부 구현이 C 등의 컴파일 언어로 작성되어 있어서 실행속도가 빠르다.
- 그래서 수치 데이터 처리에서 파이썬을 사용할 때 대부분의 라이브러리가 numpy를 기반으로 한다. numpy와 broadcasting
- 행렬과 하나의 수를 곱하면 행렬의 모든 값에 그 수를 곱한 효과가 나타난다.
- C같은 다른 프로그램에서 배열에 하나의 수를 곱하려면 for loop를 사용해야 하는데 numpy가 있으면 빠르게 할수있다.
- array와 수 하나의 연산이 가능하듯이 높은 차원 array와 낮은 차원 array 사이 연산도 가능한데
- 이때 낮춘 차원의 수가 높은 차원 쪽으로 broadcasting 된다. - ar4는 1차원 배열 1x4였고 ar1은 4x4 2차원 배열이었는데 그 두개를 더하면 ar4의 첫번째 열의 요소인 1이 ar1의 첫번째 열의 모든 요소인 1,1,1,1에 더해진다. - ar4T는 1차원 배열 4x1이고 ar1과 더하면 ar4T의 첫번째 행의 요소인 1이 ar1의 첫번째 행의 모든 요소인 1,1,1,1에 더해진다.
- broadcasting의 활용처?
- 1만개 샘플에 대해서 데이터가 100개씩 있는데, 각 샘플 단위로 표준화를 하려고 할때
- 먼저 각 샘플별로 평균과 표준편차 1만개를 구하고
- 1번 샘플의 100개 데이터를 모두 1번 샘플의 평균으로 빼고 표준편차로 나눠야 한다.
- 이를 차원별 broadcasting을 쓰면 빠르게 할수있다. numpy의 차원축소 평균(reduce mean)
- 1만개 샘플에 100개 데이터면 데이터 크기는 (10000,10)이다.
- 평균은 100개에 대해서만 구하면 된다(1만번).
- 즉 첫번째 차원(행)을 건드리지 말고 두번째 차원(컬럼)을 축소시키면서 평균을 구하면 된다.
- 두번째 차원은 axis=1이다. numpy와 이미지 데이터
- 딥러닝 데이터로 400*300 픽셀의 컬러(보통 RGB 채널) 이미지를 1000개 모아둔 array
- 즉 1000개 이미지 데이터 만들고 확인하기 - 이미지 데이터로 딥러닝을 하기 위해서는
- 먼저 이미지 파일을 읽어서 numpy array로 만든다.
- 딥러닝은 수천개 이상의 이미지를 동시에 입력해서 학습하는데
- 때문에 이 numpy array들을 하나의 큰 array로 묶어두게된다
- 이때
- 일부 이미지는 크기를 바꾸거나 노이즈를 입히는 등 가공해야할수도 있다.
- 중간중간에 이미지가 제대로 가공되는지 확인해야하는 경우도 있다.
- 최근 딥러닝에 tensorflow가 많이 사용된다.
- tensorflow의 연산도 numpy와 비슷하다. 출처 책 빅데이터&인공지능 with 생물정보학</a></p><hr><p><em>2026-01-06</em> ⋯ 데이터 분석 #5 bash python과 bioinformatics</p><p style=height:4.5em;overflow:hidden><a href=/docs/study/ai/ai42/>생물정보학의 데이터 정보학
- 서로다른 두 종류의 데이터를 연결해서 새로운 데이터를 만들수있다.
- 일일이 알고리즘을 설계하고 직접 구현하기가 어렵기 때문에 툴을 사용하면 된다.
- 다만, 툴을 쓰면서 정보학 지식에 대해서 필요성을 느끼고 지속적으로 갖춰가야한다.
- ex. 데이터 더미에서 불필요한 부분을 없애는것과 정렬 작업 중 무엇을 먼저 할까? 생물정보학
- 수학, 통계, 컴퓨터과학을 이용해서 방대한 양의 생물학 데이터를 분석하고
- 유전자의 발현과 같은 생명 현상을 이해하는 학문. 질병 관련 단백질 찾기 - 항원항체 반응
- 특정 질병과 연관된 단백질을 찾기 위해서는 발현된 특정 단백질을 찾는 '항원-항체' 반응을 이용한 단백질 검출 방법을 써야했다.
- 수만종의 단백질을 모두 확인하려면 각 단백질별 항체를 종류별로 갖춰야하기 때문에 해당 질병과 가능성이 가장 높은것 같은 몇몇 단백질에 대해서만 확인가능했다. 오믹스(genomics)
- 유전자 전부를 변수로 삼아 생명 현상을 설명하는 학문이 유전체학(genomics).
- 유전체 정보만으로는 생명현상을 제대로 이해할 수 없어서, 생명 현상을 좌우하는 다른 변수들을 찾기 위해 다양한 데이터를</a></p><hr><p><em>2026-01-05</em> ⋯ 연말과 생일</p><p style=height:4.5em;overflow:hidden><a href=/docs/hobby/daily/daily28/>수많은 추억을 끌어안구,, 정리하고 나온집 엄마아빠동생이랑 밥먹고 근처카페에서 커피도마시구 엄마가 먹고싶다한 타코야끼집이 3시 오픈이어서 카페에서 기다렸는데 25일이어서 휴무였다 ㅠㅠ 그래서 3시에 다들 집으로 돌아갔당 10분 누워있다가 바로 자기보러가깅 강남신세계 스위트파크 내가 좋아할거같다구 거기 가자고 해줬다 쓱 구경하다가 아이스크림 먹구!! 사진은 없는데 엄청마싰는 에그타르트도먹었다. ㅎㅎ 저녁은 뭐먹지머먹지 엄청 하다가 쿄코코라는 스테이크집을 갔다 자기가 무조건 구워먹어야한대서 구워먹었는데 그냥보다 훨배 마싰었다!! 방앗간에 들어간 참새가댄게 넘 기여워서 찍을수밖에없었던 ㅋㅋㅎㅎ 알차게 베라까지 먹어주고 집으로 돌아옴 다음날!! 다투느라 사진이 없지만 프릳츠가서 커피두마시고 빵도먹구... 청약할려고한 아파트도 쓱보고 자기가 유튜브에서봤다한 카츠집에서 히레카츠도 먹었당 그다음날은,, 면접준비 때문에 자기는 돌아가구 혼자가된나 27일부터 30일까지 4일 혼자있었는데 우울해서 사진도 거의없을뿐더러 떠올리고싶지않으므로!! 패쓰하겠다 면접 당일 아침으로 투썸 잉글리시머핀 먹었당 예정보다 약 한시간 일찍끝난 면접 면접전에 15분 대기했는데 사람들이 연구실사람들처럼 건조하고 남루(?)하고 연령이 다양하고 그래서 진짜 연구위주로 하는곳이군.. 생각했다. 끝나구 면접건물 근처 카페에서 자기 만나서 ㅎㅎㅎ 바로 동탄으로 넘어가따 저녁은 뭐먹지머먹지 엄청 하다가 만사부 타임테라스점 가서 먹었당 날씨 넘 추웠어서 따끈한거 먹으니까 둘다 엄청 나른해졌다 ㅎㅎ 집가기전에 홈플러스 들려서 과자랑 이것저것 엄청 사구!! 다이소가서 쇼핑도하구 집에 와서 제야의종 같이 보고 잠들었당 1월1일 넘어갈때 제야의종 보면서 생일축하받는게 매년 하던건데도 자기랑 하니까 너무너무 특별하고 행복했다 ㅎㅎ 다음날 아점 이름은 기억안나는데 정자에서도 마싯어보여서 즐찾 해놨던 곳이라 먹어보고싶어서 먹어따 후기는 너무너무 마싯었다!!!!!!! 여기 감튀가 케이준밖에없어서 일반 감튀를 다른 지점에서 시켜줬는데 최고의 선택이었다 ㅎㅎ 원래는 나가서 여기저기 돌아다닐랬는데 누워있는게 너무 행복해서 그냥 즐겨버렸다 ㅎㅎ 생일 넘어가기전에 자기가 엄청 열심히 방도 꾸며주고 케이크도 준비해주고 ㅠㅠ 마싯는것두 시켜줬다 정말 너무너무 행복한 생일이었다아 다음날 이원일 유튜브 보면서 먹고싶었던 비밀베이커리 시켜먹었는데 진짜 너무너무... 마싯었고... 집에 못사온게 한이다 ㅋㅋ 요날 저녁은 로운샤브 vs 샤브올데이 고민하다가 샤브올데이 먹었다 하지만 로운이 더 마싯다고 둘다 결론지었다 ㅎㅎㅎ 원래 1월 3일에 집가는거였는데 너무너무 아쉬워서 전화로 1박 연장하구 하루 더 있었다. 맘같아선 2주정도 있고싶었는데 ㅠㅠ 3일 저녁은 유가네 시켜먹기 ㅎㅎ 근본있는맛 다음날 여유있는퇴실은 사실 못하구... 스칼라 출근같은 퇴실을 해따 수미상관으로 만두전골 먹기로해서 만두전골집 갔는데 밥먹기전에 다퉈서 밥도 둘다 못먹구 집갈때도 소원했지만 ㅠㅠ 지금은 요날 얘기 다 풀기도 했고 다툼이 건드릴수있는 수준의 행복이 아니었기 때문에 여전히 행복한 생일로 남아있다 ㅎㅎ 마지막은 행복을 즐기느라 기록을 못써서 잔뜩 밀려버린 다이어리 ㅎㅎ</a></p><hr><div class=pagination style=margin-top:2rem;display:flex;justify-content:center;align-items:center;gap:1rem><a href=/tags/2026-01/ style="padding:.5rem 1rem;text-decoration:none">←</a>
<span style=color:#666>2 / 2</span></div></article><footer class=book-footer><div class="flex flex-wrap justify-between"></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents></nav></div></aside></main></body></html>